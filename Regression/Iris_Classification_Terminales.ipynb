{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Iris Classification.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tMJtOdlg8qxE"
      },
      "source": [
        "# Classification des Iris\n",
        "\n",
        "Dans cet exemple, nous allons développer quelques modèles d'apprentissage automatique afin de classifier différentes espèces d'Iris, en particulier l'iris Setosa (iris de l'Alaska), Versicolor (ou clajeux) et Virginica (de Virginie).\n",
        "\n",
        "Nous allons résoudre ce problème pas-à-pas afin de bien comprendre les différentes étapes mises en oeuvre dans l'apprentissage automatique, ainsi que certaines notions mathématiques associées.\n",
        "\n",
        "La [base données des Iris](https://en.wikipedia.org/wiki/Iris_flower_data_set) fait partie du module Python [Sci-kit learn](https://scikit-learn.org/stable/).\n",
        "\n",
        "![Iris Versicolor](images/iris_versicolor.png \"Iris Versicolor\")\n",
        "\n",
        "La base de données contient 50 échantillons de chacune des espèces d'iris mentionnées précédemment. Quatre caractéristiques ont été mesurées sur chaque échantillon : la longueur et la largeur des pétales et des sépales (en centimètres). Ces caractéristiques peuvent être utilisées pour classifier ou prédire l'espèce de l'iris. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iFSzmzVs8qxF"
      },
      "source": [
        "from sklearn import datasets\n",
        "import matplotlib.pyplot as plt\n",
        "import math"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R_ym5ascgYR9"
      },
      "source": [
        "## Chargement des données"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P6y8QRu88qxI"
      },
      "source": [
        "iris = datasets.load_iris()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rr_zxf6x8qxJ"
      },
      "source": [
        "print(iris.DESCR)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tOHFyZc88qxM"
      },
      "source": [
        "iris.target_names"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-qfS1nEd8qxO"
      },
      "source": [
        "len(iris.data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jZn0FLlfArFH"
      },
      "source": [
        "iris.data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EYFImHIcBPca"
      },
      "source": [
        "iris.target"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y7GbVdO08qxQ"
      },
      "source": [
        "## Affichage des longueurs et largeurs des sépales"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A4qfBxtj8JiP"
      },
      "source": [
        "# Enregistrement dans la variable X des longueurs des sépales\n",
        "# et dans la variable Y des largeurs des sépales\n",
        "X = iris.data[:, 0]\n",
        "Y = iris.data[:, 1]\n",
        "\n",
        "# Les masques contenus dans le tableau iris.target vont être utlisés pour donner une couleur à chaque espèce d'iris\n",
        "Masque_Couleur = iris.target\n",
        "\n",
        "plt.scatter(X, Y, c=Masque_Couleur)\n",
        "plt.xlabel('Longueur des Sépales (cm)')\n",
        "plt.ylabel('Largeur des Sépales (cm)')\n",
        "plt.title('Distribution des dimensions des Sépales')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TorOLhJj-h8s"
      },
      "source": [
        "## Affichage des longueurs et largeurs des pétales"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O_pbl8keDNZ7"
      },
      "source": [
        "# Code à compléter"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Modèle de Regression Logistique (Regression Logistic model)"
      ],
      "metadata": {
        "id": "i5j_7ZWkrdnG"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ZBCYsK88qxS"
      },
      "source": [
        "\n",
        "Nous allons créer un modèle qui va prédire si un échantillon appartient à une des catégories des espèces d'iris ou non.\n",
        "\n",
        "La structure de ce modèle est la suivante :\n",
        "\n",
        "![Regression logistique](images/perceptron75.png \"Perceptron\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Function Sigmoïde (Sigmoide function)"
      ],
      "metadata": {
        "id": "NB4TFS5yrZZW"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5pkp1H48t-jZ"
      },
      "source": [
        "La [fonction Sigmoïde](https://fr.wikipedia.org/wiki/Sigmo%C3%AFde_(math%C3%A9matiques)) est utilisée en regression logistique et dans les neurones artificiels. C'est une manière de transformer des valeurs continues en valeurs binaires. Cette fonction est également appellée \"Fonction d'activation\" dans les réseaux de neurones. De nombreux types de fonctions d'activations sont utilisés aujourd'hui."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "So99N93VJ9Vy"
      },
      "source": [
        "def sigmoid(z):\n",
        "  return 1.0/(1 + math.exp(-z))\n",
        "\n",
        "x = [i * 0.1 for i in range(-50, 50)]\n",
        "y = [sigmoid(z) for z in x]\n",
        "plt.plot(x, y)\n",
        "plt.xlabel('x')\n",
        "plt.ylabel('y')\n",
        "plt.title('Fonction Sigmoïde')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Fonction de prédiction (Prediction Function)"
      ],
      "metadata": {
        "id": "OoWcFFYDrVhW"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4SPj_r-Zt-jb"
      },
      "source": [
        "Cette fonction prend un échantillon et multiplie les caractéristiques par les poids, ajoute l'offset et passe la valeur obtenue dans la fonction Sigmoïde.\n",
        "\n",
        "Cette fonction sera utilisée pour déterminer les poids et l'offset à utliser pendant la phase d'apprentissage, ainsi que pour faire les prédictions une fois l'entrainement du modèle terminé.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QaERzVGXIoTc"
      },
      "source": [
        "def predict(echantillon):\n",
        "  result  = 0.0\n",
        "  for i in range(len(echantillon)):\n",
        "    result = result + poids[i] * echantillon[i]\n",
        "    \n",
        "  result = result + offset\n",
        "  return sigmoid(result)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Fonctions de Perte et de Coût (Loss and Cost Functions)"
      ],
      "metadata": {
        "id": "-0fcGMJIrPir"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NNAtSCEPt-jd"
      },
      "source": [
        "La fonction de perte (Loss function en Anglais) compare la valeur prédite à partir d'un échantillon (la valeur prédite est calculée par la fonction de prédiction) avec la valeur attendue (la valeur qu'on devrait trouver si la fonction de prédiction fonctionnait correctement - ce qui n'est pas le cas au débit de l'apprentissage !).\n",
        "\n",
        "Si la valeur absolue de la différence entre ce qui est prédit et ce qui est attendu est grande, la fonction de perte doit retourner une grande valeur. Inversement, si la valeur absolue de la différence entre ce qui est prédit et ce qui est attendu est faible, la fonction de perte doit retourner une faible valeur.\n",
        "\n",
        "Pour synthétiser : Plus la fonction de prédiction est mauvaise, plus les pertes sont élevées :\n",
        "\n",
        "<img src=\"https://github.com/AlexandreBourrieau/ML/blob/main/Regression/images/chaudFroid.png?raw=true\" width=\"500\"/>\n",
        "\n",
        "La fonction de perte n'est pas juste la valeur absolue de la différence mais est plus élaborée, afin de rendre les calculs plus rapides et l'entrainement du modèle plus simple.\n",
        "\n",
        "$$\\mathcal L(y, \\hat y) = -(y \\ln \\hat y + (1-y) \\ln (1 - \\hat y))$$\n",
        "\n",
        "$\\;\\;\\;\\;\\;\\;\\;$ $\\mathcal L$ : Pertes  \n",
        "$\\;\\;\\;\\;\\;\\;\\;$ $y$ : Valeur attendue en sortie du modèle  \n",
        "$\\;\\;\\;\\;\\;\\;\\;$ $\\hat y$ : Valeur prédite obtenue par le modèle."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bhN98ZwJNcnL"
      },
      "source": [
        "def pertes(y_attendu, y_predit):\n",
        "  return -(y_attendu * math.log(y_predit) + (1.0 - y_attendu) * math.log(1 - y_predit))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ru0QNMpUt-jg"
      },
      "source": [
        "Nous pouvons regarder à quoi ressemble cette fonction pour une valeur attendue fixe (ici 0.9) en fonction des valeurs prédites (ici allant de 0.1 à 1).\n",
        "\n",
        "On observe bien que les pertes diminuent lorsque la valeur prédite se rapproche la valeur attendue :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "89HtEbUpt-jg"
      },
      "source": [
        "y_attendu = 0.9\n",
        "x = [i * 0.1 for i in range(1, 10)]\n",
        "y = [pertes(y_attendu, yp) for yp in x]\n",
        "plt.plot(x, y)\n",
        "plt.xlabel('Valeurs prédites')\n",
        "plt.ylabel('Pertes')\n",
        "plt.title('Pertes en fonction des valeurs prédites pour une valeur attendue de %0.2f' % y_attendu)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p9w9xQEkt-ji"
      },
      "source": [
        "La fonction de coût est la valeur moyenne des pertes pour tous les échantillons testés. Ainsi, par exemple si on a testé 10 échantillons avec les résultats suivants alors le coût sera de 0.3 :\n",
        "\n",
        "<img src=\"https://github.com/AlexandreBourrieau/ML/blob/main/Regression/images/Tableau.png?raw=true\" width=\"500\"/>\n",
        "\n",
        "Mathématiquement, pour un nombre m d'échantillons testés, le coût (noté J) peut être exprimé de la manière suivante :\n",
        "\n",
        "$$\\mathcal J = \\frac{1}{m} \\sum_{i=1}^{m} \\mathcal L(y, \\hat y)$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hSLUEK-pt-jj"
      },
      "source": [
        "## Algorithme du Gradient (Gradient Descent Algorithm)\n",
        "\n",
        "[L'algorithme du gradient](https://fr.wikipedia.org/wiki/Algorithme_du_gradient) a pour but d'ajuster les poids et l'offset du modèle afin de minimiser le coût, et donc d'obtenir le modèle le plus juste possible. L'algorithme du gradient calcule la dérivée (gradient), c'est-à-dire la pente, de la fonction de coût pour différentes valeurs de poids et d'offsets.\n",
        "\n",
        "Les équations générales sont les suivantes : \n",
        "\n",
        "$$w_{k+1} = w_{k} - \\alpha J'(w)$$\n",
        "$$b_{k+1} = b_{k} - \\alpha J'(b)$$\n",
        "\n",
        "Avec :  \n",
        "$\\;\\;\\;\\;\\;\\;\\;$ $w_{k}$ et $b_{k}$ les valeurs courantes des poids et de l'offset  \n",
        "$\\;\\;\\;\\;\\;\\;\\;$ $w_{k+}$ et $b_{k+1}$ les valeurs de la prochaine itération.  \n",
        "$\\;\\;\\;\\;\\;\\;\\;$ $J'(w)$ la dérivée de la fonction de coût par rapport aux poids  \n",
        "$\\;\\;\\;\\;\\;\\;\\;$ $J'(b)$ la dérivée de la fonction de coût par rapport à l'offset\n",
        "\n",
        "\n",
        "Le nombre $\\alpha$ est le taux d'apprentissage qui permet de paramétrer la manière dont va s'exécuter l'algorithme. Si le taux d'apprentissage est trop petit, le modèle va mettre beaucoup de temps à s'entrainer. Si ce taux est trop grand, le modèle risque de ne jamais trouver de solution.\n",
        "\n",
        "Considérons un exemple simple :\n",
        "\n",
        "$$J(w) = w^2 + \\frac{w}{2}$$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9-bXBig8t-jk"
      },
      "source": [
        "def cout(w):\n",
        "    return w**2 + w/2.0\n",
        "\n",
        "w = [i * 0.1 for i in range(-10, 11)]\n",
        "J = [cout(wi) for wi in w]\n",
        "plt.plot(w, J)\n",
        "plt.xlabel('poids w')\n",
        "plt.ylabel('Coût J')\n",
        "plt.title('Fonction Coût (J)')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZaQJuoXzt-jl"
      },
      "source": [
        "La dérivée de cette fonction par rapport au poids $w$ est :\n",
        "\n",
        "$$J'(w) = 2w + 0.5$$\n",
        "\n",
        "Pour trouver le minimum avec l'algorithme du gradient, nous devons itérer cette équation :\n",
        "\n",
        "$$w_{k+1} = w_{k} - \\alpha J'(w)$$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MDK0JIfst-jm"
      },
      "source": [
        "w_k = 0.0\n",
        "\n",
        "taux_apprentissage = 0.8\n",
        "\n",
        "def derive(w):\n",
        "  return 2*w + 0.5\n",
        "\n",
        "for i in range(15):\n",
        "    gradient = derive(w_k)\n",
        "    w_k = w_k - taux_apprentissage*gradient\n",
        "\n",
        "print('Minimum %0.2f, %0.2f' % (w_k, cout(w_k)))\n",
        "print('Derivée (gradient) %0.2f' % gradient)\n",
        "\n",
        "w = [i * 0.1 for i in range(-10, 11)]\n",
        "J = [cout(wi) for wi in w]\n",
        "plt.plot(w, J)\n",
        "plt.xlabel('poids w')\n",
        "plt.ylabel('coût J')\n",
        "plt.plot(w_k, cout(w_k), 'ro')\n",
        "line_x = [w_k - 0.5, w_k + 0.5]\n",
        "line_y = [gradient*(wi-w_k)+cout(w_k) for wi in line_x]\n",
        "plt.plot(line_x, line_y)\n",
        "plt.title('Fonction parabolique')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Création du réseau de neurone avec Keras / Tensorflow"
      ],
      "metadata": {
        "id": "6o2rBuz2RSn8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nous allons utiliser la librarie Python [Keras](https://keras.io/) pour mettre en oeuvre notre modèle de classification."
      ],
      "metadata": {
        "id": "g7z_sXqCTxOP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "On commence par importer les librairies python :"
      ],
      "metadata": {
        "id": "nd1fsE30SICU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Flatten\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "ZQS7a-GiRam0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "On construit ensuite notre modèle à une couche :"
      ],
      "metadata": {
        "id": "6BuVKjaXSqb4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![Regression logistique](images/perceptron75.png \"Perceptron\")"
      ],
      "metadata": {
        "id": "tbQLUUk_S2xG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Notre modèle utilise une [couche dense](https://keras.io/api/layers/core_layers/dense/) avec une fonction d'activation de type Sigmoïde :"
      ],
      "metadata": {
        "id": "Z6oSHNIaThXH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(1,activation=\"sigmoid\",input_shape=(4,)))\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "v7SBiS8USmUO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Création des données d'entrainement et de test"
      ],
      "metadata": {
        "id": "D__MaX6gUF6I"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A partir de l'ensemble des données disponibles dans les variables `iris.data` (données d'entrées X) et `iris.target` (données des labels Y), on construit deux ensembles :\n",
        "- (X_train, y_train) : Ce sont les données dédiées à la phase d'entrainement. X_train sont les données d'entrées et y_train sont les labels en sortie.\n",
        "- (X_test, y_test) : Ce sont les données dédiées à la phase de test. Elles ne sont pas utilisées pour réaliser l'entrainement du modèle, mais uniquement pour tester le modèle."
      ],
      "metadata": {
        "id": "WAEihVBmUhlY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "La méthode [train_test_split](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html) permet de créer automatiquent ces deux ensembles, en spécifiant le poucentage de données que l'on souhaite utiliser pour l'entrainement et le test. Ici on choisit d'utiliser 20% des données pour les tests."
      ],
      "metadata": {
        "id": "NMlbCTc0VXQR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(iris.data, iris.target, test_size=0.2)"
      ],
      "metadata": {
        "id": "Pw05MfkZUPgg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape"
      ],
      "metadata": {
        "id": "FWIP_DIsVvMr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_test.shape"
      ],
      "metadata": {
        "id": "acFIXA5hV3GC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dans les données d'entrainement et de test qui contiennent les labels (y_train & y_test), on retrouve les valeurs permettant d'identifier les classes de chaque type d'Iris (les trois classes 0, 1 et 2) :"
      ],
      "metadata": {
        "id": "qTTwWuuSoc0E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_train"
      ],
      "metadata": {
        "id": "s_y7MPi-YTU2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Création des labels dédiés à l'identification d'une classe"
      ],
      "metadata": {
        "id": "TrjU5I8sozFq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A partir des labels contenus dans les variables y_train & y_test, on va maintenant créer les labels permettant d'identifier uniquement la classe 0. Les variables suivantes vont donc permettre d'identifier si les données d'entrées X correspondent à une classe 0 ou non :"
      ],
      "metadata": {
        "id": "I4svEZ5Eo4wa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "classe_a_identifier = 1\n",
        "\n",
        "train_labels = np.asarray([1 if y == classe_a_identifier else 0 for y in y_train])\n",
        "test_labels = np.asarray([1 if y == classe_a_identifier else 0 for y in y_test])"
      ],
      "metadata": {
        "id": "knQyzqWgXwEV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.asarray(train_labels)"
      ],
      "metadata": {
        "id": "1gqd8bSYYA9V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Compilation du modèle"
      ],
      "metadata": {
        "id": "ipr1KxCZWCmj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Avant de pouvoir entrainer notre modèle, nous devons le compiler en précisant les paramètres à utiliser pour :\n",
        "- L'optimiseur à utiliser (ici on utilisera l'optmiseur Adam)\n",
        "- Le taux d'apprentissage à utiliser (learning_rate)\n",
        "- La fonction de perte à utiliser\n",
        "- Et éventuellement la métrique à utiliser"
      ],
      "metadata": {
        "id": "jEGnOQZnpYZT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer=Adam(learning_rate=0.001),\n",
        "              loss=\"binary_crossentropy\",\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "1LoMxtmHWMzK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Entrainement du modèle"
      ],
      "metadata": {
        "id": "oIWbxuFUW9ot"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "historique = model.fit(X_train, train_labels, epochs=100, batch_size=1, verbose=1, validation_data=(X_test,test_labels))"
      ],
      "metadata": {
        "id": "NqBvDtqnXCMw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Affiche quelques informations sur l'entrainement du modèle :"
      ],
      "metadata": {
        "id": "cw0phZ5QsO-0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Evalue la précision du modèle avec les données de tests\n",
        "score = model.evaluate(X_test, test_labels, verbose=0)\n",
        "print('Pertes (Test) :', score[0])\n",
        "print('Précision (Test) :', score[1])\n",
        "\n",
        "# Affiche les informations\n",
        "plt.plot(historique.history['accuracy'])\n",
        "plt.plot(historique.history['val_accuracy'])\n",
        "plt.title('Précision du modèle')\n",
        "plt.ylabel('Précision')\n",
        "plt.xlabel('Itérations')\n",
        "plt.legend(['Entrainement', 'Test'], loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Jvn-9Fxrrzpa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Prédictions"
      ],
      "metadata": {
        "id": "qkN6H6nssUwK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pour réaliser des prédictions, on utliise la méthode `predict` de la classe `Model` :"
      ],
      "metadata": {
        "id": "qY4H2I8EsXdw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.predict(X_train)"
      ],
      "metadata": {
        "id": "8bmVwPrfq9Dv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0YzlLmmumyD9"
      },
      "source": [
        "predictions = []\n",
        "\n",
        "echantillons_a_tester = X_test\n",
        "valeurs_attendues_des_echantillons = test_labels\n",
        "\n",
        "m = len(echantillons_a_tester)\n",
        "correct = 0\n",
        "for i in range(m):\n",
        "  ech = echantillons_a_tester[i]\n",
        "  valeur_predite = model.predict(tf.expand_dims(ech,0))\n",
        "  if valeur_predite >= 0.5:\n",
        "    valeur_predite = 1\n",
        "  else:\n",
        "    valeur_predite = 0\n",
        "  predictions.append(valeur_predite)\n",
        "  if valeur_predite == valeurs_attendues_des_echantillons[i]:\n",
        "    correct = correct + 1.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions"
      ],
      "metadata": {
        "id": "kxLQs76Utw6a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lH4RMMVGt-jy"
      },
      "source": [
        "plt.plot(range(m), predictions, label='Prévisions')\n",
        "plt.plot(range(m), valeurs_attendues_des_echantillons, label='Vraies valeurs')\n",
        "plt.ylabel('Prévisions')\n",
        "plt.xlabel('Echantillon')\n",
        "plt.legend(loc='best')\n",
        "plt.show()\n",
        "\n",
        "print('Précision: %.2f %%' % (100 * correct/m))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Amélioration du réseau - Réseau de neurones profond"
      ],
      "metadata": {
        "id": "xP8u84q1wNbt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Flatten\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "fEu44rHFwVoQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "On construit ensuite notre modèle à une couche :"
      ],
      "metadata": {
        "id": "DSXHHPtfwVoQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![Regression logistique](images/perceptron75.png \"Perceptron\")"
      ],
      "metadata": {
        "id": "tb3ZMOv-wVoR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Notre modèle utilise une [couche dense](https://keras.io/api/layers/core_layers/dense/) avec une fonction d'activation de type Sigmoïde :"
      ],
      "metadata": {
        "id": "bAbMWiISwVoR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(4,input_shape=(4,)))\n",
        "model.add(Dense(64,activation=\"sigmoid\"))\n",
        "model.add(Dense(32))\n",
        "model.add(Dense(8))\n",
        "model.add(Dense(1,activation=\"sigmoid\"))\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "l1fNnB-owVoR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classe_a_identifier = 1\n",
        "\n",
        "train_labels = np.asarray([1 if y == classe_a_identifier else 0 for y in y_train])\n",
        "test_labels = np.asarray([1 if y == classe_a_identifier else 0 for y in y_test])"
      ],
      "metadata": {
        "id": "26Bi5gULw9O1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer=Adam(learning_rate=0.001),\n",
        "              loss=\"binary_crossentropy\",\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "1VauqU2UxCjO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "historique = model.fit(X_train, train_labels, epochs=100, batch_size=1, verbose=1, validation_data=(X_test,test_labels))"
      ],
      "metadata": {
        "id": "ppQn_gMIxHIC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evalue la précision du modèle avec les données de tests\n",
        "score = model.evaluate(X_test, test_labels, verbose=0)\n",
        "print('Pertes (Test) :', score[0])\n",
        "print('Précision (Test) :', score[1])\n",
        "\n",
        "# Affiche les informations\n",
        "plt.plot(historique.history['accuracy'])\n",
        "plt.plot(historique.history['val_accuracy'])\n",
        "plt.title('Précision du modèle')\n",
        "plt.ylabel('Précision')\n",
        "plt.xlabel('Itérations')\n",
        "plt.legend(['Entrainement', 'Test'], loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "31mXQ0oAxSLn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = []\n",
        "\n",
        "echantillons_a_tester = X_test\n",
        "valeurs_attendues_des_echantillons = test_labels\n",
        "\n",
        "m = len(echantillons_a_tester)\n",
        "correct = 0\n",
        "for i in range(m):\n",
        "  ech = echantillons_a_tester[i]\n",
        "  valeur_predite = model.predict(tf.expand_dims(ech,0))\n",
        "  if valeur_predite >= 0.5:\n",
        "    valeur_predite = 1\n",
        "  else:\n",
        "    valeur_predite = 0\n",
        "  predictions.append(valeur_predite)\n",
        "  if valeur_predite == valeurs_attendues_des_echantillons[i]:\n",
        "    correct = correct + 1.0"
      ],
      "metadata": {
        "id": "8XWlPhAExuMX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(range(m), predictions, label='Prévisions')\n",
        "plt.plot(range(m), valeurs_attendues_des_echantillons, label='Vraies valeurs')\n",
        "plt.ylabel('Prévisions')\n",
        "plt.xlabel('Echantillon')\n",
        "plt.legend(loc='best')\n",
        "plt.show()\n",
        "\n",
        "print('Précision: %.2f %%' % (100 * correct/m))"
      ],
      "metadata": {
        "id": "eDupUr4txo1w"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}