{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "colab": {
      "name": "GloVe Sentiment.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ygBHZ2O-MFK1"
      },
      "source": [
        "# Analyse des ressentis avec GloVe Vectors\n",
        "\n",
        "L'analyse des ressentis a pour objectif de classifier les opinions exprimées sous forme de texte dans un langage naturel. Différentes méthodes peuvent être utlisées pour réaliser cette analyse. Dans cet exemple, des commentaires recueillis surle site [allociné](http://www.allocine.fr/) vont être utlisés pour entrainer un modèle de classification supervisé. Le modèle utilise un réseau de neurones à convolution 1D.\n",
        "\n",
        "Les mots contenus dans les phrases doivent être encodés dans des vecteurs qui seront utilisés pour l'entrainement et les tests. Une manière simple serait d'assigner à chaque mot une valeur numérique. Le problème de cette méthode est que le contexte dans lequel les mots sont utilisés n'est pas pris en compte. Une méthode permettant de combler ce manque est d'utiliser un algorithme de prolongation lexicale (Word embedding). Parmi ce genre d'algorithme, on trouve [GloVe (Global Vectors for Word Representation)](https://nlp.stanford.edu/projects/glove/) qui se base sur les probabilités de co-occurence de mots. Une base de données pré-entrainée (mais en Anglais) est déjà disponnible sur leur site web.  \n",
        "\n",
        "Une base de donnée pré-entrainée en Français peut-être néanmoins téléchargée à cette [adresse](http://www.cs.cmu.edu/~afm/projects/multilingual_embeddings.html). C'est celle-ci que nous utiliserons."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CVAIpfO0MFK7"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "import json\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Flatten\n",
        "from tensorflow.keras.layers import Conv1D, GlobalMaxPooling1D, Embedding\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WN_eQNboMFLA"
      },
      "source": [
        "# Chargement des données d'entrainement\n",
        "\n",
        "Les données d'entrainement sont chargées dans une dataframe Panda depuis des fichiers textes. Ces données contiennent deux colonnes : Un commentaire et une valeur binaire définissant un sentiment négatif ou positif sur ce commentaire. \n",
        "\n",
        "Ces données sont disponnibles sur le github de [TheophileBlard](https://github.com/TheophileBlard/french-sentiment-analysis-with-bert/tree/master/allocine_dataset). Ces données sont issues de commentaires récupérés sur Allociné. Les utilisateurs votent avec des notes allant de 0.5 à 5.0 :    \n",
        "<img src=\"https://github.com/AlexandreBourrieau/ML-F1/blob/master/Carnets%20Jupyter/Images/rating_counts.png?raw=1\" width=\"600\"/>\n",
        "\n",
        "Afin de récupérer une note binaire (négative ou positive) à partir de cet intervalle de valeurs, les votes <= 2 sont classé comme négatifs et ceux >=4 sont classés comme positifs. Les autres sont classés comme neutres :    \n",
        "<img src=\"https://github.com/AlexandreBourrieau/ML-F1/blob/master/Carnets%20Jupyter/Images/polarity_frequency.png?raw=1\" width=\"600\"/>  \n",
        "  \n",
        "\n",
        "Enfin, pour construire les données, 100 000 avis négatifs et 100 000 avis positifs sont extraits aléatoirement, puis décomposés en deux catégories : Les données d'entrainement (80%), les données de test (10%) et les données de validation (10%) :  \n",
        "<img src=\"https://github.com/AlexandreBourrieau/ML-F1/blob/master/Carnets%20Jupyter/Images/splits_polarity.png?raw=1\" width=\"600\"/>  \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WFyrqXX4M5ek",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "830f9f52-0024-4ffd-b213-5adf93e72744"
      },
      "source": [
        "# Téléchargement des données depuis le repot github \"https://github.com/AlexandreBourrieau/ML/raw/master/Carnets%20Jupyter/Donn%C3%A9es/data.tar.bz2\"\n",
        "\n",
        "!mkdir data\n",
        "!wget get --no-check-certificate --content-disposition \"https://github.com/AlexandreBourrieau/ML/blob/main/Carnets%20Jupyter/Donn%C3%A9es/data.tar.bz2?raw=true\"\n",
        "!tar -xjvf data.tar.bz2 data\n",
        "!ls -l data"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-02-13 16:17:23--  http://get/\n",
            "Resolving get (get)... failed: Name or service not known.\n",
            "wget: unable to resolve host address ‘get’\n",
            "--2021-02-13 16:17:23--  https://github.com/AlexandreBourrieau/ML/blob/main/Carnets%20Jupyter/Donn%C3%A9es/data.tar.bz2?raw=true\n",
            "Resolving github.com (github.com)... 140.82.113.4\n",
            "Connecting to github.com (github.com)|140.82.113.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://github.com/AlexandreBourrieau/ML/raw/main/Carnets%20Jupyter/Donn%C3%A9es/data.tar.bz2 [following]\n",
            "--2021-02-13 16:17:24--  https://github.com/AlexandreBourrieau/ML/raw/main/Carnets%20Jupyter/Donn%C3%A9es/data.tar.bz2\n",
            "Reusing existing connection to github.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/AlexandreBourrieau/ML/main/Carnets%20Jupyter/Donn%C3%A9es/data.tar.bz2 [following]\n",
            "--2021-02-13 16:17:24--  https://raw.githubusercontent.com/AlexandreBourrieau/ML/main/Carnets%20Jupyter/Donn%C3%A9es/data.tar.bz2\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.109.133, 185.199.111.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 66625305 (64M) [application/octet-stream]\n",
            "Saving to: ‘data.tar.bz2’\n",
            "\n",
            "data.tar.bz2        100%[===================>]  63.54M   261MB/s    in 0.2s    \n",
            "\n",
            "2021-02-13 16:17:24 (261 MB/s) - ‘data.tar.bz2’ saved [66625305/66625305]\n",
            "\n",
            "FINISHED --2021-02-13 16:17:24--\n",
            "Total wall clock time: 0.5s\n",
            "Downloaded: 1 files, 64M in 0.2s (261 MB/s)\n",
            "data/\n",
            "data/allocine_dataset.pickle\n",
            "data/test.jsonl\n",
            "data/train.jsonl\n",
            "data/val.jsonl\n",
            "total 247576\n",
            "-rw-r--r-- 1 1000 1000 119034075 Feb  6  2020 allocine_dataset.pickle\n",
            "-rw-r--r-- 1 1000 1000  13554101 Feb  6  2020 test.jsonl\n",
            "-rw-r--r-- 1 1000 1000 107365432 Feb  6  2020 train.jsonl\n",
            "-rw-r--r-- 1 1000 1000  13550874 Feb  6  2020 val.jsonl\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8q7HjyyeMT3A"
      },
      "source": [
        "!cat /content/data/test.jsonl"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "je5Lkv_aMFLA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        },
        "outputId": "549c4191-1982-4152-a092-cf35ef7f9e08"
      },
      "source": [
        "DataEntrainement = pd.read_json(\"/content/data/train.jsonl\", lines=True)\n",
        "DataEntrainement.head(10)"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>film-url</th>\n",
              "      <th>review</th>\n",
              "      <th>polarity</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>http://www.allocine.fr/film/fichefilm-135259/c...</td>\n",
              "      <td>Si vous cherchez du cinéma abrutissant à tous ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>http://www.allocine.fr/film/fichefilm-172430/c...</td>\n",
              "      <td>Trash, re-trash et re-re-trash...! Une horreur...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>http://www.allocine.fr/film/fichefilm-15105/cr...</td>\n",
              "      <td>Et si, dans les 5 premières minutes du film, l...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>http://www.allocine.fr/film/fichefilm-188629/c...</td>\n",
              "      <td>Mon dieu ! Quelle métaphore filée ! Je suis ab...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>http://www.allocine.fr/film/fichefilm-23514/cr...</td>\n",
              "      <td>Premier film de la saga Kozure Okami, \"Le Sabr...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>http://www.allocine.fr/film/fichefilm-184629/c...</td>\n",
              "      <td>L'amnésie est un thème en or pour susciter le ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>http://www.allocine.fr/film/fichefilm-142560/c...</td>\n",
              "      <td>Tout commence comme une comédie légère avant u...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>http://www.allocine.fr/film/fichefilm-51123/cr...</td>\n",
              "      <td>un excellent film qui merite ses quatre étoile...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>http://www.allocine.fr/film/fichefilm-231/crit...</td>\n",
              "      <td>Deuxième long métrage de Pasolini, Mamma Roma ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>http://www.allocine.fr/film/fichefilm-192291/c...</td>\n",
              "      <td>Créateur de la célèbre série télévisée Kaamelo...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            film-url  ... polarity\n",
              "0  http://www.allocine.fr/film/fichefilm-135259/c...  ...        0\n",
              "1  http://www.allocine.fr/film/fichefilm-172430/c...  ...        0\n",
              "2  http://www.allocine.fr/film/fichefilm-15105/cr...  ...        0\n",
              "3  http://www.allocine.fr/film/fichefilm-188629/c...  ...        0\n",
              "4  http://www.allocine.fr/film/fichefilm-23514/cr...  ...        1\n",
              "5  http://www.allocine.fr/film/fichefilm-184629/c...  ...        0\n",
              "6  http://www.allocine.fr/film/fichefilm-142560/c...  ...        1\n",
              "7  http://www.allocine.fr/film/fichefilm-51123/cr...  ...        1\n",
              "8  http://www.allocine.fr/film/fichefilm-231/crit...  ...        1\n",
              "9  http://www.allocine.fr/film/fichefilm-192291/c...  ...        0\n",
              "\n",
              "[10 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iq6cMhkEMFLG"
      },
      "source": [
        "# Chargement des vecteurs GloVe et préparation des données\n",
        "\n",
        "**Commençons par charger les vecteurs GloVe**  \n",
        "\n",
        "Les fichiers des vecteurs GloVe sont téléchargés à partir du site de [GloVe](https://nlp.stanford.edu/projects/glove/) mais ils sont en Anglais. Nous allons utiliser une [version française](http://www.cs.cmu.edu/~afm/projects/multilingual_embeddings.html) équivalente.  \n",
        "  \n",
        "Le fichier que nous utilisons contient plus de 40000 vecteurs de dimension 300. Cela signifie que pour chaque mot contenu dans ce fichier, un vecteur de 300 valeurs permet de définir les relations lexicales de ce mots avec les autres mots du fichier.  \n",
        "\n",
        "<img src=\"https://github.com/AlexandreBourrieau/ML-F1/blob/master/Carnets%20Jupyter/Images/EmbeddedVectors.png?raw=1\"/>  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZGcwMGR-R3tR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a260dece-2bdd-4b4a-ffd0-ec1ea2f57bca"
      },
      "source": [
        "# Téléchargement des vecteurs\n",
        "!wget get --no-check-certificate --content-disposition \"https://github.com/AlexandreBourrieau/ML/blob/main/Carnets%20Jupyter/Donn%C3%A9es/multilingual_embeddings.rar?raw=true\"\n",
        "!mv multilingual_embeddings.rar /content/data/multilingual_embeddings.rar\n",
        "!unrar x /content/data/multilingual_embeddings.rar /content/data"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-02-13 16:39:13--  http://get/\n",
            "Resolving get (get)... failed: Name or service not known.\n",
            "wget: unable to resolve host address ‘get’\n",
            "--2021-02-13 16:39:13--  https://github.com/AlexandreBourrieau/ML/blob/main/Carnets%20Jupyter/Donn%C3%A9es/multilingual_embeddings.rar?raw=true\n",
            "Resolving github.com (github.com)... 140.82.114.3\n",
            "Connecting to github.com (github.com)|140.82.114.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://github.com/AlexandreBourrieau/ML/raw/main/Carnets%20Jupyter/Donn%C3%A9es/multilingual_embeddings.rar [following]\n",
            "--2021-02-13 16:39:13--  https://github.com/AlexandreBourrieau/ML/raw/main/Carnets%20Jupyter/Donn%C3%A9es/multilingual_embeddings.rar\n",
            "Reusing existing connection to github.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/AlexandreBourrieau/ML/main/Carnets%20Jupyter/Donn%C3%A9es/multilingual_embeddings.rar [following]\n",
            "--2021-02-13 16:39:13--  https://raw.githubusercontent.com/AlexandreBourrieau/ML/main/Carnets%20Jupyter/Donn%C3%A9es/multilingual_embeddings.rar\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 80894821 (77M) [application/octet-stream]\n",
            "Saving to: ‘multilingual_embeddings.rar’\n",
            "\n",
            "multilingual_embedd 100%[===================>]  77.15M   275MB/s    in 0.3s    \n",
            "\n",
            "2021-02-13 16:39:13 (275 MB/s) - ‘multilingual_embeddings.rar’ saved [80894821/80894821]\n",
            "\n",
            "FINISHED --2021-02-13 16:39:13--\n",
            "Total wall clock time: 0.4s\n",
            "Downloaded: 1 files, 77M in 0.3s (275 MB/s)\n",
            "\n",
            "UNRAR 5.50 freeware      Copyright (c) 1993-2017 Alexander Roshal\n",
            "\n",
            "\n",
            "Extracting from /content/data/multilingual_embeddings.rar\n",
            "\n",
            "Extracting  /content/data/multilingual_embeddings.fr                     \b\b\b\b  5%\b\b\b\b 10%\b\b\b\b 15%\b\b\b\b 20%\b\b\b\b 25%\b\b\b\b 31%\b\b\b\b 36%\b\b\b\b 41%\b\b\b\b 46%\b\b\b\b 51%\b\b\b\b 57%\b\b\b\b 62%\b\b\b\b 67%\b\b\b\b 72%\b\b\b\b 77%\b\b\b\b 82%\b\b\b\b 88%\b\b\b\b 93%\b\b\b\b 98%\b\b\b\b 99%\b\b\b\b\b  OK \n",
            "All OK\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PNI60PfJkhp8"
      },
      "source": [
        "**Encodage des commentaires**  \n",
        "Pour utiliser notre réseau de neurones, nous devons encoder le texte des commentaires. L'encodage suit le principe suivant :  \n",
        "* Chaque mot contenu dans l'ensemble des commentaires va se voir attribuer une valeur entière unique\n",
        "* Chaque commentaire va ensuite être transformé en un vecteur de nombre entiers, dont les nombres correspondent aux valeurs entières attribuées aux mots précédemment  \n",
        "* Les commentaires sont ensuite redimensionnés afin d'avoir tous la même dimension (avec bourrage de 0)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MobDmxmfzg69",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "20d2d072-42cd-40cb-87d2-e36fe08af4e3"
      },
      "source": [
        "print(DataEntrainement['review'][0])\n",
        "print(DataEntrainement['review'][1])"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Magnifique épopée, une belle histoire, touchante avec des acteurs qui interprètent très bien leur rôles (Mel Gibson, Heath Ledger, Jason Isaacs...), le genre de film qui se savoure en famille! :)\n",
            "Je n'ai pas aimé mais pourtant je lui mets 2 étoiles car l'expérience est louable. Rien de conventionnel ici. Une visite E.T. mais jonchée d'idées /- originales. Le soucis, tout ceci avait-il vraiment sa place dans un film de S.F. tirant sur l'horreur ? Voici un film qui, à l'inverse de tant d'autres qui y ont droit, mériterait peut-être un remake.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aGcJIZiQk8t5"
      },
      "source": [
        "Voici un exemple d'encodage de texte :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UapGqFb6lAx5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5a1ddc61-b69b-404f-9222-a56cae8a04f3"
      },
      "source": [
        "com = ['un plus un egal deux','deux plus deux cela fait quatre']\n",
        "tokenizer_ex = Tokenizer(num_words=10)\n",
        "tokenizer_ex.fit_on_texts(com)\n",
        "seq = tokenizer_ex.texts_to_sequences(com)\n",
        "bourrage = pad_sequences(seq,maxlen=10)\n",
        "\n",
        "print(com)\n",
        "print(tokenizer_ex.word_index)\n",
        "print(seq)\n",
        "print(bourrage)"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['un plus un egal deux', 'deux plus deux cela fait quatre']\n",
            "{'deux': 1, 'un': 2, 'plus': 3, 'egal': 4, 'cela': 5, 'fait': 6, 'quatre': 7}\n",
            "[[2, 3, 2, 4, 1], [1, 3, 1, 5, 6, 7]]\n",
            "[[0 0 0 0 0 2 3 2 4 1]\n",
            " [0 0 0 0 1 3 1 5 6 7]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DvcLUToHlN2N"
      },
      "source": [
        "Le code suivant réalise ces opérations avec les données d'entrainements de notre projet :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vqI5FJ8OlRWN"
      },
      "source": [
        "MAX_NB_MOTS = 1000000\n",
        "MAX_SEQUENCE_LENGTH = 1000\n",
        "\n",
        "# Chargement des commentaires et des ressentis\n",
        "commentaires = DataEntrainement['review'].astype(str).tolist()      # Récupère tous les commentaires dans une liste python\n",
        "ressentis = DataEntrainement['polarity'].tolist()                   # Récupère tous les ressentis dans une liste python\n",
        "labels = np.asarray(ressentis)                                      # Créé un tableau de type numpy avec les ressentis\n",
        "\n",
        "# Encodage des commentaires\n",
        "tokenizer = Tokenizer(num_words=MAX_NB_MOTS)                              # Initialise la fonction Tokenizer de Keras\n",
        "tokenizer.fit_on_texts(commentaires)                                      # Création des index des mots\n",
        "sequences = tokenizer.texts_to_sequences(commentaires)                    # Transformation des phrases en séquences d'index de mots \n",
        "padded_sequences = pad_sequences(sequences, maxlen=MAX_SEQUENCE_LENGTH)   # Bourrage des vecteurs"
      ],
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JCHB2BuP2vH7"
      },
      "source": [
        "padded_sequences[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x1ycKyMN296u",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6e0aa8c7-bc94-4e39-de0f-e010cd533ac0"
      },
      "source": [
        "tokenizer.index_word"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{1: 'de',\n",
              " 2: 'et',\n",
              " 3: 'le',\n",
              " 4: 'la',\n",
              " 5: 'un',\n",
              " 6: 'à',\n",
              " 7: 'film',\n",
              " 8: 'les',\n",
              " 9: 'est',\n",
              " 10: 'qui',\n",
              " 11: 'en',\n",
              " 12: 'une',\n",
              " 13: 'des',\n",
              " 14: 'pas',\n",
              " 15: 'que',\n",
              " 16: 'du',\n",
              " 17: 'ce',\n",
              " 18: 'dans',\n",
              " 19: 'pour',\n",
              " 20: 'mais',\n",
              " 21: 'a',\n",
              " 22: 'on',\n",
              " 23: 'ne',\n",
              " 24: 'il',\n",
              " 25: 'plus',\n",
              " 26: 'avec',\n",
              " 27: 'au',\n",
              " 28: 'très',\n",
              " 29: 'se',\n",
              " 30: \"c'est\",\n",
              " 31: 'par',\n",
              " 32: 'tout',\n",
              " 33: 'bien',\n",
              " 34: 'je',\n",
              " 35: 'son',\n",
              " 36: 'sur',\n",
              " 37: 'sont',\n",
              " 38: 'même',\n",
              " 39: 'fait',\n",
              " 40: 'sans',\n",
              " 41: 'comme',\n",
              " 42: 'nous',\n",
              " 43: 'peu',\n",
              " 44: 'si',\n",
              " 45: 'sa',\n",
              " 46: 'cette',\n",
              " 47: 'ou',\n",
              " 48: 'bon',\n",
              " 49: 'voir',\n",
              " 50: 'aussi',\n",
              " 51: 'ça',\n",
              " 52: 'scénario',\n",
              " 53: \"d'un\",\n",
              " 54: 'acteurs',\n",
              " 55: 'ses',\n",
              " 56: 'vraiment',\n",
              " 57: 'faire',\n",
              " 58: 'y',\n",
              " 59: \"d'une\",\n",
              " 60: 'scène',\n",
              " 61: \"n'est\",\n",
              " 62: 'rien',\n",
              " 63: 'peut',\n",
              " 64: 'être',\n",
              " 65: \"j'ai\",\n",
              " 66: 'trop',\n",
              " 67: 'vous',\n",
              " 68: 'aux',\n",
              " 69: \"qu'il\",\n",
              " 70: 'personnages',\n",
              " 71: 'grand',\n",
              " 72: 'deux',\n",
              " 73: 'films',\n",
              " 74: 'fin',\n",
              " 75: 'mal',\n",
              " 76: 'cinéma',\n",
              " 77: 'histoire',\n",
              " 78: 'où',\n",
              " 79: 'tous',\n",
              " 80: 'encore',\n",
              " 81: 'fois',\n",
              " 82: \"l'histoire\",\n",
              " 83: 'scènes',\n",
              " 84: 'entre',\n",
              " 85: 'lui',\n",
              " 86: 'car',\n",
              " 87: 'assez',\n",
              " 88: 'beaucoup',\n",
              " 89: 'elle',\n",
              " 90: 'reste',\n",
              " 91: 'vu',\n",
              " 92: 'là',\n",
              " 93: 'mise',\n",
              " 94: 'quand',\n",
              " 95: 'ces',\n",
              " 96: 'leur',\n",
              " 97: 'moins',\n",
              " 98: 'quelques',\n",
              " 99: 'vie',\n",
              " 100: 'toujours',\n",
              " 101: 'temps',\n",
              " 102: 'cela',\n",
              " 103: 'surtout',\n",
              " 104: 'dire',\n",
              " 105: 'donc',\n",
              " 106: 'réalisateur',\n",
              " 107: 'jamais',\n",
              " 108: 'me',\n",
              " 109: 'genre',\n",
              " 110: 'dont',\n",
              " 111: 'rôle',\n",
              " 112: 'comédie',\n",
              " 113: 'non',\n",
              " 114: 'alors',\n",
              " 115: 'après',\n",
              " 116: 'long',\n",
              " 117: 'été',\n",
              " 118: 'premier',\n",
              " 119: 'personnage',\n",
              " 120: 'va',\n",
              " 121: 'petit',\n",
              " 122: 'ici',\n",
              " 123: 'bonne',\n",
              " 124: 'moment',\n",
              " 125: 'belle',\n",
              " 126: 'chose',\n",
              " 127: 'bref',\n",
              " 128: 'suis',\n",
              " 129: 'monde',\n",
              " 130: 'mauvais',\n",
              " 131: 'plutôt',\n",
              " 132: 'faut',\n",
              " 133: 'ont',\n",
              " 134: 'juste',\n",
              " 135: \"qu'on\",\n",
              " 136: \"l'on\",\n",
              " 137: '«',\n",
              " 138: '»',\n",
              " 139: 'c’est',\n",
              " 140: 'part',\n",
              " 141: 'réalisation',\n",
              " 142: 'beau',\n",
              " 143: 'dialogues',\n",
              " 144: 'ils',\n",
              " 145: 'soit',\n",
              " 146: 'toute',\n",
              " 147: 'malgré',\n",
              " 148: \"n'a\",\n",
              " 149: 'musique',\n",
              " 150: 'déjà',\n",
              " 151: 'jeu',\n",
              " 152: 'ni',\n",
              " 153: 'pourtant',\n",
              " 154: 'début',\n",
              " 155: 'sous',\n",
              " 156: 'celui',\n",
              " 157: 'moi',\n",
              " 158: 'mieux',\n",
              " 159: 'autres',\n",
              " 160: 'tant',\n",
              " 161: 'passe',\n",
              " 162: 'années',\n",
              " 163: 'jeune',\n",
              " 164: 'aurait',\n",
              " 165: 'excellent',\n",
              " 166: 'était',\n",
              " 167: 'final',\n",
              " 168: 'ans',\n",
              " 169: 'seul',\n",
              " 170: 'avant',\n",
              " 171: 'suite',\n",
              " 172: 'aucun',\n",
              " 173: 'grande',\n",
              " 174: 'point',\n",
              " 175: 'femme',\n",
              " 176: 'chef',\n",
              " 177: 'avoir',\n",
              " 178: 'casting',\n",
              " 179: 'sujet',\n",
              " 180: 'drôle',\n",
              " 181: 'parfois',\n",
              " 182: 'manque',\n",
              " 183: 'loin',\n",
              " 184: 'mon',\n",
              " 185: 'vrai',\n",
              " 186: '2',\n",
              " 187: 'leurs',\n",
              " 188: 'autant',\n",
              " 189: 'absolument',\n",
              " 190: 'pu',\n",
              " 191: 'dommage',\n",
              " 192: 'tellement',\n",
              " 193: 'quoi',\n",
              " 194: 'partie',\n",
              " 195: 'bout',\n",
              " 196: 'effets',\n",
              " 197: 'côté',\n",
              " 198: 'magnifique',\n",
              " 199: 'coup',\n",
              " 200: 'souvent',\n",
              " 201: 'donne',\n",
              " 202: 'avait',\n",
              " 203: \"n'y\",\n",
              " 204: 'autre',\n",
              " 205: 'vite',\n",
              " 206: 'font',\n",
              " 207: 'spectateur',\n",
              " 208: 'première',\n",
              " 209: 'regarder',\n",
              " 210: 'puis',\n",
              " 211: 'comment',\n",
              " 212: 'the',\n",
              " 213: 'certains',\n",
              " 214: 'ainsi',\n",
              " 215: 'voit',\n",
              " 216: 'notre',\n",
              " 217: 'guerre',\n",
              " 218: 'totalement',\n",
              " 219: 'français',\n",
              " 220: 'minutes',\n",
              " 221: 'rythme',\n",
              " 222: '5',\n",
              " 223: 'série',\n",
              " 224: \"d'être\",\n",
              " 225: 'trouve',\n",
              " 226: 'meilleur',\n",
              " 227: 'bons',\n",
              " 228: 'sens',\n",
              " 229: 'famille',\n",
              " 230: 'cet',\n",
              " 231: 'contre',\n",
              " 232: 'petite',\n",
              " 233: 'bande',\n",
              " 234: 'laisse',\n",
              " 235: 'passer',\n",
              " 236: 'enfin',\n",
              " 237: 'ma',\n",
              " 238: 'plaisir',\n",
              " 239: 'presque',\n",
              " 240: 'dit',\n",
              " 241: 'ci',\n",
              " 242: 'celle',\n",
              " 243: \"m'a\",\n",
              " 244: 'gros',\n",
              " 245: 'ceux',\n",
              " 246: 'intérêt',\n",
              " 247: 'niveau',\n",
              " 248: 'aucune',\n",
              " 249: 'décors',\n",
              " 250: 'métrage',\n",
              " 251: 'images',\n",
              " 252: 'pourquoi',\n",
              " 253: 'toutes',\n",
              " 254: 'documentaire',\n",
              " 255: 'prend',\n",
              " 256: 'devant',\n",
              " 257: 'simple',\n",
              " 258: 'spéciaux',\n",
              " 259: 'fond',\n",
              " 260: 'd’un',\n",
              " 261: 'quelque',\n",
              " 262: 'joue',\n",
              " 263: 'mort',\n",
              " 264: 'rire',\n",
              " 265: 'nul',\n",
              " 266: 'qualité',\n",
              " 267: 'enfants',\n",
              " 268: 'cas',\n",
              " 269: 'retrouve',\n",
              " 270: 'homme',\n",
              " 271: 'intéressant',\n",
              " 272: 'semble',\n",
              " 273: 'd’une',\n",
              " 274: 'simplement',\n",
              " 275: 'noir',\n",
              " 276: 'façon',\n",
              " 277: 'parce',\n",
              " 278: 'notamment',\n",
              " 279: 'fille',\n",
              " 280: 'sait',\n",
              " 281: 'pendant',\n",
              " 282: 'franchement',\n",
              " 283: 'doute',\n",
              " 284: 'super',\n",
              " 285: 'grâce',\n",
              " 286: 'héros',\n",
              " 287: \"d'action\",\n",
              " 288: 'certes',\n",
              " 289: 'fort',\n",
              " 290: 'classique',\n",
              " 291: 'plans',\n",
              " 292: 'veut',\n",
              " 293: 'trois',\n",
              " 294: 'quel',\n",
              " 295: 'malheureusement',\n",
              " 296: 'seule',\n",
              " 297: 'dernier',\n",
              " 298: 'place',\n",
              " 299: \"d'oeuvre\",\n",
              " 300: 'talent',\n",
              " 301: 'père',\n",
              " 302: 'passé',\n",
              " 303: 'réussi',\n",
              " 304: 'plein',\n",
              " 305: 'complètement',\n",
              " 306: \"qu'un\",\n",
              " 307: \"d'ailleurs\",\n",
              " 308: 'surprise',\n",
              " 309: \"n'ai\",\n",
              " 310: 'eu',\n",
              " 311: 'véritable',\n",
              " 312: 'face',\n",
              " 313: 'ridicule',\n",
              " 314: 'chaque',\n",
              " 315: 'également',\n",
              " 316: 'tête',\n",
              " 317: 'réalisé',\n",
              " 318: 'depuis',\n",
              " 319: '3',\n",
              " 320: 'critique',\n",
              " 321: 'original',\n",
              " 322: 'rôles',\n",
              " 323: 'thriller',\n",
              " 324: 'montre',\n",
              " 325: 'mettre',\n",
              " 326: 'moments',\n",
              " 327: \"l'un\",\n",
              " 328: 'superbe',\n",
              " 329: 'jean',\n",
              " 330: 'nos',\n",
              " 331: 'finalement',\n",
              " 332: 'force',\n",
              " 333: 'pire',\n",
              " 334: 'vue',\n",
              " 335: 'parfaitement',\n",
              " 336: 'effet',\n",
              " 337: 'acteur',\n",
              " 338: 'oui',\n",
              " 339: 'chez',\n",
              " 340: 'forme',\n",
              " 341: \"s'en\",\n",
              " 342: 'titre',\n",
              " 343: \"n'en\",\n",
              " 344: 'navet',\n",
              " 345: \"qu'elle\",\n",
              " 346: 'difficile',\n",
              " 347: \"l'ensemble\",\n",
              " 348: 'manière',\n",
              " 349: 'principal',\n",
              " 350: \"d'autres\",\n",
              " 351: 'devient',\n",
              " 352: 'aimé',\n",
              " 353: 'jeunes',\n",
              " 354: 'travers',\n",
              " 355: 'oeuvre',\n",
              " 356: 'ennuyeux',\n",
              " 357: 'caméra',\n",
              " 358: 'grands',\n",
              " 359: 'style',\n",
              " 360: 'voilà',\n",
              " 361: 'certaines',\n",
              " 362: 'doit',\n",
              " 363: 'clichés',\n",
              " 364: 'livre',\n",
              " 365: 'n’est',\n",
              " 366: 'tel',\n",
              " 367: 'prendre',\n",
              " 368: 'peine',\n",
              " 369: 'nouveau',\n",
              " 370: 'john',\n",
              " 371: 'situations',\n",
              " 372: 'mis',\n",
              " 373: 'cinéaste',\n",
              " 374: 'mère',\n",
              " 375: 'tient',\n",
              " 376: 'beauté',\n",
              " 377: 'particulièrement',\n",
              " 378: 'seconde',\n",
              " 379: 'envie',\n",
              " 380: 'vraie',\n",
              " 381: 'violence',\n",
              " 382: '4',\n",
              " 383: 'trouvé',\n",
              " 384: 'seulement',\n",
              " 385: 'mérite',\n",
              " 386: 'drame',\n",
              " 387: 'savoir',\n",
              " 388: 'humour',\n",
              " 389: \"l'humour\",\n",
              " 390: 'étant',\n",
              " 391: 'critiques',\n",
              " 392: 'quant',\n",
              " 393: 'nouvelle',\n",
              " 394: 'pense',\n",
              " 395: 'plan',\n",
              " 396: 'dès',\n",
              " 397: 'plusieurs',\n",
              " 398: 'qu’il',\n",
              " 399: 'public',\n",
              " 400: \"qu'ils\",\n",
              " 401: 'choses',\n",
              " 402: \"jusqu'à\",\n",
              " 403: 'met',\n",
              " 404: 'france',\n",
              " 405: 'donner',\n",
              " 406: 'réalité',\n",
              " 407: \"l'époque\",\n",
              " 408: 'serait',\n",
              " 409: 'yeux',\n",
              " 410: 'joué',\n",
              " 411: 'vaut',\n",
              " 412: 'femmes',\n",
              " 413: 'réussite',\n",
              " 414: 'gens',\n",
              " 415: 'jour',\n",
              " 416: 'arrive',\n",
              " 417: 'compte',\n",
              " 418: 'couple',\n",
              " 419: 'meilleurs',\n",
              " 420: 'vers',\n",
              " 421: 'ca',\n",
              " 422: 'eux',\n",
              " 423: 'pris',\n",
              " 424: '1',\n",
              " 425: 'travail',\n",
              " 426: 'fils',\n",
              " 427: 'sort',\n",
              " 428: \"d'amour\",\n",
              " 429: 'trouver',\n",
              " 430: 'revoir',\n",
              " 431: 'possible',\n",
              " 432: \"l'intrigue\",\n",
              " 433: 'b',\n",
              " 434: 'votre',\n",
              " 435: 'originale',\n",
              " 436: \"qu'une\",\n",
              " 437: 'parfait',\n",
              " 438: 'peur',\n",
              " 439: 'téléfilm',\n",
              " 440: 'heure',\n",
              " 441: 'western',\n",
              " 442: 'comprendre',\n",
              " 443: 'idée',\n",
              " 444: 'quelle',\n",
              " 445: 'société',\n",
              " 446: 'lors',\n",
              " 447: 'découvrir',\n",
              " 448: 'présence',\n",
              " 449: 'dernière',\n",
              " 450: 'suspense',\n",
              " 451: 'récit',\n",
              " 452: 'droit',\n",
              " 453: 'rend',\n",
              " 454: 'hommes',\n",
              " 455: 'vient',\n",
              " 456: 'gags',\n",
              " 457: 'personne',\n",
              " 458: 'efficace',\n",
              " 459: 'belles',\n",
              " 460: 'version',\n",
              " 461: 'demande',\n",
              " 462: 'pourrait',\n",
              " 463: 'pays',\n",
              " 464: 'sorte',\n",
              " 465: 'oublier',\n",
              " 466: 'charme',\n",
              " 467: 'sûr',\n",
              " 468: 'parle',\n",
              " 469: 'opus',\n",
              " 470: 'excellente',\n",
              " 471: 'sinon',\n",
              " 472: 'duo',\n",
              " 473: 'crédible',\n",
              " 474: 'bonnes',\n",
              " 475: 'lent',\n",
              " 476: 'sera',\n",
              " 477: 'moyen',\n",
              " 478: 'rare',\n",
              " 479: 'éviter',\n",
              " 480: 'thème',\n",
              " 481: \"s'ennuie\",\n",
              " 482: 'départ',\n",
              " 483: 'sortie',\n",
              " 484: 'roman',\n",
              " 485: 'séquences',\n",
              " 486: 'second',\n",
              " 487: 'milieu',\n",
              " 488: 'sauf',\n",
              " 489: 'sympathique',\n",
              " 490: 'choix',\n",
              " 491: 'américain',\n",
              " 492: 'cinématographique',\n",
              " 493: 'parler',\n",
              " 494: \"d'acteurs\",\n",
              " 495: 'incroyable',\n",
              " 496: 'question',\n",
              " 497: \"d'humour\",\n",
              " 498: 'fantastique',\n",
              " 499: 'suivre',\n",
              " 500: 'ambiance',\n",
              " 501: \"l'image\",\n",
              " 502: \"l'autre\",\n",
              " 503: 'nom',\n",
              " 504: 'blanc',\n",
              " 505: 'offre',\n",
              " 506: 'génial',\n",
              " 507: 'sent',\n",
              " 508: 'jouer',\n",
              " 509: 'aller',\n",
              " 510: 'james',\n",
              " 511: 'vont',\n",
              " 512: 'mes',\n",
              " 513: \"s'il\",\n",
              " 514: 'l',\n",
              " 515: 'fiction',\n",
              " 516: 'voix',\n",
              " 517: 'petits',\n",
              " 518: 'cependant',\n",
              " 519: 'résultat',\n",
              " 520: 'filmé',\n",
              " 521: \"l'amour\",\n",
              " 522: 'émouvant',\n",
              " 523: 'sombre',\n",
              " 524: 'agréable',\n",
              " 525: 'montage',\n",
              " 526: \"d'avoir\",\n",
              " 527: \"l'impression\",\n",
              " 528: 'beaux',\n",
              " 529: 'croire',\n",
              " 530: 'vieux',\n",
              " 531: 'touchant',\n",
              " 532: 'salle',\n",
              " 533: 'photographie',\n",
              " 534: 'problème',\n",
              " 535: 'culte',\n",
              " 536: \"l'action\",\n",
              " 537: 'l’histoire',\n",
              " 538: 'intrigue',\n",
              " 539: 'sauver',\n",
              " 540: 'rendre',\n",
              " 541: \"l'ambiance\",\n",
              " 542: 'propos',\n",
              " 543: 'suit',\n",
              " 544: 'ton',\n",
              " 545: 'certain',\n",
              " 546: 'raté',\n",
              " 547: 'robert',\n",
              " 548: 'cause',\n",
              " 549: 'pouvoir',\n",
              " 550: 'heureusement',\n",
              " 551: 'permet',\n",
              " 552: 'déçu',\n",
              " 553: 'sublime',\n",
              " 554: \"s'agit\",\n",
              " 555: 'compris',\n",
              " 556: \"l'idée\",\n",
              " 557: 'lieu',\n",
              " 558: 'terrible',\n",
              " 559: 'adaptation',\n",
              " 560: 'comprend',\n",
              " 561: 'vide',\n",
              " 562: 'sympa',\n",
              " 563: \"s'est\",\n",
              " 564: 'durant',\n",
              " 565: 'deuxième',\n",
              " 566: 'regard',\n",
              " 567: 'déception',\n",
              " 568: 'rapidement',\n",
              " 569: 'vivre',\n",
              " 570: 'prévisible',\n",
              " 571: 'montrer',\n",
              " 572: 'propre',\n",
              " 573: 'époque',\n",
              " 574: 'fan',\n",
              " 575: \"d'horreur\",\n",
              " 576: 'ville',\n",
              " 577: 'chemin',\n",
              " 578: 'saga',\n",
              " 579: 'écrit',\n",
              " 580: 'etc',\n",
              " 581: 'française',\n",
              " 582: 'près',\n",
              " 583: 'remarquable',\n",
              " 584: 'dramatique',\n",
              " 585: 'merveille',\n",
              " 586: 't',\n",
              " 587: 'intéressante',\n",
              " 588: 'sentiments',\n",
              " 589: 'd',\n",
              " 590: 'succès',\n",
              " 591: 'penser',\n",
              " 592: \"qu'à\",\n",
              " 593: 'paysages',\n",
              " 594: 'autour',\n",
              " 595: 'connu',\n",
              " 596: 'limite',\n",
              " 597: 'chacun',\n",
              " 598: 'exemple',\n",
              " 599: 'divertissement',\n",
              " 600: \"c'était\",\n",
              " 601: 'mauvaise',\n",
              " 602: 'ayant',\n",
              " 603: 'pur',\n",
              " 604: 'budget',\n",
              " 605: '20',\n",
              " 606: 'prestation',\n",
              " 607: 'plat',\n",
              " 608: 'elles',\n",
              " 609: 'commence',\n",
              " 610: 'heures',\n",
              " 611: 'tres',\n",
              " 612: 'certaine',\n",
              " 613: 'faux',\n",
              " 614: 'personnes',\n",
              " 615: 'comédiens',\n",
              " 616: 'enfant',\n",
              " 617: \"n'ont\",\n",
              " 618: 'vision',\n",
              " 619: 'digne',\n",
              " 620: 'politique',\n",
              " 621: 'jours',\n",
              " 622: '10',\n",
              " 623: \"aujourd'hui\",\n",
              " 624: 'longtemps',\n",
              " 625: 'lequel',\n",
              " 626: 'parvient',\n",
              " 627: 'michael',\n",
              " 628: 'pleine',\n",
              " 629: 'merci',\n",
              " 630: 'adoré',\n",
              " 631: 'tension',\n",
              " 632: 'étoiles',\n",
              " 633: 'sortir',\n",
              " 634: 'tombe',\n",
              " 635: 'coeur',\n",
              " 636: 'rarement',\n",
              " 637: 'ensuite',\n",
              " 638: 'réaliste',\n",
              " 639: 'nombreux',\n",
              " 640: 'comique',\n",
              " 641: 'retrouver',\n",
              " 642: \"jusqu'au\",\n",
              " 643: 'combats',\n",
              " 644: 'interprétation',\n",
              " 645: 'voire',\n",
              " 646: 'rapport',\n",
              " 647: 'œuvre',\n",
              " 648: 'court',\n",
              " 649: 'spectateurs',\n",
              " 650: 'haut',\n",
              " 651: 'perdu',\n",
              " 652: 'moyens',\n",
              " 653: 'décevant',\n",
              " 654: 'volet',\n",
              " 655: 'carrière',\n",
              " 656: 'peuvent',\n",
              " 657: 'base',\n",
              " 658: 'méchant',\n",
              " 659: 'particulier',\n",
              " 660: 'combat',\n",
              " 661: 'derrière',\n",
              " 662: \"l'écran\",\n",
              " 663: 'production',\n",
              " 664: 'laisser',\n",
              " 665: \"n'importe\",\n",
              " 666: \"d'acteur\",\n",
              " 667: 'situation',\n",
              " 668: 'univers',\n",
              " 669: 'pauvre',\n",
              " 670: 'pierre',\n",
              " 671: 'regarde',\n",
              " 672: \"qu'est\",\n",
              " 673: 'aime',\n",
              " 674: 'bas',\n",
              " 675: 'bravo',\n",
              " 676: 'passionnant',\n",
              " 677: 'grosse',\n",
              " 678: 'idées',\n",
              " 679: 'actrice',\n",
              " 680: 'polar',\n",
              " 681: 'jouent',\n",
              " 682: \"j'avais\",\n",
              " 683: 'évidemment',\n",
              " 684: 'movie',\n",
              " 685: 'finit',\n",
              " 686: 'nanar',\n",
              " 687: 'coté',\n",
              " 688: 'of',\n",
              " 689: 'faisant',\n",
              " 690: \"l'homme\",\n",
              " 691: 'mélange',\n",
              " 692: 'dvd',\n",
              " 693: 'bonheur',\n",
              " 694: 'sais',\n",
              " 695: 'nuit',\n",
              " 696: 'porte',\n",
              " 697: 'ai',\n",
              " 698: 'forcément',\n",
              " 699: 'triste',\n",
              " 700: 'retour',\n",
              " 701: 'sourire',\n",
              " 702: 'magnifiques',\n",
              " 703: 'rencontre',\n",
              " 704: 'maison',\n",
              " 705: 'interprété',\n",
              " 706: 'raison',\n",
              " 707: 'mêmes',\n",
              " 708: 'message',\n",
              " 709: 'histoires',\n",
              " 710: 'disney',\n",
              " 711: 'présente',\n",
              " 712: 'spectacle',\n",
              " 713: 'sorti',\n",
              " 714: 'fans',\n",
              " 715: \"l'acteur\",\n",
              " 716: 'lourd',\n",
              " 717: 'hors',\n",
              " 718: \"j'en\",\n",
              " 719: 'voyage',\n",
              " 720: 'signe',\n",
              " 721: 'puisque',\n",
              " 722: 'allez',\n",
              " 723: 'relation',\n",
              " 724: 'tourné',\n",
              " 725: 'laquelle',\n",
              " 726: 'art',\n",
              " 727: 'pouvait',\n",
              " 728: 'attachants',\n",
              " 729: 'prix',\n",
              " 730: 'passage',\n",
              " 731: 'prenant',\n",
              " 732: \"l'ai\",\n",
              " 733: 'répliques',\n",
              " 734: 'actrices',\n",
              " 735: 'fil',\n",
              " 736: 'corps',\n",
              " 737: 'extrêmement',\n",
              " 738: 'nature',\n",
              " 739: 'telle',\n",
              " 740: 'remake',\n",
              " 741: 'raconte',\n",
              " 742: 'parfaite',\n",
              " 743: 'couleurs',\n",
              " 744: 'touche',\n",
              " 745: 'l’on',\n",
              " 746: 'lorsque',\n",
              " 747: 'rebondissements',\n",
              " 748: 'romantique',\n",
              " 749: 'type',\n",
              " 750: 'premiers',\n",
              " 751: 'c',\n",
              " 752: 'tu',\n",
              " 753: 'principaux',\n",
              " 754: 'premières',\n",
              " 755: 'protagonistes',\n",
              " 756: 'nombreuses',\n",
              " 757: 'goût',\n",
              " 758: 'j’ai',\n",
              " 759: \"l'interprétation\",\n",
              " 760: 'cœur',\n",
              " 761: 'gore',\n",
              " 762: 'sérieux',\n",
              " 763: 'historique',\n",
              " 764: 'longueurs',\n",
              " 765: 'route',\n",
              " 766: 'dessus',\n",
              " 767: 'jolie',\n",
              " 768: 'réussit',\n",
              " 769: 'amateurs',\n",
              " 770: 'quasi',\n",
              " 771: 'réel',\n",
              " 772: 'étoile',\n",
              " 773: 'image',\n",
              " 774: 'clairement',\n",
              " 775: 'inutile',\n",
              " 776: 'morale',\n",
              " 777: 'réellement',\n",
              " 778: 'poésie',\n",
              " 779: 'ben',\n",
              " 780: 'néanmoins',\n",
              " 781: 'costumes',\n",
              " 782: 'fou',\n",
              " 783: 'trés',\n",
              " 784: \"d'autant\",\n",
              " 785: 'paul',\n",
              " 786: 'demi',\n",
              " 787: 'note',\n",
              " 788: 'fut',\n",
              " 789: \"l'univers\",\n",
              " 790: 'sang',\n",
              " 791: 'tard',\n",
              " 792: 'donné',\n",
              " 793: 'devenir',\n",
              " 794: 'épisode',\n",
              " 795: 'américains',\n",
              " 796: 'contraire',\n",
              " 797: 'mot',\n",
              " 798: '80',\n",
              " 799: 'amoureux',\n",
              " 800: 'excellents',\n",
              " 801: 'impossible',\n",
              " 802: 'paris',\n",
              " 803: 'ressemble',\n",
              " 804: 'jeux',\n",
              " 805: 'amour',\n",
              " 806: 'drôles',\n",
              " 807: 'finale',\n",
              " 808: 'mots',\n",
              " 809: \"d'abord\",\n",
              " 810: 'passages',\n",
              " 811: 'présent',\n",
              " 812: 'proche',\n",
              " 813: 'dur',\n",
              " 814: 'certainement',\n",
              " 815: 'hélas',\n",
              " 816: 'top',\n",
              " 817: 'ennui',\n",
              " 818: 'david',\n",
              " 819: 'troisième',\n",
              " 820: 'annonce',\n",
              " 821: 'richard',\n",
              " 822: 'terre',\n",
              " 823: 'américaine',\n",
              " 824: 'perdre',\n",
              " 825: 'n’a',\n",
              " 826: \"j'aime\",\n",
              " 827: 'folie',\n",
              " 828: 'longue',\n",
              " 829: 'générique',\n",
              " 830: 'peux',\n",
              " 831: 'moindre',\n",
              " 832: 'partir',\n",
              " 833: 'noter',\n",
              " 834: 'tour',\n",
              " 835: 'meme',\n",
              " 836: 'plupart',\n",
              " 837: 'j',\n",
              " 838: 'réalisme',\n",
              " 839: 'lumière',\n",
              " 840: 'mesure',\n",
              " 841: 'dure',\n",
              " 842: 'maître',\n",
              " 843: 'aura',\n",
              " 844: \"s'y\",\n",
              " 845: 'fonctionne',\n",
              " 846: 'unique',\n",
              " 847: 'preuve',\n",
              " 848: 'tourne',\n",
              " 849: 'différents',\n",
              " 850: 'tomber',\n",
              " 851: 'riche',\n",
              " 852: 'parents',\n",
              " 853: 'perd',\n",
              " 854: 'croit',\n",
              " 855: 'michel',\n",
              " 856: 'amis',\n",
              " 857: 'facile',\n",
              " 858: 'intelligent',\n",
              " 859: 'parti',\n",
              " 860: 'performance',\n",
              " 861: 'portrait',\n",
              " 862: 'inspiré',\n",
              " 863: 'attention',\n",
              " 864: 'sert',\n",
              " 865: 'vérité',\n",
              " 866: 'dieu',\n",
              " 867: 'rêve',\n",
              " 868: 'suffit',\n",
              " 869: 'ultra',\n",
              " 870: 'largement',\n",
              " 871: 'génie',\n",
              " 872: 'émotion',\n",
              " 873: 'lee',\n",
              " 874: 'groupe',\n",
              " 875: 'filles',\n",
              " 876: 'formidable',\n",
              " 877: 'profondeur',\n",
              " 878: 'rares',\n",
              " 879: 'but',\n",
              " 880: 'seconds',\n",
              " 881: 'conseille',\n",
              " 882: \"d'animation\",\n",
              " 883: 'avis',\n",
              " 884: 'finir',\n",
              " 885: 'ailleurs',\n",
              " 886: 'médiocre',\n",
              " 887: 'rester',\n",
              " 888: 'totale',\n",
              " 889: 'dernières',\n",
              " 890: 'justesse',\n",
              " 891: 'réflexion',\n",
              " 892: 'hommage',\n",
              " 893: 'faute',\n",
              " 894: 'humaine',\n",
              " 895: 'petites',\n",
              " 896: 'révèle',\n",
              " 897: 'conte',\n",
              " 898: 'star',\n",
              " 899: 'psychologique',\n",
              " 900: 'découvre',\n",
              " 901: \"m'attendais\",\n",
              " 902: 'besoin',\n",
              " 903: 'charisme',\n",
              " 904: 'séquence',\n",
              " 905: 'humain',\n",
              " 906: 'points',\n",
              " 907: 'hauteur',\n",
              " 908: 'méchants',\n",
              " 909: 'soi',\n",
              " 910: 'main',\n",
              " 911: 'voulu',\n",
              " 912: 'sexe',\n",
              " 913: 'réalisateurs',\n",
              " 914: 'voila',\n",
              " 915: 'avez',\n",
              " 916: \"l'air\",\n",
              " 917: 'suspens',\n",
              " 918: 'cherche',\n",
              " 919: 'mourir',\n",
              " 920: 'animé',\n",
              " 921: 'dû',\n",
              " 922: 'delà',\n",
              " 923: 'célèbre',\n",
              " 924: 'science',\n",
              " 925: 'action',\n",
              " 926: 'attachant',\n",
              " 927: 's',\n",
              " 928: 'ait',\n",
              " 929: 'recherche',\n",
              " 930: 'porté',\n",
              " 931: 'sommes',\n",
              " 932: 'faits',\n",
              " 933: 'violent',\n",
              " 934: 'toutefois',\n",
              " 935: 'sentiment',\n",
              " 936: 'comédies',\n",
              " 937: 'énorme',\n",
              " 938: 'mari',\n",
              " 939: 'frères',\n",
              " 940: \"d'autre\",\n",
              " 941: 'produit',\n",
              " 942: 'dessin',\n",
              " 943: 'quatre',\n",
              " 944: 'étrange',\n",
              " 945: 'souffle',\n",
              " 946: 'émotions',\n",
              " 947: 'siècle',\n",
              " 948: 'réalisatrice',\n",
              " 949: 'qu’on',\n",
              " 950: 'pure',\n",
              " 951: '30',\n",
              " 952: 'ah',\n",
              " 953: 'propose',\n",
              " 954: 'truc',\n",
              " 955: 'mode',\n",
              " 956: 'contexte',\n",
              " 957: 'nombre',\n",
              " 958: 'meilleure',\n",
              " 959: 'profond',\n",
              " 960: 'théâtre',\n",
              " 961: 'liberté',\n",
              " 962: 'recommande',\n",
              " 963: 'réalise',\n",
              " 964: 'aventure',\n",
              " 965: 'réussie',\n",
              " 966: 'classe',\n",
              " 967: 'léger',\n",
              " 968: 'afin',\n",
              " 969: 'uniquement',\n",
              " 970: \"l'esprit\",\n",
              " 971: 'convaincant',\n",
              " 972: 'grandes',\n",
              " 973: 'tueur',\n",
              " 974: 'ridicules',\n",
              " 975: 'ensemble',\n",
              " 976: 'valeur',\n",
              " 977: 'maintenant',\n",
              " 978: \"j'adore\",\n",
              " 979: 'su',\n",
              " 980: 'technique',\n",
              " 981: 'degré',\n",
              " 982: 'mention',\n",
              " 983: 'originalité',\n",
              " 984: 'qualités',\n",
              " 985: 'peau',\n",
              " 986: 'total',\n",
              " 987: 'défaut',\n",
              " 988: 'relations',\n",
              " 989: 'filmer',\n",
              " 990: 'daube',\n",
              " 991: \"s'avère\",\n",
              " 992: 'quasiment',\n",
              " 993: 'complexe',\n",
              " 994: 'questions',\n",
              " 995: 'new',\n",
              " 996: 'terriblement',\n",
              " 997: 'surprenant',\n",
              " 998: 'selon',\n",
              " 999: 'catastrophe',\n",
              " 1000: 'pseudo',\n",
              " ...}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uvHU4F21lWHh"
      },
      "source": [
        "**Création des données d'entrainement et de tests**  \n",
        "On utilise la fonction `train_test_split` de [ScikitLearn](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html) afin de créer les données d'entrainement et de tests à partir des séquences :\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oBFoHU9RlkOD"
      },
      "source": [
        "index_des_mots = tokenizer.word_index\n",
        "nbr_mots = min(MAX_NB_MOTS, len(index_des_mots)) + 1\n",
        "\n",
        "x_entrainement, x_test, y_entrainement, y_test = train_test_split(padded_sequences, labels, test_size=0.2)"
      ],
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fg3t3ahhxJ9p",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dc942e05-4c6e-45ed-9c80-daf9981ef25f"
      },
      "source": [
        "x_entrainement.shape"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(128000, 1000)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tdcJUpqilsoC"
      },
      "source": [
        "**Création de la matrice embarquant les données numériques des vecteurs des mots contenus dans les commentaires**  \n",
        "L'objectif est ici de créer une matrice dont chaque ligne contient le vecteur du mot issu de l'algorithme GolVe. La matrice est donc de taille n x m avec :  \n",
        "* n : Nombre de mots (uniques) pris en compte dans l'ensemble des commentiares  \n",
        "* m : Nombre de valeurs contenues dans les vecteurs GolvE (300 dans notre exemple)  \n",
        "  \n",
        "$$\\begin{array}{*{20}{c}}\n",
        "{glace}\\\\\n",
        "{soda}\\\\\n",
        "{...}\\\\\n",
        "{film}\n",
        "\\end{array}\\left( \\begin{array}{l}\n",
        "\\begin{array}{*{20}{c}}\n",
        "{ - 0.3}&{0.2}&{...}&{0.32}&{ - 0.24}\n",
        "\\end{array}\\\\\n",
        "\\begin{array}{*{20}{c}}\n",
        "{ - 0.1}&{0.3}&{...}&{0.52}&{ - 0.94}\n",
        "\\end{array}\\\\\n",
        "\\begin{array}{*{20}{c}}\n",
        "{...}&{...}&{...}&{...}&{...}\n",
        "\\end{array}\\\\\n",
        "\\begin{array}{*{20}{c}}\n",
        "{ - 0.5}&{0.9}&{...}&{0.72}&{ - 0.24}\n",
        "\\end{array}\n",
        "\\end{array} \\right)$$    \n",
        "  \n",
        "    \n",
        "\n",
        "Les lignes ne sont pas arrangées dans n'importe quel ordre : Elles suivent l'ordre des séquences créées par la fonction `tokenizer.texts_to_sequences()`\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qp7oQXgtVz8x"
      },
      "source": [
        "Pour cela définit tout d'abord la fonction `Chargement_Vecteurs()` qui va créer un tableau de type numpy, avec pour chaque mot son vecteur correspondant :  \n",
        "\n",
        "\n",
        "```\n",
        "  ...\n",
        "  'embêtant': array([-2.26152748e-01,  3.20324749e-01, -1.10406213e-01, -6.05279326e-01,\n",
        "        -4.68072683e-01,  1.29561171e-01,  5.62916815e-01, -1.16834176e+00,\n",
        "       ...\n",
        "        -7.50736117e-01, -2.48611599e-01, -2.42264550e-02, -9.54209745e-01],\n",
        "       dtype=float32),\n",
        " 'lockheed': array([ 3.6074609e-01, -8.0667698e-01,  8.7549436e-01,  6.2351477e-01,\n",
        "        -9.2155904e-01,  7.3180795e-01, -2.8121206e-01,  2.9078028e-01,\n",
        "        ...\n",
        "         1.5100185e+00,  8.1941241e-01, -1.6970781e+00,  1.9289741e-01],\n",
        "       dtype=float32),\n",
        " 'séparez': array([-0.5703459 , -0.8884122 , -0.4579496 ,  0.55588883, -0.8727098 ,\n",
        "         0.56783265, -0.10067926,  0.14027229, -0.89301944, -0.42706665,\n",
        "        ...\n",
        "        -0.36254016, -0.40695533,  1.087127  , -0.641696  ,  0.10919298,\n",
        "        ...\n",
        "```  \n",
        "\n",
        "Puis la fonction `Creation_Matrice()` qui va créer notre matrice. Pour chaque mot contenu dans les séquences créées par la fonction `tokenizer.texts_to_sequences` on récupère le vecteur correspondant à l'aide du tableau numpy créé précédemment. Ainsi chaque ligne de la matrice indexe chaque mot des séquences.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zVeUb4AsMFLG"
      },
      "source": [
        "MAX_NB_VECTORS = 400000\n",
        "EMBEDDING_DIM = 300\n",
        "\n",
        "def Chargement_Vecteurs():\n",
        "    print('Chargement des vecteurs GloVe...')\n",
        "    glove_dict = {}\n",
        "    Max_Nb_Vect = 0\n",
        "    with open('/content/data/multilingual_embeddings.fr', encoding='utf8') as fichier:\n",
        "        for ligne in fichier:\n",
        "            Max_Nb_Vect = Max_Nb_Vect + 1\n",
        "            if Max_Nb_Vect > MAX_NB_VECTORS:\n",
        "              break\n",
        "            valeur = ligne.split()\n",
        "            mot = valeur[0]\n",
        "            glove_dict[mot] = np.asarray(valeur[1:], dtype='float32')\n",
        "    return glove_dict\n",
        "\n",
        "def Creation_Matrice(index_mot, nbr_mots):\n",
        "    glove_dict = Chargement_Vecteurs()\n",
        "    matrice = np.zeros((nbr_mots, EMBEDDING_DIM))\n",
        "    for mot, i in index_mot.items():\n",
        "        if i > nbr_mots:\n",
        "            continue\n",
        "        vector = glove_dict.get(mot)\n",
        "        if vector is not None:\n",
        "            matrice[i] = vector\n",
        "    print('Matrice créée...')\n",
        "    return matrice"
      ],
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AKg1xxG1t7rQ"
      },
      "source": [
        "Regardons à quoi cela ressemble sur notre précédent exemple :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ocbWFigsU7I5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d3a823a7-8c57-4490-8e5b-c464d59f5600"
      },
      "source": [
        "print(com)\n",
        "print(tokenizer_ex.word_index)\n",
        "\n",
        "matrice = Creation_Matrice(tokenizer_ex.word_index, 10)"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['un plus un egal deux', 'deux plus deux cela fait quatre']\n",
            "{'deux': 1, 'un': 2, 'plus': 3, 'egal': 4, 'cela': 5, 'fait': 6, 'quatre': 7}\n",
            "Chargement des vecteurs GloVe...\n",
            "Matrice créée...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wiyyluWRvSEa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9b571e1d-6d8e-43e4-d193-5a762cd03012"
      },
      "source": [
        "matrice"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
              "         0.        ,  0.        ],\n",
              "       [-0.14380729, -0.15245135, -0.32095706, ..., -0.2833837 ,\n",
              "         0.20184219, -0.3477053 ],\n",
              "       [ 0.02684828,  0.34394601, -0.17763138, ..., -0.31729311,\n",
              "        -0.08849339,  0.17732655],\n",
              "       ...,\n",
              "       [ 0.38667157, -0.01152001, -0.22971489, ..., -0.3842952 ,\n",
              "         0.18768422, -0.45241103],\n",
              "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
              "         0.        ,  0.        ],\n",
              "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
              "         0.        ,  0.        ]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LQJoxfCTf1Hd"
      },
      "source": [
        "On créé donc maintenant la matrice pour notre projet :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EZlja3d1MFLL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1de42011-1eee-445d-9ad9-b68c5e1ddbf2"
      },
      "source": [
        "matrice = Creation_Matrice(index_des_mots, nbr_mots)"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Chargement des vecteurs GloVe...\n",
            "Matrice créée...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6mnxIJKC5wPO"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d03F2eT2gbYG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "38ffb014-62cf-4e62-b8f8-26a520a7ddad"
      },
      "source": [
        "matrice.shape"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(186308, 300)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OSCKoWPYMFLN"
      },
      "source": [
        "# Définition du Modèle\n",
        "\n",
        "Nous utilisons un réseau de neurones à convolution 1D avec Keras et en utilisant la matrice créée précédemment afin de paramétrer la couche interne. La couche interne est pré-entrainée donc nous n'avons pas d'entrainement à réaliser sur celle-ci.  \n",
        "\n",
        "La structure du réseau est la suivante :  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o9G1oAXnVJJP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 486
        },
        "outputId": "d760514e-57d1-4c50-c584-ef451594307c"
      },
      "source": [
        "from IPython.display import Image\n",
        "Image(url='https://github.com/AlexandreBourrieau/ML/blob/main/Carnets%20Jupyter/Images/Conv1D2.png?raw=true', width=1180)"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<img src=\"https://github.com/AlexandreBourrieau/ML/blob/main/Carnets%20Jupyter/Images/Conv1D2.png?raw=true\" width=\"1180\"/>"
            ],
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b0IUw1VDMFLO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7fcce2f0-f634-4ffa-cca1-da4ecf7b7ba1"
      },
      "source": [
        "dropout = 0.4\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(nbr_mots, EMBEDDING_DIM, weights=[matrice],\n",
        "                    input_length=MAX_SEQUENCE_LENGTH, trainable=False))\n",
        "model.add(Dropout(dropout))\n",
        "\n",
        "model.add(Conv1D(128, 5, activation='relu', padding='same', strides=2))\n",
        "model.add(GlobalMaxPooling1D())\n",
        "model.add(Dropout(dropout))\n",
        "\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dropout(dropout))\n",
        "model.add(Dense(2, activation='softmax'))\n",
        "model.summary()"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      (None, 1000, 300)         55892400  \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 1000, 300)         0         \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, 500, 128)          192128    \n",
            "_________________________________________________________________\n",
            "global_max_pooling1d_1 (Glob (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 128)               16512     \n",
            "_________________________________________________________________\n",
            "dropout_5 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 2)                 258       \n",
            "=================================================================\n",
            "Total params: 56,101,298\n",
            "Trainable params: 208,898\n",
            "Non-trainable params: 55,892,400\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vWFUoRi6XZYU"
      },
      "source": [
        "# Entrainement du modèle"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BUMaXNjMMFLQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 545
        },
        "outputId": "390ee6c3-fb15-4ec2-9cc1-9e83717bb5b0"
      },
      "source": [
        "model.compile(loss='sparse_categorical_crossentropy', optimizer=Adam(), metrics=['acc'])\n",
        "\n",
        "# Entraine le modèle sur un certain nombre d'itérations\n",
        "historique = model.fit(x_entrainement, y_entrainement, batch_size=128, epochs=40, verbose=1, validation_data=(x_test, y_test))\n",
        "\n",
        "# Evalue le modèle avec les échantillons de tests\n",
        "score = model.evaluate(x_test, y_test, verbose=0)\n",
        "print('Fonction d\\'objectif des tests :', score[0])\n",
        "print('Précision des tests :', score[1])\n",
        "\n",
        "# Synthèse\n",
        "plt.plot(historique.history['acc'])\n",
        "plt.plot(historique.history['val_acc'])\n",
        "plt.title('Précision du modèle')\n",
        "plt.ylabel('Précision')\n",
        "plt.xlabel('Itérations')\n",
        "plt.legend(['Entrainements', 'Tests'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/40\n",
            "1000/1000 [==============================] - 72s 72ms/step - loss: 0.6742 - acc: 0.6163 - val_loss: 0.4267 - val_acc: 0.8186\n",
            "Epoch 2/40\n",
            "1000/1000 [==============================] - 72s 72ms/step - loss: 0.4763 - acc: 0.7732 - val_loss: 0.3863 - val_acc: 0.8428\n",
            "Epoch 3/40\n",
            "1000/1000 [==============================] - 72s 72ms/step - loss: 0.4375 - acc: 0.7983 - val_loss: 0.3476 - val_acc: 0.8544\n",
            "Epoch 4/40\n",
            "1000/1000 [==============================] - 72s 72ms/step - loss: 0.4191 - acc: 0.8075 - val_loss: 0.3346 - val_acc: 0.8617\n",
            "Epoch 5/40\n",
            " 636/1000 [==================>...........] - ETA: 22s - loss: 0.4069 - acc: 0.8162"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-82-5d9588bd4f6f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Entraine le modèle sur un certain nombre d'itérations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mhistorique\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_entrainement\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_entrainement\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m40\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# Evalue le modèle avec les échantillons de tests\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 _r=1):\n\u001b[1;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    853\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 855\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    856\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    857\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2942\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2943\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2945\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1917\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1918\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1919\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1921\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    558\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    561\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3LVwi0vLMFLS"
      },
      "source": [
        "# Prédictions\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_i423WNQMFLS"
      },
      "source": [
        "predictions = model.predict(padded_sequences)\n",
        "plus_probable = predictions.argmax(1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Ve2a-roMFLV"
      },
      "source": [
        "index = random.randrange(len(predictions))\n",
        "print(commentaires[index])\n",
        "print('Prédiction: %d, label: %d' % (plus_probable[index], ressentis[index]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FcR3Qu6FMFLX"
      },
      "source": [
        "# Analyse des erreurs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T7aMVD5lMFLX"
      },
      "source": [
        "for i in range(10000):\n",
        "    index = random.randrange(len(predictions))\n",
        "    if plus_probable[index] != ressentis[index]:\n",
        "        break\n",
        "\n",
        "print(commentaires[index])\n",
        "print('Prédiction: %d, label: %d' % (plus_probable[index], ressentis[index]))\n",
        "\n",
        "plt.bar(range(2), predictions[index], tick_label=range(2))\n",
        "plt.title('Valeur prédite ')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}