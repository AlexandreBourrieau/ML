{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "VDSR.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AlexandreBourrieau/ML/blob/main/Carnets%20Jupyter/VDSR.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wtkMiy5pIIZY"
      },
      "source": [
        "\r\n",
        "# Very Deep Super-Resolution avec le Deep Learning\r\n",
        "\r\n",
        "Nous allons voir comment entrainer un réseau de neurones \"Very-Deep Super-Resolution\" (VDSR) et utiliser le réseau afin d'obtenir une image haute résolution à partir d'une image en basse résolution. \r\n",
        "\r\n",
        "\r\n",
        "![Présentation](https://github.com/AlexandreBourrieau/ML/blob/main/Carnets%20Jupyter/Images/illustration_2.png?raw=true) \r\n",
        "  \r\n",
        "Plusieurs techniques permettent de produire une image haute résolution à partir d'une image basse résolution, dont les techniques à base d'apprentissage profond. Nous allons ici utiliser [l'algorithme VDSR](https://arxiv.org/abs/1511.04587)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-_rAdcNlKHcT"
      },
      "source": [
        "import glob\r\n",
        "\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import matplotlib.image as mpimg\r\n",
        "import numpy as np\r\n",
        "import random\r\n",
        "\r\n",
        "from tensorflow.keras import backend as K\r\n",
        "from tensorflow.keras.models import Sequential\r\n",
        "from tensorflow.keras.layers import Conv2D\r\n",
        "from tensorflow.keras import regularizers\r\n",
        "from tensorflow.keras.optimizers import SGD\r\n",
        "from tensorflow.keras.optimizers import schedules\r\n",
        "from tensorflow.keras import metrics\r\n",
        "from tensorflow.keras import losses\r\n",
        "from tensorflow.image import extract_patches\r\n",
        "from tensorflow.keras.models import model_from_json\r\n",
        "\r\n",
        "import sklearn.feature_extraction as feature_extract\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "\r\n",
        "\r\n",
        "from PIL import Image, ImageOps\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "00hWdsB0IjZ2"
      },
      "source": [
        "# Téléchargement et chargement des données\r\n",
        "\r\n",
        "Le nombre de données est très grand, le fichier contient 20 000 images et sa taille est d'environ 1,6 Go"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6J-lHeobHoji"
      },
      "source": [
        "!wget \"http://www-i6.informatik.rwth-aachen.de/imageclef/resources/iaprtc12.tgz\"\r\n",
        "!tar xzf iaprtc12.tgz"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G4RvfGvuKRml"
      },
      "source": [
        "!ls iaprtc12/images/ -l"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ZASoz3vNCPU"
      },
      "source": [
        "Affichage d'une image aléatoire contenue dans le répertoire /images/39/ :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gZPifXdDKKLJ"
      },
      "source": [
        "fichier = \"iaprtc12/images/39/39\"+str(int((random.randrange(0,1000))))+\".jpg\"\r\n",
        "img=mpimg.imread(fichier)\r\n",
        "plt.imshow(img)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kguUrt2zSZVw"
      },
      "source": [
        "img"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zCVjnQLCNoi8"
      },
      "source": [
        "Chargement des images contenues dans le répertoire /images/39/"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P3kT2Mc6WVAD"
      },
      "source": [
        "def ChargementImages(repertoire):\r\n",
        "  images = []\r\n",
        "  fichiers = sorted(glob.glob(repertoire+\"*.jpg\"))\r\n",
        "  for fichier in fichiers:\r\n",
        "    img = mpimg.imread(fichier)\r\n",
        "    images.append(img)\r\n",
        "  return np.array(images, dtype=object)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k0M4DJCeZHLi"
      },
      "source": [
        "images = ChargementImages(\"iaprtc12/images/39/\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "24myq3dNV3C7"
      },
      "source": [
        "images.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nogPUSThkrk3"
      },
      "source": [
        "plt.imshow(images[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GZMPIsRmaFDq"
      },
      "source": [
        "# Préparation des données d'entrainement\r\n",
        "\r\n",
        "Chaque échantillon d'entrainement doit contenir :\r\n",
        " - X : Le canal de luminance de l'image basse résolution traitée par interpolation bicubique : Ybr\r\n",
        " - Y : L'image résiduelle : Yresiduelle = Yhr - Ybr (différence entre la luminance de l'image originale haute résolution et la luminance de l'image haute résolution reconstituée par interpolation bicubique à partir de l'image basse résolution)  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "37bCFPmhfgDQ"
      },
      "source": [
        "![ApprentissageRéseau](https://github.com/AlexandreBourrieau/ML/blob/main/Carnets%20Jupyter/Images/apprentissage_reseau.png?raw=true) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qmG9QHk6k6Ri"
      },
      "source": [
        "Les étapes sont les suivantes :  \r\n",
        "- Convertir les images RGB au format YCbCr\r\n",
        "- Normaliser les valeurs des pixels en un nombre à virgule flottante sur 64 bits compris entre 0.0 et 1.0\r\n",
        "- Appliquer un facteur d'échelle aléatoire afin de créer une image basse résolution et extraire la partie luminance de l'image basse résolution\r\n",
        "- Reconvertir cette image en haute résolution à l'aide de l'interpolation bicubique puis en extraire la luminance. **Ces données seront les échantillons X.**\r\n",
        "- Extraire la luminance résiduelle (différence entre la luminance de l'image originale et la luminance de l'image reconstituée en haute résolution par interpolation bicubique). **Ces données seront les échantillons Y.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tDlakAXkdcZ5"
      },
      "source": [
        "**1. Conversion des images RGB au format YCrCb**  \r\n",
        "Le [modèle **YCbCr**](https://fr.wikipedia.org/wiki/YCbCr) est une manière de représenter l'espace colorimétrique en vidéo, issue essentiellement des problèmes de transmission hertzienne. Ce standard a été développé à une époque où il fallait assurer la compatibilité des récépteurs de télévision noir et blanc et des récepteurs couleur.  \r\n",
        "\r\n",
        "La couleur étant créée par la juxtaposition de trois types de luminophores rouge (R), vert (anglais : green, G) et bleu (B), il faut transmettre trois composantes, trois signaux. Cependant, le noir et blanc ne comprend qu'une seule teinte, le niveau de gris.  \r\n",
        "\r\n",
        "Les trois signaux transmis ne sont donc pas les trois composantes RGB mais la teinte de gris Y, et la différence entre cette teinte et deux autres composantes.\r\n",
        "\r\n",
        "Les trois informations sont donc la luminance (teinte de gris) et les deux chrominances. Le récepteur noir et blanc ne traitera que la luminance et les récepteurs en couleur déduiront les trois composantes RVB à partir de la luminance et des deux chrominances :  \r\n",
        "- La luminance Y : Y = R + G + B (teinte de gris)\r\n",
        "- La chrominance Cb : Y - B\r\n",
        "- La chrominance Cr : Y - R  \r\n",
        "\r\n",
        "Dans la pratique, les luminophores n'ont pas le même rendement, on applique donc des coefficients correcteurs."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Szl8Rh7qon4W"
      },
      "source": [
        "Pour calculer les valeurs des composantes YCbCr d'une image à partir des composantes RVB (qui varient de 0 à 255), on utilise les formules suivantes :  \r\n",
        "\r\n",
        "$\\left\\{ \\begin{array}{l}\r\n",
        "Y = 0,299R + 0,587V + 0,114B\\\\\r\n",
        "{C_b} =  - 0,1687R - 0,3313V + 0,5B + 128\\\\\r\n",
        "{C_r} = 0,5R - 0,4187V - 0,0813B + 128\r\n",
        "\\end{array} \\right.$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4cxYPfaTntv2"
      },
      "source": [
        "def rgb2ycbcr(img):\r\n",
        "    xform = np.array([[.299, .587, .114], [-.1687, -.3313, .5], [.5, -.4187, -.0813]])\r\n",
        "    ycbcr = img.dot(xform.T)\r\n",
        "    ycbcr[:,:,[1,2]] += 128\r\n",
        "    return np.uint8(ycbcr)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ir4EBq5Ei7oV"
      },
      "source": [
        "images_YCbCr = []\r\n",
        "\r\n",
        "for img in images:\r\n",
        "  images_YCbCr.append(rgb2ycbcr(img))\r\n",
        "\r\n",
        "images_YCbCr = np.array(images_YCbCr,dtype=object)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LerKnfjlmT1G"
      },
      "source": [
        "images_YCbCr[0][:,:,:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QEtBVEXNm9vX"
      },
      "source": [
        "**2. Application d'un facteur d'échelle aléatoire pour créer la luminance basse résolution**  \r\n",
        "Pour créer l'image basse résolution, nous allons simplement utiliser la fonction resize du [module Image de la librairie Pillow](https://pillow.readthedocs.io/en/stable/reference/Image.html?highlight=resize%20image#module-PIL.Image), avec des échelles aléatoires et une interpolation de type bicubique."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6hg60pEbpWOH"
      },
      "source": [
        "Facteurs = [2,3,4]\r\n",
        "\r\n",
        "images_Y_br = []\r\n",
        "\r\n",
        "for img in images_YCbCr:\r\n",
        "  FacteurEchelle = random.randrange(min(Facteurs),max(Facteurs)+1)\r\n",
        "  img_PIL = Image.fromarray(img)\r\n",
        "  img_PIL = img_PIL.resize(((round(img_PIL.size[0]*(1/FacteurEchelle)), round(img_PIL.size[1]*(1/FacteurEchelle)))),Image.BICUBIC)\r\n",
        "  images_Y_br.append(np.array(img_PIL)[:,:,0])\r\n",
        "\r\n",
        "images_Y_br = np.array(images_Y_br,dtype=object)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XvJ6_sUaLl1u"
      },
      "source": [
        "images_Y_br[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lgLmIaXbwbSe"
      },
      "source": [
        "index = random.randrange(0,len(images)+1)\r\n",
        "\r\n",
        "fig, axes = plt.subplots(nrows=1, ncols=3,figsize=(12,12))\r\n",
        "fig.tight_layout()\r\n",
        "ax = axes.ravel()\r\n",
        "\r\n",
        "ax[0].imshow(images[index])\r\n",
        "ax[0].set_title(\"Image originale\")\r\n",
        "\r\n",
        "ax[1].imshow(images_YCbCr[index])\r\n",
        "ax[1].set_title(\"Image YCbCr\")\r\n",
        "\r\n",
        "ax[2].imshow(np.array(images_Y_br[index],dtype='uint8'),cmap='gray')\r\n",
        "ax[2].set_title(\"Luminance (Echelle 1/%d)\" %(images[index].shape[0]/images_Y_br[index].shape[0]))\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vQ3MvyQknz5H"
      },
      "source": [
        "**3. Reconversion de la luminance en haute résolution à l'aide de l'interpolation bicubique**  \r\n",
        "L'agrandissement des images se fait par interpolation. Il existe différentes méthodes : interpolation par plus proche voisin, interpolation bilinéaire, [interpolation bicubique](https://fr.wikipedia.org/wiki/Interpolation_bicubique).  \r\n",
        "\r\n",
        "Dans le domaine du traitement d'images numériques, l'interpolation bicubique est souvent préférée à une interpolation bilinéaire ou à la technique du plus proche voisin pour le ré-échantillonnage d'images, lorsque le temps de traitement n'est pas critique. Contrairement à une interpolation bilinéaire, qui ne prend que 4 pixels (2 × 2) en compte, l'interpolation bicubique considère un voisinage de 16 pixels (4 × 4). Les images ré-échantillonnées par une interpolation bicubique sont donc plus lisses et ont moins d'artefacts d'interpolation. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WcRxJtlp0dQk"
      },
      "source": [
        "Commençons par créer les agrandissements avec l'interpolation bicubique des images en basse résolution :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7YF_nu5jtcwO"
      },
      "source": [
        "images[0].shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H1JUNVZKxwS4"
      },
      "source": [
        "images_Y_hr = []\r\n",
        "\r\n",
        "for index in range(0,len(images_Y_br)):\r\n",
        "  Echelle = images[index].shape[0] // images_Y_br[index].shape[0]\r\n",
        "  img_PIL = Image.fromarray(images_Y_br[index])\r\n",
        "  img_PIL = img_PIL.resize(((round(images_YCbCr[index].shape[1]), round(images_YCbCr[index].shape[0]))),Image.BICUBIC)\r\n",
        "  images_Y_hr.append(np.array(img_PIL))\r\n",
        "\r\n",
        "images_Y_hr = np.array(images_Y_hr,dtype=object)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wndtw2yzy_jV"
      },
      "source": [
        "index = random.randrange(0,len(images)+1)\r\n",
        "\r\n",
        "fig, axes = plt.subplots(nrows=1, ncols=3,figsize=(12,12))\r\n",
        "fig.tight_layout()\r\n",
        "ax = axes.ravel()\r\n",
        "\r\n",
        "ax[0].imshow(images[index])\r\n",
        "ax[0].set_title(\"Image originale (%d)\" %index)\r\n",
        "\r\n",
        "ax[1].imshow(images_YCbCr[index])\r\n",
        "ax[1].set_title(\"Image YCbCr\")\r\n",
        "\r\n",
        "ax[2].imshow(images_Y_br[index],cmap='gray')\r\n",
        "ax[2].set_title(\"Luminance (Echelle 1/%d)\" %(images[index].shape[0]/images_Y_br[index].shape[0]))\r\n",
        "\r\n",
        "fig, axes = plt.subplots(nrows=1, ncols=2,figsize=(12,12))\r\n",
        "fig.tight_layout()\r\n",
        "ax = axes.ravel()\r\n",
        "\r\n",
        "ax[0].imshow(images_YCbCr[index][:,:,0],cmap='gray')\r\n",
        "ax[0].set_title(\"Luminance originale\")\r\n",
        "\r\n",
        "ax[1].imshow(np.array(images_Y_hr[index],dtype='uint8'),cmap='gray')\r\n",
        "ax[1].set_title(\"Luminance HR (bicubique)\")\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-tmPXQpV0ro7"
      },
      "source": [
        "**4. Extraction des luminances résiduelles**  \r\n",
        "Maintenant, sauvegardons les images résiduelles. La construction se fait en simplement en soustrayant les valeurs numériques des pixels de l'image au format YCbCr avec ceux de la luminance :  \r\n",
        "  \r\n",
        "\r\n",
        "![ConstructionImageResiduelle](https://github.com/AlexandreBourrieau/ML/blob/main/Carnets%20Jupyter/Images/construction_img_residuelle.png?raw=true) \r\n",
        "\r\n",
        "Avant d'effectuer le calcul, on normalise les images au type `double` (valeurs flottantes 64 bits) entre [0,1] pour pouvoir gérer les valeurs négatives."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BvzK71RG0z58"
      },
      "source": [
        "images_residuelles_Y = []\r\n",
        "\r\n",
        "for index in range(0,len(images)):\r\n",
        "  images_residuelles_Y.append((images_YCbCr[index][:,:,0].astype('double')/255.0 - images_Y_hr[index].astype('double')/255.0))\r\n",
        "images_residuelles_Y = np.array(images_residuelles_Y,dtype=object)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pu4TcTDTk1qz"
      },
      "source": [
        "images_residuelles_Y[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QgSjbPCGokIy"
      },
      "source": [
        "Pour afficher les images résiduelles, on il faut retransformer les pixels en valeurs comprises entre 0 et 255 en prenant garde de ne pas garder les valeurs négatives :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yYFjCKfArC2Z"
      },
      "source": [
        "np.asarray(images_residuelles_Y[0].clip(0,255)*255.0,dtype='uint8')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zGI9R6zt4cqr"
      },
      "source": [
        "index = random.randrange(0,len(images)+1)\r\n",
        "\r\n",
        "fig, axes = plt.subplots(nrows=1, ncols=2,figsize=(12,12))\r\n",
        "fig.tight_layout()\r\n",
        "ax = axes.ravel()\r\n",
        "\r\n",
        "ax[0].imshow(images[index])\r\n",
        "ax[0].set_title(\"Image originale (%d)\" %index)\r\n",
        "\r\n",
        "ax[1].imshow(np.asarray(images_residuelles_Y[index].clip(0,255)*255.0,dtype='uint8'),cmap='gray')\r\n",
        "ax[1].set_title(\"Image résiduelle Y\")\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MhYy1qSxX-Ij"
      },
      "source": [
        "# Augmentation artificielle du nombre de données pour l'entrainement"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WaaRh9u9YMT5"
      },
      "source": [
        "Les entrées du réseau sont les images en basse résolution qui ont été traitées par interpolation bicubique. Les sorties du réseau sont les images résiduelles.  \r\n",
        "Afin d'augmenter significativement le nombre d'échantillons d'entrainement, les images d'entrées vont être transformées aléatoirement en les pivotant d'un angle soit de 0° ou de 90°, puis en ajoutant un effet miroir horizontal.  \r\n",
        "Le code ci-dessous réalise ces opérations :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J60J_kNGZhyq"
      },
      "source": [
        "# Fonction pour retourner aléatoirement une paire d'images\r\n",
        "# Chaque image de la paire est construite avec les mêmes caractéritiques\r\n",
        "\r\n",
        "def imageDataAugmenter(img):\r\n",
        "  reflexion =random.randrange(0,2)\r\n",
        "  angle = random.randrange(0,2)\r\n",
        "  img_PIL1 = Image.fromarray(img[0])\r\n",
        "  img_PIL1 = img_PIL1.rotate(angle*90)\r\n",
        "  img_PIL2 = Image.fromarray(img[1])\r\n",
        "  img_PIL2 = img_PIL2.rotate(angle*90)\r\n",
        "\r\n",
        "  if reflexion == 0:\r\n",
        "    return(np.array([np.array(img_PIL1),np.array(img_PIL2)]))\r\n",
        "  else:\r\n",
        "    return(np.array(([np.array(ImageOps.flip(img_PIL1)), np.array(ImageOps.flip(img_PIL2))])))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y4GJjnR7fryD"
      },
      "source": [
        "index = random.randrange(0,len(images)+1)\r\n",
        "\r\n",
        "images_augmente = imageDataAugmenter(np.array([images_Y_hr[index], images_residuelles_Y[index]]))\r\n",
        "\r\n",
        "fig, axes = plt.subplots(nrows=1, ncols=2,figsize=(10,10))\r\n",
        "fig.tight_layout()\r\n",
        "ax = axes.ravel()\r\n",
        "\r\n",
        "ax[0].imshow(images_augmente[0],cmap=\"gray\")\r\n",
        "ax[0].set_title(\"Luminance HR bicubique (%d)\" %index)\r\n",
        "\r\n",
        "ax[1].imshow(np.asarray(images_augmente[1].clip(0,255)*255.0,dtype='uint8'),cmap=\"gray\")\r\n",
        "ax[1].set_title(\"Image résiduelle\")\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UUAubCa4bStq"
      },
      "source": [
        "Pour augmenter davantage le nombre des échantillons d'entrainement, les images d'entrées vont maintenant être découpées en petits morceaux de manière aléatoire. Ce procédé est souvent utilisé dans les problèmes de régressions sur les images, offrant la possibilité d'effectuer du traitement en parallèle sur plusieurs réseaux de neurones, chacun s'occupant de traiter des petits morceaux d'images.  \r\n",
        "Pour cela, nous allons utiliser la fonction [extract_patches_2d](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.image.extract_patches_2d.html) disponnible avec Scikit Learn.    "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qLKA1QiaeLUR"
      },
      "source": [
        "taille_morceau = (41,41)\r\n",
        "nbr_morceaux = 64\r\n",
        "\r\n",
        "morceaux = feature_extract.image.extract_patches_2d(images_Y_hr[0], patch_size = taille_morceau,max_patches = nbr_morceaux)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YsvBpNKQE-s-"
      },
      "source": [
        "morceaux[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fNVmrNAz2czU"
      },
      "source": [
        "fig, axes = plt.subplots(nrows=1, ncols=3,figsize=(12,12))\r\n",
        "fig.tight_layout()\r\n",
        "ax = axes.ravel()\r\n",
        "\r\n",
        "ax[0].imshow(morceaux[random.randrange(0,nbr_morceaux)],cmap=\"gray\")\r\n",
        "ax[1].imshow(morceaux[random.randrange(0,nbr_morceaux)],cmap=\"gray\")\r\n",
        "ax[2].imshow(morceaux[random.randrange(0,nbr_morceaux)],cmap=\"gray\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B4U8d4dHhhil"
      },
      "source": [
        "# Création des échantillons (X,Y) d'entrainement pour les itérations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0y6VWKlqho0X"
      },
      "source": [
        "Nous allons maintenant créer des paires d'échantillons (X,Y) qui seront utilisés pendant l'entrainement et qui changeront à chaque itération :  \r\n",
        "\r\n",
        "![ReseauNeurone](https://github.com/AlexandreBourrieau/ML/blob/main/Carnets%20Jupyter/Images/illustration_1.png?raw=true)  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xBEt6jvJGRqo"
      },
      "source": [
        "# Fonction d'extraction aléatoire des morceaux\r\n",
        "# Retourne les morceaux X et Y\r\n",
        "\r\n",
        "def ExtractionMorceauxAleatoire(img,nbr,taille):\r\n",
        "  morceaux_hr = []\r\n",
        "  morceaux_residuelle = []\r\n",
        "\r\n",
        "  for i in range(0,nbr):\r\n",
        "    rnd = random.randrange(0,100000)\r\n",
        "    morceaux_hr.append(np.array(feature_extract.image.extract_patches_2d(img[0], patch_size = taille, max_patches=1, random_state = rnd)))\r\n",
        "    morceaux_residuelle.append(np.array(feature_extract.image.extract_patches_2d(img[1], patch_size = taille, max_patches=1, random_state = rnd)))\r\n",
        "  return(np.array([morceaux_hr, morceaux_residuelle])[:,:,0,:,:])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vj843r9hiEGH"
      },
      "source": [
        "# Création du jeu de données d'entrainement (X,Y)\r\n",
        "\r\n",
        "taille_morceau = (41,41)\r\n",
        "nbr_morceaux = 64\r\n",
        "\r\n",
        "X_partitions = []\r\n",
        "Y_partitions = []\r\n",
        "\r\n",
        "for i in range(0,len(images)):\r\n",
        "  im_aug = imageDataAugmenter(np.array([images_Y_hr[i], images_residuelles_Y[i]]))\r\n",
        "  [X,Y] = np.array(ExtractionMorceauxAleatoire(np.array(im_aug),nbr_morceaux,taille_morceau))\r\n",
        "  X_partitions.append(X)\r\n",
        "  Y_partitions.append(Y)\r\n",
        "X_partitions = np.array(X_partitions,dtype=\"uint8\")\r\n",
        "Y_partitions = np.array(Y_partitions,dtype='double')\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "keNGLfPGLKn0"
      },
      "source": [
        "print(X_partitions.shape)\r\n",
        "print(X_partitions[800][10])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xfsi-P3DDkMF"
      },
      "source": [
        "print(Y_partitions.shape)\r\n",
        "print(Y_partitions[0][0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dziVJgXmOnmU"
      },
      "source": [
        "index = random.randrange(0,nbr_morceaux)\r\n",
        "\r\n",
        "fig, axes = plt.subplots(nrows=3, ncols=2,figsize=(10,10))\r\n",
        "fig.tight_layout()\r\n",
        "ax = axes.ravel()\r\n",
        "\r\n",
        "ax[0].imshow(X_partitions[0,index,:,:],cmap=\"gray\")\r\n",
        "ax[0].set_title(\"Luminance HR bicubique\")\r\n",
        "ax[1].imshow(np.asarray(Y_partitions[0,index,:,:].clip(0,255)*255.0,dtype='uint8'),cmap=\"gray\")\r\n",
        "ax[1].set_title(\"Image résiduelle\")\r\n",
        "\r\n",
        "ax[2].imshow(X_partitions[0,index+1,:,:],cmap=\"gray\")\r\n",
        "ax[3].imshow(np.asarray(Y_partitions[0,index+1,:,:].clip(0,255)*255.0,dtype='uint8'),cmap=\"gray\")\r\n",
        "\r\n",
        "ax[4].imshow(X_partitions[0,index+2,:,:],cmap=\"gray\")\r\n",
        "ax[5].imshow(np.asarray(Y_partitions[0,index+2,:,:].clip(0,255)*255.0,dtype='uint8'),cmap=\"gray\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q5icivJ7wgJI"
      },
      "source": [
        "# Préparation des données pour Keras "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_kA6FfPwwqad"
      },
      "source": [
        "Le format des données dans les variables X_Partitions et Y_Partitions est : (916,64,41,41) - ce qui représente 916 ensembles de 64 morceaux d'images de 41x41 pixels.  \r\n",
        "On va transformer ce format en un nouveau format pour les données d'entrées dans Keras : (916*64,41,41) = (58624,41,41) - ce qui représente 58624 morceaux d'images de 41x41 pixels. Avec un batch_size de 64, chaque ensemble de 64 morceaux sera traité à chaque itération.  \r\n",
        "\r\n",
        "Enfin, on réserve 10% des données pour les tests et on normalise les données en type à virgule flottante sur 64 bits, compris entre 0.0 et 1.0\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ez_dy7xp5-8x"
      },
      "source": [
        "**1. Reformatage des données au format (916,64,41,41) en un format (58624,41,41)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Kv4JO_3lAoL"
      },
      "source": [
        "X_partitions.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u9pSz4EGk0yF"
      },
      "source": [
        "x_entrainement = X_partitions.reshape(916*64,41,41)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E59wNZ9OlLmc"
      },
      "source": [
        "print(x_entrainement.shape)\r\n",
        "print(x_entrainement[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T_Oymp2xlOsc"
      },
      "source": [
        "index = random.randrange(0,nbr_morceaux)\r\n",
        "\r\n",
        "fig, axes = plt.subplots(nrows=1, ncols=2,figsize=(10,10))\r\n",
        "fig.tight_layout()\r\n",
        "ax = axes.ravel()\r\n",
        "\r\n",
        "ax[0].imshow(X_partitions[1][index],cmap=\"gray\")\r\n",
        "ax[0].set_title(\"X_Partition[1][%d] (luminance bicubique)\" %index)\r\n",
        "ax[1].imshow(x_entrainement[index+64],cmap=\"gray\")\r\n",
        "ax[1].set_title(\"x_entrainement[%d] (liminance bicubique)\" %(index+64))\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7eqHlwfIrWCw"
      },
      "source": [
        "# Modification du format des données et\r\n",
        "# séparation les données d'entrainement et de test\r\n",
        " \r\n",
        "x_entrainement, x_test, y_entrainement, y_test = train_test_split(X_partitions.reshape(916*64,41,41), Y_partitions.reshape(916*64,41,41), test_size=0.1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gTTH-h-LrmgG"
      },
      "source": [
        "print(x_entrainement.shape)\r\n",
        "print(x_entrainement[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9YXPi-naICF1"
      },
      "source": [
        "print(y_entrainement.shape)\r\n",
        "print(y_entrainement[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KmfRhMWSanOg"
      },
      "source": [
        "index = random.randrange(0,nbr_morceaux)\r\n",
        "\r\n",
        "fig, axes = plt.subplots(nrows=1, ncols=2,figsize=(10,10))\r\n",
        "fig.tight_layout()\r\n",
        "ax = axes.ravel()\r\n",
        "\r\n",
        "ax[0].imshow(x_entrainement[index],cmap=\"gray\")\r\n",
        "ax[0].set_title(\"x_entrainement[%d] (luminance bicubique)\" %index)\r\n",
        "ax[1].imshow(np.array(y_entrainement[index].clip(0,255)*255.0).astype('uint8'),cmap=\"gray\")\r\n",
        "ax[1].set_title(\"y_entrainement[%d] (image résiduelle)\" %index)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OiswQRHN6YHg"
      },
      "source": [
        "**2. Structuration des données d'entrée pour Keras au format \"channels_first\" et normalisation des valeurs**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MsjheFK3qOjs"
      },
      "source": [
        "Les données sont structurées afin d'être compatibles avec la forme d'entrée attendue par Keras :  \r\n",
        "- Soit du type : (RGB, hauteur, largeur)\r\n",
        "- Soit du type : (hauteur, largeur, RGB)  \r\n",
        "  \r\n",
        "Ensuite, on normalise les données X en type flottant 64 bits, dont les valeurs sont comprises entre 0.0 et 1.0."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gyC0RKKIwwVY"
      },
      "source": [
        "# Choix du format des données\r\n",
        "choix = \"channels_first\"\r\n",
        "K.set_image_data_format(choix)\r\n",
        "\r\n",
        "if K.image_data_format() == 'channels_first':\r\n",
        "    x_entrainement = x_entrainement.reshape(x_entrainement.shape[0], 1, 41, 41)\r\n",
        "    x_test = x_test.reshape(x_test.shape[0], 1, 41, 41)\r\n",
        "    y_entrainement = y_entrainement.reshape(y_entrainement.shape[0], 1, 41, 41)\r\n",
        "    y_test = y_test.reshape(y_test.shape[0], 1, 41, 41)\r\n",
        "    input_shape = (1, 41, 41)\r\n",
        "else:\r\n",
        "    x_entrainement = x_entrainement.reshape(x_entrainement.shape[0], 41, 41, 1)\r\n",
        "    x_test = x_test.reshape(x_test.shape[0], 41, 41, 1)\r\n",
        "    y_entrainement = y_entrainement.reshape(y_entrainement.shape[0], 41, 41, 1)\r\n",
        "    y_test = y_test.reshape(y_test.shape[0], 41, 41, 1)\r\n",
        "    input_shape = (41, 41, 1)\r\n",
        "\r\n",
        "x_entrainement = x_entrainement.astype('double')/255.0\r\n",
        "x_test = x_test.astype('double')/255.0\r\n",
        "\r\n",
        "print(x_entrainement.shape[0], 'train samples')\r\n",
        "print(x_test.shape[0], 'test samples')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "umR2gvd2mkam"
      },
      "source": [
        "print(x_entrainement.shape)\r\n",
        "print(x_entrainement[0])\r\n",
        "print(y_entrainement.shape)\r\n",
        "print(y_entrainement[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5e3oLijLmtOY"
      },
      "source": [
        "# Définition de la structure du réseau VDSR"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4GvydIJDm0aP"
      },
      "source": [
        "La structure du réseau de neurones VDSR est la suivante :\r\n",
        "- Une couche de **convolution 2D** avec **64 filtres** à convolution de **3x3 pixels**, un **padding de type same** avec un **stride de 1** (ajout d'une colonne à gauche et à droite de l'entrée et d'une ligne en haut et à bas de l'entrée). La sortie a donc la même dimension que l'entrée. Chaque couche de convolution 2D est suivie d'une **fonction d'activation de type ReLU** qui introduit une non-linéarité dans le réseau.  \r\n",
        "Les **poids sont initialisés** [**méthode de Kaiming**](https://paperswithcode.com/method/he-initialization). Cette méthode initialise les poids avec des valeurs aléatoires tirées d'une distribution normale à valeur moyenne nulle et à variance égale à 2/(3x3x1) (filtres 3x3 et images en N&B donc 1 canal).  \r\n",
        "Les **offsets sont initialisés par défaut à zéros**.\r\n",
        "- 18 paires de **couches cachées**. Chaque paire est constituée de :\r\n",
        "    - Une couche de **convolution 2D** avec **64 filtres** à convolution de **3x3 pixels**, un **padding de type same** avec un **stride de 1**. Les **poids sont initialisés avec la méthode de Kaiming** et les **offsets sont initialisés par défaut à zéros**.\r\n",
        "    - Une **fonction d'activation de type ReLU**.\r\n",
        "- Une **couche de convolution 2D** avec **un seul filtre de 3x3 pixels** sans fonction d'activation de sortie. Le but de cette couche de sortie est de reconstruire l'image. Les autres caractéristiques sont identiques aux couches de convolutions précédentes.  \r\n",
        "\r\n",
        "\r\n",
        "**Régularisation L2** \r\n",
        "\r\n",
        ">La régularisation L2 ajoute un terme de régularisation aux poids de la fonction de pertes. Les offsets ne sont pas régularisés. Cela permet de réduire le sur-apprentissage."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u1Z1Mchuv7et"
      },
      "source": [
        "# Construction du modèle VDSR\r\n",
        "\r\n",
        "l2reg = 0.0001\r\n",
        "\r\n",
        "model = Sequential()\r\n",
        "model.add(Conv2D(64, kernel_size=(3, 3), padding=\"same\", activation='relu', kernel_initializer=\"he_normal\", input_shape=input_shape,  kernel_regularizer=regularizers.l2(l=l2reg)))\r\n",
        "\r\n",
        "for i in range(0,18):\r\n",
        "  model.add(Conv2D(64, kernel_size=(3, 3), padding=\"same\", activation='relu', kernel_initializer=\"he_normal\", kernel_regularizer=regularizers.l2(l=l2reg)))\r\n",
        "\r\n",
        "model.add(Conv2D(1, kernel_size=(3, 3), padding=\"same\", kernel_initializer=\"he_normal\", kernel_regularizer=regularizers.l2(l=l2reg)))\r\n",
        "\r\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u1aNBWjh5IwE"
      },
      "source": [
        "# Entrainement du modèle"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nKNeGUCGHknL"
      },
      "source": [
        "Ce modèle étant un modèle particulièrement lourd, nous allons optimiser les calculs lors de l'entrainement en jouant sur les paramètres suivants :\r\n",
        "- Le type d'algorithme choisi est l'algotithme du gradient stochastique avec moment\r\n",
        "- Le taux d'apprentissage va décroitre pendant l'entrainement\r\n",
        "- La valeur du gradient d'un paramètre d'apprentissage doit rester dans un intervalle donné"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "98RBDv3f5jY0"
      },
      "source": [
        "**Type d'algorithme utilisé**  \r\n",
        "\r\n",
        ">Le calcul de l'erreur est basé sur **l'erreur quadratique moyenne**, et l'optimiseur utilisé est de type **SGDM (stochastic gradient descent with momentum - [Algorithme du gradient stochastique avec moment](https://fr.wikipedia.org/wiki/Algorithme_du_gradient_stochastique))**. Contrairement à la méthode de descente du gradient que nous avons étudiée précédemment, cette méthode stochastique calcule les dérivées des fonctions de coût par rapport aux poids et aux offsets à des points choisis aléatoirement. Par conséquent, le nombre de calculs effectués décroit. La valeur du moment est choisie à 0.9.\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "**Décroissance du taux d'apprentissage pendant l'entrainement**  \r\n",
        "\r\n",
        ">Le **taux d'apprentissage** est réglé initialement sur une valeur de 0.1 et paramétré pour décroitre d'un facteur de 0.1 toutes les 10 périodes. Ce réglage se fait en utilisant l'api [learning rate schedules](https://keras.io/api/optimizers/learning_rate_schedules/) de Keras, en particulier en utilisant une paramétrisation temporelle du taux d'apprentissage ([Inverse Time Decay](https://keras.io/api/optimizers/learning_rate_schedules/inverse_time_decay/)).  \r\n",
        "  \r\n",
        "\r\n",
        "\r\n",
        "**Surveillance des valeurs du gradients** \r\n",
        "\r\n",
        ">L'entrainement d'un modèle d'apprentissage profond demande beaucoup de temps. On peut augmenter le taux d'apprentissage pour le réduire mais cela peut engendrer une divergence de l'algorithme du gradient et un échec d'apprentissage du réseau. Afin de garder le gradient dans un intervalle significatif, nous utilisons la fonction de coupure du gradient (gradient clipping method). Vous trouverez [sur cette page](https://machinelearningmastery.com/how-to-avoid-exploding-gradients-in-neural-networks-with-gradient-clipping/) différentes méthodes pour éviter les problèmes de divergence de gradient. On fait en sorte que si la norme L2 (racine carré de la somme des composantes au carré) du gradient d'un pramètre d'apprentissage dépasse la valeur 0.01, alors le gradient est mis à l'échelle de sorte que sa norme L2 soit égale à 0.01.  \r\n",
        "\r\n",
        "**Personnalisation de la fonction d'objectif**  \r\n",
        ">Nous allons utiliser l'erreur quadratique moyenne divisée par deux (half mean squared error) :  \r\n",
        ">\r\n",
        ">$erreur = \\frac{1}{2}\\sum\\limits_{p = 1}^{HLC} {{{\\left( {{y_p} - {{\\hat y}_p}} \\right)}^2}}$  \r\n",
        "  >\r\n",
        ">\r\n",
        ">Avec :  \r\n",
        "  - ${y_p}$ : Valeur de la sortie attendue sur le pixel $p$\r\n",
        "  - ${\\hat y_p}$ : Valeur de la sortie estimée par le modèle sur le pixel $p$\r\n",
        "  - $H$, $L$, $C$ : Hauteur, largeur et canaux de l'image  \r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "**Personnalisation de la métrique**  \r\n",
        ">Pour la métrique, nous allons afficher la racine carrée de l'erreur quadratique moyenne (Root Mean Squared Error - RMSE) ainsi que le pourcentage d'erreur (accurancy).\r\n",
        "\r\n",
        "Le **nombre de périodes** est réglé sur 100. Puisque nous avons réservé 90% des ensembles de morceaux pour l'entrainement, il y aura donc 0.9*916 = environ 825 ensembles de 64 morceaux calculés à chaque période. Comme la valeur du batch_size est de 64, à chaque itération l'algorithme traite 64 morceaux. Il y aura donc 825 itérations par période. \r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m3-cCsmx5LOE"
      },
      "source": [
        "periodes = 100\r\n",
        "batch_size = 64\r\n",
        "\r\n",
        "# Définition des paramètres liés à l'évolution du taux d'apprentissage\r\n",
        "lr_schedule = schedules.InverseTimeDecay(\r\n",
        "    initial_learning_rate=0.1,\r\n",
        "    decay_steps=10,\r\n",
        "    decay_rate=0.1)\r\n",
        "\r\n",
        "# Définition de la fonction d'objectif\r\n",
        "# format y_predit  : (64,1,41,41)\r\n",
        "# format y_attendu : (64,1,41,41)\r\n",
        "def keras_half_mean_squared_function(y_attendu, y_predit):\r\n",
        "  erreur = K.sum(K.square(y_attendu[:,0,:,:] - y_predit[:,0,:,:]))\r\n",
        "  return(0.5*erreur/batch_size)\r\n",
        "\r\n",
        "#definition de la métrique\r\n",
        "def keras_mean_squared_metric(y_attendu, y_predit):\r\n",
        "  erreur = K.sqrt(K.mean(K.square(y_attendu[:,0,:,:] - y_predit[:,0,:,:])))\r\n",
        "  return(erreur)\r\n",
        "\r\n",
        "model.compile(loss=keras_half_mean_squared_function, optimizer=SGD(learning_rate=lr_schedule, momentum=0.9, clipnorm=0.01), metrics=[keras_mean_squared_metric, 'acc'])\r\n",
        "\r\n",
        "historique = model.fit(x_entrainement, y_entrainement, batch_size=batch_size, epochs=periodes, verbose=1, validation_data=(x_test, y_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QwFi3CArKwFK"
      },
      "source": [
        "Affichons les informations sur la précision du modèle après entrainement :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MyaJToh2K0-q"
      },
      "source": [
        "# Evalue la précision du modèle avec les données de tests\r\n",
        "score = model.evaluate(x_test, y_test, verbose=0)\r\n",
        "print('Pertes (Test) :', score[0])\r\n",
        "print('Précision (Test) :', score[1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1EDDaHhktx_G"
      },
      "source": [
        "# Sauvegarde du modèle"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jsTPZulgt06P"
      },
      "source": [
        "model_structure = model.to_json()\r\n",
        "with open(\"model.json\", \"w\") as json_file:\r\n",
        "    json_file.write(model_structure)\r\n",
        "model.save_weights(\"weights.h5\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ezV0nL7PCNfl"
      },
      "source": [
        "from google.colab import files\r\n",
        "files.download('model.json')\r\n",
        "files.download('weights.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v6DN0rgDt__n"
      },
      "source": [
        "# Chargement du modèle entrainé sous Google Colab"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WFgR6dd61PhX"
      },
      "source": [
        "!wget --no-check-certificate --content-disposition \"https://github.com/AlexandreBourrieau/ML/blob/main/Carnets%20Jupyter/modeles/models.zip?raw=true\"\r\n",
        "!unzip \"models.zip\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DK7qONCNnYt-"
      },
      "source": [
        "with open('model-916-2_3_4.json', 'r') as json_file:\r\n",
        "    loaded_model_json = json_file.read()\r\n",
        "rmodel = model_from_json(loaded_model_json)\r\n",
        "rmodel.load_weights(\"weights-916-2_3_4.h5\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MIQxjVBbuC3P"
      },
      "source": [
        "periodes = 100\r\n",
        "batch_size = 64\r\n",
        "\r\n",
        "# Définition des paramètres liés à l'évolution du taux d'apprentissage\r\n",
        "lr_schedule = schedules.InverseTimeDecay(\r\n",
        "    initial_learning_rate=0.1,\r\n",
        "    decay_steps=10,\r\n",
        "    decay_rate=0.1)\r\n",
        "\r\n",
        "# Définition de la fonction d'objectif\r\n",
        "# format y_predit  : (64,1,41,41)\r\n",
        "# format y_attendu : (64,1,41,41)\r\n",
        "def keras_half_mean_squared_function(y_attendu, y_predit):\r\n",
        "  erreur = K.sum(K.square(y_attendu[:,0,:,:] - y_predit[:,0,:,:]))\r\n",
        "  return(0.5*erreur/batch_size)\r\n",
        "\r\n",
        "#definition de la métrique\r\n",
        "def keras_mean_squared_metric(y_attendu, y_predit):\r\n",
        "  erreur = K.sqrt(K.mean(K.square(y_attendu[:,0,:,:] - y_predit[:,0,:,:])))\r\n",
        "  return(erreur)\r\n",
        "\r\n",
        "rmodel2.compile(loss=keras_half_mean_squared_function, optimizer=SGD(learning_rate=lr_schedule, momentum=0.9, clipnorm=0.01), metrics=[keras_mean_squared_metric, 'acc'])\r\n",
        "rmodel2.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PfSGq3kQlFxV"
      },
      "source": [
        "batch_size = 64\r\n",
        "\r\n",
        "score = rmodel.evaluate(x=x_test, y=y_test, batch_size=batch_size, verbose=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aXYZ2hPLmaDc"
      },
      "source": [
        "# Prédictions avec le modèle de Google Colab"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HbaI-VlPm096"
      },
      "source": [
        "Effectuons quelques prédictions sur les images de tests afin d'observer les différences obtenues entre ce qui est attendu et ce qui est estimé."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0TkHY6uNvtWw"
      },
      "source": [
        "x_test.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nPtAEK__mXji"
      },
      "source": [
        "index = random.randrange(0,len(x_test))\r\n",
        "\r\n",
        "y_prediction = rmodel.predict(x_test[index].reshape(1,1,41,41))[0,0,:,:]\r\n",
        "\r\n",
        "fig, axes = plt.subplots(nrows=1, ncols=3,figsize=(10,10))\r\n",
        "fig.tight_layout()\r\n",
        "ax = axes.ravel()\r\n",
        "\r\n",
        "ax[0].imshow(x_test[index][0,:,:],cmap=\"gray\")\r\n",
        "ax[0].set_title(\"Entrée (luminance bicubique)\")\r\n",
        "ax[1].imshow(y_test[index][0,:,:],cmap=\"gray\")\r\n",
        "ax[1].set_title(\"Sortie attendue (image résiduelle)\")\r\n",
        "ax[2].imshow(y_prediction,cmap=\"gray\")\r\n",
        "ax[2].set_title(\"Prédiction (image résiduelle)\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FyLNQm9uvRR7"
      },
      "source": [
        "# Chargement du modèle au format ONNX"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uGLCfIgovTf3"
      },
      "source": [
        "Le modèle a été entrainé sur Matlab et exporté au format [ONNX](https://onnx.ai/) (Open Neural Network Exchange).  \r\n",
        "Ce [fichier](https://github.com/AlexandreBourrieau/ML/blob/main/Carnets%20Jupyter/modeles/VDSR_export.onnx?raw=true) peut être lu par exemple avec l'application [Netron](https://github.com/lutzroeder/Netron) afin d'en visualiser la structure et les différents paramètres."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iA9CMuvCvXs4"
      },
      "source": [
        "!wget --no-check-certificate --content-disposition \"https://github.com/AlexandreBourrieau/ML/blob/main/Carnets%20Jupyter/modeles/VDSR_export.onnx?raw=true\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "suwgQXCAy2CW"
      },
      "source": [
        "Pour importer notre modèle dans Keras, nous allons utiliser la librairie [onnx2keras](https://github.com/nerox8664/onnx2keras)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nmXA3l-KzDWf"
      },
      "source": [
        "!pip install onnx onnx2keras --quiet"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UrcjDxXNzwLv"
      },
      "source": [
        "import onnx\r\n",
        "from onnx2keras import onnx_to_keras\r\n",
        "\r\n",
        "# Chargement du modèle ONNX\r\n",
        "onnx_model = onnx.load('VDSR_export.onnx')\r\n",
        "\r\n",
        "# Conversion du modèle (input : nom de l'entrée du modèle entrainé)\r\n",
        "k_model = onnx_to_keras(onnx_model, ['InputLayer'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t666NBtX0ihR"
      },
      "source": [
        "k_model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gW2M_2l801ft"
      },
      "source": [
        "lr_schedule = schedules.InverseTimeDecay(\r\n",
        "    initial_learning_rate=0.1,\r\n",
        "    decay_steps=10,\r\n",
        "    decay_rate=0.1)\r\n",
        "\r\n",
        "def keras_half_mean_squared_function(y_attendu, y_predit):\r\n",
        "  erreur = K.sum(K.square(y_attendu[:,0,:,:] - y_predit[:,0,:,:]))\r\n",
        "  return(0.5*erreur/batch_size)\r\n",
        "\r\n",
        "def keras_mean_squared_metric(y_attendu, y_predit):\r\n",
        "  erreur = K.sqrt(K.mean(K.square(y_attendu[:,0,:,:] - y_predit[:,0,:,:])))\r\n",
        "  return(erreur)\r\n",
        "\r\n",
        "k_model.compile(loss=keras_half_mean_squared_function, optimizer=SGD(learning_rate=lr_schedule, momentum=0.9, clipnorm=0.01), metrics=[keras_mean_squared_metric, 'acc'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fdx7pgVgA7Qv"
      },
      "source": [
        "x_test.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s6O_2ALWBf1t"
      },
      "source": [
        "batch_size = 64\r\n",
        "\r\n",
        "score = k_model.evaluate(x=x_test, y=y_test, batch_size=batch_size, verbose=1)\r\n",
        "print('Pertes (Test) :', score[0])\r\n",
        "print('Précision (Test) :', score[1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-J2W9RuSFNCZ"
      },
      "source": [
        "# Prédiction d'une image entière "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8cD4RlHXXyut"
      },
      "source": [
        "**1. Découpage de l'image en morceaux**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zPc0tmU8HDBb"
      },
      "source": [
        "Pour réaliser la prédiction sur une image entière, il faut tout d'abord la découper en morceaux de taille équivalente aux dimensions des images utilisées pour l'entrainement du modèle (41x41 pixels). Ensuite, il faut agencer ces morceaux les uns à la suite des autres dans un vecteur dont le format est compatible avec celui du modèle d'entrée (none, 1, 41, 41).  \r\n",
        "\r\n",
        "Voici l'exemple à suivre pour transformer une image de (360x480) en 20 morceaux de (100x100) :  \r\n",
        "\r\n",
        "![ReseauNeurone](https://github.com/AlexandreBourrieau/ML/blob/main/Carnets%20Jupyter/Images/decoupage_images.png?raw=true) "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HJ4EnBQB18T7"
      },
      "source": [
        "image = images_Y_hr[3]\r\n",
        "plt.figure(figsize=(10,10))\r\n",
        "plt.imshow(image,cmap=\"gray\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nYJs4riiHtT1"
      },
      "source": [
        "Affichons le format de cette image :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KI7NIPFK6wQB"
      },
      "source": [
        "np.array(image).shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QEJJtI_7Hwh_"
      },
      "source": [
        "Transformons cette image au format (1, hauteur, largeur, 1) qui est demandé par la fonction de tensorflow [extract_patches](https://www.tensorflow.org/api_docs/python/tf/image/extract_patches) permettant de découper les tenseurs puis réalisons le découpage de l'image :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CAIDNODi9gTx"
      },
      "source": [
        "np.array([[image]]).reshape(1,image.shape[0],image.shape[1],1).shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g9e1k4xR5rz3"
      },
      "source": [
        "taille_morceaux = [1,100,100,1]\r\n",
        "morceaux = extract_patches(np.array([[image]]).reshape(1,image.shape[0],image.shape[1],1), sizes = taille_morceaux, strides=taille_morceaux, rates = [1,1,1,1], padding='SAME')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hg3kr57jIOpJ"
      },
      "source": [
        "La variable retournée est de la forme (1,A,B,C) avec :\r\n",
        "- A : Nombre de paquets \"verticaux\" au format découpés \r\n",
        "- B : Nombre de paquets \"horizontaux\" au format découpé "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xqqA1xxq_DL8"
      },
      "source": [
        "morceaux.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nHykSeZQQokG"
      },
      "source": [
        "On transforme maintenant le format afin d'avoir les morceaux agencé dans le tenseur :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dXj-eRgo8Pqx"
      },
      "source": [
        "n_X = morceaux[0].shape[1]\r\n",
        "n_Y = morceaux[0].shape[0]\r\n",
        "\r\n",
        "morceaux = np.reshape(morceaux[0],(morceaux[0].shape[0]*morceaux[0].shape[1],taille_morceaux[1],taille_morceaux[2]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x7oU-dRDDX4F"
      },
      "source": [
        "print(morceaux.shape)\r\n",
        "print(morceaux[0,:,:])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RM95CfLmQ1CN"
      },
      "source": [
        "Reconstituons l'image à l'aide des morceaux :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "thwTQf2SVzmM"
      },
      "source": [
        "fig = plt.figure(figsize=(10,10))\r\n",
        "ax = [fig.add_subplot(n_Y,n_X,i+1) for i in range(n_X*n_Y)]\r\n",
        "\r\n",
        "k=0\r\n",
        "for a in ax:\r\n",
        "    a.imshow(morceaux[k,:,:],cmap=\"gray\")\r\n",
        "    a.set_xticklabels([])\r\n",
        "    a.set_yticklabels([])\r\n",
        "    a.set_aspect('equal')\r\n",
        "    k=k+1\r\n",
        "fig.subplots_adjust(wspace=0, hspace=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZtOSRJpMX7ph"
      },
      "source": [
        "**2. Prédiction de l'image**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "plcupZyHbHKo"
      },
      "source": [
        "On commence par découper l'image au format (41x41) puis adapter le tenseur d'entrée au format (None,1,41,41)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BfUqJN0lbWkd"
      },
      "source": [
        "# Charge l'image dans la variable image\r\n",
        "image = images_Y_hr[3]\r\n",
        "sortie_attendue =  images_residuelles_Y[3]\r\n",
        "\r\n",
        "hauteur_image = image.shape[0]\r\n",
        "largeur_image = image.shape[1]\r\n",
        "\r\n",
        "# Découpe l'image en morceaux de (41x41) pixels\r\n",
        "taille_morceaux = [1,41,41,1]\r\n",
        "morceaux = extract_patches(np.array([[image]]).reshape(1,image.shape[0],image.shape[1],1), sizes = taille_morceaux, strides=taille_morceaux, rates = [1,1,1,1], padding='SAME')\r\n",
        "\r\n",
        "# Sauvegardes le nombres de morceaux verticaux et horizontaux\r\n",
        "n_Y = morceaux[0].shape[0]\r\n",
        "n_X = morceaux[0].shape[1]\r\n",
        "\r\n",
        "# Modifie le format des morceaux au format (nombre_morceaux,41,41)\r\n",
        "morceaux = np.reshape(morceaux[0],(morceaux[0].shape[0]*morceaux[0].shape[1],1,taille_morceaux[1],taille_morceaux[2]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gQalc5xvb2Z5"
      },
      "source": [
        "morceaux.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wJIYMWKb5dIl"
      },
      "source": [
        "morceaux[0,0,:,:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HAuzEEc0du8v"
      },
      "source": [
        "On lance le modèle puis on récupère les morceaux :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "igMbrp8kdt4R"
      },
      "source": [
        "prediction = k_model.predict(morceaux.astype('double')/255.0)\r\n",
        "prediction = (prediction.clip(0,255)*255.0).astype(\"uint8\")\r\n",
        "prediction.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vnBJrRsz5hnS"
      },
      "source": [
        "prediction[0,0,:,:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mX5zext9a4sJ"
      },
      "source": [
        "fig = plt.figure(figsize=(10,10))\r\n",
        "ax = [fig.add_subplot(n_Y,n_X,i+1) for i in range(n_X*n_Y)]\r\n",
        "\r\n",
        "k=0\r\n",
        "for a in ax:\r\n",
        "    a.imshow(prediction[k,0,:,:],cmap=\"gray\")\r\n",
        "    a.set_xticklabels([])\r\n",
        "    a.set_yticklabels([])\r\n",
        "    a.set_aspect('equal')\r\n",
        "    k=k+1\r\n",
        "fig.subplots_adjust(wspace=0, hspace=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Si2FeJmcej9V"
      },
      "source": [
        "On assemble les morceaux pour recréer l'image :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5H4AHyOmmw6B"
      },
      "source": [
        "prediction.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kV5z0M1dk0sF"
      },
      "source": [
        "# Fonction pour ré-assembler l'image à partir des morceaux\r\n",
        "def ReassemblageImage(img, n_X, n_Y):\r\n",
        "  reconstruction = np.zeros([n_Y*41,n_X*41],dtype=np.uint8)\r\n",
        "  k=0\r\n",
        "\r\n",
        "  for i in range(0,n_Y):\r\n",
        "    for j in range(0,n_X):\r\n",
        "      reconstruction[i*41:i*41+41,j*41:j*41+41]=img[k,:,:]\r\n",
        "      k = k+1\r\n",
        "  return(reconstruction)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BiM20H1glBps"
      },
      "source": [
        "rec = ReassemblageImage(prediction,n_X,n_Y)\r\n",
        "\r\n",
        "fig, axes = plt.subplots(nrows=1, ncols=2,figsize=(20,20))\r\n",
        "fig.tight_layout()\r\n",
        "ax = axes.ravel()\r\n",
        "\r\n",
        "ax[0].imshow(np.array(rec),cmap=\"gray\")\r\n",
        "ax[0].set_title(\"Image prédite\")\r\n",
        "\r\n",
        "ax[1].imshow(np.array(sortie_attendue.clip(0,255.0)*255.0,dtype='uint8'),cmap=\"gray\")\r\n",
        "ax[1].set_title(\"Sortie attendue\")\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wN_wpCh1g84u"
      },
      "source": [
        "fig, axes = plt.subplots(nrows=1, ncols=3,figsize=(20,20))\r\n",
        "fig.tight_layout()\r\n",
        "ax = axes.ravel()\r\n",
        "\r\n",
        "ax[0].imshow(image,cmap=\"gray\")\r\n",
        "ax[0].set_title(\"Entrée (luminance bicubique)\")\r\n",
        "ax[1].imshow(np.array((sortie_attendue).clip(0,255.0)*255.0,dtype='uint8'),cmap=\"gray\")\r\n",
        "ax[1].set_title(\"Sortie attendue (image résiduelle)\")\r\n",
        "ax[2].imshow(rec,cmap=\"gray\")\r\n",
        "ax[2].set_title(\"Prédiction (image résiduelle)\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kzZqNtxjTUtJ"
      },
      "source": [
        "Voici quelques prédiction aléatoires :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XcIG5uOgUDVc"
      },
      "source": [
        "# Définition d'une fonction de prédiction d'une image entière\r\n",
        "def Prediction_Image_Entiere(image):\r\n",
        "  hauteur_image = image.shape[0]\r\n",
        "  largeur_image = image.shape[1]\r\n",
        "\r\n",
        "  # Découpe l'image en morceaux de (41x41) pixels\r\n",
        "  taille_morceaux = [1,41,41,1]\r\n",
        "  morceaux = extract_patches(np.array([[image]]).reshape(1,image.shape[0],image.shape[1],1), sizes = taille_morceaux, strides=taille_morceaux, rates = [1,1,1,1], padding='SAME')\r\n",
        "\r\n",
        "  # Sauvegardes le nombres de morceaux verticaux et horizontaux\r\n",
        "  n_Y = morceaux[0].shape[0]\r\n",
        "  n_X = morceaux[0].shape[1]\r\n",
        "\r\n",
        "  # Modifie le format des morceaux au format (nombre_morceaux,41,41)\r\n",
        "  morceaux = np.reshape(morceaux[0],(morceaux[0].shape[0]*morceaux[0].shape[1],1,taille_morceaux[1],taille_morceaux[2]))\r\n",
        "\r\n",
        "  # Lance la prédiction\r\n",
        "  prediction = k_model.predict(morceaux.astype('double')/255.0)\r\n",
        "  prediction = (prediction.clip(0,255)*255.0).astype(\"uint8\")\r\n",
        "\r\n",
        "  # Ré-assemble l'image\r\n",
        "  rec = ReassemblageImage(prediction,n_X,n_Y)\r\n",
        "  return(rec)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CrFgOO-uTaXP"
      },
      "source": [
        "# Charge l'image dans la variable image\r\n",
        "index = random.randrange(0,916);\r\n",
        "\r\n",
        "image = images_Y_hr[index]\r\n",
        "sortie_attendue =  images_residuelles_Y[index]\r\n",
        "\r\n",
        "rec = Prediction_Image_Entiere(image)\r\n",
        "\r\n",
        "# Affiche les résultats\r\n",
        "fig, axes = plt.subplots(nrows=1, ncols=3,figsize=(20,20))\r\n",
        "fig.tight_layout()\r\n",
        "ax = axes.ravel()\r\n",
        "\r\n",
        "ax[0].imshow(image,cmap=\"gray\")\r\n",
        "ax[0].set_title(\"Entrée (luminance bicubique)\")\r\n",
        "ax[1].imshow(np.array((sortie_attendue).clip(0,255.0)*255.0,dtype='uint8'),cmap=\"gray\")\r\n",
        "ax[1].set_title(\"Sortie attendue (image résiduelle)\")\r\n",
        "ax[2].imshow(rec,cmap=\"gray\")\r\n",
        "ax[2].set_title(\"Prédiction (image résiduelle)\")\r\n",
        "\r\n",
        "fig, axes = plt.subplots(nrows=1, ncols=2,figsize=(20,20))\r\n",
        "fig.tight_layout()\r\n",
        "ax = axes.ravel()\r\n",
        "\r\n",
        "ax[0].imshow(np.array(sortie_attendue.clip(0,255.0)*255.0,dtype='uint8'),cmap=\"gray\")\r\n",
        "ax[0].set_title(\"Sortie attendue (image résiduelle)\")\r\n",
        "ax[1].imshow(np.array(rec),cmap=\"gray\")\r\n",
        "ax[1].set_title(\"Prédiciton (image résiduelle)\")\r\n",
        "\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bnoOApEgdsD1"
      },
      "source": [
        "# Application de l'algorithme pour augmenter la résolution d'une image "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KY0edSwVgVLK"
      },
      "source": [
        "Pour réaliser l'augmentation de la résolution d'une image basse résolution avec le réseau VDSR, il faut suivre la procédure suivante :"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zeDnKBlRg2vq"
      },
      "source": [
        "![ConstructionHR](https://github.com/AlexandreBourrieau/ML/blob/main/Carnets%20Jupyter/Images/ConstructionImgAugmentee.png?raw=true) "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S3Oefp07n-Oi"
      },
      "source": [
        "taille_morceaux = [1,41,41,1]\r\n",
        "\r\n",
        "# Converison RGB => YCbCr\r\n",
        "def rgb2ycbcr(img):\r\n",
        "    xform = np.array([[.299, .587, .114], [-.1687, -.3313, .5], [.5, -.4187, -.0813]])\r\n",
        "    ycbcr = img.dot(xform.T)\r\n",
        "    ycbcr[:,:,[1,2]] += 128\r\n",
        "    return np.uint8(ycbcr)\r\n",
        "\r\n",
        "# Fonction pour ré-assembler l'image à partir des morceaux\r\n",
        "def ReassemblageImage(img, n_X, n_Y):\r\n",
        "  reconstruction = np.zeros([n_Y*41,n_X*41],dtype=np.uint8)\r\n",
        "  k=0\r\n",
        "\r\n",
        "  for i in range(0,n_Y):\r\n",
        "    for j in range(0,n_X):\r\n",
        "      reconstruction[i*41:i*41+41,j*41:j*41+41]=img[k,:,:]\r\n",
        "      k = k+1\r\n",
        "  return(reconstruction)\r\n",
        "\r\n",
        "# Définition d'une fonction de prédiction d'une image entière\r\n",
        "def Prediction_Image_Entiere(image,model):\r\n",
        "  hauteur_image = image.shape[0]\r\n",
        "  largeur_image = image.shape[1]\r\n",
        "\r\n",
        "  # Découpe l'image en morceaux de (41x41) pixels\r\n",
        "  taille_morceaux = [1,41,41,1]\r\n",
        "  morceaux = extract_patches(np.array([[image]]).reshape(1,image.shape[0],image.shape[1],1), sizes = taille_morceaux, strides=taille_morceaux, rates = [1,1,1,1], padding='SAME')\r\n",
        "\r\n",
        "  # Sauvegardes le nombres de morceaux verticaux et horizontaux\r\n",
        "  n_Y = morceaux[0].shape[0]\r\n",
        "  n_X = morceaux[0].shape[1]\r\n",
        "\r\n",
        "  # Modifie le format des morceaux au format (nombre_morceaux,41,41)\r\n",
        "  morceaux = np.reshape(morceaux[0],(morceaux[0].shape[0]*morceaux[0].shape[1],1,taille_morceaux[1],taille_morceaux[2]))\r\n",
        "\r\n",
        "  # Lance la prédiction\r\n",
        "  prediction = model.predict(morceaux.astype('double')/255.0)\r\n",
        "  prediction = (prediction.clip(0,255)*255.0).astype(\"uint8\")\r\n",
        "\r\n",
        "  # Ré-assemble l'image\r\n",
        "  rec = ReassemblageImage(prediction,n_X,n_Y)\r\n",
        "  return(rec)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ms11GyBFd2FT"
      },
      "source": [
        "Appliquons maintenant l'algorithme VDSR sur une image basse résolution afin d'augmenter sa résolution, et comparons le résultat obtenu par interpolation bicubique."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9zPrHzQseHVI"
      },
      "source": [
        "**1. Création d'une image test basse résolution**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jUzY4WijeNOA"
      },
      "source": [
        "Téléchargeons un ensemble de 10 images, stockées sur github puis chargeons une image en mémoire :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VpoIwaPkeXvr"
      },
      "source": [
        "!wget --no-check-certificate --content-disposition \"https://github.com/AlexandreBourrieau/ML/blob/main/Carnets%20Jupyter/Donn%C3%A9es/ImagesPourVDSR.zip?raw=true\"\r\n",
        "!unzip ImagesPourVDSR.zip -d ImagePourVDSR"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HtkWP-yhiVTR"
      },
      "source": [
        "Chargeons une image et réduisons sa taille de 1/4 :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wQ1ZfhBphPP3"
      },
      "source": [
        "FacteurEchelle = 4\r\n",
        "\r\n",
        "# Chargement de l'image originale\r\n",
        "fichier = \"ImagePourVDSR/sherlock.jpg\"\r\n",
        "image_reference=mpimg.imread(fichier)\r\n",
        "\r\n",
        "# Réduction de l'image d'un facteur 1/4\r\n",
        "img_PIL = Image.fromarray(image_reference)\r\n",
        "img_PIL = img_PIL.resize(((round(img_PIL.size[0]*(1/FacteurEchelle)), round(img_PIL.size[1]*(1/FacteurEchelle)))))\r\n",
        "image_br = np.array(img_PIL)\r\n",
        "\r\n",
        "fig, axes = plt.subplots(nrows=1, ncols=2,figsize=(15,15))\r\n",
        "fig.tight_layout()\r\n",
        "ax = axes.ravel()\r\n",
        "\r\n",
        "ax[0].imshow(image_reference)\r\n",
        "ax[0].set_title(\"Image originale\")\r\n",
        "\r\n",
        "ax[1].imshow(image_br)\r\n",
        "ax[1].set_title(\"Image basse résolution\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HmqB_VF4igHv"
      },
      "source": [
        "**2. Amélioration de la résolution de l'image par la méthode d'interpolation bicubique**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TsHcyQUwioSo"
      },
      "source": [
        "La manière basique pour augmenter la résolution d'une image est d'utiliser l'interpolation bicubique :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z-t7Ulgui_LC"
      },
      "source": [
        "# Augmentation de la résolution avec la méthode bicubique\r\n",
        "img_PIL = Image.fromarray(image_br)\r\n",
        "img_PIL = img_PIL.resize(((round(img_PIL.size[0]*(FacteurEchelle)), round(img_PIL.size[1]*(FacteurEchelle)))))\r\n",
        "image_hr_bicubique = np.array(img_PIL)\r\n",
        "\r\n",
        "fig, axes = plt.subplots(nrows=1, ncols=3,figsize=(20,20))\r\n",
        "fig.tight_layout()\r\n",
        "ax = axes.ravel()\r\n",
        "\r\n",
        "ax[0].imshow(image_reference)\r\n",
        "ax[0].set_title(\"Image originale\")\r\n",
        "\r\n",
        "ax[1].imshow(image_br)\r\n",
        "ax[1].set_title(\"Image basse résolution\")\r\n",
        "\r\n",
        "ax[2].imshow(image_hr_bicubique)\r\n",
        "ax[2].set_title(\"Image interpollée bicubique\")\r\n",
        "\r\n",
        "fig, axes = plt.subplots(nrows=1, ncols=2,figsize=(20,20))\r\n",
        "fig.tight_layout()\r\n",
        "ax = axes.ravel()\r\n",
        "\r\n",
        "ax[0].imshow(image_reference)\r\n",
        "ax[0].set_title(\"Image originale\")\r\n",
        "\r\n",
        "ax[1].imshow(image_hr_bicubique)\r\n",
        "ax[1].set_title(\"Image interpollée bicubique\")\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vs7dCJ6oj0Bv"
      },
      "source": [
        "**3. Amélioration de la résolution de l'image par le réseau neuronal VDSR**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dUIYYX6gj8lY"
      },
      "source": [
        "On commence par extraire les composantes Y Cr Cb de l'image basse résolution : "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bu9zA07ukXmY"
      },
      "source": [
        "image_br_YCbCr = rgb2ycbcr(image_br)\r\n",
        "\r\n",
        "image_Y = image_br_YCbCr[:,:,0]\r\n",
        "image_Cb = image_br_YCbCr[:,:,1]\r\n",
        "image_Cr = image_br_YCbCr[:,:,2]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NP1vbzPqkyUz"
      },
      "source": [
        "On augmente ensuite les composantes par interpolation bicubique puis on calcule l'image résiduelle avec le réseau de neurones :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ers9P3YLuqHz"
      },
      "source": [
        "# Augmentation de la résolution des composantes par interpolation bicubique\r\n",
        "img_PIL = Image.fromarray(image_Y)\r\n",
        "img_PIL = img_PIL.resize(((round(img_PIL.size[0]*(FacteurEchelle)), round(img_PIL.size[1]*(FacteurEchelle)))),Image.BICUBIC)\r\n",
        "image_Y_bicubique = np.array(img_PIL)\r\n",
        "\r\n",
        "img_PIL = Image.fromarray(image_Cb)\r\n",
        "img_PIL = img_PIL.resize(((round(img_PIL.size[0]*(FacteurEchelle)), round(img_PIL.size[1]*(FacteurEchelle)))),Image.BICUBIC)\r\n",
        "image_Cb_bicubique = np.array(img_PIL)\r\n",
        "\r\n",
        "img_PIL = Image.fromarray(image_Cr)\r\n",
        "img_PIL = img_PIL.resize(((round(img_PIL.size[0]*(FacteurEchelle)), round(img_PIL.size[1]*(FacteurEchelle)))),Image.BICUBIC)\r\n",
        "image_Cr_bicubique = np.array(img_PIL)\r\n",
        "\r\n",
        "# Récupération des morceaux pour chaque image interpollée bicubique Y, Cb et Cr\r\n",
        "morceaux_Y_bicubique = extract_patches(np.array([[image_Y_bicubique]]).reshape(1,image_Y_bicubique.shape[0],image_Y_bicubique.shape[1],1), sizes = taille_morceaux, strides=taille_morceaux, rates = [1,1,1,1], padding='SAME')\r\n",
        "morceaux_Cb_bicubique = extract_patches(np.array([[image_Cb_bicubique]]).reshape(1,image_Cb_bicubique.shape[0],image_Cb_bicubique.shape[1],1), sizes = taille_morceaux, strides=taille_morceaux, rates = [1,1,1,1], padding='SAME')\r\n",
        "morceaux_Cr_bicubique = extract_patches(np.array([[image_Cr_bicubique]]).reshape(1,image_Cr_bicubique.shape[0],image_Cr_bicubique.shape[1],1), sizes = taille_morceaux, strides=taille_morceaux, rates = [1,1,1,1], padding='SAME')\r\n",
        "\r\n",
        "# Prédiction de l'image résiduelle\r\n",
        "image_residuelle = Prediction_Image_Entiere(image_Y_bicubique,rmodel)\r\n",
        "\r\n",
        "# Reconstruction de l'image bicubique à partir des morceaux\r\n",
        "image_Y_bicubique = ReassemblageImage(np.array(morceaux_Y_bicubique).reshape(morceaux_Y_bicubique[0].shape[0]*morceaux_Y_bicubique[0].shape[1],1,41,41),morceaux_Y_bicubique[0].shape[1],morceaux_Y_bicubique[0].shape[0])\r\n",
        "image_Cb_bicubique = ReassemblageImage(np.array(morceaux_Cb_bicubique).reshape(morceaux_Cb_bicubique[0].shape[0]*morceaux_Cb_bicubique[0].shape[1],1,41,41),morceaux_Cb_bicubique[0].shape[1],morceaux_Cb_bicubique[0].shape[0])\r\n",
        "image_Cr_bicubique = ReassemblageImage(np.array(morceaux_Cr_bicubique).reshape(morceaux_Cr_bicubique[0].shape[0]*morceaux_Cr_bicubique[0].shape[1],1,41,41),morceaux_Cr_bicubique[0].shape[1],morceaux_Cr_bicubique[0].shape[0])\r\n",
        "\r\n",
        "# Affichage du résultat\r\n",
        "fig, axes = plt.subplots(nrows=1, ncols=2,figsize=(20,20))\r\n",
        "fig.tight_layout()\r\n",
        "ax = axes.ravel()\r\n",
        "\r\n",
        "ax[0].imshow(image_Y_bicubique,cmap='gray')\r\n",
        "ax[0].set_title(\"Image bicubique d'entrée\")\r\n",
        "\r\n",
        "ax[1].imshow(image_residuelle,cmap='gray')\r\n",
        "ax[1].set_title(\"Image résiduelle prédite\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IYaTdgiVm733"
      },
      "source": [
        "On ajoute ensuite la luminance de l'image bicubique à l'image résiduelle :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CSMI0WS_l_iZ"
      },
      "source": [
        "Y_finale = image_residuelle + image_Y_bicubique"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ldl4sB9UvKRU"
      },
      "source": [
        "Y_finale.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4SnnSk7QtMiO"
      },
      "source": [
        "# Ajoute les 3 canaux Y, Cb et Cr à l'image finale\r\n",
        "hauteur_image = Y_finale.shape[0]\r\n",
        "largeur_image = Y_finale.shape[1]\r\n",
        "\r\n",
        "Y_finale = Y_finale.reshape(hauteur_image,largeur_image,1)\r\n",
        "image_Cb_bicubique = image_Cb_bicubique.reshape(hauteur_image,largeur_image,1)\r\n",
        "image_Cr_bicubique = image_Cr_bicubique.reshape(hauteur_image,largeur_image,1)\r\n",
        "\r\n",
        "Y_finale = np.concatenate((Y_finale,image_Cb_bicubique),axis=2)\r\n",
        "Y_finale = np.concatenate((Y_finale,image_Cr_bicubique),axis=2)\r\n",
        "\r\n",
        "#Enlève les bords de l'image finale\r\n",
        "largeur_bande_verticale = int(((Y_finale.shape[1] - image_hr_bicubique.shape[1])/2))\r\n",
        "hauteur_bande_verticale = int(((Y_finale.shape[0] - image_hr_bicubique.shape[0])/2))\r\n",
        "\r\n",
        "Y_finale = Y_finale[hauteur_bande_verticale:(Y_finale.shape[0]-hauteur_bande_verticale),\r\n",
        "                                    largeur_bande_verticale:(Y_finale.shape[1]-largeur_bande_verticale),:]\r\n",
        "\r\n",
        "if Y_finale.shape[0] > image_br_YCbCr.shape[0]:\r\n",
        "  Y_finale = Y_finale[:Y_finale.shape[0]-1,:,:]\r\n",
        "if Y_finale.shape[1] > image_br_YCbCr.shape[1]:\r\n",
        "  Y_finale = Y_finale[:,:Y_finale.shape[1]-1,:]\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ChAGVDg92xdz"
      },
      "source": [
        "Y_finale"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PhIJkqhsuNjs"
      },
      "source": [
        "Y_finale.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ttHFe2W0rMg-"
      },
      "source": [
        "Enfin, on reconstitue l'image finale à partir des composantes Y, Cr et Cb vers une image au format RGB :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7aZuoYCMrpCj"
      },
      "source": [
        "  def ycbcr2rgb(im):\r\n",
        "    xform = np.array([[1, 0, 1.402], [1, -0.34414, -.71414], [1, 1.772, 0]])\r\n",
        "    rgb = im.astype(np.float)\r\n",
        "    rgb[:,:,[1,2]] -= 128\r\n",
        "    rgb = rgb.dot(xform.T)\r\n",
        "    np.putmask(rgb, rgb > 255, 255)\r\n",
        "    np.putmask(rgb, rgb < 0, 0)\r\n",
        "    return np.uint8(rgb)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nImn1xs8rR67"
      },
      "source": [
        "image_finale = ycbcr2rgb(Y_finale)\r\n",
        "\r\n",
        "# Affichage du résultat\r\n",
        "fig, axes = plt.subplots(nrows=1, ncols=3,figsize=(20,20))\r\n",
        "fig.tight_layout()\r\n",
        "ax = axes.ravel()\r\n",
        "\r\n",
        "ax[0].imshow(image_reference)\r\n",
        "ax[0].set_title(\"Image originale\")\r\n",
        "\r\n",
        "ax[1].imshow(image_hr_bicubique)\r\n",
        "ax[1].set_title(\"Image interpollée bicubique\")\r\n",
        "\r\n",
        "ax[2].imshow(image_finale)\r\n",
        "ax[2].set_title(\"Image avec VDSR\")\r\n",
        "\r\n",
        "fig, axes = plt.subplots(nrows=1, ncols=2,figsize=(20,20))\r\n",
        "fig.tight_layout()\r\n",
        "ax = axes.ravel()\r\n",
        "\r\n",
        "ax[0].imshow(image_hr_bicubique)\r\n",
        "ax[0].set_title(\"Image interpollée bicubique\")\r\n",
        "\r\n",
        "ax[1].imshow(image_finale)\r\n",
        "ax[1].set_title(\"Image avec VDSR\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TjoIxcskwSVP"
      },
      "source": [
        "fig, axes = plt.subplots(nrows=1, ncols=2,figsize=(20,20))\r\n",
        "fig.tight_layout()\r\n",
        "ax = axes.ravel()\r\n",
        "\r\n",
        "ax[0].imshow(image_hr_bicubique[0:500,300:800])\r\n",
        "ax[0].set_title(\"Image interpollée bicubique\")\r\n",
        "\r\n",
        "ax[1].imshow(image_finale[0:500,300:800])\r\n",
        "ax[1].set_title(\"Image avec VDSR\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uXxkGZJ5570u"
      },
      "source": [
        "**4. Comparaison de deux modèles**\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3jWY7oymAGNq"
      },
      "source": [
        "with open('model-916-2_3_4.json', 'r') as json_file:\r\n",
        "    loaded_model_json = json_file.read()\r\n",
        "rmodel1 = model_from_json(loaded_model_json)\r\n",
        "rmodel1.load_weights(\"weights-916-2_3_4.h5\")\r\n",
        "\r\n",
        "with open('model-2741-4-200.json', 'r') as json_file:\r\n",
        "    loaded_model_json = json_file.read()\r\n",
        "rmodel2 = model_from_json(loaded_model_json)\r\n",
        "rmodel2.load_weights(\"weights-2741-4-200.h5\")\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Isni9TvWAiGd"
      },
      "source": [
        "periodes = 100\r\n",
        "batch_size = 64\r\n",
        "\r\n",
        "# Définition des paramètres liés à l'évolution du taux d'apprentissage\r\n",
        "lr_schedule = schedules.InverseTimeDecay(\r\n",
        "    initial_learning_rate=0.1,\r\n",
        "    decay_steps=10,\r\n",
        "    decay_rate=0.1)\r\n",
        "\r\n",
        "# Définition de la fonction d'objectif\r\n",
        "# format y_predit  : (64,1,41,41)\r\n",
        "# format y_attendu : (64,1,41,41)\r\n",
        "def keras_half_mean_squared_function(y_attendu, y_predit):\r\n",
        "  erreur = K.sum(K.square(y_attendu[:,0,:,:] - y_predit[:,0,:,:]))\r\n",
        "  return(0.5*erreur/batch_size)\r\n",
        "\r\n",
        "#definition de la métrique\r\n",
        "def keras_mean_squared_metric(y_attendu, y_predit):\r\n",
        "  erreur = K.sqrt(K.mean(K.square(y_attendu[:,0,:,:] - y_predit[:,0,:,:])))\r\n",
        "  return(erreur)\r\n",
        "\r\n",
        "rmodel1.compile(loss=keras_half_mean_squared_function, optimizer=SGD(learning_rate=lr_schedule, momentum=0.9, clipnorm=0.01), metrics=[keras_mean_squared_metric, 'acc'])\r\n",
        "rmodel2.compile(loss=keras_half_mean_squared_function, optimizer=SGD(learning_rate=lr_schedule, momentum=0.9, clipnorm=0.01), metrics=[keras_mean_squared_metric, 'acc'])\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LswzfIc_6Jpv"
      },
      "source": [
        "FacteurEchelle = 4\r\n",
        "\r\n",
        "# Chargement de l'image originale\r\n",
        "fichier = \"ImagePourVDSR/BaliEtJava.jpg\"\r\n",
        "image_reference=mpimg.imread(fichier)\r\n",
        "\r\n",
        "# Réduction de l'image d'un facteur 1/4\r\n",
        "img_PIL = Image.fromarray(image_reference)\r\n",
        "img_PIL = img_PIL.resize(((round(img_PIL.size[0]*(1/FacteurEchelle)), round(img_PIL.size[1]*(1/FacteurEchelle)))))\r\n",
        "image_br = np.array(img_PIL)\r\n",
        "\r\n",
        "# Augmentation de la résolution avec la méthode bicubique\r\n",
        "img_PIL = Image.fromarray(image_br)\r\n",
        "img_PIL = img_PIL.resize(((round(img_PIL.size[0]*(FacteurEchelle)), round(img_PIL.size[1]*(FacteurEchelle)))))\r\n",
        "image_hr_bicubique = np.array(img_PIL)\r\n",
        "\r\n",
        "image_br_YCbCr = rgb2ycbcr(image_br)\r\n",
        "image_Y = image_br_YCbCr[:,:,0]\r\n",
        "image_Cb = image_br_YCbCr[:,:,1]\r\n",
        "image_Cr = image_br_YCbCr[:,:,2]\r\n",
        "\r\n",
        "# Augmentation de la résolution des composantes par interpolation bicubique\r\n",
        "img_PIL = Image.fromarray(image_Y)\r\n",
        "img_PIL = img_PIL.resize(((round(img_PIL.size[0]*(FacteurEchelle)), round(img_PIL.size[1]*(FacteurEchelle)))),Image.BICUBIC)\r\n",
        "image_Y_bicubique = np.array(img_PIL)\r\n",
        "\r\n",
        "img_PIL = Image.fromarray(image_Cb)\r\n",
        "img_PIL = img_PIL.resize(((round(img_PIL.size[0]*(FacteurEchelle)), round(img_PIL.size[1]*(FacteurEchelle)))),Image.BICUBIC)\r\n",
        "image_Cb_bicubique = np.array(img_PIL)\r\n",
        "\r\n",
        "img_PIL = Image.fromarray(image_Cr)\r\n",
        "img_PIL = img_PIL.resize(((round(img_PIL.size[0]*(FacteurEchelle)), round(img_PIL.size[1]*(FacteurEchelle)))),Image.BICUBIC)\r\n",
        "image_Cr_bicubique = np.array(img_PIL)\r\n",
        "\r\n",
        "# Récupération des morceaux pour chaque image interpollée bicubique Y, Cb et Cr\r\n",
        "morceaux_Y_bicubique = extract_patches(np.array([[image_Y_bicubique]]).reshape(1,image_Y_bicubique.shape[0],image_Y_bicubique.shape[1],1), sizes = taille_morceaux, strides=taille_morceaux, rates = [1,1,1,1], padding='SAME')\r\n",
        "morceaux_Cb_bicubique = extract_patches(np.array([[image_Cb_bicubique]]).reshape(1,image_Cb_bicubique.shape[0],image_Cb_bicubique.shape[1],1), sizes = taille_morceaux, strides=taille_morceaux, rates = [1,1,1,1], padding='SAME')\r\n",
        "morceaux_Cr_bicubique = extract_patches(np.array([[image_Cr_bicubique]]).reshape(1,image_Cr_bicubique.shape[0],image_Cr_bicubique.shape[1],1), sizes = taille_morceaux, strides=taille_morceaux, rates = [1,1,1,1], padding='SAME')\r\n",
        "\r\n",
        "# Prédiction de l'image résiduelle\r\n",
        "image_residuelle1 = Prediction_Image_Entiere(image_Y_bicubique,rmodel)\r\n",
        "image_residuelle2 = Prediction_Image_Entiere(image_Y_bicubique,rmodel2)\r\n",
        "\r\n",
        "# Reconstruction de l'image bicubique à partir des morceaux\r\n",
        "image_Y_bicubique = ReassemblageImage(np.array(morceaux_Y_bicubique).reshape(morceaux_Y_bicubique[0].shape[0]*morceaux_Y_bicubique[0].shape[1],1,41,41),morceaux_Y_bicubique[0].shape[1],morceaux_Y_bicubique[0].shape[0])\r\n",
        "image_Cb_bicubique = ReassemblageImage(np.array(morceaux_Cb_bicubique).reshape(morceaux_Cb_bicubique[0].shape[0]*morceaux_Cb_bicubique[0].shape[1],1,41,41),morceaux_Cb_bicubique[0].shape[1],morceaux_Cb_bicubique[0].shape[0])\r\n",
        "image_Cr_bicubique = ReassemblageImage(np.array(morceaux_Cr_bicubique).reshape(morceaux_Cr_bicubique[0].shape[0]*morceaux_Cr_bicubique[0].shape[1],1,41,41),morceaux_Cr_bicubique[0].shape[1],morceaux_Cr_bicubique[0].shape[0])\r\n",
        "\r\n",
        "Y_finale1 = image_residuelle1 + image_Y_bicubique\r\n",
        "Y_finale2 = image_residuelle2 + image_Y_bicubique\r\n",
        "\r\n",
        "Y_finale1 = Y_finale1.reshape(Y_finale1.shape[0],Y_finale1.shape[1],1)\r\n",
        "Y_finale2 = Y_finale1.reshape(Y_finale2.shape[0],Y_finale2.shape[1],1)\r\n",
        "\r\n",
        "# Ajoute les 3 canaux Y, Cb et Cr à l'image finale\r\n",
        "hauteur_image = Y_finale1.shape[0]\r\n",
        "largeur_image = Y_finale1.shape[1]\r\n",
        "\r\n",
        "Y_finale1 = Y_finale1.reshape(hauteur_image,largeur_image,1)\r\n",
        "Y_finale2 = Y_finale2.reshape(hauteur_image,largeur_image,1)\r\n",
        "image_Cb_bicubique = image_Cb_bicubique.reshape(hauteur_image,largeur_image,1)\r\n",
        "image_Cr_bicubique = image_Cr_bicubique.reshape(hauteur_image,largeur_image,1)\r\n",
        "\r\n",
        "Y_finale1 = np.concatenate((Y_finale1,image_Cb_bicubique),axis=2)\r\n",
        "Y_finale1 = np.concatenate((Y_finale1,image_Cr_bicubique),axis=2)\r\n",
        "Y_finale2 = np.concatenate((Y_finale2,image_Cb_bicubique),axis=2)\r\n",
        "Y_finale2 = np.concatenate((Y_finale2,image_Cr_bicubique),axis=2)\r\n",
        "\r\n",
        "\r\n",
        "#Enlève les bords de l'image finale\r\n",
        "largeur_bande_verticale = int(((Y_finale1.shape[1] - image_hr_bicubique.shape[1])/2))\r\n",
        "hauteur_bande_verticale = int(((Y_finale1.shape[0] - image_hr_bicubique.shape[0])/2))\r\n",
        "\r\n",
        "Y_finale1 = Y_finale1[hauteur_bande_verticale:(Y_finale1.shape[0]-hauteur_bande_verticale),\r\n",
        "                                    largeur_bande_verticale:(Y_finale1.shape[1]-largeur_bande_verticale),:]\r\n",
        "Y_finale2 = Y_finale2[hauteur_bande_verticale:(Y_finale2.shape[0]-hauteur_bande_verticale),\r\n",
        "                                    largeur_bande_verticale:(Y_finale2.shape[1]-largeur_bande_verticale),:]\r\n",
        "\r\n",
        "if Y_finale1.shape[0] > image_br_YCbCr.shape[0]:\r\n",
        "  Y_finale1 = Y_finale1[:Y_finale1.shape[0]-1,:,:]\r\n",
        "  Y_finale2 = Y_finale2[:Y_finale2.shape[0]-1,:,:]\r\n",
        "if Y_finale1.shape[1] > image_br_YCbCr.shape[1]:\r\n",
        "  Y_finale1 = Y_finale1[:,:Y_finale1.shape[1]-1,:]\r\n",
        "  Y_finale2 = Y_finale2[:,:Y_finale2.shape[1]-1,:]\r\n",
        "\r\n",
        "image_finale1 = ycbcr2rgb(Y_finale1)\r\n",
        "image_finale2 = ycbcr2rgb(Y_finale2)\r\n",
        "\r\n",
        "\r\n",
        "# Affichage du résultat\r\n",
        "fig, axes = plt.subplots(nrows=1, ncols=4,figsize=(20,20))\r\n",
        "fig.tight_layout()\r\n",
        "ax = axes.ravel()\r\n",
        "\r\n",
        "ax[0].imshow(image_reference)\r\n",
        "ax[0].set_title(\"Image originale\")\r\n",
        "\r\n",
        "ax[1].imshow(image_hr_bicubique)\r\n",
        "ax[1].set_title(\"Image interpollée bicubique\")\r\n",
        "\r\n",
        "ax[2].imshow(image_finale1)\r\n",
        "ax[2].set_title(\"Image avec VDSR #1\")\r\n",
        "\r\n",
        "ax[3].imshow(image_finale2)\r\n",
        "ax[3].set_title(\"Image avec VDSR #2\")\r\n",
        "\r\n",
        "fig, axes = plt.subplots(nrows=1, ncols=2,figsize=(20,20))\r\n",
        "fig.tight_layout()\r\n",
        "ax = axes.ravel()\r\n",
        "\r\n",
        "ax[0].imshow(image_hr_bicubique)\r\n",
        "ax[0].set_title(\"Image interpollée bicubique\")\r\n",
        "\r\n",
        "ax[1].imshow(image_finale1)\r\n",
        "ax[1].set_title(\"Image avec VDSR #1\")\r\n",
        "\r\n",
        "fig, axes = plt.subplots(nrows=1, ncols=2,figsize=(20,20))\r\n",
        "fig.tight_layout()\r\n",
        "ax = axes.ravel()\r\n",
        "\r\n",
        "ax[0].imshow(image_hr_bicubique)\r\n",
        "ax[0].set_title(\"Image interpollée bicubique\")\r\n",
        "\r\n",
        "ax[1].imshow(image_finale2)\r\n",
        "ax[1].set_title(\"Image avec VDSR #2\")\r\n",
        "\r\n",
        "fig, axes = plt.subplots(nrows=1, ncols=2,figsize=(20,20))\r\n",
        "fig.tight_layout()\r\n",
        "ax = axes.ravel()\r\n",
        "\r\n",
        "ax[0].imshow(image_hr_bicubique[0:250,350:600])\r\n",
        "ax[0].set_title(\"Image interpollée bicubique\")\r\n",
        "\r\n",
        "ax[1].imshow(image_finale1[0:250,350:600])\r\n",
        "ax[1].set_title(\"Image avec VDSR #1\")\r\n",
        "\r\n",
        "fig, axes = plt.subplots(nrows=1, ncols=2,figsize=(20,20))\r\n",
        "fig.tight_layout()\r\n",
        "ax = axes.ravel()\r\n",
        "\r\n",
        "ax[0].imshow(image_hr_bicubique[0:250,350:600])\r\n",
        "ax[0].set_title(\"Image interpollée bicubique\")\r\n",
        "\r\n",
        "ax[1].imshow(image_finale2[0:250,350:600])\r\n",
        "ax[1].set_title(\"Image avec VDSR #2\")\r\n",
        "\r\n",
        "fig, axes = plt.subplots(nrows=1, ncols=2,figsize=(20,20))\r\n",
        "fig.tight_layout()\r\n",
        "ax = axes.ravel()\r\n",
        "\r\n",
        "ax[0].imshow(image_finale1[0:250,350:600])\r\n",
        "ax[0].set_title(\"Image avec VDSR #1\")\r\n",
        "\r\n",
        "ax[1].imshow(image_finale2[0:250,350:600])\r\n",
        "ax[1].set_title(\"Image avec VDSR #2\")\r\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}