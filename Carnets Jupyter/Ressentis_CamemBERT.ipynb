{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Sentiment-BERT.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oS3VTFrtP_EA"
      },
      "source": [
        "# **Classification de ressentis avec CamemBERT**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0pbPgf-yQGdW"
      },
      "source": [
        "L'objectif est de créer un modèle qui prend en entrée des commentaires (en Français) et attribue à chacun un ressenti positif ou négatif.  \n",
        "Le modèle global est composé de deux parties :  \n",
        "* [CamemBERT](https://camembert-model.fr/) va encoder le commentaire et en extraire des informations qui seront passées ensuite au réseau de neurones.  \n",
        "* Le modèle suivant est un réseau de neurones qui sera créé avec l'API [Keras](https://www.tensorflow.org/guide/keras?hl=fr) de [Tensorflow](https://www.tensorflow.org/?hl=fr).  \n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/AlexandreBourrieau/ML-F1/master/Carnets%20Jupyter/Images/SchemaCamembert1.png\" />  \n",
        "  \n",
        "  Les données qui s'échangent entre les deux modèles sont des vecteurs de dimension 768. On peut voir ces vecteurs comme l'équivalent de l'application d'un algorithme de prolongation lexicale sur les mots qui composent le commentaire."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZdwgQ7MfNoj2"
      },
      "source": [
        "!pip install transformers --quiet"
      ],
      "execution_count": 111,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VJzvJaBONyHe"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras.layers import Dense, Dropout, Input, Dropout, Lambda\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from transformers import CamembertConfig\n",
        "from transformers import TFCamembertModel\n",
        "from transformers import AutoTokenizer\n",
        "\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 113,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tl9VyhxKnZRP"
      },
      "source": [
        "# Importation des données\n",
        "\n",
        "Téléchargement des ressentis Allociné"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gr-B216RN3zu"
      },
      "source": [
        "# Téléchargement des données depuis le repot github \"https://github.com/AlexandreBourrieau/ML-F1/raw/master/Carnets%20Jupyter/Donn%C3%A9es/data.tar.bz2\"\n",
        "\n",
        "!wget -q \"https://github.com/AlexandreBourrieau/ML-F1/raw/master/Carnets%20Jupyter/Donn%C3%A9es/data.tar.bz2\"\n",
        "!tar -xjvf data.tar.bz2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cYpXPzRhogfQ"
      },
      "source": [
        "df = pd.read_json(\"/content/data/test.jsonl\", lines=True)\n",
        "df.head(5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xiO-lNQ6zYpU"
      },
      "source": [
        "Affiche quelques informations :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SxMNwnpKQ6B5"
      },
      "source": [
        "def LongueurMax(df):\n",
        "  Lmax = 0\n",
        "  for com in df['review']:\n",
        "    Longueur = len(com)\n",
        "    if Lmax < Longueur:\n",
        "      Lmax = Longueur\n",
        "  return Lmax"
      ],
      "execution_count": 116,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2-_65fyzQ80e"
      },
      "source": [
        "print(df[0:10])\n",
        "print(\"Total des données : \", str(len(df)))\n",
        "print(\"Nombre d'avis positifs et négatifs : \",df['polarity'].value_counts())\n",
        "print(\"Longueur maximale d'un commentaire : \",LongueurMax(df))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4J-bB1p3uS2u"
      },
      "source": [
        "On ne va garder que les commentaires dont la longueur est inférieure à une certaine valeur :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tObZSipZzxxi"
      },
      "source": [
        "L_MAX = 300\n",
        "\n",
        "df2 = df[df['review'].str.len()<L_MAX]"
      ],
      "execution_count": 118,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ojEyeQyRznp"
      },
      "source": [
        "# **Préparation des données**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aARCujGCqVud"
      },
      "source": [
        "def LongueurMax2(df):\n",
        "  Lmax = 0\n",
        "  for com in df:\n",
        "    Longueur = len(com)\n",
        "    if Lmax < Longueur:\n",
        "      Lmax = Longueur\n",
        "  return Lmax"
      ],
      "execution_count": 119,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VSFqQME7RgFH"
      },
      "source": [
        "# Chargement des commentaires et des ressentis\n",
        "commentaires = df2['review'].astype(str).tolist()    # Récupère tous les commentaires dans une liste python\n",
        "ressentis = df2['polarity'].tolist()                   # Récupère tous les ressentis dans une liste python\n",
        "labels = np.asarray(ressentis)               # Créé un tableau de type numpy avec les ressentis\n",
        "\n",
        "x_entrainement, x_test, y_entrainement, y_test = train_test_split(commentaires[0:MAX], labels[0:MAX], test_size=0.25)"
      ],
      "execution_count": 120,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wqx6-1JYqios"
      },
      "source": [
        "Longueur_max_entrainement = LongueurMax2(x_entrainement)\n",
        "Longueur_max_tests = LongueurMax2(x_test)\n",
        "print(\"Longueur maximale des commentaires : \", max([Longueur_max_entrainement, Longueur_max_tests]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vhArZ0AeRlzt"
      },
      "source": [
        "print (\"Nombre de commentaires pour l'entrainement : \", len(x_entrainement))\n",
        "print (\"Nombre de commentaires pour les tests : \", len(x_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n4Vcm5K3Dej4"
      },
      "source": [
        "# **Tokénisation**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KCLBUOUGR9yl"
      },
      "source": [
        "LONGUEUR_MAX_COMMENTAIRE = max([Longueur_max_entrainement, Longueur_max_tests])\n",
        "\n",
        "\n",
        "# Instanciation du tokeniseur\n",
        "tokenizer = AutoTokenizer.from_pretrained('jplu/tf-camembert-base')\n",
        "\n",
        "# Préparation des données d'entrainement\n",
        "output_tokenizer_entrainement = tokenizer(x_entrainement,max_length=LONGUEUR_MAX_COMMENTAIRE, padding='max_length', truncation=False, return_tensors='tf',add_special_tokens=True)\n",
        "\n",
        "# Préparation des données de tests\n",
        "output_tokenizer_tests = tokenizer(x_test,max_length=LONGUEUR_MAX_COMMENTAIRE, padding='max_length', truncation=False, return_tensors='tf',add_special_tokens=True)"
      ],
      "execution_count": 123,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kzboG3fX5LkP"
      },
      "source": [
        "Regardons un peu comment sont formatées les données en sortie du tokéniseur :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PngM0hP2SaY2"
      },
      "source": [
        "output_tokenizer_entrainement"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fejN7ZrzzaOu"
      },
      "source": [
        "Regardons comment le premier commentaire a été encodé :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n_U6gUTtSkjP"
      },
      "source": [
        "print(\"Commentaire original :\", x_entrainement[0])\n",
        "print(\"input_ids: \", output_tokenizer_entrainement['input_ids'][0])\n",
        "print(\"attention_mask: \", output_tokenizer_entrainement['attention_mask'][0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mbk3Ha0zTBhm"
      },
      "source": [
        "# **Définition et utilisation du modèle camemBERT avec Keras**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1yplJTKgTHUW"
      },
      "source": [
        "# Instanciation du modèle camemBERT\n",
        "transformer_model = TFCamembertModel.from_pretrained('jplu/tf-camembert-base')\n",
        "\n",
        "# Défintion du format des entrées du modèle\n",
        "entrees_ids = tf.keras.layers.Input(shape=(LONGUEUR_MAX_COMMENTAIRE,), name='input_token', dtype='int32')\n",
        "entrees_masks = tf.keras.layers.Input(shape=(LONGUEUR_MAX_COMMENTAIRE,), name='masked_token', dtype='int32') \n",
        "\n",
        "# Création de la sortie du modèle\n",
        "sortie_camemBERT = transformer_model([entrees_ids,entrees_masks])\n",
        "\n",
        "# Instanciation du modèle avec Keras\n",
        "model_camemBERT = tf.keras.Model(inputs=[entrees_ids, entrees_masks], outputs = sortie_camemBERT,trainable=False)\n",
        "model_camemBERT.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iyWJkTbu5rMo"
      },
      "source": [
        "Si on regarde le format de la sortie du modèle camemBERT, on voit qu'elle est composée de deux sorties :\n",
        "* Une sortie avec un format (None,MAX_SEQUENCE_LENGTH,768)\n",
        "* Une sortie avec un format (None,768)  \n",
        "  \n",
        "On trouve la signification de ces sorties [sur le site de hugginface](https://huggingface.co/transformers/main_classes/output.html#tfbasemodeloutput). Ainsi, la première sortie est de type `last_hidden_state` et la deuxième de type `pooler_output`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DbqJEKUR5wNn"
      },
      "source": [
        "sortie_camemBERT"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UjOGqVhS82S9"
      },
      "source": [
        " Celle qui nous interesse ici est la sortie `last_hidden_state` : C'est elle qui contient le résultat de l'encodage des mots des commentaires"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "drPY4gEO84Fk"
      },
      "source": [
        "sortie_camemBERT[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RDYf-Owpwk4Q"
      },
      "source": [
        "La fonction `predict()` permet d'exécuter le modèle sur les séquences d'entrées"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l-NlEgWUxehg"
      },
      "source": [
        "sortie_vecteurs_camemBERT = model_camemBERT.predict(\n",
        "    [output_tokenizer_entrainement['input_ids'][0:2],\n",
        "     output_tokenizer_entrainement['attention_mask'][0:2]]\n",
        "     ,verbose=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nr1pLKgsCwMP"
      },
      "source": [
        "Regardons à quoi ressemble la sortie de camemBERT :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m173U4t5oyzw"
      },
      "source": [
        "sortie_vecteurs_camemBERT"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0bjWNVb4KdZG"
      },
      "source": [
        "# **Ajout du réseau de neurones simple en sortie du modèle camemBERT**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xd2hHeGJGtVB"
      },
      "source": [
        "**Extraction des vecteurs [CLS]**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "guk_K_70pPU1"
      },
      "source": [
        "Parmi les MAX_SEQUENCE_LENGTH vecteurs en sortie, il ne nous faut que le premier (celui qui correspond au mot clé [CLS]). On doit donc récupérer, pour chaque commentaire, le premier vecteur de dimension 768 parmi les MAX_SEQUENCE_LENGTH en sortie :  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jpyV9C1gpSLr"
      },
      "source": [
        "sortie_camemBERT[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7H26bHc7GxhP"
      },
      "source": [
        "**Construction du modèle global**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T_2vHlNspbVe"
      },
      "source": [
        "Les vecteurs de dimension 768 correspondants aux sorties [CLS] de chaque commentaire sont envoyés dans un réseau de neurones à 2 neurones avec une fonction d'activation Softmax :\n",
        "<img src=\"https://raw.githubusercontent.com/AlexandreBourrieau/ML-F1/master/Carnets%20Jupyter/Images/SchemaCamembert2.png\"/>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MUUwxLMsp40U"
      },
      "source": [
        "# Instanciation du modèle camemBERT\n",
        "transformer_model = TFCamembertModel.from_pretrained('jplu/tf-camembert-base')\n",
        "\n",
        "# Défintion du format des entrées du modèle\n",
        "entrees_ids = tf.keras.layers.Input(shape=(LONGUEUR_MAX_COMMENTAIRE,), name='input_token', dtype='int32')\n",
        "entrees_masks = tf.keras.layers.Input(shape=(LONGUEUR_MAX_COMMENTAIRE,), name='masked_token', dtype='int32') \n",
        "\n",
        "# Création de la sortie du modèle\n",
        "sortie_camemBERT = transformer_model([entrees_ids,entrees_masks])\n",
        "\n",
        "# Instanciation du modèle avec Keras\n",
        "model_camemBERT = tf.keras.Model(inputs=[entrees_ids, entrees_masks], outputs = sortie_camemBERT,trainable=False)\n",
        "\n",
        "# Défintion du format des entrées du modèle\n",
        "entrees_ids = tf.keras.layers.Input(shape=(LONGUEUR_MAX_COMMENTAIRE,), name='input_token', dtype='int32')\n",
        "entrees_masks = tf.keras.layers.Input(shape=(LONGUEUR_MAX_COMMENTAIRE,), name='masked_token', dtype='int32') \n",
        "\n",
        "# Création de la sortie du modèle\n",
        "sortie_camemBERT = transformer_model([entrees_ids,entrees_masks])[0]\n",
        "\n",
        "\n",
        "l1 = Lambda(lambda seq: seq[:, 0, :])(sortie_camemBERT)        # On ne récupère que les vecteurs [CLS]\n",
        "output = Dense(2, activation='softmax')(l1)\n",
        "\n",
        "model = tf.keras.Model(inputs=[entrees_ids, entrees_masks], outputs = output)\n",
        "model.layers[2].trainable = False         # Désactive d'entrainement de camemBERT\n",
        "\n",
        "model.compile(loss='sparse_categorical_crossentropy', optimizer=Adam(), metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q0NXqJTWDroW"
      },
      "source": [
        "On lance maintenant l'entrainement du modèle :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tDLirYrZqCad"
      },
      "source": [
        "history = model.fit([output_tokenizer_entrainement['input_ids'],output_tokenizer_entrainement['attention_mask']],y_entrainement,\n",
        "                    epochs=5, verbose=1, batch_size = 3,\n",
        "                    validation_data=([output_tokenizer_tests['input_ids'],output_tokenizer_tests['attention_mask']],y_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gKU2TlZDqFws"
      },
      "source": [
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('Précision du modèle')\n",
        "plt.ylabel('Précision')\n",
        "plt.xlabel('Itération')\n",
        "plt.legend(['Entrainement', 'Test'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T5ThHOoGRGIa"
      },
      "source": [
        "# **Fine Tuning**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QhYtyQjuIIAZ"
      },
      "source": [
        "Afin d'obtenir une meilleur précision, on va également entrainer camemBERT : "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5eui3V0PRI6U"
      },
      "source": [
        "model.layers[2].trainable = True\n",
        "model.compile(loss='sparse_categorical_crossentropy', optimizer=Adam(1e-5), metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eO3HSM6dRYl_"
      },
      "source": [
        "history = model.fit([output_tokenizer_entrainement['input_ids'],output_tokenizer_entrainement['attention_mask']],y_entrainement,\n",
        "                    epochs=5, verbose=1, batch_size = 3,\n",
        "                    validation_data=([output_tokenizer_tests['input_ids'],output_tokenizer_tests['attention_mask']],y_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TGsA4TSdRvnu"
      },
      "source": [
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('Précision du modèle')\n",
        "plt.ylabel('Précision')\n",
        "plt.xlabel('Itération')\n",
        "plt.legend(['Entrainement', 'Test'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}