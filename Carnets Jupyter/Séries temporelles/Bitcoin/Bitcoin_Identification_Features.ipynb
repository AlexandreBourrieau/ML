{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Bitcoin_Identification_Features.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AlexandreBourrieau/ML/blob/main/Carnets%20Jupyter/S%C3%A9ries%20temporelles/Bitcoin/Bitcoin_Identification_Features.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AFEkLAfMAO7A"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import re\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_selection import RFECV\n",
        "from sklearn.preprocessing import MinMaxScaler, RobustScaler\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.pipeline import Pipeline\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "import tensorflow as tf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bz4iaArdAz_B"
      },
      "source": [
        "# Téléchargement des données"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FzVs6_U9A6th"
      },
      "source": [
        "!wget --no-check-certificate --content-disposition \"https://github.com/AlexandreBourrieau/ML/blob/main/Carnets%20Jupyter/S%C3%A9ries%20temporelles/Bitcoin/Bitcoin_complet.zip?raw=true\"\n",
        "!unzip Bitcoin_complet.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EWOVeQf5Cmaw"
      },
      "source": [
        "df_data=pd.read_csv('Bitcoin_complet.csv')\n",
        "df_data.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bToEklt9FSDo"
      },
      "source": [
        "df_data.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mBkr78F2Gkx4"
      },
      "source": [
        "# Préparation des jeux de données"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B2qDmNNHExkA"
      },
      "source": [
        "# Déplace la colonne Prix au début\n",
        "col_prix = df_data.pop('Price')\n",
        "df_data.insert(1,'Price',col_prix)\n",
        "df_data.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v9A9h3ChD9gf"
      },
      "source": [
        "X_raw = df_data.iloc[:,2:20]\n",
        "X_raw.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vSc5nB1EGUyH"
      },
      "source": [
        "y = df_data.iloc[:,1:2]\n",
        "y.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xJxIcLu7GoQG"
      },
      "source": [
        "# Identification des variables par Random Forest : Choix des paramètres"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X1Us6Y5sXB70"
      },
      "source": [
        "**1. Construction du dataframe sur 1 jour**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iym6DSyGXOE_"
      },
      "source": [
        "X = df_data\n",
        "X = X.drop(columns=['Price','Dates'])\n",
        "Xdrop = SimpleImputer(missing_values=np.nan,strategy='most_frequent').fit_transform(X)\n",
        "Xdrop = pd.DataFrame(Xdrop)\n",
        "Xdrop.columns =X.columns\n",
        "X = Xdrop\n",
        "X"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AJ31wXkIYBkJ"
      },
      "source": [
        "**2. Choix du nombre d'arbres :**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "to4oNuBvX-ZM"
      },
      "source": [
        "# Informations sur les données\n",
        "n = 2309              # Nombre d'observations\n",
        "p = 778               # Nombre de variables\n",
        "\n",
        "n_arbres_max = 25\n",
        "\n",
        "n_arbres = np.linspace(1,n_arbres_max,10).astype(np.int32)\n",
        "mtry = np.sqrt(p).astype(np.int32)\n",
        "OOB_err = []\n",
        "\n",
        "for i in n_arbres:\n",
        "  print(\"#Arbres : %d\" %i)\n",
        "  clf = RandomForestRegressor(n_estimators=i, bootstrap=True, oob_score=True, max_samples = n, max_features = mtry, n_jobs=-1)\n",
        "  clf.fit(X,tf.squeeze(np.asarray(y),1))\n",
        "  OOB_err.append(1 - clf.oob_score_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vboxsfzvZnwE"
      },
      "source": [
        "plt.plot(n_arbres,OOB_err)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LMH0zucGdM1e"
      },
      "source": [
        "On choisit n_arbres = 25"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6FBFag3_cs0y"
      },
      "source": [
        "**3. Choix de la valeur de mtry (nombre de variables testées à chaque division)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dq1ic9GGc7jp"
      },
      "source": [
        "(np.sqrt(p)/2).astype(np.int32)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ouyEKtz0cxfk"
      },
      "source": [
        "# Informations sur les données\n",
        "n = 2309              # Nombre d'observations\n",
        "p = 778               # Nombre de variables\n",
        "\n",
        "n_arbres = 25\n",
        "mtry_0 = (np.sqrt(p)/2).astype(np.int32)\n",
        "\n",
        "m_try = np.linspace(mtry_0,778,10).astype(np.int32)\n",
        "\n",
        "OOB_err = []\n",
        "\n",
        "for i in m_try:\n",
        "   print(\"mtry = %s\" %i)\n",
        "   clf = RandomForestRegressor(n_estimators=n_arbres, bootstrap=True, oob_score=True, max_features=i, n_jobs=-1)\n",
        "   clf.fit(X,tf.squeeze(np.asarray(y),1))\n",
        "   OOB_err.append(1 - clf.oob_score_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YIWW_x-odL0h"
      },
      "source": [
        "plt.plot(m_try,OOB_err)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zRHrn3eJhNuY"
      },
      "source": [
        "On choisit mtry = 768"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R50LkwoXhA4Z"
      },
      "source": [
        "# Importance des variables - Pemière approche : Importance sans permutations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LqhQIBES9oVw"
      },
      "source": [
        "**1. Entrainement de la forêt**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iHyhGi8qhEEJ"
      },
      "source": [
        "from sklearn.inspection import permutation_importance\n",
        "\n",
        "# Informations sur les données\n",
        "n = 102               # Nombre d'observations\n",
        "p = 6033              # Nombre de variables\n",
        "n_arbres = 25\n",
        "m_try = 768\n",
        "\n",
        "clf = RandomForestRegressor(n_estimators=n_arbres, bootstrap=True, oob_score=True, max_features=m_try, n_jobs=-1)\n",
        "clf.fit(X,tf.squeeze(np.asarray(y),1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DeFCobxh9t7Z"
      },
      "source": [
        "**2. Affichage de l'importance des variables**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hJqQQhlchR5w"
      },
      "source": [
        "col_sorted_by_importance=clf.feature_importances_.argsort()\n",
        "feat_imp = pd.DataFrame({'cols':X.columns[col_sorted_by_importance],'imps':clf.feature_importances_[col_sorted_by_importance]})\n",
        "feat_imp"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OZ9qGeLShWbZ"
      },
      "source": [
        "!pip install plotly_express --upgrade -q"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lWyOziwshYoZ"
      },
      "source": [
        "import plotly_express as px\n",
        "import plotly.offline as po\n",
        "\n",
        "px.bar(feat_imp.sort_values(['imps'], ascending=False)[:30], x='cols', y='imps', labels={'cols':'column', 'imps':'feature importance'})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "02NKzth3hl0w"
      },
      "source": [
        "# Importance des variables - Deuxième approche : Méthode par permutations des importances"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_tqAQxfPyG6D"
      },
      "source": [
        "Permutation importance is a technique where we shuffle the values of a single column and run the model to see how the scores get affected. If the scores are affected greatly, then the feature is highly important to the model and if not, it does not add significant value to the model.\n",
        "\n",
        "Let us see the feature importances for recall score on the test dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QBHw66JPhpBg"
      },
      "source": [
        "import random\n",
        "\n",
        "def PermImportance(X, y, clf, metric, num_iterations=100):\n",
        "    '''\n",
        "    Calculates the permutation importance of features in a dataset.\n",
        "    Inputs:\n",
        "    X: dataframe with all the features\n",
        "    y: array-like sequence of labels\n",
        "    clf: sklearn classifier, already trained on training data\n",
        "    num_iterations: no. of repetitive runs of the permutation\n",
        "    Outputs:\n",
        "    baseline: the baseline metric without any of the columns permutated\n",
        "    scores: differences in baseline metric caused by permutation of each feature, dict in the format {feature:[diffs]}\n",
        "    '''\n",
        "    bar=progressbar.ProgressBar(max_value=len(X.columns))\n",
        "#    baseline_metric=metric(y, clf.predict(X))\n",
        "    baseline_metric=clf.score(X,y)\n",
        "    scores={c:[] for c in X.columns}\n",
        "    for c in X.columns:\n",
        "        X1=X.copy(deep=True)\n",
        "        for _ in range(num_iterations):\n",
        "            temp=X1[c].tolist()\n",
        "            random.shuffle(temp)\n",
        "            X1[c]=temp\n",
        "#            score=metric(y, clf.predict(X1))\n",
        "            score = clf.score(X1,y)\n",
        "            scores[c].append(baseline_metric-score)\n",
        "        bar.update(X.columns.tolist().index(c))\n",
        "    return baseline_metric, scores"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zAkVvmOThqhQ"
      },
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "import progressbar\n",
        "\n",
        "baseline, scores = PermImportance(X, tf.squeeze(np.asarray(y),1), clf, recall_score, num_iterations=10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cMnNYUey6ZMd"
      },
      "source": [
        "percent_changes={c:[] for c in X.columns}\n",
        "for c in scores:\n",
        "    for i in range(len(scores[c])):\n",
        "        percent_changes[c].append(scores[c][i]/baseline*100)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9adxKQD-KFKA"
      },
      "source": [
        "pd.DataFrame.from_dict(percent_changes).melt().groupby(['variable']).mean().reset_index().sort_values(['value'], ascending=False)[:25]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "70_JkYdu6gd8"
      },
      "source": [
        "px.bar(\n",
        "    pd.DataFrame.from_dict(percent_changes).melt().groupby(['variable']).mean().reset_index().sort_values(['value'], ascending=False)[:25], \n",
        "    x='variable',y='value',labels={'variable':'column','value':'% change in recall'})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ff96TbRjyddL"
      },
      "source": [
        "# Comparaison entre les deux méthodes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "14NvUUYR0AjV"
      },
      "source": [
        "# Calcul des écarts-types et des moyennes\n",
        "scores_std = {}\n",
        "scores_mean = {}\n",
        "for element in scores:\n",
        "  scores_std[element] = np.std(scores[element])\n",
        "  scores_mean[element] = np.mean(scores[element])\n",
        "\n",
        "df_perm = pd.DataFrame.from_dict([scores_std, scores_mean]).transpose()\n",
        "df_perm = df_perm.rename(columns={0:\"std\",1:\"mean\"})\n",
        "df_perm = df_perm.sort_values(by=['mean'],ascending=False)\n",
        "df_perm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G9WRJi_SyxKX"
      },
      "source": [
        "feature_perm = df_perm[0:30]\n",
        "feature_imp = feat_imp.sort_values(['imps'],ascending=False)\n",
        "feature_imp = feature_imp[0:30]\n",
        "\n",
        "tree_indices = np.arange(0, len(feature_imp)) + 0.5\n",
        "\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 8))\n",
        "\n",
        "ax1.barh(tree_indices,feature_imp['imps'].values, height=0.7)\n",
        "ax1.set_yticks(tree_indices)\n",
        "ax1.set_yticklabels(feature_imp['cols'].values)\n",
        "ax1.set_ylim((0, len(feature_imp)))\n",
        "\n",
        "ax2.boxplot(feature_perm, vert=False,labels=feature_perm.index.values)\n",
        "fig.tight_layout()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v3iC1j98LCc7"
      },
      "source": [
        "# Sélection des variables à partir des méthodes précédentes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vi3lrF5aL4jJ"
      },
      "source": [
        "**1. Elimination préliminaire dans les résultats de la première méthode**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zt2bU_LbMSPx"
      },
      "source": [
        "feature_imp = feat_imp.sort_values(['imps'],ascending=False)\n",
        "feature_imp = feature_imp.reset_index()\n",
        "feature_imp\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5KLhijYxPqQy"
      },
      "source": [
        "feature_imp = feat_imp.sort_values(['imps'],ascending=False)\n",
        "feature_imp = feature_imp.reset_index()\n",
        "feature_imp = feature_imp[0:100]\n",
        "feature_imp = feature_imp.reset_index()\n",
        "\n",
        "plt.plot(feature_imp.index.values,feature_imp['imps'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H1F7KxiJM-Ga"
      },
      "source": [
        "feature_imp = feat_imp.sort_values(['imps'],ascending=False)\n",
        "feature_imp = feature_imp.reset_index()\n",
        "feature_imp = feature_imp[0:30]\n",
        "feature_imp = feature_imp.reset_index()\n",
        "\n",
        "plt.plot(feature_imp.index.values,feature_imp['imps'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_4or17NJLJYs"
      },
      "source": [
        "On retient les 30 premières variables"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wk613D5FPmuI"
      },
      "source": [
        "**2. Elimination préliminaire dans les résultats de la deuxième méthode**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ngogSaYuQNEE"
      },
      "source": [
        "On commence par rechercher le minimum où la courbe se stabilise :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3dcM23RAPz5n"
      },
      "source": [
        "feature_perm = df_perm.sort_values(['mean'],ascending=False)\n",
        "feature_perm = feature_perm.reset_index()\n",
        "feature_perm = feature_perm[0:8]\n",
        "feature_perm = feature_perm.reset_index()\n",
        "\n",
        "plt.plot(feature_perm.index.values,feature_perm['mean'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E-JQScayQRqS"
      },
      "source": [
        "On affiche maintenant l'écart type de chaque variable :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xy9uhV18QWWo"
      },
      "source": [
        "feature_perm = df_perm.sort_values(['mean'],ascending=False)\n",
        "feature_perm = feature_perm.reset_index()\n",
        "feature_perm = feature_perm[0:8]\n",
        "feature_perm = feature_perm.reset_index()\n",
        "\n",
        "plt.plot(feature_perm.index.values,feature_perm['std'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rnMNaDggRB5p"
      },
      "source": [
        "On fit cette courbe avec un modèle CART (Classification and Regression Trees) :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vJvaEzkqSDNA"
      },
      "source": [
        "from sklearn.tree import DecisionTreeRegressor\n",
        "\n",
        "regr = DecisionTreeRegressor(criterion=\"mse\")\n",
        "regr.fit(np.reshape(np.array(feature_perm.index.values),(-1,1)),feature_perm['std'].values)\n",
        "y_reg = regr.predict(np.reshape(np.array(feature_perm.index.values),(-1,1)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LP37pe33TuIE"
      },
      "source": [
        "import plotly.graph_objects as go\n",
        "\n",
        "fig = go.Figure()\n",
        "\n",
        "\n",
        "fig.add_trace(go.Scatter(x=feature_perm.index.values,y=feature_perm['std'],line=dict(color='blue', width=1)))\n",
        "fig.add_trace(go.Scatter(x=feature_perm.index.values,y=y_reg,line=dict(color='red', width=1)))\n",
        "\n",
        "fig.update_xaxes(rangeslider_visible=True)\n",
        "yaxis=dict(autorange = True,fixedrange= False)\n",
        "fig.update_yaxes(yaxis)\n",
        "fig.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KAjHVWBNWXla"
      },
      "source": [
        "index = []\n",
        "\n",
        "for i in feature_perm.index.values.astype(np.int32):\n",
        "  if feature_perm['std'].values[i] >= y_reg[i]:\n",
        "    index.append(i)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-d746NdLW-cy"
      },
      "source": [
        "index"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IrmVIXXHXSPO"
      },
      "source": [
        "variables_selected = feature_perm.iloc[index]\n",
        "variables_selected = variables_selected.drop(columns='level_0')\n",
        "variables_selected['index'].values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CeFT-74Aad_W"
      },
      "source": [
        "**Fusion des valeurs**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B0X8X8h1amvd"
      },
      "source": [
        "df_reduit1 = X[feature_imp['cols'].values]\n",
        "df_reduit1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T2ums0knaheM"
      },
      "source": [
        "df_reduit2 = X[variables_selected['index'].values]\n",
        "df_reduit2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xk1_2w1aa9aD"
      },
      "source": [
        "df_merged=df_reduit2.merge(df_reduit1,how='outer')\n",
        "df_merged"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qTmcrWwlYlKO"
      },
      "source": [
        "**Elimination des variables corrélées**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WWcxFY-3Ykm-"
      },
      "source": [
        "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
        "from statsmodels.tools.tools import add_constant\n",
        "\n",
        "#function for removing features with high vif\n",
        "def drop_high_vif(X, thresh=100):\n",
        "    cols = X.columns\n",
        "    variables = np.arange(X.shape[1])\n",
        "    dropped=True\n",
        "    while dropped:\n",
        "        dropped=False\n",
        "        c = X[cols[variables]].values\n",
        "        vif = [variance_inflation_factor(c, ix) for ix in np.arange(c.shape[1])]\n",
        "\n",
        "        maxloc = vif.index(max(vif))\n",
        "        if max(vif) > thresh:\n",
        "            print('dropping \\'' + X[cols[variables]].columns[maxloc] + '\\' at index: ' + str(maxloc))\n",
        "            variables = np.delete(variables, maxloc)\n",
        "            dropped=True\n",
        "\n",
        "    print('Remaining variables:')\n",
        "    print(X.columns[variables])\n",
        "    return X[cols[variables]]\n",
        "\n",
        "#function for listing vif values\n",
        "def vif_values(X):\n",
        "    add_constant(X)\n",
        "    df=pd.Series([variance_inflation_factor(X.values, i) for i in range(X.shape[1])], index=X.columns)\n",
        "    return df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ljn9PCewYqH3"
      },
      "source": [
        "variables_selected_reduit = drop_high_vif(df_merged,thresh=10)\n",
        "variables_selected_reduit"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UjRhi5rzMIX1"
      },
      "source": [
        "# Sélection des variables par méthode RFE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XumxAK2mMkeF"
      },
      "source": [
        "from sklearn.feature_selection import RFE\n",
        "\n",
        "# Informations sur les données\n",
        "n = 102               # Nombre d'observations\n",
        "p = 6033              # Nombre de variables\n",
        "n_arbres = 25\n",
        "m_try = 768\n",
        "\n",
        "clf = RandomForestRegressor(n_estimators=n_arbres, bootstrap=True, oob_score=True, max_features=m_try, n_jobs=-1)\n",
        "rfe = RFE(estimator=clf, n_features_to_select=10, step=1, verbose=1)\n",
        "rfe.fit(X, tf.squeeze(np.asarray(y),1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zh_PRuZxRDI8"
      },
      "source": [
        "# Sélection des variables par méthode RFE-CV"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8iI_zoEYRIH3"
      },
      "source": [
        "from sklearn.feature_selection import RFECV\n",
        "\n",
        "# Informations sur les données\n",
        "n = 102               # Nombre d'observations\n",
        "p = 6033              # Nombre de variables\n",
        "n_arbres = 100\n",
        "m_try = 768\n",
        "\n",
        "clf = RandomForestRegressor(n_estimators=n_arbres, bootstrap=True, oob_score=True, max_features=\"auto\", n_jobs=-1)\n",
        "rfecv = RFECV(estimator=clf, step=1, cv=5, scoring='neg_mean_absolute_error',min_features_to_select=1, verbose=1)\n",
        "rfecv.fit(X, tf.squeeze(np.asarray(y),1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E5JlcXHEXFrM"
      },
      "source": [
        "# Autre"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mQcStfHvJpgB"
      },
      "source": [
        "features_list=[]\n",
        "indicateurs_techniques=['sma','ema','wma','trix', 'std','skew','rsi','roc']\n",
        "periode=['3','7','14','30','90']\n",
        "\n",
        "for indicateur in indicateurs_techniques:\n",
        "    for i in periode:\n",
        "      print(\"%s%s\" %(indicateur, i))\n",
        "      filtre = str(indicateur) + str(i) + \"$\"\n",
        "\n",
        "      X = df_data.filter(regex=filtre,axis=1)\n",
        "      X = SimpleImputer(missing_values=np.nan,strategy='most_frequent').fit_transform(X)\n",
        "      X = pd.DataFrame(X)\n",
        "      X.columns = df_data.filter(regex=filtre,axis=1).columns\n",
        "\n",
        "      rf1 = RandomForestRegressor(random_state=7,n_jobs=-1)\n",
        "      rfecv = RFECV(rf1,step=0.9,min_features_to_select=1,verbose=1,cv=5,scoring='neg_mean_absolute_error', n_jobs=1)\n",
        "      rfecv.fit(X,tf.squeeze(np.asarray(y),1))\n",
        "\n",
        "      if rfecv.n_features_ > 1:\n",
        "        rf1.fit(X,tf.squeeze(np.asarray(y),1))\n",
        "        maximp = rf1.feature_importances_.max()\n",
        "        for x in range(len(rf1.feature_importances_)):\n",
        "          if maximp==rf1.feature_importances_[x]:\n",
        "            new_features = X.columns[x]\n",
        "      else:\n",
        "        mask = rfecv.get_support()\n",
        "        new_features = X.columns[mask]\n",
        "      features_list.append(str(new_features))\n",
        "      print(filtre+ ': ' + new_features)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nBx72JIezD1U"
      },
      "source": [
        "features_list"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fVSzwVs1y861"
      },
      "source": [
        "l1=[]\n",
        "\n",
        "for j in range(len(features_list)):\n",
        "    result1 = re.search(\"'(.*)'],\", features_list[j])\n",
        "    if result1!=None:\n",
        "        l1.append(result1.group(1))\n",
        "        \n",
        "for i in range(len(features_list)):\n",
        "    result2 = re.search('.*',features_list[i])\n",
        "    if len(result2.group(0))<33:\n",
        "        l1.append(result2.group(0))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "57GxV4JKzU6U"
      },
      "source": [
        "l1.sort()\n",
        "l1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4CT3qzPrzxIj"
      },
      "source": [
        "df_data_reduit=df_data[l1]\n",
        "df_data_reduit.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bjy_YVTr1m7M"
      },
      "source": [
        "Suppresion des valeurs non numériques :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "31ApzegO1QDk"
      },
      "source": [
        "df_data_reduit = SimpleImputer(missing_values=np.nan,strategy='most_frequent').fit_transform(df_data_reduit)\n",
        "df_data_reduit = pd.DataFrame(X)\n",
        "df_data_reduit.columns = df_data_reduit.columns\n",
        "df_data_reduit"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k63XrNH-0tOH"
      },
      "source": [
        "# Identifications des variables réstantes collinéraires "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1SFtVw21029m"
      },
      "source": [
        "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
        "from statsmodels.tools.tools import add_constant\n",
        "\n",
        "#function for removing features with high vif\n",
        "def drop_high_vif(X, thresh=100):\n",
        "    cols = X.columns\n",
        "    variables = np.arange(X.shape[1])\n",
        "    dropped=True\n",
        "    while dropped:\n",
        "        dropped=False\n",
        "        c = X[cols[variables]].values\n",
        "        vif = [variance_inflation_factor(c, ix) for ix in np.arange(c.shape[1])]\n",
        "\n",
        "        maxloc = vif.index(max(vif))\n",
        "        if max(vif) > thresh:\n",
        "            print('dropping \\'' + X[cols[variables]].columns[maxloc] + '\\' at index: ' + str(maxloc))\n",
        "            variables = np.delete(variables, maxloc)\n",
        "            dropped=True\n",
        "\n",
        "    print('Remaining variables:')\n",
        "    print(X.columns[variables])\n",
        "    return X[cols[variables]]\n",
        "\n",
        "#function for listing vif values\n",
        "def vif_values(X):\n",
        "    add_constant(X)\n",
        "    df=pd.Series([variance_inflation_factor(X.values, i) for i in range(X.shape[1])], index=X.columns)\n",
        "    return df\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OswToUPs0JlN"
      },
      "source": [
        "df_data_reduit = drop_high_vif(df_data_reduit,thresh=5)\n",
        "df_data_reduit"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NB1kSVbn2Pzv"
      },
      "source": [
        "vif_values(df_data_reduit)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LlOkpbgl2qDF"
      },
      "source": [
        "Raw=drop_high_vif(X_raw,thresh=10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6gZ2kL_Y2wRU"
      },
      "source": [
        "vif_values(Raw)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "goBAbqwd4RQd"
      },
      "source": [
        "Raw.insert(0,'Dates',df_data['Dates'])\n",
        "df_data_reduit.insert(0,'Dates',df_data['Dates'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8VGQs-5q4pmN"
      },
      "source": [
        "df_merged=Raw.merge(df_data_reduit,how='outer')\n",
        "df_merged.drop_duplicates()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IiKVRyIe5XLW"
      },
      "source": [
        "df_merged.drop(columns='Dates',inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IlqWHI2t5agO"
      },
      "source": [
        "df_data_reduit=drop_high_vif(df_merged,thresh=10)\n",
        "df_data_reduit"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zccw4Htr5l9v"
      },
      "source": [
        "vif_values(df_data_reduit)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0oTJu09w5wYj"
      },
      "source": [
        "rf_final=RandomForestRegressor(random_state=7,n_jobs=-1)\n",
        "rf_final.fit(df_data_reduit,tf.squeeze(np.asarray(y),1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dCS6ALKs6EwL"
      },
      "source": [
        "# function for creating a feature importance dataframe\n",
        "def feature_importance(column_names, importances):\n",
        "    df = pd.DataFrame({'feature': column_names, 'feature_importance': importances}).sort_values('feature_importance', ascending = False).reset_index(drop = True)\n",
        "    return df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-0zNaiQr6RJO"
      },
      "source": [
        "# plotting a feature importance dataframe (horizontal barchart)\n",
        "def plot_feature_importance(imp_df, title):\n",
        "    # figure size in inches\n",
        "    plt.rcParams['figure.figsize'] = 11.7,8.27\n",
        "    imp_df.columns = ['feature', 'feature_importance']\n",
        "    sns.barplot(x = 'feature_importance', y = 'feature', data = imp_df, color = 'royalblue').set_title(title, fontsize = 20)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NevJa1uu6DUj"
      },
      "source": [
        "imp_feat=feature_importance(df_data_reduit.columns,rf_final.feature_importances_)\n",
        "plot_feature_importance(imp_feat,'feature importance')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CMmGxitm6634"
      },
      "source": [
        "imp_feat[imp_feat['feature_importance']>0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "keB7Vwbp7fIL"
      },
      "source": [
        "selected = imp_feat[imp_feat['feature_importance']>0]\n",
        "selected"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v3Uw2i_a7tOb"
      },
      "source": [
        "selected.feature_importance.sum()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SYpnTmoB7vtJ"
      },
      "source": [
        "df_data_reduit_high = df_data_reduit[np.asarray(selected.feature)]\n",
        "df_data_reduit_high.sort_index(axis=1,inplace=True)\n",
        "df_data_reduit_high['Price'] = np.ravel(y)\n",
        "df_data_reduit_high = df_data_reduit_high[df_data_reduit_high['Price']!=1]\n",
        "df_data_reduit_high"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PTZxkbtW8QnF"
      },
      "source": [
        "corr = df_data_reduit_high.corr()\n",
        "\n",
        "# Generate a mask for the upper triangle\n",
        "mask = np.triu(np.ones_like(corr, dtype=np.bool))\n",
        "\n",
        "# Set up the matplotlib figure\n",
        "f, ax = plt.subplots(figsize=(15, 8))\n",
        "\n",
        "sns.heatmap(corr,mask=mask, cmap='coolwarm',annot=True, fmt='.2f')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B1vTUIhB_hxU"
      },
      "source": [
        "from sklearn.ensemble import IsolationForest\n",
        "\n",
        "anomalies=IsolationForest(contamination=0.1)\n",
        "\n",
        "price=df_data_reduit_high['Price']\n",
        "price=price.values\n",
        "price=np.reshape(price,(-1,1))\n",
        "anomalies.fit(price)\n",
        "\n",
        "pred=anomalies.predict(price)\n",
        "\n",
        "df_data_reduit_high['Anomalies'] = pred\n",
        "df_data_reduit_high['Anomalies'] = df_data_reduit_high['Anomalies'].apply(lambda x: 1 if (x==-1) else 0)\n",
        "\n",
        "# Affiche les informations sur les anomalies\n",
        "print(df_data_reduit_high['Anomalies'].value_counts())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WvF0VEoYAwzB"
      },
      "source": [
        "import plotly.express as px\n",
        "\n",
        "# Affiche la série\n",
        "\n",
        "fig = px.line(x=df_data_reduit_high.index,y=df_data_reduit_high['Price'],title=\"Evolution du prix du BTC\")\n",
        "fig.add_trace(px.scatter(x=df_data_reduit_high.index,y=df_data_reduit_high['Anomalies']*df_data_reduit_high['Price'],color=df_data_reduit_high['Anomalies'].astype(np.bool)).data[0])\n",
        "\n",
        "fig.update_xaxes(rangeslider_visible=True)\n",
        "yaxis=dict(autorange = True,fixedrange= False)\n",
        "fig.update_yaxes(yaxis)\n",
        "fig.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fA8SLXVYAMax"
      },
      "source": [
        "#df_data_reduit_high.reset_index(drop=True,inplace=True)\n",
        "df_data_reduit_high.drop(columns=['Anomalies'],inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yuNLVObdBS-I"
      },
      "source": [
        "df_data_reduit_high.insert(0,'Dates',df_data['Dates'])\n",
        "df_data_reduit_high.set_index(df_data_reduit_high['Dates'])\n",
        "df_data_reduit_high"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XU01ischDDiA"
      },
      "source": [
        "df_data_reduit_high.columns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d54pzv4cDNpQ"
      },
      "source": [
        "df_data_reduit_high.to_csv('reg_1d.csv')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}