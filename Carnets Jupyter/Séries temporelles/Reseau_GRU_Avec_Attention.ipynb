{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Reseau_GRU_Avec_Attention.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOhWsCSn9kMU6aX5SgNIb7s",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AlexandreBourrieau/ML/blob/main/Carnets%20Jupyter/S%C3%A9ries%20temporelles/Reseau_GRU_Avec_Attention.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ubCeIvtF6R4W"
      },
      "source": [
        "Dans ce carnet nous allons mettre en place un modèle à réseau de neurones récurrent de type GRU associé à une couche d'attention pour réaliser des prédictions sur notre série temporelle."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RRhtHsNn5fc3"
      },
      "source": [
        "import tensorflow as tf\r\n",
        "from tensorflow import keras\r\n",
        "\r\n",
        "import numpy as np\r\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 261,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XFeah3y_6kif"
      },
      "source": [
        "# Création de la série temporelle et du dataset pour l'entrainement"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vJfSLtub6sdc"
      },
      "source": [
        "# Fonction permettant d'afficher une série temporelle\r\n",
        "def affiche_serie(temps, serie, format=\"-\", debut=0, fin=None, label=None):\r\n",
        "    plt.plot(temps[debut:fin], serie[debut:fin], format, label=label)\r\n",
        "    plt.xlabel(\"Temps\")\r\n",
        "    plt.ylabel(\"Valeur\")\r\n",
        "    if label:\r\n",
        "        plt.legend(fontsize=14)\r\n",
        "    plt.grid(True)\r\n",
        "\r\n",
        "# Fonction permettant de créer une tendance\r\n",
        "def tendance(temps, pente=0):\r\n",
        "    return pente * temps\r\n",
        "\r\n",
        "# Fonction permettant de créer un motif\r\n",
        "def motif_periodique(instants):\r\n",
        "    return (np.where(instants < 0.4,                            # Si les instants sont < 0.4\r\n",
        "                    np.cos(instants * 2 * np.pi),               # Alors on retourne la fonction cos(2*pi*t)\r\n",
        "                    1 / np.exp(3 * instants)))                  # Sinon, on retourne la fonction exp(-3t)\r\n",
        "\r\n",
        "# Fonction permettant de créer une saisonnalité avec un motif\r\n",
        "def saisonnalite(temps, periode, amplitude=1, phase=0):\r\n",
        "    \"\"\"Répétition du motif sur la même période\"\"\"\r\n",
        "    instants = ((temps + phase) % periode) / periode            # Mapping du temps =[0 1 2 ... 1460] => instants = [0.0 ... 1.0]\r\n",
        "    return amplitude * motif_periodique(instants)\r\n",
        "\r\n",
        "# Fonction permettant de générer du bruit gaussien N(0,1)\r\n",
        "def bruit_blanc(temps, niveau_bruit=1, graine=None):\r\n",
        "    rnd = np.random.RandomState(graine)\r\n",
        "    return rnd.randn(len(temps)) * niveau_bruit\r\n",
        "\r\n",
        "# Fonction permettant de créer un dataset à partir des données de la série temporelle\r\n",
        "# au format X(X1,X2,...Xn) / Y(Y1,Y2,...,Yn)\r\n",
        "# X sont les données d'entrées du réseau\r\n",
        "# Y sont les labels\r\n",
        "\r\n",
        "def prepare_dataset_XY(serie, taille_fenetre, batch_size, buffer_melange):\r\n",
        "  dataset = tf.data.Dataset.from_tensor_slices(serie)\r\n",
        "  dataset = dataset.window(taille_fenetre+1, shift=1, drop_remainder=True)\r\n",
        "  dataset = dataset.flat_map(lambda x: x.batch(taille_fenetre + 1))\r\n",
        "  dataset = dataset.shuffle(buffer_melange).map(lambda x: (x[:-1], x[-1:]))\r\n",
        "  dataset = dataset.batch(batch_size,drop_remainder=True).prefetch(1)\r\n",
        "  return dataset\r\n",
        "\r\n",
        "\r\n",
        "# Création de la série temporelle\r\n",
        "temps = np.arange(4 * 365)                # temps = [0 1 2 .... 4*365] = [0 1 2 .... 1460]\r\n",
        "amplitude = 40                            # Amplitude de la la saisonnalité\r\n",
        "niveau_bruit = 5                          # Niveau du bruit\r\n",
        "offset = 10                               # Offset de la série\r\n",
        "\r\n",
        "serie = offset + tendance(temps, 0.1) + saisonnalite(temps, periode=365, amplitude=amplitude) + bruit_blanc(temps,niveau_bruit)\r\n",
        "\r\n",
        "temps_separation = 1000\r\n",
        "\r\n",
        "# Extraction des temps et des données d'entrainement\r\n",
        "temps_entrainement = temps[:temps_separation]\r\n",
        "x_entrainement = serie[:temps_separation]\r\n",
        "\r\n",
        "# Exctraction des temps et des données de valiadation\r\n",
        "temps_validation = temps[temps_separation:]\r\n",
        "x_validation = serie[temps_separation:]\r\n",
        "\r\n",
        "# Définition des caractéristiques du dataset que l'on souhaite créer\r\n",
        "taille_fenetre = 20\r\n",
        "batch_size = 1\r\n",
        "buffer_melange = 1000\r\n",
        "\r\n",
        "# Création du dataset X,Y\r\n",
        "dataset = prepare_dataset_XY(serie,taille_fenetre,batch_size,buffer_melange)\r\n",
        "\r\n",
        "# Création du dataset X,Y de validation\r\n",
        "dataset_Val = prepare_dataset_XY(x_validation,taille_fenetre,batch_size,buffer_melange)"
      ],
      "execution_count": 262,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Yt-EgZ3sgPY"
      },
      "source": [
        "# Création du modèle GRU avec couche d'attention personnalisée simple"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dyrcfKcgCsZ7"
      },
      "source": [
        "**1. Création du réseau et adaptation des formats d'entrée et de sortie**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zeJyix8HK7Kt"
      },
      "source": [
        "Sous forme de shéma, notre réseau est donc le suivant :\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1OZkfsmnBNHY"
      },
      "source": [
        "<img src=\"https://github.com/AlexandreBourrieau/ML/blob/main/Carnets%20Jupyter/S%C3%A9ries%20temporelles/images/LSTM_1.png?raw=true\" width=\"1200\"> "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4kgTrJOQ5DUo"
      },
      "source": [
        "# Remise à zéro de tous les états générés par Keras\r\n",
        "tf.keras.backend.clear_session()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hLNIAGDlBizT"
      },
      "source": [
        "On créé une classe dérivée de la classe [Layer](https://keras.io/api/layers/base_layer/#layer-class) de Keras. Les méthodes utilisées sont les suivantes :  \r\n",
        " - [build](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Layer#build) : Permet de créer les variables utilisées par la couche (commes les poids et les offsets)\r\n",
        " - [call](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Layer#call) : Permet d'implanter la logique de la couche"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FkseSQGFp56u"
      },
      "source": [
        "# Importe le Backend de Keras\r\n",
        "from keras import backend as K\r\n",
        "\r\n",
        "# Définit une nouvelle classe Couche_Attention\r\n",
        "# Héritée de la classe Layer de Keras\r\n",
        "\r\n",
        "class Couche_Attention(tf.keras.layers.Layer):\r\n",
        "  # Fonction d'initialisation de la classe d'attention\r\n",
        "  def __init__(self,dim):\r\n",
        "    self.dense_layer = tf.keras.layers.Dense(units=1,activation=\"tanh\",trainable=True)\r\n",
        "    self.dim = dim              # Dimension des vecteurs cachés de la couche récurrente\r\n",
        "    super().__init__()          # Appel du __init__() de la classe Layer\r\n",
        "  \r\n",
        "  def build(self,input_shape):\r\n",
        "    super().build(input_shape)        # Appel de la méthode build()\r\n",
        "\r\n",
        "  # Définit la logique de la couche d'attention\r\n",
        "  # Arguments :   x : Tenseur d'entrée de dimension (None, nbr_v,dim)\r\n",
        "  def call(self,x):\r\n",
        "    e = self.dense_layer(x)\r\n",
        "    a = tf.keras.activations.softmax(e,axis=1)\r\n",
        "    print(x.shape)\r\n",
        "    print(a.shape)\r\n",
        "    xa = tf.multiply(x,a)\r\n",
        "    sortie = K.sum(xa,axis=1)\r\n",
        "    return sortie"
      ],
      "execution_count": 144,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fh6VKh5GHhUi"
      },
      "source": [
        "# Importe le Backend de Keras\r\n",
        "from keras import backend as K\r\n",
        "\r\n",
        "# Définit une nouvelle classe Couche_Attention\r\n",
        "# Héritée de la classe Layer de Keras\r\n",
        "\r\n",
        "class Couche_Attention(tf.keras.layers.Layer):\r\n",
        "  # Fonction d'initialisation de la classe d'attention\r\n",
        "  def __init__(self,dim):\r\n",
        "    self.dense_layer = tf.keras.layers.Dense(units=1,activation=\"tanh\",trainable=True)\r\n",
        "    self.dim = dim              # Dimension des vecteurs cachés de la couche récurrente\r\n",
        "    super().__init__()          # Appel du __init__() de la classe Layer\r\n",
        "  \r\n",
        "  def build(self,input_shape):\r\n",
        "    super().build(input_shape)        # Appel de la méthode build()\r\n",
        "\r\n",
        "  # Définit la logique de la couche d'attention\r\n",
        "  # Arguments :   x : Tenseur d'entrée de dimension (None, nbr_v,dim)\r\n",
        "  def call(self,x,Y):\r\n",
        "    e = self.dense_layer(x)\r\n",
        "    a = tf.keras.activations.softmax(e,axis=1)\r\n",
        "#    print(\"x : %s\" %x.shape)\r\n",
        "#    print(\"Y : %s\" %Y.shape)\r\n",
        "#    print(\"a : %s\" %a.shape)\r\n",
        "    t0 = tf.expand_dims(tf.multiply(a[0,:,:],Y[0,:]),axis=0)\r\n",
        "    for i in range(1,x.shape[0]):\r\n",
        "      t1 = tf.expand_dims(tf.multiply(a[i,:,:],Y[i,:]),axis=0)\r\n",
        "      t2 = tf.concat([t0,t1],0)\r\n",
        "      t0 = t2\r\n",
        "\r\n",
        "#    xa = tf.multiply(a,Y)\r\n",
        "    sortie = K.sum(t0,axis=1)\r\n",
        "    return sortie"
      ],
      "execution_count": 318,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JWett9utSPAJ",
        "outputId": "38845a77-3c24-4edb-9465-440753c4e447"
      },
      "source": [
        "summary_placeholders = K.placeholder(shape=(1))\r\n",
        "summary_placeholders"
      ],
      "execution_count": 273,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<KerasTensor: shape=(1,) dtype=float32 (created by layer 'input_87')>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 273
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A4N-kZanH656",
        "outputId": "160008a9-b8fa-44da-bac5-6e03f3e15c2c"
      },
      "source": [
        "Y = tf.Variable([[1,2,3],[1,2,3]],dtype=tf.float32)\r\n",
        "x = tf.Variable([[[1,2,1,1],[1,1,1,1],[1,1,1,1]],[[1,2,1,1],[1,1,1,1],[1,1,1,1]]],dtype=tf.float32)\r\n",
        "a = tf.Variable([[[2],[1],[1]],[[2],[1],[1]]],dtype=tf.float32)\r\n",
        "xa = x*a\r\n",
        "print(\"x : %s\" %x.shape)\r\n",
        "print(\"Y : %s\" %Y.shape)\r\n",
        "print(\"a : %s\" %a.shape)\r\n",
        "\r\n",
        "s = K.sum(xa,axis=1)\r\n",
        "res = K.placeholder(shape=(2,2,1),dtype=tf.float32)\r\n",
        "#tf.add(res,tf.multiply(a[0,:,:],Y[0,:]))\r\n",
        "\r\n",
        "t1 = tf.expand_dims(tf.multiply(a[0,:,:],Y[0,:]),axis=0)\r\n",
        "t2 = tf.expand_dims(tf.multiply(a[1,:,:],Y[1,:]),axis=0)\r\n",
        "tf.concat([t1,t2],0)"
      ],
      "execution_count": 306,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x : (2, 3, 4)\n",
            "Y : (2, 3)\n",
            "a : (2, 3, 1)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2, 3, 3), dtype=float32, numpy=\n",
              "array([[[2., 4., 6.],\n",
              "        [1., 2., 3.],\n",
              "        [1., 2., 3.]],\n",
              "\n",
              "       [[2., 4., 6.],\n",
              "        [1., 2., 3.],\n",
              "        [1., 2., 3.]]], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 306
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b1eWoM9uII4q",
        "outputId": "f8c4bd42-0999-4e70-d433-f87e9e10a7a2"
      },
      "source": [
        "Couche_Attention(4)(x,X)"
      ],
      "execution_count": 222,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1, 3)\n",
            "(1, 3, 1)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 3), dtype=float32, numpy=array([[1., 2., 3.]], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 222
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RTqdYAsF_ici",
        "outputId": "718685a8-10f1-4c5b-cc30-782aa6006a8c"
      },
      "source": [
        "# Couche d'attention perso\r\n",
        "\r\n",
        "dim_GRU = 40\r\n",
        "\r\n",
        "# Fonction de la couche lambda d'entrée\r\n",
        "def Traitement_Entrees(x):\r\n",
        "  return tf.expand_dims(x,axis=-1)\r\n",
        "\r\n",
        "# Fonction dela couche lambda de sortie\r\n",
        "def Traitement_Sorties(x):\r\n",
        "  return(x*100.0)\r\n",
        "\r\n",
        "inputs = tf.keras.Input(shape=(20),batch_size=32)\r\n",
        "a = tf.keras.layers.Lambda(Traitement_Entrees)(inputs)\r\n",
        "b = tf.keras.layers.GRU(dim_GRU,return_sequences=True)(a)\r\n",
        "c = Couche_Attention(dim=dim_GRU)(b,inputs)\r\n",
        "d = tf.keras.layers.Dense(1)(c)\r\n",
        "e = tf.keras.layers.Lambda(Traitement_Sorties)(d)\r\n",
        "\r\n",
        "model = tf.keras.Model(inputs,e)\r\n",
        "\r\n",
        "model.save_weights('model_initial.h5')\r\n",
        "\r\n",
        "model.summary()"
      ],
      "execution_count": 324,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_14\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_117 (InputLayer)          [(32, 20)]           0                                            \n",
            "__________________________________________________________________________________________________\n",
            "lambda_109 (Lambda)             (32, 20, 1)          0           input_117[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "gru_70 (GRU)                    (32, 20, 40)         5160        lambda_109[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "couche__attention_100 (Couche_A (32, 20)             41          gru_70[0][0]                     \n",
            "                                                                 input_117[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_142 (Dense)               (32, 1)              21          couche__attention_100[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "lambda_110 (Lambda)             (32, 1)              0           dense_142[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 5,222\n",
            "Trainable params: 5,222\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CjIDum89KZu5"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dsyTyoMk8mzf"
      },
      "source": [
        "x = tf.Variable([[[1,2,1,1],[1,1,1,1],[1,1,1,1]]])\r\n",
        "a = tf.Variable([[[2],[1],[1]]])\r\n",
        "xa = x*a\r\n",
        "print(xa)\r\n",
        "s = K.sum(xa,axis=1)\r\n",
        "print(s)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MUM0-SSXGLIQ"
      },
      "source": [
        "**2. Optimisation du taux d'apprentissage**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jejCBhXVuNQ4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 575
        },
        "outputId": "2294ac06-3083-45d2-c81e-8e2878c223a6"
      },
      "source": [
        "# Définition de la fonction de régulation du taux d'apprentissage\r\n",
        "def RegulationTauxApprentissage(periode, taux):\r\n",
        "  return 1e-8*10**(periode/10)\r\n",
        "\r\n",
        "# Définition de l'optimiseur à utiliser\r\n",
        "optimiseur=tf.keras.optimizers.Adam()\r\n",
        "\r\n",
        "# Utilisation de la méthode ModelCheckPoint\r\n",
        "CheckPoint = tf.keras.callbacks.ModelCheckpoint(\"poids.hdf5\", monitor='loss', verbose=1, save_best_only=True, save_weights_only = True, mode='auto', save_freq='epoch')\r\n",
        "\r\n",
        "# Compile le modèle\r\n",
        "model.compile(loss=tf.keras.losses.Huber(), optimizer=optimiseur, metrics=\"mae\")\r\n",
        "\r\n",
        "# Entraine le modèle en utilisant notre fonction personnelle de régulation du taux d'apprentissage\r\n",
        "historique = model.fit(dataset,epochs=100,verbose=1, callbacks=[tf.keras.callbacks.LearningRateScheduler(RegulationTauxApprentissage), CheckPoint])"
      ],
      "execution_count": 325,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "WARNING:tensorflow:Model was constructed with shape (32, 20) for input KerasTensor(type_spec=TensorSpec(shape=(32, 20), dtype=tf.float32, name='input_117'), name='input_117', description=\"created by layer 'input_117'\"), but it was called on an input with incompatible shape (1, None).\n",
            "WARNING:tensorflow:Model was constructed with shape (32, 20) for input KerasTensor(type_spec=TensorSpec(shape=(32, 20), dtype=tf.float32, name='input_117'), name='input_117', description=\"created by layer 'input_117'\"), but it was called on an input with incompatible shape (1, None).\n",
            "1440/1440 [==============================] - 11s 6ms/step - loss: 9214.7506 - mae: 9215.2485\n",
            "\n",
            "Epoch 00001: loss improved from inf to 9722.86914, saving model to poids.hdf5\n",
            "Epoch 2/100\n",
            "1440/1440 [==============================] - 9s 6ms/step - loss: 8896.8739 - mae: 8897.3715\n",
            "\n",
            "Epoch 00002: loss improved from 9722.86914 to 9721.14746, saving model to poids.hdf5\n",
            "Epoch 3/100\n",
            " 673/1440 [=============>................] - ETA: 5s - loss: 8602.8150 - mae: 8603.3150"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-325-822545f8e42c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m# Entraine le modèle en utilisant notre fonction personnelle de régulation du taux d'apprentissage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mhistorique\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLearningRateScheduler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRegulationTauxApprentissage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCheckPoint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 _r=1):\n\u001b[1;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    853\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 855\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    856\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    857\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2942\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2943\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2945\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1917\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1918\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1919\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1921\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    558\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    561\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q1_WMNlzu2B4"
      },
      "source": [
        "# Construit un vecteur avec les valeurs du taux d'apprentissage à chaque période \r\n",
        "taux = 1e-8*(10**(np.arange(100)/10))\r\n",
        "\r\n",
        "# Affiche l'erreur en fonction du taux d'apprentissage\r\n",
        "plt.figure(figsize=(10, 6))\r\n",
        "plt.semilogx(taux,historique.history[\"loss\"])\r\n",
        "plt.axis([ taux[0], taux[99], 0, 100])\r\n",
        "plt.title(\"Evolution de l'erreur en fonction du taux d'apprentissage\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6XdXh_b0GP_F"
      },
      "source": [
        "**3. Entrainement du modèle**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "80pEtJ10wIfY"
      },
      "source": [
        "# Charge les meilleurs poids\r\n",
        "model.load_weights(\"poids.hdf5\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "16ujUiELwR33"
      },
      "source": [
        "# Définition de l'optimiseur à utiliser\r\n",
        "optimiseur=tf.keras.optimizers.Adam(lr=1e-2)\r\n",
        "\r\n",
        "\r\n",
        "# Utilisation de la méthode ModelCheckPoint\r\n",
        "CheckPoint = tf.keras.callbacks.ModelCheckpoint(\"poids.hdf5\", monitor='loss', verbose=1, save_best_only=True, save_weights_only = True, mode='auto', save_freq='epoch')\r\n",
        "\r\n",
        "# Compile le modèle\r\n",
        "model.compile(loss=tf.keras.losses.Huber(), optimizer=optimiseur,metrics=\"mae\")\r\n",
        "\r\n",
        "# Entraine le modèle\r\n",
        "historique = model.fit(dataset,validation_data=dataset_Val, epochs=500,verbose=1, callbacks=[CheckPoint])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "COP9u4yitvmw"
      },
      "source": [
        "erreur_entrainement = historique.history[\"loss\"]\r\n",
        "erreur_validation = historique.history[\"val_loss\"]\r\n",
        "\r\n",
        "# Affiche l'erreur en fonction de la période\r\n",
        "plt.figure(figsize=(10, 6))\r\n",
        "plt.plot(np.arange(0,len(erreur_entrainement)),erreur_entrainement, label=\"Erreurs sur les entrainements\")\r\n",
        "plt.plot(np.arange(0,len(erreur_entrainement)),erreur_validation, label =\"Erreurs sur les validations\")\r\n",
        "plt.legend()\r\n",
        "\r\n",
        "plt.title(\"Evolution de l'erreur en fonction de la période\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_o2zh6N9t1b7"
      },
      "source": [
        "erreur_entrainement = historique.history[\"loss\"]\r\n",
        "erreur_validation = historique.history[\"val_loss\"]\r\n",
        "\r\n",
        "# Affiche l'erreur en fonction de la période\r\n",
        "plt.figure(figsize=(10, 6))\r\n",
        "plt.plot(np.arange(0,len(erreur_entrainement[400:500])),erreur_entrainement[400:500], label=\"Erreurs sur les entrainements\")\r\n",
        "plt.plot(np.arange(0,len(erreur_entrainement[400:500])),erreur_validation[400:500], label =\"Erreurs sur les validations\")\r\n",
        "plt.legend()\r\n",
        "\r\n",
        "plt.title(\"Evolution de l'erreur en fonction de la période\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T6Gq2CkeGR_1"
      },
      "source": [
        "**4. Prédictions**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OcGnqie_GVNE"
      },
      "source": [
        "# Charge les meilleurs poids\r\n",
        "model.load_weights(\"poids.hdf5\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HRxXtHRXGXfF"
      },
      "source": [
        "taille_fenetre = 20\r\n",
        "\r\n",
        "# Création d'une liste vide pour recevoir les prédictions\r\n",
        "predictions = []\r\n",
        "\r\n",
        "# Calcul des prédiction pour chaque groupe de 20 valeurs consécutives de la série\r\n",
        "# dans l'intervalle de validation\r\n",
        "for t in temps[temps_separation:-taille_fenetre]:\r\n",
        "    X = np.reshape(serie[t:t+taille_fenetre],(1,taille_fenetre))\r\n",
        "    predictions.append(model.predict(X))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wd2nfDcgG8EO"
      },
      "source": [
        "# Affiche la série et les prédictions\r\n",
        "plt.figure(figsize=(10, 6))\r\n",
        "affiche_serie(temps,serie,label=\"Série temporelle\")\r\n",
        "affiche_serie(temps[temps_separation+taille_fenetre:],np.asarray(predictions)[:,0,0],label=\"Prédictions\")\r\n",
        "plt.title('Prédictions avec le modèle de régression linéaire')\r\n",
        "plt.show()\r\n",
        "\r\n",
        "# Zoom sur l'intervalle de validation\r\n",
        "plt.figure(figsize=(10, 6))\r\n",
        "affiche_serie(temps[temps_separation:],serie[temps_separation:],label=\"Série temporelle\")\r\n",
        "affiche_serie(temps[temps_separation+taille_fenetre:],np.asarray(predictions)[:,0,0],label=\"Prédictions\")\r\n",
        "plt.title(\"Prédictions avec le modèle de régression linéaire (zoom sur l'intervalle de validation)\")\r\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PDS7BJvZG_e1"
      },
      "source": [
        "# Calcule de l'erreur quadratique moyenne et de l'erreur absolue moyenne \r\n",
        "\r\n",
        "mae = tf.keras.metrics.mean_absolute_error(serie[temps_separation+taille_fenetre:],np.asarray(predictions)[:,0,0]).numpy()\r\n",
        "mse = tf.keras.metrics.mean_squared_error(serie[temps_separation+taille_fenetre:],np.asarray(predictions)[:,0,0]).numpy()\r\n",
        "\r\n",
        "print(mae)\r\n",
        "print(mse)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}