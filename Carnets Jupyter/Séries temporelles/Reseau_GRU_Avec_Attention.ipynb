{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Reseau_GRU_Avec_Attention.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AlexandreBourrieau/ML/blob/main/Carnets%20Jupyter/S%C3%A9ries%20temporelles/Reseau_GRU_Avec_Attention.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ubCeIvtF6R4W"
      },
      "source": [
        "Dans ce carnet nous allons mettre en place un modèle à réseau de neurones récurrent de type GRU associé à une couche d'attention pour réaliser des prédictions sur notre série temporelle."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RRhtHsNn5fc3"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XFeah3y_6kif"
      },
      "source": [
        "# Création de la série temporelle et du dataset pour l'entrainement"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vJfSLtub6sdc"
      },
      "source": [
        "# Fonction permettant d'afficher une série temporelle\n",
        "def affiche_serie(temps, serie, format=\"-\", debut=0, fin=None, label=None):\n",
        "    plt.plot(temps[debut:fin], serie[debut:fin], format, label=label)\n",
        "    plt.xlabel(\"Temps\")\n",
        "    plt.ylabel(\"Valeur\")\n",
        "    if label:\n",
        "        plt.legend(fontsize=14)\n",
        "    plt.grid(True)\n",
        "\n",
        "# Fonction permettant de créer une tendance\n",
        "def tendance(temps, pente=0):\n",
        "    return pente * temps\n",
        "\n",
        "# Fonction permettant de créer un motif\n",
        "def motif_periodique(instants):\n",
        "    return (np.where(instants < 0.4,                            # Si les instants sont < 0.4\n",
        "                    np.cos(instants * 2 * np.pi),               # Alors on retourne la fonction cos(2*pi*t)\n",
        "                    1 / np.exp(3 * instants)))                  # Sinon, on retourne la fonction exp(-3t)\n",
        "\n",
        "# Fonction permettant de créer une saisonnalité avec un motif\n",
        "def saisonnalite(temps, periode, amplitude=1, phase=0):\n",
        "    \"\"\"Répétition du motif sur la même période\"\"\"\n",
        "    instants = ((temps + phase) % periode) / periode            # Mapping du temps =[0 1 2 ... 1460] => instants = [0.0 ... 1.0]\n",
        "    return amplitude * motif_periodique(instants)\n",
        "\n",
        "# Fonction permettant de générer du bruit gaussien N(0,1)\n",
        "def bruit_blanc(temps, niveau_bruit=1, graine=None):\n",
        "    rnd = np.random.RandomState(graine)\n",
        "    return rnd.randn(len(temps)) * niveau_bruit\n",
        "\n",
        "# Fonction permettant de créer un dataset à partir des données de la série temporelle\n",
        "# au format X(X1,X2,...Xn) / Y(Y1,Y2,...,Yn)\n",
        "# X sont les données d'entrées du réseau\n",
        "# Y sont les labels\n",
        "\n",
        "def prepare_dataset_XY(serie, taille_fenetre, batch_size, buffer_melange):\n",
        "  dataset = tf.data.Dataset.from_tensor_slices(serie)\n",
        "  dataset = dataset.window(taille_fenetre+1, shift=1, drop_remainder=True)\n",
        "  dataset = dataset.flat_map(lambda x: x.batch(taille_fenetre + 1))\n",
        "  dataset = dataset.shuffle(buffer_melange).map(lambda x: (x[:-1], x[-1:]))\n",
        "  dataset = dataset.batch(batch_size,drop_remainder=True).prefetch(1)\n",
        "  return dataset\n",
        "\n",
        "\n",
        "# Création de la série temporelle\n",
        "temps = np.arange(4 * 365)                # temps = [0 1 2 .... 4*365] = [0 1 2 .... 1460]\n",
        "amplitude = 40                            # Amplitude de la la saisonnalité\n",
        "niveau_bruit = 5                          # Niveau du bruit\n",
        "offset = 10                               # Offset de la série\n",
        "\n",
        "serie = offset + tendance(temps, 0.1) + saisonnalite(temps, periode=365, amplitude=amplitude) + bruit_blanc(temps,niveau_bruit,graine=40)\n",
        "\n",
        "temps_separation = 1000\n",
        "\n",
        "# Extraction des temps et des données d'entrainement\n",
        "temps_entrainement = temps[:temps_separation]\n",
        "x_entrainement = serie[:temps_separation]\n",
        "\n",
        "# Exctraction des temps et des données de valiadation\n",
        "temps_validation = temps[temps_separation:]\n",
        "x_validation = serie[temps_separation:]\n",
        "\n",
        "# Définition des caractéristiques du dataset que l'on souhaite créer\n",
        "taille_fenetre = 20\n",
        "batch_size = 32\n",
        "buffer_melange = 1000\n",
        "\n",
        "# Création du dataset X,Y\n",
        "dataset = prepare_dataset_XY(x_entrainement,taille_fenetre,batch_size,buffer_melange)\n",
        "\n",
        "# Création du dataset X,Y de validation\n",
        "dataset_Val = prepare_dataset_XY(x_validation,taille_fenetre,batch_size,buffer_melange)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OyndQsxw0wue"
      },
      "source": [
        "# Calcul de la moyenne et de l'écart type de la série\n",
        "mean = tf.math.reduce_mean(serie)\n",
        "std = tf.math.reduce_std(serie)\n",
        "\n",
        "# Normalise les données\n",
        "Serie_Normalisee = (serie-mean)/std\n",
        "min = tf.math.reduce_min(serie)\n",
        "max = tf.math.reduce_max(serie)\n",
        "\n",
        "# Création des données pour l'entrainement et le test\n",
        "x_entrainement_norm = Serie_Normalisee[:temps_separation]\n",
        "x_validation_norm = Serie_Normalisee[temps_separation:]\n",
        "\n",
        "# Création du dataset X,Y\n",
        "dataset_norm = prepare_dataset_XY(x_entrainement_norm,taille_fenetre,batch_size,buffer_melange)\n",
        "\n",
        "# Création du dataset X,Y de validation\n",
        "dataset_Val_norm = prepare_dataset_XY(x_validation_norm,taille_fenetre,batch_size,buffer_melange)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1OqVqloRUw23"
      },
      "source": [
        "# Structure de base de type \"Séquence vers Séquence\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EycYqI-BpYrm"
      },
      "source": [
        "**1. Création du réseau**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bqh25e6kVBU2"
      },
      "source": [
        "dim_GRU = 40\n",
        "\n",
        "# Fonction de la couche lambda d'entrée\n",
        "def Traitement_Entrees(x):\n",
        "  return tf.expand_dims(x,axis=-1)\n",
        "\n",
        "model = tf.keras.models.Sequential()\n",
        "\n",
        "# Encodeur\n",
        "model.add(tf.keras.Input(shape=(None,)))\n",
        "model.add(tf.keras.layers.Lambda(Traitement_Entrees))\n",
        "model.add(tf.keras.layers.LSTM(40))\n",
        "\n",
        "# Décodeur\n",
        "model.add()\n",
        "model.add(tf.keras.layers.Dense(40,activation=\"tanh\"))\n",
        "\n",
        "# Générateur\n",
        "model.add(tf.keras.layers.Dense(1,activation=\"selu\"))\n",
        "\n",
        "\n",
        "model.save_weights('model_initial.h5')\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GoTPo68gpbrt"
      },
      "source": [
        "**2. Entrainement**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F74NnaZfkZVn"
      },
      "source": [
        "# Définition de la fonction de régulation du taux d'apprentissage\n",
        "def RegulationTauxApprentissage(periode, taux):\n",
        "  return 1e-8*10**(periode/10)\n",
        "\n",
        "# Définition de l'optimiseur à utiliser\n",
        "optimiseur=tf.keras.optimizers.SGD(lr=1e-8)\n",
        "\n",
        "# Utilisation de la méthode ModelCheckPoint\n",
        "CheckPoint = tf.keras.callbacks.ModelCheckpoint(\"poids.hdf5\", monitor='loss', verbose=1, save_best_only=True, save_weights_only = True, mode='auto', save_freq='epoch')\n",
        "\n",
        "# Compile le modèle\n",
        "model.compile(loss=tf.keras.losses.Huber(), optimizer=optimiseur, metrics=\"mae\")\n",
        "\n",
        "# Entraine le modèle en utilisant notre fonction personnelle de régulation du taux d'apprentissage\n",
        "historique = model.fit(dataset_norm,epochs=100,verbose=1, callbacks=[tf.keras.callbacks.LearningRateScheduler(RegulationTauxApprentissage), CheckPoint])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8-3sn0p-kscf"
      },
      "source": [
        "# Construit un vecteur avec les valeurs du taux d'apprentissage à chaque période \n",
        "taux = 1e-8*(10**(np.arange(100)/10))\n",
        "\n",
        "# Affiche l'erreur en fonction du taux d'apprentissage\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.semilogx(taux,historique.history[\"loss\"])\n",
        "plt.axis([ taux[0], taux[99], 0, 1])\n",
        "plt.title(\"Evolution de l'erreur en fonction du taux d'apprentissage\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2cgMrH2rky_2"
      },
      "source": [
        "# Charge les meilleurs poids\n",
        "model.load_weights(\"poids.hdf5\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3V6VC3sFk2uG"
      },
      "source": [
        "from timeit import default_timer as timer\n",
        "\n",
        "class TimingCallback(keras.callbacks.Callback):\n",
        "    def __init__(self, logs={}):\n",
        "        self.logs=[]\n",
        "    def on_epoch_begin(self, epoch, logs={}):\n",
        "        self.starttime = timer()\n",
        "    def on_epoch_end(self, epoch, logs={}):\n",
        "        self.logs.append(timer()-self.starttime)\n",
        "\n",
        "cb = TimingCallback()\n",
        "\n",
        "# Définition des paramètres liés à l'évolution du taux d'apprentissage\n",
        "lr_schedule = tf.keras.optimizers.schedules.InverseTimeDecay(\n",
        "    initial_learning_rate=0.2,\n",
        "    decay_steps=10,\n",
        "    decay_rate=0.05)\n",
        "\n",
        "# Définition de l'optimiseur à utiliser\n",
        "optimiseur=tf.keras.optimizers.SGD(learning_rate=lr_schedule,momentum=0.9)\n",
        "\n",
        "# Utilisation de la méthode ModelCheckPoint\n",
        "CheckPoint = tf.keras.callbacks.ModelCheckpoint(\"poids.hdf5\", monitor='loss', verbose=1, save_best_only=True, save_weights_only = True, mode='auto', save_freq='epoch')\n",
        "\n",
        "# Compile le modèle\n",
        "model.compile(loss=tf.keras.losses.Huber(), optimizer=optimiseur,metrics=\"mae\")\n",
        "\n",
        "# Entraine le modèle\n",
        "historique = model.fit(dataset_norm,validation_data=dataset_Val_norm, epochs=500,verbose=1, callbacks=[CheckPoint,cb])\n",
        "\n",
        "print(cb.logs)\n",
        "print(sum(cb.logs))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TJ8T28sIpoaX"
      },
      "source": [
        "erreur_entrainement = historique.history[\"loss\"]\n",
        "erreur_validation = historique.history[\"val_loss\"]\n",
        "\n",
        "# Affiche l'erreur en fonction de la période\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(np.arange(0,len(erreur_entrainement)),erreur_entrainement, label=\"Erreurs sur les entrainements\")\n",
        "plt.plot(np.arange(0,len(erreur_entrainement)),erreur_validation, label =\"Erreurs sur les validations\")\n",
        "plt.legend()\n",
        "\n",
        "plt.title(\"Evolution de l'erreur en fonction de la période\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qKOQt1cbpvqD"
      },
      "source": [
        "erreur_entrainement = historique.history[\"loss\"]\n",
        "erreur_validation = historique.history[\"val_loss\"]\n",
        "\n",
        "# Affiche l'erreur en fonction de la période\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(np.arange(0,len(erreur_entrainement[400:500])),erreur_entrainement[400:500], label=\"Erreurs sur les entrainements\")\n",
        "plt.plot(np.arange(0,len(erreur_entrainement[400:500])),erreur_validation[400:500], label =\"Erreurs sur les validations\")\n",
        "plt.legend()\n",
        "\n",
        "plt.title(\"Evolution de l'erreur en fonction de la période\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c4g1tUx9pjFi"
      },
      "source": [
        "**3. Prédictions**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "09PPC44WpigO"
      },
      "source": [
        "taille_fenetre = 20\n",
        "\n",
        "# Création d'une liste vide pour recevoir les prédictions\n",
        "predictions = []\n",
        "\n",
        "# Calcul des prédiction pour chaque groupe de 20 valeurs consécutives de la série\n",
        "# dans l'intervalle de validation\n",
        "for t in temps[temps_separation:-taille_fenetre]:\n",
        "    X = np.reshape(Serie_Normalisee[t:t+taille_fenetre],(1,taille_fenetre))\n",
        "    predictions.append(model.predict(X))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "shk5-XEzp1lg"
      },
      "source": [
        "# Affiche la série et les prédictions\n",
        "plt.figure(figsize=(10, 6))\n",
        "affiche_serie(temps,serie,label=\"Série temporelle\")\n",
        "affiche_serie(temps[temps_separation+taille_fenetre:],np.asarray(predictions*std+mean)[:,0,0],label=\"Prédictions\")\n",
        "plt.title('Prédictions avec le modèle GRU (Séquence-Séquence) sans attention')\n",
        "plt.show()\n",
        "\n",
        "# Zoom sur l'intervalle de validation\n",
        "plt.figure(figsize=(10, 6))\n",
        "affiche_serie(temps[temps_separation:],serie[temps_separation:],label=\"Série temporelle\")\n",
        "affiche_serie(temps[temps_separation+taille_fenetre:],np.asarray(predictions*std+mean)[:,0,0],label=\"Prédictions\")\n",
        "plt.title(\"Prédictions avec le modèle GRU (Séquence-Séquence) sans attention (zoom sur l'intervalle de validation)\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UwuCyXhXp7XX"
      },
      "source": [
        "# Calcule de l'erreur quadratique moyenne et de l'erreur absolue moyenne \n",
        "\n",
        "mae = tf.keras.metrics.mean_absolute_error(serie[temps_separation+taille_fenetre:],np.asarray(predictions*std+mean)[:,0,0]).numpy()\n",
        "mse = tf.keras.metrics.mean_squared_error(serie[temps_separation+taille_fenetre:],np.asarray(predictions*std+mean)[:,0,0]).numpy()\n",
        "\n",
        "print(mae)\n",
        "print(mse)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Yt-EgZ3sgPY"
      },
      "source": [
        "# Création du modèle GRU avec couche d'attention personnalisée simple"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dyrcfKcgCsZ7"
      },
      "source": [
        "**1. Création du réseau et adaptation des formats d'entrée et de sortie**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zeJyix8HK7Kt"
      },
      "source": [
        "Sous forme de shéma, notre réseau est donc le suivant :\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1OZkfsmnBNHY"
      },
      "source": [
        "<img src=\"https://github.com/AlexandreBourrieau/ML/blob/main/Carnets%20Jupyter/S%C3%A9ries%20temporelles/images/attention_11_Attention.png?raw=true\" width=\"1200\"> "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4kgTrJOQ5DUo"
      },
      "source": [
        "# Remise à zéro de tous les états générés par Keras\n",
        "tf.keras.backend.clear_session()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hLNIAGDlBizT"
      },
      "source": [
        "On créé une classe dérivée de la classe [Layer](https://keras.io/api/layers/base_layer/#layer-class) de Keras. Les méthodes utilisées sont les suivantes :  \n",
        " - [build](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Layer#build) : Permet de créer les variables utilisées par la couche (commes les poids et les offsets)\n",
        " - [call](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Layer#call) : Permet d'implanter la logique de la couche"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3COaR59t5WzJ"
      },
      "source": [
        "<img src=\"https://github.com/AlexandreBourrieau/ML/blob/main/Carnets%20Jupyter/S%C3%A9ries%20temporelles/images/attention_11_Attention_2.png?raw=true\" width=\"1200\"> "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hhk0kmPSgqva"
      },
      "source": [
        "# Classe d'attention simple\n",
        "# Applique les poids d'attention sur les vecteurs de la couche récurrente\n",
        "\n",
        "# Importe le Backend de Keras\n",
        "from keras import backend as K\n",
        "\n",
        "# Définit une nouvelle classe Couche_Attention\n",
        "# Héritée de la classe Layer de Keras\n",
        "\n",
        "class Couche_Attention(tf.keras.layers.Layer):\n",
        "  # Fonction d'initialisation de la classe d'attention\n",
        "  def __init__(self):\n",
        "    super().__init__()          # Appel du __init__() de la classe Layer\n",
        "  \n",
        "  def build(self,input_shape):\n",
        "    self.w = self.add_weight(shape=(input_shape[2],1),initializer=\"normal\",name=\"w\")\n",
        "    self.b = self.add_weight(shape=(input_shape[1],1),initializer=\"zeros\",name=\"b\")\n",
        "    super().build(input_shape)        # Appel de la méthode build()\n",
        "\n",
        "  # Définit la logique de la couche d'attention\n",
        "  # Arguments :   x : Tenseur d'entrée de dimension (None, nbr_v,dim)\n",
        "  def call(self,x):\n",
        "    e = K.tanh(K.dot(x,self.w)+self.b)\n",
        "    a = tf.keras.activations.softmax(e,axis=1)\n",
        "    xa = tf.multiply(x,a)\n",
        "    sortie = K.sum(xa,axis=1)\n",
        "    return sortie"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bfKC89gnniH5",
        "outputId": "77b0b2b0-3a42-440a-b361-c518c780ec66",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "dim_GRU = 40\n",
        "\n",
        "# Fonction de la couche lambda d'entrée\n",
        "def Traitement_Entrees(x):\n",
        "  return tf.expand_dims(x,axis=-1)\n",
        "\n",
        "model = tf.keras.models.Sequential()\n",
        "\n",
        "# Encodeur\n",
        "model.add(tf.keras.Input(shape=(taille_fenetre,),batch_size=batch_size))\n",
        "model.add(tf.keras.layers.Lambda(Traitement_Entrees))\n",
        "model.add(tf.keras.layers.Dropout(0.05))\n",
        "model.add(tf.keras.layers.GRU(dim_GRU,return_sequences=True))\n",
        "\n",
        "# Décodeur\n",
        "model.add(Couche_Attention())\n",
        "model.add(tf.keras.layers.Dense(40,activation=\"tanh\"))\n",
        "\n",
        "# Générateur\n",
        "model.add(tf.keras.layers.Dense(1,activation=\"selu\"))\n",
        "\n",
        "\n",
        "model.save_weights('model_initial.h5')\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lambda_6 (Lambda)            (32, 20, 1)               0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (32, 20, 1)               0         \n",
            "_________________________________________________________________\n",
            "gru_2 (GRU)                  (32, 20, 40)              5160      \n",
            "_________________________________________________________________\n",
            "couche__attention_5 (Couche_ (32, 40)                  60        \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (32, 40)                  1640      \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (32, 1)                   41        \n",
            "=================================================================\n",
            "Total params: 6,901\n",
            "Trainable params: 6,901\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MUM0-SSXGLIQ"
      },
      "source": [
        "**2. Optimisation du taux d'apprentissage**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jejCBhXVuNQ4",
        "outputId": "e48de519-dcb7-4a28-f35a-48e226df2550",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Définition de la fonction de régulation du taux d'apprentissage\n",
        "def RegulationTauxApprentissage(periode, taux):\n",
        "  return 1e-8*10**(periode/10)\n",
        "\n",
        "# Définition de l'optimiseur à utiliser\n",
        "optimiseur=tf.keras.optimizers.SGD(lr=1e-8)\n",
        "\n",
        "# Utilisation de la méthode ModelCheckPoint\n",
        "CheckPoint = tf.keras.callbacks.ModelCheckpoint(\"poids.hdf5\", monitor='loss', verbose=1, save_best_only=True, save_weights_only = True, mode='auto', save_freq='epoch')\n",
        "\n",
        "# Compile le modèle\n",
        "model.compile(loss=tf.keras.losses.Huber(), optimizer=optimiseur, metrics=\"mae\")\n",
        "\n",
        "# Entraine le modèle en utilisant notre fonction personnelle de régulation du taux d'apprentissage\n",
        "historique = model.fit(dataset_norm,epochs=100,verbose=1, callbacks=[tf.keras.callbacks.LearningRateScheduler(RegulationTauxApprentissage), CheckPoint])"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "30/30 [==============================] - 2s 7ms/step - loss: 0.3958 - mae: 0.7716\n",
            "\n",
            "Epoch 00001: loss improved from inf to 0.38011, saving model to poids.hdf5\n",
            "Epoch 2/100\n",
            "30/30 [==============================] - 0s 7ms/step - loss: 0.4064 - mae: 0.7908\n",
            "\n",
            "Epoch 00002: loss did not improve from 0.38011\n",
            "Epoch 3/100\n",
            "30/30 [==============================] - 0s 7ms/step - loss: 0.3865 - mae: 0.7639\n",
            "\n",
            "Epoch 00003: loss did not improve from 0.38011\n",
            "Epoch 4/100\n",
            "30/30 [==============================] - 0s 7ms/step - loss: 0.3697 - mae: 0.7435\n",
            "\n",
            "Epoch 00004: loss did not improve from 0.38011\n",
            "Epoch 5/100\n",
            "30/30 [==============================] - 0s 7ms/step - loss: 0.3941 - mae: 0.7773\n",
            "\n",
            "Epoch 00005: loss did not improve from 0.38011\n",
            "Epoch 6/100\n",
            "30/30 [==============================] - 0s 7ms/step - loss: 0.3881 - mae: 0.7701\n",
            "\n",
            "Epoch 00006: loss did not improve from 0.38011\n",
            "Epoch 7/100\n",
            "30/30 [==============================] - 0s 7ms/step - loss: 0.3813 - mae: 0.7616\n",
            "\n",
            "Epoch 00007: loss did not improve from 0.38011\n",
            "Epoch 8/100\n",
            "30/30 [==============================] - 0s 7ms/step - loss: 0.3830 - mae: 0.7561\n",
            "\n",
            "Epoch 00008: loss did not improve from 0.38011\n",
            "Epoch 9/100\n",
            "30/30 [==============================] - 0s 7ms/step - loss: 0.3812 - mae: 0.7553\n",
            "\n",
            "Epoch 00009: loss did not improve from 0.38011\n",
            "Epoch 10/100\n",
            "30/30 [==============================] - 0s 7ms/step - loss: 0.3935 - mae: 0.7755\n",
            "\n",
            "Epoch 00010: loss did not improve from 0.38011\n",
            "Epoch 11/100\n",
            "30/30 [==============================] - 0s 7ms/step - loss: 0.4103 - mae: 0.7933\n",
            "\n",
            "Epoch 00011: loss did not improve from 0.38011\n",
            "Epoch 12/100\n",
            "30/30 [==============================] - 0s 7ms/step - loss: 0.3700 - mae: 0.7463\n",
            "\n",
            "Epoch 00012: loss did not improve from 0.38011\n",
            "Epoch 13/100\n",
            "30/30 [==============================] - 0s 7ms/step - loss: 0.3970 - mae: 0.7735\n",
            "\n",
            "Epoch 00013: loss did not improve from 0.38011\n",
            "Epoch 14/100\n",
            "30/30 [==============================] - 0s 7ms/step - loss: 0.3757 - mae: 0.7455\n",
            "\n",
            "Epoch 00014: loss did not improve from 0.38011\n",
            "Epoch 15/100\n",
            "30/30 [==============================] - 0s 7ms/step - loss: 0.3696 - mae: 0.7413\n",
            "\n",
            "Epoch 00015: loss did not improve from 0.38011\n",
            "Epoch 16/100\n",
            "30/30 [==============================] - 0s 7ms/step - loss: 0.3782 - mae: 0.7521\n",
            "\n",
            "Epoch 00016: loss did not improve from 0.38011\n",
            "Epoch 17/100\n",
            "30/30 [==============================] - 0s 7ms/step - loss: 0.3652 - mae: 0.7335\n",
            "\n",
            "Epoch 00017: loss did not improve from 0.38011\n",
            "Epoch 18/100\n",
            "30/30 [==============================] - 0s 7ms/step - loss: 0.3651 - mae: 0.7333\n",
            "\n",
            "Epoch 00018: loss did not improve from 0.38011\n",
            "Epoch 19/100\n",
            "30/30 [==============================] - 0s 7ms/step - loss: 0.3770 - mae: 0.7540\n",
            "\n",
            "Epoch 00019: loss did not improve from 0.38011\n",
            "Epoch 20/100\n",
            "30/30 [==============================] - 0s 7ms/step - loss: 0.3787 - mae: 0.7547\n",
            "\n",
            "Epoch 00020: loss did not improve from 0.38011\n",
            "Epoch 21/100\n",
            "30/30 [==============================] - 0s 7ms/step - loss: 0.3821 - mae: 0.7597\n",
            "\n",
            "Epoch 00021: loss did not improve from 0.38011\n",
            "Epoch 22/100\n",
            "30/30 [==============================] - 0s 7ms/step - loss: 0.3655 - mae: 0.7383\n",
            "\n",
            "Epoch 00022: loss did not improve from 0.38011\n",
            "Epoch 23/100\n",
            "30/30 [==============================] - 0s 7ms/step - loss: 0.3857 - mae: 0.7613\n",
            "\n",
            "Epoch 00023: loss did not improve from 0.38011\n",
            "Epoch 24/100\n",
            "30/30 [==============================] - 0s 7ms/step - loss: 0.3870 - mae: 0.7640\n",
            "\n",
            "Epoch 00024: loss did not improve from 0.38011\n",
            "Epoch 25/100\n",
            "30/30 [==============================] - 0s 7ms/step - loss: 0.3862 - mae: 0.7641\n",
            "\n",
            "Epoch 00025: loss did not improve from 0.38011\n",
            "Epoch 26/100\n",
            "30/30 [==============================] - 0s 7ms/step - loss: 0.3841 - mae: 0.7594\n",
            "\n",
            "Epoch 00026: loss did not improve from 0.38011\n",
            "Epoch 27/100\n",
            "30/30 [==============================] - 0s 7ms/step - loss: 0.3746 - mae: 0.7474\n",
            "\n",
            "Epoch 00027: loss did not improve from 0.38011\n",
            "Epoch 28/100\n",
            "30/30 [==============================] - 0s 7ms/step - loss: 0.3866 - mae: 0.7670\n",
            "\n",
            "Epoch 00028: loss did not improve from 0.38011\n",
            "Epoch 29/100\n",
            "30/30 [==============================] - 0s 7ms/step - loss: 0.3832 - mae: 0.7603\n",
            "\n",
            "Epoch 00029: loss did not improve from 0.38011\n",
            "Epoch 30/100\n",
            "30/30 [==============================] - 0s 7ms/step - loss: 0.3955 - mae: 0.7769\n",
            "\n",
            "Epoch 00030: loss did not improve from 0.38011\n",
            "Epoch 31/100\n",
            "30/30 [==============================] - 0s 7ms/step - loss: 0.3721 - mae: 0.7492\n",
            "\n",
            "Epoch 00031: loss did not improve from 0.38011\n",
            "Epoch 32/100\n",
            "30/30 [==============================] - 0s 7ms/step - loss: 0.3790 - mae: 0.7572\n",
            "\n",
            "Epoch 00032: loss did not improve from 0.38011\n",
            "Epoch 33/100\n",
            "30/30 [==============================] - 0s 7ms/step - loss: 0.3945 - mae: 0.7776\n",
            "\n",
            "Epoch 00033: loss did not improve from 0.38011\n",
            "Epoch 34/100\n",
            "30/30 [==============================] - 0s 7ms/step - loss: 0.3656 - mae: 0.7430\n",
            "\n",
            "Epoch 00034: loss did not improve from 0.38011\n",
            "Epoch 35/100\n",
            "30/30 [==============================] - 0s 7ms/step - loss: 0.3819 - mae: 0.7592\n",
            "\n",
            "Epoch 00035: loss improved from 0.38011 to 0.37795, saving model to poids.hdf5\n",
            "Epoch 36/100\n",
            "30/30 [==============================] - 0s 7ms/step - loss: 0.3664 - mae: 0.7371\n",
            "\n",
            "Epoch 00036: loss improved from 0.37795 to 0.37596, saving model to poids.hdf5\n",
            "Epoch 37/100\n",
            "30/30 [==============================] - 0s 8ms/step - loss: 0.3876 - mae: 0.7682\n",
            "\n",
            "Epoch 00037: loss did not improve from 0.37596\n",
            "Epoch 38/100\n",
            "30/30 [==============================] - 0s 7ms/step - loss: 0.3520 - mae: 0.7233\n",
            "\n",
            "Epoch 00038: loss improved from 0.37596 to 0.37575, saving model to poids.hdf5\n",
            "Epoch 39/100\n",
            "30/30 [==============================] - 0s 7ms/step - loss: 0.3513 - mae: 0.7203\n",
            "\n",
            "Epoch 00039: loss improved from 0.37575 to 0.36978, saving model to poids.hdf5\n",
            "Epoch 40/100\n",
            "30/30 [==============================] - 0s 7ms/step - loss: 0.3619 - mae: 0.7271\n",
            "\n",
            "Epoch 00040: loss improved from 0.36978 to 0.36463, saving model to poids.hdf5\n",
            "Epoch 41/100\n",
            "30/30 [==============================] - 0s 7ms/step - loss: 0.3599 - mae: 0.7270\n",
            "\n",
            "Epoch 00041: loss improved from 0.36463 to 0.35869, saving model to poids.hdf5\n",
            "Epoch 42/100\n",
            "30/30 [==============================] - 0s 7ms/step - loss: 0.3421 - mae: 0.7066\n",
            "\n",
            "Epoch 00042: loss improved from 0.35869 to 0.34313, saving model to poids.hdf5\n",
            "Epoch 43/100\n",
            "30/30 [==============================] - 0s 7ms/step - loss: 0.3320 - mae: 0.6917\n",
            "\n",
            "Epoch 00043: loss improved from 0.34313 to 0.32760, saving model to poids.hdf5\n",
            "Epoch 44/100\n",
            "30/30 [==============================] - 0s 6ms/step - loss: 0.3245 - mae: 0.6796\n",
            "\n",
            "Epoch 00044: loss improved from 0.32760 to 0.31088, saving model to poids.hdf5\n",
            "Epoch 45/100\n",
            "30/30 [==============================] - 0s 7ms/step - loss: 0.2867 - mae: 0.6333\n",
            "\n",
            "Epoch 00045: loss improved from 0.31088 to 0.28724, saving model to poids.hdf5\n",
            "Epoch 46/100\n",
            "30/30 [==============================] - 0s 7ms/step - loss: 0.2756 - mae: 0.6162\n",
            "\n",
            "Epoch 00046: loss improved from 0.28724 to 0.26807, saving model to poids.hdf5\n",
            "Epoch 47/100\n",
            "30/30 [==============================] - 0s 7ms/step - loss: 0.2612 - mae: 0.6039\n",
            "\n",
            "Epoch 00047: loss improved from 0.26807 to 0.24436, saving model to poids.hdf5\n",
            "Epoch 48/100\n",
            "30/30 [==============================] - 0s 7ms/step - loss: 0.2302 - mae: 0.5636\n",
            "\n",
            "Epoch 00048: loss improved from 0.24436 to 0.22201, saving model to poids.hdf5\n",
            "Epoch 49/100\n",
            "30/30 [==============================] - 0s 7ms/step - loss: 0.2165 - mae: 0.5442\n",
            "\n",
            "Epoch 00049: loss improved from 0.22201 to 0.20090, saving model to poids.hdf5\n",
            "Epoch 50/100\n",
            "30/30 [==============================] - 0s 7ms/step - loss: 0.1815 - mae: 0.5018\n",
            "\n",
            "Epoch 00050: loss improved from 0.20090 to 0.17851, saving model to poids.hdf5\n",
            "Epoch 51/100\n",
            "30/30 [==============================] - 0s 7ms/step - loss: 0.1645 - mae: 0.4755\n",
            "\n",
            "Epoch 00051: loss improved from 0.17851 to 0.16048, saving model to poids.hdf5\n",
            "Epoch 52/100\n",
            "30/30 [==============================] - 0s 7ms/step - loss: 0.1507 - mae: 0.4566\n",
            "\n",
            "Epoch 00052: loss improved from 0.16048 to 0.14100, saving model to poids.hdf5\n",
            "Epoch 53/100\n",
            "30/30 [==============================] - 0s 7ms/step - loss: 0.1337 - mae: 0.4272\n",
            "\n",
            "Epoch 00053: loss improved from 0.14100 to 0.12464, saving model to poids.hdf5\n",
            "Epoch 54/100\n",
            "30/30 [==============================] - 0s 7ms/step - loss: 0.1029 - mae: 0.3746\n",
            "\n",
            "Epoch 00054: loss improved from 0.12464 to 0.10823, saving model to poids.hdf5\n",
            "Epoch 55/100\n",
            "30/30 [==============================] - 0s 7ms/step - loss: 0.1047 - mae: 0.3714\n",
            "\n",
            "Epoch 00055: loss improved from 0.10823 to 0.09587, saving model to poids.hdf5\n",
            "Epoch 56/100\n",
            "30/30 [==============================] - 0s 7ms/step - loss: 0.0848 - mae: 0.3347\n",
            "\n",
            "Epoch 00056: loss improved from 0.09587 to 0.08402, saving model to poids.hdf5\n",
            "Epoch 57/100\n",
            "30/30 [==============================] - 0s 7ms/step - loss: 0.0750 - mae: 0.3045\n",
            "\n",
            "Epoch 00057: loss improved from 0.08402 to 0.07207, saving model to poids.hdf5\n",
            "Epoch 58/100\n",
            "30/30 [==============================] - 0s 8ms/step - loss: 0.0635 - mae: 0.2734\n",
            "\n",
            "Epoch 00058: loss improved from 0.07207 to 0.06150, saving model to poids.hdf5\n",
            "Epoch 59/100\n",
            "30/30 [==============================] - 0s 7ms/step - loss: 0.0512 - mae: 0.2333\n",
            "\n",
            "Epoch 00059: loss improved from 0.06150 to 0.05199, saving model to poids.hdf5\n",
            "Epoch 60/100\n",
            "30/30 [==============================] - 0s 7ms/step - loss: 0.0463 - mae: 0.2181\n",
            "\n",
            "Epoch 00060: loss improved from 0.05199 to 0.04476, saving model to poids.hdf5\n",
            "Epoch 61/100\n",
            "30/30 [==============================] - 0s 8ms/step - loss: 0.0425 - mae: 0.2014\n",
            "\n",
            "Epoch 00061: loss improved from 0.04476 to 0.04070, saving model to poids.hdf5\n",
            "Epoch 62/100\n",
            "30/30 [==============================] - 0s 7ms/step - loss: 0.0373 - mae: 0.1862\n",
            "\n",
            "Epoch 00062: loss improved from 0.04070 to 0.03606, saving model to poids.hdf5\n",
            "Epoch 63/100\n",
            "30/30 [==============================] - 0s 7ms/step - loss: 0.0307 - mae: 0.1678\n",
            "\n",
            "Epoch 00063: loss did not improve from 0.03606\n",
            "Epoch 64/100\n",
            "30/30 [==============================] - 0s 7ms/step - loss: 0.0359 - mae: 0.1818\n",
            "\n",
            "Epoch 00064: loss did not improve from 0.03606\n",
            "Epoch 65/100\n",
            "30/30 [==============================] - 0s 8ms/step - loss: 0.0371 - mae: 0.1846\n",
            "\n",
            "Epoch 00065: loss did not improve from 0.03606\n",
            "Epoch 66/100\n",
            "30/30 [==============================] - 0s 7ms/step - loss: 0.0382 - mae: 0.1881\n",
            "\n",
            "Epoch 00066: loss improved from 0.03606 to 0.03593, saving model to poids.hdf5\n",
            "Epoch 67/100\n",
            "30/30 [==============================] - 0s 7ms/step - loss: 0.0344 - mae: 0.1799\n",
            "\n",
            "Epoch 00067: loss improved from 0.03593 to 0.03578, saving model to poids.hdf5\n",
            "Epoch 68/100\n",
            "30/30 [==============================] - 0s 7ms/step - loss: 0.0337 - mae: 0.1797\n",
            "\n",
            "Epoch 00068: loss did not improve from 0.03578\n",
            "Epoch 69/100\n",
            "30/30 [==============================] - 0s 7ms/step - loss: 0.0353 - mae: 0.1832\n",
            "\n",
            "Epoch 00069: loss did not improve from 0.03578\n",
            "Epoch 70/100\n",
            "30/30 [==============================] - 0s 7ms/step - loss: 0.0374 - mae: 0.1871\n",
            "\n",
            "Epoch 00070: loss did not improve from 0.03578\n",
            "Epoch 71/100\n",
            "30/30 [==============================] - 0s 7ms/step - loss: 0.0350 - mae: 0.1847\n",
            "\n",
            "Epoch 00071: loss did not improve from 0.03578\n",
            "Epoch 72/100\n",
            "30/30 [==============================] - 0s 8ms/step - loss: 0.0399 - mae: 0.1922\n",
            "\n",
            "Epoch 00072: loss improved from 0.03578 to 0.03546, saving model to poids.hdf5\n",
            "Epoch 73/100\n",
            "30/30 [==============================] - 0s 7ms/step - loss: 0.0364 - mae: 0.1842\n",
            "\n",
            "Epoch 00073: loss did not improve from 0.03546\n",
            "Epoch 74/100\n",
            "30/30 [==============================] - 0s 8ms/step - loss: 0.0346 - mae: 0.1829\n",
            "\n",
            "Epoch 00074: loss did not improve from 0.03546\n",
            "Epoch 75/100\n",
            "30/30 [==============================] - 0s 7ms/step - loss: 0.0398 - mae: 0.2003\n",
            "\n",
            "Epoch 00075: loss did not improve from 0.03546\n",
            "Epoch 76/100\n",
            "30/30 [==============================] - 0s 8ms/step - loss: 0.0423 - mae: 0.2150\n",
            "\n",
            "Epoch 00076: loss did not improve from 0.03546\n",
            "Epoch 77/100\n",
            "30/30 [==============================] - 0s 8ms/step - loss: 0.0423 - mae: 0.2120\n",
            "\n",
            "Epoch 00077: loss did not improve from 0.03546\n",
            "Epoch 78/100\n",
            "30/30 [==============================] - 0s 8ms/step - loss: 0.0475 - mae: 0.2255\n",
            "\n",
            "Epoch 00078: loss did not improve from 0.03546\n",
            "Epoch 79/100\n",
            "30/30 [==============================] - 0s 7ms/step - loss: 0.0519 - mae: 0.2445\n",
            "\n",
            "Epoch 00079: loss did not improve from 0.03546\n",
            "Epoch 80/100\n",
            "30/30 [==============================] - 0s 7ms/step - loss: 0.0545 - mae: 0.2534\n",
            "\n",
            "Epoch 00080: loss did not improve from 0.03546\n",
            "Epoch 81/100\n",
            "30/30 [==============================] - 0s 8ms/step - loss: 0.0502 - mae: 0.2339\n",
            "\n",
            "Epoch 00081: loss did not improve from 0.03546\n",
            "Epoch 82/100\n",
            "30/30 [==============================] - 0s 8ms/step - loss: 0.0788 - mae: 0.2994\n",
            "\n",
            "Epoch 00082: loss did not improve from 0.03546\n",
            "Epoch 83/100\n",
            "30/30 [==============================] - 0s 7ms/step - loss: 0.1307 - mae: 0.3891\n",
            "\n",
            "Epoch 00083: loss did not improve from 0.03546\n",
            "Epoch 84/100\n",
            "30/30 [==============================] - 0s 7ms/step - loss: 0.8171 - mae: 1.2673\n",
            "\n",
            "Epoch 00084: loss did not improve from 0.03546\n",
            "Epoch 85/100\n",
            "30/30 [==============================] - 0s 8ms/step - loss: 0.8187 - mae: 1.2730\n",
            "\n",
            "Epoch 00085: loss did not improve from 0.03546\n",
            "Epoch 86/100\n",
            "30/30 [==============================] - 0s 7ms/step - loss: 0.8402 - mae: 1.2971\n",
            "\n",
            "Epoch 00086: loss did not improve from 0.03546\n",
            "Epoch 87/100\n",
            "30/30 [==============================] - 0s 8ms/step - loss: 0.8007 - mae: 1.2526\n",
            "\n",
            "Epoch 00087: loss did not improve from 0.03546\n",
            "Epoch 88/100\n",
            "30/30 [==============================] - 0s 7ms/step - loss: 0.8221 - mae: 1.2754\n",
            "\n",
            "Epoch 00088: loss did not improve from 0.03546\n",
            "Epoch 89/100\n",
            "30/30 [==============================] - 0s 8ms/step - loss: 0.7894 - mae: 1.2387\n",
            "\n",
            "Epoch 00089: loss did not improve from 0.03546\n",
            "Epoch 90/100\n",
            "30/30 [==============================] - 0s 8ms/step - loss: 0.8116 - mae: 1.2608\n",
            "\n",
            "Epoch 00090: loss did not improve from 0.03546\n",
            "Epoch 91/100\n",
            "30/30 [==============================] - 0s 8ms/step - loss: 0.8106 - mae: 1.2608\n",
            "\n",
            "Epoch 00091: loss did not improve from 0.03546\n",
            "Epoch 92/100\n",
            "30/30 [==============================] - 0s 7ms/step - loss: 0.7966 - mae: 1.2423\n",
            "\n",
            "Epoch 00092: loss did not improve from 0.03546\n",
            "Epoch 93/100\n",
            "30/30 [==============================] - 0s 7ms/step - loss: 0.8228 - mae: 1.2759\n",
            "\n",
            "Epoch 00093: loss did not improve from 0.03546\n",
            "Epoch 94/100\n",
            "30/30 [==============================] - 0s 8ms/step - loss: 0.8418 - mae: 1.2959\n",
            "\n",
            "Epoch 00094: loss did not improve from 0.03546\n",
            "Epoch 95/100\n",
            "30/30 [==============================] - 0s 7ms/step - loss: 0.8179 - mae: 1.2697\n",
            "\n",
            "Epoch 00095: loss did not improve from 0.03546\n",
            "Epoch 96/100\n",
            "30/30 [==============================] - 0s 8ms/step - loss: 0.8161 - mae: 1.2654\n",
            "\n",
            "Epoch 00096: loss did not improve from 0.03546\n",
            "Epoch 97/100\n",
            "30/30 [==============================] - 0s 8ms/step - loss: 0.8172 - mae: 1.2708\n",
            "\n",
            "Epoch 00097: loss did not improve from 0.03546\n",
            "Epoch 98/100\n",
            "30/30 [==============================] - 0s 8ms/step - loss: 0.8315 - mae: 1.2850\n",
            "\n",
            "Epoch 00098: loss did not improve from 0.03546\n",
            "Epoch 99/100\n",
            "30/30 [==============================] - 0s 8ms/step - loss: 0.8472 - mae: 1.2942\n",
            "\n",
            "Epoch 00099: loss did not improve from 0.03546\n",
            "Epoch 100/100\n",
            "30/30 [==============================] - 0s 7ms/step - loss: 0.8063 - mae: 1.2578\n",
            "\n",
            "Epoch 00100: loss did not improve from 0.03546\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q1_WMNlzu2B4",
        "outputId": "b0555e0a-8f33-4ed5-ffa5-6ba33e84f2bd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 411
        }
      },
      "source": [
        "# Construit un vecteur avec les valeurs du taux d'apprentissage à chaque période \n",
        "taux = 1e-8*(10**(np.arange(100)/10))\n",
        "\n",
        "# Affiche l'erreur en fonction du taux d'apprentissage\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.semilogx(taux,historique.history[\"loss\"])\n",
        "plt.axis([ taux[0], taux[99], 0, 1])\n",
        "plt.title(\"Evolution de l'erreur en fonction du taux d'apprentissage\")"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, \"Evolution de l'erreur en fonction du taux d'apprentissage\")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6XdXh_b0GP_F"
      },
      "source": [
        "**3. Entrainement du modèle**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "80pEtJ10wIfY"
      },
      "source": [
        "# Charge les meilleurs poids\n",
        "model.load_weights(\"poids.hdf5\")"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "16ujUiELwR33",
        "outputId": "d4788c10-9674-4559-801a-acd5bf8fe543",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from timeit import default_timer as timer\n",
        "\n",
        "class TimingCallback(keras.callbacks.Callback):\n",
        "    def __init__(self, logs={}):\n",
        "        self.logs=[]\n",
        "    def on_epoch_begin(self, epoch, logs={}):\n",
        "        self.starttime = timer()\n",
        "    def on_epoch_end(self, epoch, logs={}):\n",
        "        self.logs.append(timer()-self.starttime)\n",
        "\n",
        "cb = TimingCallback()\n",
        "\n",
        "# Définition des paramètres liés à l'évolution du taux d'apprentissage\n",
        "lr_schedule = tf.keras.optimizers.schedules.InverseTimeDecay(\n",
        "    initial_learning_rate=0.1,\n",
        "    decay_steps=10,\n",
        "    decay_rate=0.05)\n",
        "\n",
        "# Définition de l'optimiseur à utiliser\n",
        "optimiseur=tf.keras.optimizers.SGD(learning_rate=lr_schedule,momentum=0.9)\n",
        "\n",
        "# Utilisation de la méthode ModelCheckPoint\n",
        "CheckPoint = tf.keras.callbacks.ModelCheckpoint(\"poids.hdf5\", monitor='loss', verbose=1, save_best_only=True, save_weights_only = True, mode='auto', save_freq='epoch')\n",
        "\n",
        "# Compile le modèle\n",
        "model.compile(loss=tf.keras.losses.Huber(), optimizer=optimiseur,metrics=\"mae\")\n",
        "\n",
        "# Entraine le modèle\n",
        "historique = model.fit(dataset_norm,validation_data=dataset_Val_norm, epochs=500,verbose=1, callbacks=[CheckPoint,cb])\n",
        "\n",
        "print(cb.logs)\n",
        "print(sum(cb.logs))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/500\n",
            "30/30 [==============================] - 3s 29ms/step - loss: 0.0356 - mae: 0.1839 - val_loss: 0.0316 - val_mae: 0.2057\n",
            "\n",
            "Epoch 00001: loss improved from inf to 0.03539, saving model to poids.hdf5\n",
            "Epoch 2/500\n",
            "30/30 [==============================] - 0s 12ms/step - loss: 0.0389 - mae: 0.2058 - val_loss: 0.0599 - val_mae: 0.2824\n",
            "\n",
            "Epoch 00002: loss did not improve from 0.03539\n",
            "Epoch 3/500\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.0346 - mae: 0.1856 - val_loss: 0.0328 - val_mae: 0.1931\n",
            "\n",
            "Epoch 00003: loss improved from 0.03539 to 0.03400, saving model to poids.hdf5\n",
            "Epoch 4/500\n",
            "30/30 [==============================] - 0s 12ms/step - loss: 0.0387 - mae: 0.1914 - val_loss: 0.0361 - val_mae: 0.2077\n",
            "\n",
            "Epoch 00004: loss improved from 0.03400 to 0.03378, saving model to poids.hdf5\n",
            "Epoch 5/500\n",
            "30/30 [==============================] - 0s 12ms/step - loss: 0.0294 - mae: 0.1712 - val_loss: 0.0327 - val_mae: 0.1931\n",
            "\n",
            "Epoch 00005: loss improved from 0.03378 to 0.03306, saving model to poids.hdf5\n",
            "Epoch 6/500\n",
            "30/30 [==============================] - 0s 12ms/step - loss: 0.0412 - mae: 0.1987 - val_loss: 0.0479 - val_mae: 0.2487\n",
            "\n",
            "Epoch 00006: loss did not improve from 0.03306\n",
            "Epoch 7/500\n",
            "30/30 [==============================] - 0s 12ms/step - loss: 0.0331 - mae: 0.1758 - val_loss: 0.0350 - val_mae: 0.2084\n",
            "\n",
            "Epoch 00007: loss improved from 0.03306 to 0.03198, saving model to poids.hdf5\n",
            "Epoch 8/500\n",
            "30/30 [==============================] - 0s 12ms/step - loss: 0.0286 - mae: 0.1665 - val_loss: 0.0568 - val_mae: 0.2762\n",
            "\n",
            "Epoch 00008: loss improved from 0.03198 to 0.03153, saving model to poids.hdf5\n",
            "Epoch 9/500\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.0325 - mae: 0.1803 - val_loss: 0.0576 - val_mae: 0.2783\n",
            "\n",
            "Epoch 00009: loss improved from 0.03153 to 0.03125, saving model to poids.hdf5\n",
            "Epoch 10/500\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.0312 - mae: 0.1742 - val_loss: 0.0589 - val_mae: 0.2851\n",
            "\n",
            "Epoch 00010: loss improved from 0.03125 to 0.02972, saving model to poids.hdf5\n",
            "Epoch 11/500\n",
            "30/30 [==============================] - 0s 12ms/step - loss: 0.0268 - mae: 0.1620 - val_loss: 0.0640 - val_mae: 0.2978\n",
            "\n",
            "Epoch 00011: loss improved from 0.02972 to 0.02954, saving model to poids.hdf5\n",
            "Epoch 12/500\n",
            "30/30 [==============================] - 0s 12ms/step - loss: 0.0332 - mae: 0.1771 - val_loss: 0.0408 - val_mae: 0.2375\n",
            "\n",
            "Epoch 00012: loss did not improve from 0.02954\n",
            "Epoch 13/500\n",
            "30/30 [==============================] - 0s 12ms/step - loss: 0.0310 - mae: 0.1812 - val_loss: 0.0697 - val_mae: 0.3125\n",
            "\n",
            "Epoch 00013: loss improved from 0.02954 to 0.02910, saving model to poids.hdf5\n",
            "Epoch 14/500\n",
            "30/30 [==============================] - 0s 12ms/step - loss: 0.0325 - mae: 0.1777 - val_loss: 0.0845 - val_mae: 0.3503\n",
            "\n",
            "Epoch 00014: loss improved from 0.02910 to 0.02824, saving model to poids.hdf5\n",
            "Epoch 15/500\n",
            "30/30 [==============================] - 0s 12ms/step - loss: 0.0271 - mae: 0.1655 - val_loss: 0.0899 - val_mae: 0.3613\n",
            "\n",
            "Epoch 00015: loss improved from 0.02824 to 0.02698, saving model to poids.hdf5\n",
            "Epoch 16/500\n",
            "30/30 [==============================] - 0s 12ms/step - loss: 0.0286 - mae: 0.1674 - val_loss: 0.0736 - val_mae: 0.3234\n",
            "\n",
            "Epoch 00016: loss did not improve from 0.02698\n",
            "Epoch 17/500\n",
            "30/30 [==============================] - 0s 12ms/step - loss: 0.0282 - mae: 0.1653 - val_loss: 0.0699 - val_mae: 0.3145\n",
            "\n",
            "Epoch 00017: loss improved from 0.02698 to 0.02642, saving model to poids.hdf5\n",
            "Epoch 18/500\n",
            "30/30 [==============================] - 0s 12ms/step - loss: 0.0290 - mae: 0.1728 - val_loss: 0.0678 - val_mae: 0.3101\n",
            "\n",
            "Epoch 00018: loss did not improve from 0.02642\n",
            "Epoch 19/500\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.0268 - mae: 0.1655 - val_loss: 0.0943 - val_mae: 0.3733\n",
            "\n",
            "Epoch 00019: loss improved from 0.02642 to 0.02584, saving model to poids.hdf5\n",
            "Epoch 20/500\n",
            "30/30 [==============================] - 0s 12ms/step - loss: 0.0256 - mae: 0.1582 - val_loss: 0.0928 - val_mae: 0.3708\n",
            "\n",
            "Epoch 00020: loss improved from 0.02584 to 0.02457, saving model to poids.hdf5\n",
            "Epoch 21/500\n",
            "30/30 [==============================] - 0s 12ms/step - loss: 0.0253 - mae: 0.1593 - val_loss: 0.1043 - val_mae: 0.3979\n",
            "\n",
            "Epoch 00021: loss did not improve from 0.02457\n",
            "Epoch 22/500\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.0263 - mae: 0.1658 - val_loss: 0.0788 - val_mae: 0.3389\n",
            "\n",
            "Epoch 00022: loss did not improve from 0.02457\n",
            "Epoch 23/500\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.0262 - mae: 0.1643 - val_loss: 0.0585 - val_mae: 0.2849\n",
            "\n",
            "Epoch 00023: loss did not improve from 0.02457\n",
            "Epoch 24/500\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.0271 - mae: 0.1664 - val_loss: 0.0643 - val_mae: 0.3014\n",
            "\n",
            "Epoch 00024: loss improved from 0.02457 to 0.02403, saving model to poids.hdf5\n",
            "Epoch 25/500\n",
            "30/30 [==============================] - 0s 12ms/step - loss: 0.0231 - mae: 0.1507 - val_loss: 0.0489 - val_mae: 0.2559\n",
            "\n",
            "Epoch 00025: loss improved from 0.02403 to 0.02329, saving model to poids.hdf5\n",
            "Epoch 26/500\n",
            "30/30 [==============================] - 0s 12ms/step - loss: 0.0218 - mae: 0.1494 - val_loss: 0.0453 - val_mae: 0.2440\n",
            "\n",
            "Epoch 00026: loss improved from 0.02329 to 0.02324, saving model to poids.hdf5\n",
            "Epoch 27/500\n",
            "30/30 [==============================] - 0s 12ms/step - loss: 0.0240 - mae: 0.1544 - val_loss: 0.0281 - val_mae: 0.1853\n",
            "\n",
            "Epoch 00027: loss improved from 0.02324 to 0.02200, saving model to poids.hdf5\n",
            "Epoch 28/500\n",
            "30/30 [==============================] - 0s 12ms/step - loss: 0.0205 - mae: 0.1486 - val_loss: 0.0338 - val_mae: 0.2042\n",
            "\n",
            "Epoch 00028: loss did not improve from 0.02200\n",
            "Epoch 29/500\n",
            "30/30 [==============================] - 0s 12ms/step - loss: 0.0213 - mae: 0.1487 - val_loss: 0.0370 - val_mae: 0.2154\n",
            "\n",
            "Epoch 00029: loss did not improve from 0.02200\n",
            "Epoch 30/500\n",
            "30/30 [==============================] - 1s 14ms/step - loss: 0.0204 - mae: 0.1460 - val_loss: 0.0372 - val_mae: 0.2145\n",
            "\n",
            "Epoch 00030: loss did not improve from 0.02200\n",
            "Epoch 31/500\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.0193 - mae: 0.1416 - val_loss: 0.0218 - val_mae: 0.1551\n",
            "\n",
            "Epoch 00031: loss improved from 0.02200 to 0.02114, saving model to poids.hdf5\n",
            "Epoch 32/500\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.0225 - mae: 0.1486 - val_loss: 0.0189 - val_mae: 0.1391\n",
            "\n",
            "Epoch 00032: loss did not improve from 0.02114\n",
            "Epoch 33/500\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.0190 - mae: 0.1412 - val_loss: 0.0243 - val_mae: 0.1581\n",
            "\n",
            "Epoch 00033: loss improved from 0.02114 to 0.02105, saving model to poids.hdf5\n",
            "Epoch 34/500\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.0224 - mae: 0.1475 - val_loss: 0.0246 - val_mae: 0.1581\n",
            "\n",
            "Epoch 00034: loss improved from 0.02105 to 0.02048, saving model to poids.hdf5\n",
            "Epoch 35/500\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.0208 - mae: 0.1409 - val_loss: 0.0179 - val_mae: 0.1369\n",
            "\n",
            "Epoch 00035: loss did not improve from 0.02048\n",
            "Epoch 36/500\n",
            "30/30 [==============================] - 0s 12ms/step - loss: 0.0199 - mae: 0.1443 - val_loss: 0.0188 - val_mae: 0.1310\n",
            "\n",
            "Epoch 00036: loss improved from 0.02048 to 0.01941, saving model to poids.hdf5\n",
            "Epoch 37/500\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.0219 - mae: 0.1499 - val_loss: 0.0193 - val_mae: 0.1327\n",
            "\n",
            "Epoch 00037: loss did not improve from 0.01941\n",
            "Epoch 38/500\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.0203 - mae: 0.1407 - val_loss: 0.0181 - val_mae: 0.1300\n",
            "\n",
            "Epoch 00038: loss did not improve from 0.01941\n",
            "Epoch 39/500\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.0186 - mae: 0.1414 - val_loss: 0.0181 - val_mae: 0.1305\n",
            "\n",
            "Epoch 00039: loss did not improve from 0.01941\n",
            "Epoch 40/500\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.0199 - mae: 0.1425 - val_loss: 0.0172 - val_mae: 0.1278\n",
            "\n",
            "Epoch 00040: loss improved from 0.01941 to 0.01938, saving model to poids.hdf5\n",
            "Epoch 41/500\n",
            "30/30 [==============================] - 0s 12ms/step - loss: 0.0203 - mae: 0.1467 - val_loss: 0.0205 - val_mae: 0.1492\n",
            "\n",
            "Epoch 00041: loss did not improve from 0.01938\n",
            "Epoch 42/500\n",
            "30/30 [==============================] - 0s 12ms/step - loss: 0.0205 - mae: 0.1466 - val_loss: 0.0177 - val_mae: 0.1275\n",
            "\n",
            "Epoch 00042: loss did not improve from 0.01938\n",
            "Epoch 43/500\n",
            "30/30 [==============================] - 1s 14ms/step - loss: 0.0204 - mae: 0.1456 - val_loss: 0.0189 - val_mae: 0.1357\n",
            "\n",
            "Epoch 00043: loss did not improve from 0.01938\n",
            "Epoch 44/500\n",
            "30/30 [==============================] - 0s 12ms/step - loss: 0.0182 - mae: 0.1387 - val_loss: 0.0183 - val_mae: 0.1344\n",
            "\n",
            "Epoch 00044: loss did not improve from 0.01938\n",
            "Epoch 45/500\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.0203 - mae: 0.1436 - val_loss: 0.0174 - val_mae: 0.1298\n",
            "\n",
            "Epoch 00045: loss did not improve from 0.01938\n",
            "Epoch 46/500\n",
            "30/30 [==============================] - 0s 12ms/step - loss: 0.0208 - mae: 0.1445 - val_loss: 0.0220 - val_mae: 0.1428\n",
            "\n",
            "Epoch 00046: loss did not improve from 0.01938\n",
            "Epoch 47/500\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.0181 - mae: 0.1391 - val_loss: 0.0189 - val_mae: 0.1404\n",
            "\n",
            "Epoch 00047: loss did not improve from 0.01938\n",
            "Epoch 48/500\n",
            "30/30 [==============================] - 0s 12ms/step - loss: 0.0188 - mae: 0.1390 - val_loss: 0.0194 - val_mae: 0.1461\n",
            "\n",
            "Epoch 00048: loss did not improve from 0.01938\n",
            "Epoch 49/500\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.0208 - mae: 0.1448 - val_loss: 0.0190 - val_mae: 0.1372\n",
            "\n",
            "Epoch 00049: loss did not improve from 0.01938\n",
            "Epoch 50/500\n",
            "30/30 [==============================] - 0s 12ms/step - loss: 0.0185 - mae: 0.1360 - val_loss: 0.0195 - val_mae: 0.1364\n",
            "\n",
            "Epoch 00050: loss improved from 0.01938 to 0.01930, saving model to poids.hdf5\n",
            "Epoch 51/500\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.0219 - mae: 0.1499 - val_loss: 0.0199 - val_mae: 0.1450\n",
            "\n",
            "Epoch 00051: loss did not improve from 0.01930\n",
            "Epoch 52/500\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.0166 - mae: 0.1330 - val_loss: 0.0224 - val_mae: 0.1563\n",
            "\n",
            "Epoch 00052: loss improved from 0.01930 to 0.01888, saving model to poids.hdf5\n",
            "Epoch 53/500\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.0190 - mae: 0.1361 - val_loss: 0.0202 - val_mae: 0.1466\n",
            "\n",
            "Epoch 00053: loss improved from 0.01888 to 0.01855, saving model to poids.hdf5\n",
            "Epoch 54/500\n",
            "30/30 [==============================] - 1s 13ms/step - loss: 0.0185 - mae: 0.1353 - val_loss: 0.0215 - val_mae: 0.1480\n",
            "\n",
            "Epoch 00054: loss did not improve from 0.01855\n",
            "Epoch 55/500\n",
            "30/30 [==============================] - 0s 12ms/step - loss: 0.0182 - mae: 0.1407 - val_loss: 0.0214 - val_mae: 0.1473\n",
            "\n",
            "Epoch 00055: loss did not improve from 0.01855\n",
            "Epoch 56/500\n",
            "30/30 [==============================] - 0s 12ms/step - loss: 0.0203 - mae: 0.1462 - val_loss: 0.0193 - val_mae: 0.1319\n",
            "\n",
            "Epoch 00056: loss did not improve from 0.01855\n",
            "Epoch 57/500\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.0220 - mae: 0.1502 - val_loss: 0.0197 - val_mae: 0.1429\n",
            "\n",
            "Epoch 00057: loss did not improve from 0.01855\n",
            "Epoch 58/500\n",
            "30/30 [==============================] - 0s 12ms/step - loss: 0.0178 - mae: 0.1392 - val_loss: 0.0218 - val_mae: 0.1543\n",
            "\n",
            "Epoch 00058: loss did not improve from 0.01855\n",
            "Epoch 59/500\n",
            "30/30 [==============================] - 0s 12ms/step - loss: 0.0195 - mae: 0.1491 - val_loss: 0.0226 - val_mae: 0.1569\n",
            "\n",
            "Epoch 00059: loss did not improve from 0.01855\n",
            "Epoch 60/500\n",
            "30/30 [==============================] - 1s 14ms/step - loss: 0.0184 - mae: 0.1410 - val_loss: 0.0213 - val_mae: 0.1578\n",
            "\n",
            "Epoch 00060: loss did not improve from 0.01855\n",
            "Epoch 61/500\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.0228 - mae: 0.1477 - val_loss: 0.0203 - val_mae: 0.1371\n",
            "\n",
            "Epoch 00061: loss did not improve from 0.01855\n",
            "Epoch 62/500\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.0174 - mae: 0.1327 - val_loss: 0.0217 - val_mae: 0.1581\n",
            "\n",
            "Epoch 00062: loss improved from 0.01855 to 0.01851, saving model to poids.hdf5\n",
            "Epoch 63/500\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.0185 - mae: 0.1415 - val_loss: 0.0195 - val_mae: 0.1390\n",
            "\n",
            "Epoch 00063: loss did not improve from 0.01851\n",
            "Epoch 64/500\n",
            "30/30 [==============================] - 0s 12ms/step - loss: 0.0200 - mae: 0.1425 - val_loss: 0.0202 - val_mae: 0.1431\n",
            "\n",
            "Epoch 00064: loss did not improve from 0.01851\n",
            "Epoch 65/500\n",
            "30/30 [==============================] - 0s 12ms/step - loss: 0.0215 - mae: 0.1388 - val_loss: 0.0227 - val_mae: 0.1575\n",
            "\n",
            "Epoch 00065: loss did not improve from 0.01851\n",
            "Epoch 66/500\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.0173 - mae: 0.1353 - val_loss: 0.0230 - val_mae: 0.1576\n",
            "\n",
            "Epoch 00066: loss did not improve from 0.01851\n",
            "Epoch 67/500\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.0185 - mae: 0.1385 - val_loss: 0.0196 - val_mae: 0.1372\n",
            "\n",
            "Epoch 00067: loss did not improve from 0.01851\n",
            "Epoch 68/500\n",
            "30/30 [==============================] - 1s 14ms/step - loss: 0.0208 - mae: 0.1472 - val_loss: 0.0190 - val_mae: 0.1334\n",
            "\n",
            "Epoch 00068: loss did not improve from 0.01851\n",
            "Epoch 69/500\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.0183 - mae: 0.1378 - val_loss: 0.0279 - val_mae: 0.1865\n",
            "\n",
            "Epoch 00069: loss did not improve from 0.01851\n",
            "Epoch 70/500\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.0176 - mae: 0.1347 - val_loss: 0.0248 - val_mae: 0.1729\n",
            "\n",
            "Epoch 00070: loss did not improve from 0.01851\n",
            "Epoch 71/500\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.0170 - mae: 0.1349 - val_loss: 0.0221 - val_mae: 0.1564\n",
            "\n",
            "Epoch 00071: loss did not improve from 0.01851\n",
            "Epoch 72/500\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.0186 - mae: 0.1374 - val_loss: 0.0248 - val_mae: 0.1718\n",
            "\n",
            "Epoch 00072: loss did not improve from 0.01851\n",
            "Epoch 73/500\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.0160 - mae: 0.1341 - val_loss: 0.0198 - val_mae: 0.1406\n",
            "\n",
            "Epoch 00073: loss did not improve from 0.01851\n",
            "Epoch 74/500\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.0197 - mae: 0.1431 - val_loss: 0.0242 - val_mae: 0.1681\n",
            "\n",
            "Epoch 00074: loss did not improve from 0.01851\n",
            "Epoch 75/500\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.0183 - mae: 0.1399 - val_loss: 0.0271 - val_mae: 0.1814\n",
            "\n",
            "Epoch 00075: loss did not improve from 0.01851\n",
            "Epoch 76/500\n",
            "30/30 [==============================] - 1s 13ms/step - loss: 0.0178 - mae: 0.1372 - val_loss: 0.0240 - val_mae: 0.1634\n",
            "\n",
            "Epoch 00076: loss did not improve from 0.01851\n",
            "Epoch 77/500\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.0184 - mae: 0.1377 - val_loss: 0.0229 - val_mae: 0.1595\n",
            "\n",
            "Epoch 00077: loss did not improve from 0.01851\n",
            "Epoch 78/500\n",
            "30/30 [==============================] - 0s 12ms/step - loss: 0.0178 - mae: 0.1373 - val_loss: 0.0214 - val_mae: 0.1477\n",
            "\n",
            "Epoch 00078: loss did not improve from 0.01851\n",
            "Epoch 79/500\n",
            "30/30 [==============================] - 0s 12ms/step - loss: 0.0199 - mae: 0.1420 - val_loss: 0.0213 - val_mae: 0.1504\n",
            "\n",
            "Epoch 00079: loss did not improve from 0.01851\n",
            "Epoch 80/500\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.0220 - mae: 0.1495 - val_loss: 0.0213 - val_mae: 0.1462\n",
            "\n",
            "Epoch 00080: loss did not improve from 0.01851\n",
            "Epoch 81/500\n",
            "30/30 [==============================] - 0s 12ms/step - loss: 0.0215 - mae: 0.1454 - val_loss: 0.0210 - val_mae: 0.1489\n",
            "\n",
            "Epoch 00081: loss did not improve from 0.01851\n",
            "Epoch 82/500\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.0182 - mae: 0.1351 - val_loss: 0.0202 - val_mae: 0.1406\n",
            "\n",
            "Epoch 00082: loss did not improve from 0.01851\n",
            "Epoch 83/500\n",
            "30/30 [==============================] - 0s 12ms/step - loss: 0.0175 - mae: 0.1349 - val_loss: 0.0209 - val_mae: 0.1472\n",
            "\n",
            "Epoch 00083: loss did not improve from 0.01851\n",
            "Epoch 84/500\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.0193 - mae: 0.1362 - val_loss: 0.0216 - val_mae: 0.1596\n",
            "\n",
            "Epoch 00084: loss did not improve from 0.01851\n",
            "Epoch 85/500\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.0193 - mae: 0.1396 - val_loss: 0.0206 - val_mae: 0.1451\n",
            "\n",
            "Epoch 00085: loss did not improve from 0.01851\n",
            "Epoch 86/500\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.0181 - mae: 0.1325 - val_loss: 0.0230 - val_mae: 0.1635\n",
            "\n",
            "Epoch 00086: loss improved from 0.01851 to 0.01815, saving model to poids.hdf5\n",
            "Epoch 87/500\n",
            "30/30 [==============================] - 0s 12ms/step - loss: 0.0206 - mae: 0.1449 - val_loss: 0.0220 - val_mae: 0.1531\n",
            "\n",
            "Epoch 00087: loss did not improve from 0.01815\n",
            "Epoch 88/500\n",
            "30/30 [==============================] - 0s 12ms/step - loss: 0.0197 - mae: 0.1417 - val_loss: 0.0226 - val_mae: 0.1577\n",
            "\n",
            "Epoch 00088: loss did not improve from 0.01815\n",
            "Epoch 89/500\n",
            "30/30 [==============================] - 0s 12ms/step - loss: 0.0197 - mae: 0.1401 - val_loss: 0.0234 - val_mae: 0.1673\n",
            "\n",
            "Epoch 00089: loss did not improve from 0.01815\n",
            "Epoch 90/500\n",
            "30/30 [==============================] - 0s 14ms/step - loss: 0.0174 - mae: 0.1350 - val_loss: 0.0236 - val_mae: 0.1639\n",
            "\n",
            "Epoch 00090: loss did not improve from 0.01815\n",
            "Epoch 91/500\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.0191 - mae: 0.1421 - val_loss: 0.0199 - val_mae: 0.1413\n",
            "\n",
            "Epoch 00091: loss did not improve from 0.01815\n",
            "Epoch 92/500\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.0169 - mae: 0.1362 - val_loss: 0.0238 - val_mae: 0.1651\n",
            "\n",
            "Epoch 00092: loss did not improve from 0.01815\n",
            "Epoch 93/500\n",
            "30/30 [==============================] - 0s 12ms/step - loss: 0.0167 - mae: 0.1336 - val_loss: 0.0212 - val_mae: 0.1492\n",
            "\n",
            "Epoch 00093: loss improved from 0.01815 to 0.01801, saving model to poids.hdf5\n",
            "Epoch 94/500\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.0170 - mae: 0.1335 - val_loss: 0.0209 - val_mae: 0.1463\n",
            "\n",
            "Epoch 00094: loss did not improve from 0.01801\n",
            "Epoch 95/500\n",
            "30/30 [==============================] - 1s 13ms/step - loss: 0.0162 - mae: 0.1348 - val_loss: 0.0233 - val_mae: 0.1623\n",
            "\n",
            "Epoch 00095: loss did not improve from 0.01801\n",
            "Epoch 96/500\n",
            "30/30 [==============================] - 1s 14ms/step - loss: 0.0183 - mae: 0.1376 - val_loss: 0.0252 - val_mae: 0.1718\n",
            "\n",
            "Epoch 00096: loss did not improve from 0.01801\n",
            "Epoch 97/500\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.0186 - mae: 0.1421 - val_loss: 0.0216 - val_mae: 0.1518\n",
            "\n",
            "Epoch 00097: loss did not improve from 0.01801\n",
            "Epoch 98/500\n",
            "30/30 [==============================] - 1s 13ms/step - loss: 0.0169 - mae: 0.1358 - val_loss: 0.0244 - val_mae: 0.1682\n",
            "\n",
            "Epoch 00098: loss did not improve from 0.01801\n",
            "Epoch 99/500\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.0183 - mae: 0.1421 - val_loss: 0.0202 - val_mae: 0.1403\n",
            "\n",
            "Epoch 00099: loss did not improve from 0.01801\n",
            "Epoch 100/500\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.0186 - mae: 0.1428 - val_loss: 0.0195 - val_mae: 0.1390\n",
            "\n",
            "Epoch 00100: loss did not improve from 0.01801\n",
            "Epoch 101/500\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.0196 - mae: 0.1407 - val_loss: 0.0228 - val_mae: 0.1640\n",
            "\n",
            "Epoch 00101: loss did not improve from 0.01801\n",
            "Epoch 102/500\n",
            "30/30 [==============================] - 1s 13ms/step - loss: 0.0182 - mae: 0.1385 - val_loss: 0.0298 - val_mae: 0.1930\n",
            "\n",
            "Epoch 00102: loss did not improve from 0.01801\n",
            "Epoch 103/500\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.0184 - mae: 0.1394 - val_loss: 0.0231 - val_mae: 0.1644\n",
            "\n",
            "Epoch 00103: loss did not improve from 0.01801\n",
            "Epoch 104/500\n",
            "30/30 [==============================] - 1s 13ms/step - loss: 0.0172 - mae: 0.1349 - val_loss: 0.0198 - val_mae: 0.1406\n",
            "\n",
            "Epoch 00104: loss improved from 0.01801 to 0.01794, saving model to poids.hdf5\n",
            "Epoch 105/500\n",
            "30/30 [==============================] - 1s 13ms/step - loss: 0.0189 - mae: 0.1369 - val_loss: 0.0200 - val_mae: 0.1473\n",
            "\n",
            "Epoch 00105: loss did not improve from 0.01794\n",
            "Epoch 106/500\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.0174 - mae: 0.1306 - val_loss: 0.0239 - val_mae: 0.1665\n",
            "\n",
            "Epoch 00106: loss did not improve from 0.01794\n",
            "Epoch 107/500\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.0211 - mae: 0.1477 - val_loss: 0.0243 - val_mae: 0.1681\n",
            "\n",
            "Epoch 00107: loss did not improve from 0.01794\n",
            "Epoch 108/500\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.0161 - mae: 0.1290 - val_loss: 0.0261 - val_mae: 0.1780\n",
            "\n",
            "Epoch 00108: loss improved from 0.01794 to 0.01733, saving model to poids.hdf5\n",
            "Epoch 109/500\n",
            "30/30 [==============================] - 1s 14ms/step - loss: 0.0180 - mae: 0.1351 - val_loss: 0.0204 - val_mae: 0.1425\n",
            "\n",
            "Epoch 00109: loss did not improve from 0.01733\n",
            "Epoch 110/500\n",
            "30/30 [==============================] - 1s 17ms/step - loss: 0.0178 - mae: 0.1377 - val_loss: 0.0221 - val_mae: 0.1549\n",
            "\n",
            "Epoch 00110: loss did not improve from 0.01733\n",
            "Epoch 111/500\n",
            "30/30 [==============================] - 0s 14ms/step - loss: 0.0164 - mae: 0.1291 - val_loss: 0.0228 - val_mae: 0.1598\n",
            "\n",
            "Epoch 00111: loss did not improve from 0.01733\n",
            "Epoch 112/500\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.0176 - mae: 0.1373 - val_loss: 0.0237 - val_mae: 0.1700\n",
            "\n",
            "Epoch 00112: loss did not improve from 0.01733\n",
            "Epoch 113/500\n",
            "30/30 [==============================] - 0s 14ms/step - loss: 0.0172 - mae: 0.1345 - val_loss: 0.0205 - val_mae: 0.1447\n",
            "\n",
            "Epoch 00113: loss did not improve from 0.01733\n",
            "Epoch 114/500\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.0162 - mae: 0.1285 - val_loss: 0.0252 - val_mae: 0.1723\n",
            "\n",
            "Epoch 00114: loss did not improve from 0.01733\n",
            "Epoch 115/500\n",
            "30/30 [==============================] - 1s 14ms/step - loss: 0.0187 - mae: 0.1404 - val_loss: 0.0225 - val_mae: 0.1571\n",
            "\n",
            "Epoch 00115: loss did not improve from 0.01733\n",
            "Epoch 116/500\n",
            "30/30 [==============================] - 1s 13ms/step - loss: 0.0176 - mae: 0.1359 - val_loss: 0.0217 - val_mae: 0.1530\n",
            "\n",
            "Epoch 00116: loss did not improve from 0.01733\n",
            "Epoch 117/500\n",
            "30/30 [==============================] - 1s 14ms/step - loss: 0.0166 - mae: 0.1360 - val_loss: 0.0253 - val_mae: 0.1709\n",
            "\n",
            "Epoch 00117: loss did not improve from 0.01733\n",
            "Epoch 118/500\n",
            "30/30 [==============================] - 1s 14ms/step - loss: 0.0177 - mae: 0.1374 - val_loss: 0.0211 - val_mae: 0.1495\n",
            "\n",
            "Epoch 00118: loss did not improve from 0.01733\n",
            "Epoch 119/500\n",
            "30/30 [==============================] - 0s 14ms/step - loss: 0.0171 - mae: 0.1346 - val_loss: 0.0207 - val_mae: 0.1476\n",
            "\n",
            "Epoch 00119: loss did not improve from 0.01733\n",
            "Epoch 120/500\n",
            "30/30 [==============================] - 1s 14ms/step - loss: 0.0196 - mae: 0.1394 - val_loss: 0.0227 - val_mae: 0.1584\n",
            "\n",
            "Epoch 00120: loss did not improve from 0.01733\n",
            "Epoch 121/500\n",
            "30/30 [==============================] - 1s 13ms/step - loss: 0.0187 - mae: 0.1395 - val_loss: 0.0190 - val_mae: 0.1441\n",
            "\n",
            "Epoch 00121: loss did not improve from 0.01733\n",
            "Epoch 122/500\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.0189 - mae: 0.1395 - val_loss: 0.0288 - val_mae: 0.1891\n",
            "\n",
            "Epoch 00122: loss did not improve from 0.01733\n",
            "Epoch 123/500\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.0176 - mae: 0.1329 - val_loss: 0.0238 - val_mae: 0.1654\n",
            "\n",
            "Epoch 00123: loss did not improve from 0.01733\n",
            "Epoch 124/500\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.0196 - mae: 0.1365 - val_loss: 0.0216 - val_mae: 0.1561\n",
            "\n",
            "Epoch 00124: loss did not improve from 0.01733\n",
            "Epoch 125/500\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.0206 - mae: 0.1460 - val_loss: 0.0258 - val_mae: 0.1769\n",
            "\n",
            "Epoch 00125: loss did not improve from 0.01733\n",
            "Epoch 126/500\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.0184 - mae: 0.1398 - val_loss: 0.0211 - val_mae: 0.1536\n",
            "\n",
            "Epoch 00126: loss did not improve from 0.01733\n",
            "Epoch 127/500\n",
            "30/30 [==============================] - 1s 14ms/step - loss: 0.0181 - mae: 0.1360 - val_loss: 0.0245 - val_mae: 0.1706\n",
            "\n",
            "Epoch 00127: loss did not improve from 0.01733\n",
            "Epoch 128/500\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.0164 - mae: 0.1308 - val_loss: 0.0217 - val_mae: 0.1549\n",
            "\n",
            "Epoch 00128: loss did not improve from 0.01733\n",
            "Epoch 129/500\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.0186 - mae: 0.1353 - val_loss: 0.0257 - val_mae: 0.1752\n",
            "\n",
            "Epoch 00129: loss did not improve from 0.01733\n",
            "Epoch 130/500\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.0181 - mae: 0.1394 - val_loss: 0.0201 - val_mae: 0.1406\n",
            "\n",
            "Epoch 00130: loss did not improve from 0.01733\n",
            "Epoch 131/500\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.0186 - mae: 0.1402 - val_loss: 0.0181 - val_mae: 0.1371\n",
            "\n",
            "Epoch 00131: loss did not improve from 0.01733\n",
            "Epoch 132/500\n",
            "30/30 [==============================] - 0s 12ms/step - loss: 0.0207 - mae: 0.1406 - val_loss: 0.0234 - val_mae: 0.1626\n",
            "\n",
            "Epoch 00132: loss did not improve from 0.01733\n",
            "Epoch 133/500\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.0194 - mae: 0.1394 - val_loss: 0.0251 - val_mae: 0.1734\n",
            "\n",
            "Epoch 00133: loss did not improve from 0.01733\n",
            "Epoch 134/500\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.0222 - mae: 0.1500 - val_loss: 0.0232 - val_mae: 0.1626\n",
            "\n",
            "Epoch 00134: loss did not improve from 0.01733\n",
            "Epoch 135/500\n",
            "30/30 [==============================] - 0s 12ms/step - loss: 0.0180 - mae: 0.1344 - val_loss: 0.0208 - val_mae: 0.1463\n",
            "\n",
            "Epoch 00135: loss did not improve from 0.01733\n",
            "Epoch 136/500\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.0187 - mae: 0.1364 - val_loss: 0.0247 - val_mae: 0.1712\n",
            "\n",
            "Epoch 00136: loss did not improve from 0.01733\n",
            "Epoch 137/500\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.0179 - mae: 0.1360 - val_loss: 0.0205 - val_mae: 0.1458\n",
            "\n",
            "Epoch 00137: loss did not improve from 0.01733\n",
            "Epoch 138/500\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.0178 - mae: 0.1326 - val_loss: 0.0240 - val_mae: 0.1712\n",
            "\n",
            "Epoch 00138: loss did not improve from 0.01733\n",
            "Epoch 139/500\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.0191 - mae: 0.1402 - val_loss: 0.0228 - val_mae: 0.1579\n",
            "\n",
            "Epoch 00139: loss did not improve from 0.01733\n",
            "Epoch 140/500\n",
            "30/30 [==============================] - 0s 12ms/step - loss: 0.0174 - mae: 0.1348 - val_loss: 0.0207 - val_mae: 0.1484\n",
            "\n",
            "Epoch 00140: loss did not improve from 0.01733\n",
            "Epoch 141/500\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.0179 - mae: 0.1352 - val_loss: 0.0221 - val_mae: 0.1568\n",
            "\n",
            "Epoch 00141: loss did not improve from 0.01733\n",
            "Epoch 142/500\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.0168 - mae: 0.1303 - val_loss: 0.0277 - val_mae: 0.1853\n",
            "\n",
            "Epoch 00142: loss did not improve from 0.01733\n",
            "Epoch 143/500\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.0168 - mae: 0.1346 - val_loss: 0.0219 - val_mae: 0.1558\n",
            "\n",
            "Epoch 00143: loss did not improve from 0.01733\n",
            "Epoch 144/500\n",
            "30/30 [==============================] - 0s 12ms/step - loss: 0.0159 - mae: 0.1312 - val_loss: 0.0212 - val_mae: 0.1498\n",
            "\n",
            "Epoch 00144: loss did not improve from 0.01733\n",
            "Epoch 145/500\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.0193 - mae: 0.1408 - val_loss: 0.0220 - val_mae: 0.1577\n",
            "\n",
            "Epoch 00145: loss did not improve from 0.01733\n",
            "Epoch 146/500\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.0189 - mae: 0.1381 - val_loss: 0.0196 - val_mae: 0.1459\n",
            "\n",
            "Epoch 00146: loss did not improve from 0.01733\n",
            "Epoch 147/500\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.0203 - mae: 0.1373 - val_loss: 0.0204 - val_mae: 0.1456\n",
            "\n",
            "Epoch 00147: loss did not improve from 0.01733\n",
            "Epoch 148/500\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.0192 - mae: 0.1413 - val_loss: 0.0222 - val_mae: 0.1570\n",
            "\n",
            "Epoch 00148: loss did not improve from 0.01733\n",
            "Epoch 149/500\n",
            "30/30 [==============================] - 0s 14ms/step - loss: 0.0160 - mae: 0.1298 - val_loss: 0.0205 - val_mae: 0.1470\n",
            "\n",
            "Epoch 00149: loss did not improve from 0.01733\n",
            "Epoch 150/500\n",
            "30/30 [==============================] - 0s 14ms/step - loss: 0.0169 - mae: 0.1328 - val_loss: 0.0203 - val_mae: 0.1490\n",
            "\n",
            "Epoch 00150: loss did not improve from 0.01733\n",
            "Epoch 151/500\n",
            "30/30 [==============================] - 1s 14ms/step - loss: 0.0194 - mae: 0.1397 - val_loss: 0.0263 - val_mae: 0.1790\n",
            "\n",
            "Epoch 00151: loss did not improve from 0.01733\n",
            "Epoch 152/500\n",
            "30/30 [==============================] - 1s 13ms/step - loss: 0.0201 - mae: 0.1407 - val_loss: 0.0202 - val_mae: 0.1506\n",
            "\n",
            "Epoch 00152: loss did not improve from 0.01733\n",
            "Epoch 153/500\n",
            "30/30 [==============================] - 1s 13ms/step - loss: 0.0209 - mae: 0.1428 - val_loss: 0.0216 - val_mae: 0.1556\n",
            "\n",
            "Epoch 00153: loss did not improve from 0.01733\n",
            "Epoch 154/500\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.0191 - mae: 0.1396 - val_loss: 0.0248 - val_mae: 0.1714\n",
            "\n",
            "Epoch 00154: loss did not improve from 0.01733\n",
            "Epoch 155/500\n",
            "30/30 [==============================] - 0s 12ms/step - loss: 0.0186 - mae: 0.1375 - val_loss: 0.0230 - val_mae: 0.1608\n",
            "\n",
            "Epoch 00155: loss did not improve from 0.01733\n",
            "Epoch 156/500\n",
            "30/30 [==============================] - 1s 14ms/step - loss: 0.0167 - mae: 0.1266 - val_loss: 0.0230 - val_mae: 0.1654\n",
            "\n",
            "Epoch 00156: loss did not improve from 0.01733\n",
            "Epoch 157/500\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.0193 - mae: 0.1405 - val_loss: 0.0205 - val_mae: 0.1447\n",
            "\n",
            "Epoch 00157: loss did not improve from 0.01733\n",
            "Epoch 158/500\n",
            "30/30 [==============================] - 1s 14ms/step - loss: 0.0168 - mae: 0.1336 - val_loss: 0.0230 - val_mae: 0.1628\n",
            "\n",
            "Epoch 00158: loss did not improve from 0.01733\n",
            "Epoch 159/500\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.0172 - mae: 0.1348 - val_loss: 0.0212 - val_mae: 0.1515\n",
            "\n",
            "Epoch 00159: loss did not improve from 0.01733\n",
            "Epoch 160/500\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.0174 - mae: 0.1334 - val_loss: 0.0210 - val_mae: 0.1516\n",
            "\n",
            "Epoch 00160: loss improved from 0.01733 to 0.01727, saving model to poids.hdf5\n",
            "Epoch 161/500\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.0148 - mae: 0.1273 - val_loss: 0.0218 - val_mae: 0.1554\n",
            "\n",
            "Epoch 00161: loss did not improve from 0.01727\n",
            "Epoch 162/500\n",
            "30/30 [==============================] - 1s 14ms/step - loss: 0.0177 - mae: 0.1372 - val_loss: 0.0205 - val_mae: 0.1470\n",
            "\n",
            "Epoch 00162: loss did not improve from 0.01727\n",
            "Epoch 163/500\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.0169 - mae: 0.1337 - val_loss: 0.0232 - val_mae: 0.1636\n",
            "\n",
            "Epoch 00163: loss did not improve from 0.01727\n",
            "Epoch 164/500\n",
            "30/30 [==============================] - 1s 14ms/step - loss: 0.0198 - mae: 0.1411 - val_loss: 0.0198 - val_mae: 0.1456\n",
            "\n",
            "Epoch 00164: loss did not improve from 0.01727\n",
            "Epoch 165/500\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.0161 - mae: 0.1322 - val_loss: 0.0211 - val_mae: 0.1495\n",
            "\n",
            "Epoch 00165: loss improved from 0.01727 to 0.01687, saving model to poids.hdf5\n",
            "Epoch 166/500\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.0179 - mae: 0.1373 - val_loss: 0.0196 - val_mae: 0.1439\n",
            "\n",
            "Epoch 00166: loss did not improve from 0.01687\n",
            "Epoch 167/500\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.0188 - mae: 0.1412 - val_loss: 0.0214 - val_mae: 0.1515\n",
            "\n",
            "Epoch 00167: loss did not improve from 0.01687\n",
            "Epoch 168/500\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.0180 - mae: 0.1385 - val_loss: 0.0187 - val_mae: 0.1433\n",
            "\n",
            "Epoch 00168: loss did not improve from 0.01687\n",
            "Epoch 169/500\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.0185 - mae: 0.1404 - val_loss: 0.0201 - val_mae: 0.1442\n",
            "\n",
            "Epoch 00169: loss did not improve from 0.01687\n",
            "Epoch 170/500\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.0186 - mae: 0.1356 - val_loss: 0.0230 - val_mae: 0.1620\n",
            "\n",
            "Epoch 00170: loss did not improve from 0.01687\n",
            "Epoch 171/500\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.0176 - mae: 0.1338 - val_loss: 0.0222 - val_mae: 0.1565\n",
            "\n",
            "Epoch 00171: loss did not improve from 0.01687\n",
            "Epoch 172/500\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.0169 - mae: 0.1361 - val_loss: 0.0227 - val_mae: 0.1635\n",
            "\n",
            "Epoch 00172: loss did not improve from 0.01687\n",
            "Epoch 173/500\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.0165 - mae: 0.1335 - val_loss: 0.0232 - val_mae: 0.1625\n",
            "\n",
            "Epoch 00173: loss did not improve from 0.01687\n",
            "Epoch 174/500\n",
            "30/30 [==============================] - 1s 15ms/step - loss: 0.0164 - mae: 0.1337 - val_loss: 0.0199 - val_mae: 0.1421\n",
            "\n",
            "Epoch 00174: loss did not improve from 0.01687\n",
            "Epoch 175/500\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.0185 - mae: 0.1369 - val_loss: 0.0225 - val_mae: 0.1587\n",
            "\n",
            "Epoch 00175: loss did not improve from 0.01687\n",
            "Epoch 176/500\n",
            "30/30 [==============================] - 1s 15ms/step - loss: 0.0174 - mae: 0.1344 - val_loss: 0.0215 - val_mae: 0.1539\n",
            "\n",
            "Epoch 00176: loss did not improve from 0.01687\n",
            "Epoch 177/500\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.0160 - mae: 0.1287 - val_loss: 0.0238 - val_mae: 0.1663\n",
            "\n",
            "Epoch 00177: loss did not improve from 0.01687\n",
            "Epoch 178/500\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.0159 - mae: 0.1279 - val_loss: 0.0239 - val_mae: 0.1682\n",
            "\n",
            "Epoch 00178: loss did not improve from 0.01687\n",
            "Epoch 179/500\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.0187 - mae: 0.1362 - val_loss: 0.0194 - val_mae: 0.1476\n",
            "\n",
            "Epoch 00179: loss did not improve from 0.01687\n",
            "Epoch 180/500\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.0183 - mae: 0.1369 - val_loss: 0.0207 - val_mae: 0.1505\n",
            "\n",
            "Epoch 00180: loss did not improve from 0.01687\n",
            "Epoch 181/500\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.0164 - mae: 0.1290 - val_loss: 0.0206 - val_mae: 0.1558\n",
            "\n",
            "Epoch 00181: loss did not improve from 0.01687\n",
            "Epoch 182/500\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.0159 - mae: 0.1298 - val_loss: 0.0201 - val_mae: 0.1460\n",
            "\n",
            "Epoch 00182: loss did not improve from 0.01687\n",
            "Epoch 183/500\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.0178 - mae: 0.1326 - val_loss: 0.0219 - val_mae: 0.1555\n",
            "\n",
            "Epoch 00183: loss did not improve from 0.01687\n",
            "Epoch 184/500\n",
            "30/30 [==============================] - 1s 13ms/step - loss: 0.0176 - mae: 0.1354 - val_loss: 0.0196 - val_mae: 0.1443\n",
            "\n",
            "Epoch 00184: loss did not improve from 0.01687\n",
            "Epoch 185/500\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.0182 - mae: 0.1390 - val_loss: 0.0217 - val_mae: 0.1555\n",
            "\n",
            "Epoch 00185: loss did not improve from 0.01687\n",
            "Epoch 186/500\n",
            "30/30 [==============================] - 1s 13ms/step - loss: 0.0178 - mae: 0.1347 - val_loss: 0.0202 - val_mae: 0.1444\n",
            "\n",
            "Epoch 00186: loss did not improve from 0.01687\n",
            "Epoch 187/500\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.0185 - mae: 0.1356 - val_loss: 0.0243 - val_mae: 0.1691\n",
            "\n",
            "Epoch 00187: loss did not improve from 0.01687\n",
            "Epoch 188/500\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.0169 - mae: 0.1357 - val_loss: 0.0220 - val_mae: 0.1576\n",
            "\n",
            "Epoch 00188: loss did not improve from 0.01687\n",
            "Epoch 189/500\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.0180 - mae: 0.1376 - val_loss: 0.0211 - val_mae: 0.1514\n",
            "\n",
            "Epoch 00189: loss did not improve from 0.01687\n",
            "Epoch 190/500\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.0206 - mae: 0.1423 - val_loss: 0.0223 - val_mae: 0.1569\n",
            "\n",
            "Epoch 00190: loss did not improve from 0.01687\n",
            "Epoch 191/500\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.0180 - mae: 0.1318 - val_loss: 0.0214 - val_mae: 0.1540\n",
            "\n",
            "Epoch 00191: loss did not improve from 0.01687\n",
            "Epoch 192/500\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.0179 - mae: 0.1384 - val_loss: 0.0200 - val_mae: 0.1454\n",
            "\n",
            "Epoch 00192: loss did not improve from 0.01687\n",
            "Epoch 193/500\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.0186 - mae: 0.1364 - val_loss: 0.0218 - val_mae: 0.1561\n",
            "\n",
            "Epoch 00193: loss did not improve from 0.01687\n",
            "Epoch 194/500\n",
            "30/30 [==============================] - 1s 13ms/step - loss: 0.0151 - mae: 0.1287 - val_loss: 0.0203 - val_mae: 0.1491\n",
            "\n",
            "Epoch 00194: loss did not improve from 0.01687\n",
            "Epoch 195/500\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.0188 - mae: 0.1385 - val_loss: 0.0231 - val_mae: 0.1623\n",
            "\n",
            "Epoch 00195: loss did not improve from 0.01687\n",
            "Epoch 196/500\n",
            "30/30 [==============================] - 1s 14ms/step - loss: 0.0203 - mae: 0.1413 - val_loss: 0.0202 - val_mae: 0.1468\n",
            "\n",
            "Epoch 00196: loss did not improve from 0.01687\n",
            "Epoch 197/500\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.0164 - mae: 0.1282 - val_loss: 0.0223 - val_mae: 0.1611\n",
            "\n",
            "Epoch 00197: loss did not improve from 0.01687\n",
            "Epoch 198/500\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.0184 - mae: 0.1366 - val_loss: 0.0200 - val_mae: 0.1474\n",
            "\n",
            "Epoch 00198: loss did not improve from 0.01687\n",
            "Epoch 199/500\n",
            "30/30 [==============================] - 1s 14ms/step - loss: 0.0173 - mae: 0.1329 - val_loss: 0.0201 - val_mae: 0.1455\n",
            "\n",
            "Epoch 00199: loss did not improve from 0.01687\n",
            "Epoch 200/500\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.0178 - mae: 0.1324 - val_loss: 0.0210 - val_mae: 0.1543\n",
            "\n",
            "Epoch 00200: loss did not improve from 0.01687\n",
            "Epoch 201/500\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.0169 - mae: 0.1354 - val_loss: 0.0188 - val_mae: 0.1452\n",
            "\n",
            "Epoch 00201: loss did not improve from 0.01687\n",
            "Epoch 202/500\n",
            "30/30 [==============================] - 1s 14ms/step - loss: 0.0165 - mae: 0.1291 - val_loss: 0.0220 - val_mae: 0.1576\n",
            "\n",
            "Epoch 00202: loss did not improve from 0.01687\n",
            "Epoch 203/500\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.0202 - mae: 0.1374 - val_loss: 0.0202 - val_mae: 0.1498\n",
            "\n",
            "Epoch 00203: loss did not improve from 0.01687\n",
            "Epoch 204/500\n",
            "30/30 [==============================] - 1s 13ms/step - loss: 0.0157 - mae: 0.1311 - val_loss: 0.0215 - val_mae: 0.1565\n",
            "\n",
            "Epoch 00204: loss did not improve from 0.01687\n",
            "Epoch 205/500\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.0180 - mae: 0.1331 - val_loss: 0.0235 - val_mae: 0.1645\n",
            "\n",
            "Epoch 00205: loss did not improve from 0.01687\n",
            "Epoch 206/500\n",
            "30/30 [==============================] - 1s 13ms/step - loss: 0.0157 - mae: 0.1324 - val_loss: 0.0214 - val_mae: 0.1530\n",
            "\n",
            "Epoch 00206: loss did not improve from 0.01687\n",
            "Epoch 207/500\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.0191 - mae: 0.1397 - val_loss: 0.0183 - val_mae: 0.1401\n",
            "\n",
            "Epoch 00207: loss did not improve from 0.01687\n",
            "Epoch 208/500\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.0167 - mae: 0.1284 - val_loss: 0.0206 - val_mae: 0.1504\n",
            "\n",
            "Epoch 00208: loss did not improve from 0.01687\n",
            "Epoch 209/500\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.0163 - mae: 0.1305 - val_loss: 0.0206 - val_mae: 0.1489\n",
            "\n",
            "Epoch 00209: loss did not improve from 0.01687\n",
            "Epoch 210/500\n",
            "30/30 [==============================] - 1s 13ms/step - loss: 0.0192 - mae: 0.1366 - val_loss: 0.0215 - val_mae: 0.1557\n",
            "\n",
            "Epoch 00210: loss did not improve from 0.01687\n",
            "Epoch 211/500\n",
            "30/30 [==============================] - 1s 14ms/step - loss: 0.0159 - mae: 0.1313 - val_loss: 0.0186 - val_mae: 0.1397\n",
            "\n",
            "Epoch 00211: loss did not improve from 0.01687\n",
            "Epoch 212/500\n",
            "30/30 [==============================] - 1s 14ms/step - loss: 0.0190 - mae: 0.1387 - val_loss: 0.0207 - val_mae: 0.1536\n",
            "\n",
            "Epoch 00212: loss did not improve from 0.01687\n",
            "Epoch 213/500\n",
            "30/30 [==============================] - 1s 14ms/step - loss: 0.0178 - mae: 0.1373 - val_loss: 0.0213 - val_mae: 0.1575\n",
            "\n",
            "Epoch 00213: loss did not improve from 0.01687\n",
            "Epoch 214/500\n",
            "30/30 [==============================] - 0s 14ms/step - loss: 0.0191 - mae: 0.1384 - val_loss: 0.0203 - val_mae: 0.1497\n",
            "\n",
            "Epoch 00214: loss did not improve from 0.01687\n",
            "Epoch 215/500\n",
            "30/30 [==============================] - 1s 14ms/step - loss: 0.0203 - mae: 0.1438 - val_loss: 0.0199 - val_mae: 0.1439\n",
            "\n",
            "Epoch 00215: loss did not improve from 0.01687\n",
            "Epoch 216/500\n",
            "30/30 [==============================] - 1s 15ms/step - loss: 0.0160 - mae: 0.1306 - val_loss: 0.0197 - val_mae: 0.1441\n",
            "\n",
            "Epoch 00216: loss did not improve from 0.01687\n",
            "Epoch 217/500\n",
            "30/30 [==============================] - 1s 14ms/step - loss: 0.0192 - mae: 0.1359 - val_loss: 0.0201 - val_mae: 0.1516\n",
            "\n",
            "Epoch 00217: loss did not improve from 0.01687\n",
            "Epoch 218/500\n",
            "30/30 [==============================] - 1s 13ms/step - loss: 0.0176 - mae: 0.1358 - val_loss: 0.0197 - val_mae: 0.1440\n",
            "\n",
            "Epoch 00218: loss improved from 0.01687 to 0.01676, saving model to poids.hdf5\n",
            "Epoch 219/500\n",
            "30/30 [==============================] - 1s 14ms/step - loss: 0.0184 - mae: 0.1356 - val_loss: 0.0209 - val_mae: 0.1517\n",
            "\n",
            "Epoch 00219: loss did not improve from 0.01676\n",
            "Epoch 220/500\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.0158 - mae: 0.1298 - val_loss: 0.0219 - val_mae: 0.1572\n",
            "\n",
            "Epoch 00220: loss did not improve from 0.01676\n",
            "Epoch 221/500\n",
            "30/30 [==============================] - 1s 14ms/step - loss: 0.0191 - mae: 0.1403 - val_loss: 0.0203 - val_mae: 0.1503\n",
            "\n",
            "Epoch 00221: loss did not improve from 0.01676\n",
            "Epoch 222/500\n",
            "30/30 [==============================] - 1s 14ms/step - loss: 0.0162 - mae: 0.1326 - val_loss: 0.0209 - val_mae: 0.1520\n",
            "\n",
            "Epoch 00222: loss did not improve from 0.01676\n",
            "Epoch 223/500\n",
            "30/30 [==============================] - 1s 14ms/step - loss: 0.0174 - mae: 0.1339 - val_loss: 0.0200 - val_mae: 0.1459\n",
            "\n",
            "Epoch 00223: loss did not improve from 0.01676\n",
            "Epoch 224/500\n",
            "30/30 [==============================] - 1s 14ms/step - loss: 0.0177 - mae: 0.1343 - val_loss: 0.0217 - val_mae: 0.1554\n",
            "\n",
            "Epoch 00224: loss did not improve from 0.01676\n",
            "Epoch 225/500\n",
            "30/30 [==============================] - 1s 14ms/step - loss: 0.0174 - mae: 0.1345 - val_loss: 0.0203 - val_mae: 0.1476\n",
            "\n",
            "Epoch 00225: loss did not improve from 0.01676\n",
            "Epoch 226/500\n",
            "30/30 [==============================] - 1s 14ms/step - loss: 0.0182 - mae: 0.1364 - val_loss: 0.0203 - val_mae: 0.1475\n",
            "\n",
            "Epoch 00226: loss did not improve from 0.01676\n",
            "Epoch 227/500\n",
            "30/30 [==============================] - 1s 14ms/step - loss: 0.0165 - mae: 0.1316 - val_loss: 0.0188 - val_mae: 0.1385\n",
            "\n",
            "Epoch 00227: loss did not improve from 0.01676\n",
            "Epoch 228/500\n",
            "30/30 [==============================] - 1s 14ms/step - loss: 0.0178 - mae: 0.1347 - val_loss: 0.0195 - val_mae: 0.1409\n",
            "\n",
            "Epoch 00228: loss did not improve from 0.01676\n",
            "Epoch 229/500\n",
            "30/30 [==============================] - 1s 14ms/step - loss: 0.0172 - mae: 0.1328 - val_loss: 0.0195 - val_mae: 0.1423\n",
            "\n",
            "Epoch 00229: loss did not improve from 0.01676\n",
            "Epoch 230/500\n",
            "30/30 [==============================] - 1s 14ms/step - loss: 0.0187 - mae: 0.1363 - val_loss: 0.0209 - val_mae: 0.1503\n",
            "\n",
            "Epoch 00230: loss did not improve from 0.01676\n",
            "Epoch 231/500\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.0173 - mae: 0.1327 - val_loss: 0.0203 - val_mae: 0.1476\n",
            "\n",
            "Epoch 00231: loss did not improve from 0.01676\n",
            "Epoch 232/500\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.0146 - mae: 0.1245 - val_loss: 0.0195 - val_mae: 0.1440\n",
            "\n",
            "Epoch 00232: loss improved from 0.01676 to 0.01671, saving model to poids.hdf5\n",
            "Epoch 233/500\n",
            "30/30 [==============================] - 0s 14ms/step - loss: 0.0172 - mae: 0.1353 - val_loss: 0.0197 - val_mae: 0.1476\n",
            "\n",
            "Epoch 00233: loss did not improve from 0.01671\n",
            "Epoch 234/500\n",
            "30/30 [==============================] - 1s 13ms/step - loss: 0.0177 - mae: 0.1355 - val_loss: 0.0208 - val_mae: 0.1506\n",
            "\n",
            "Epoch 00234: loss did not improve from 0.01671\n",
            "Epoch 235/500\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.0167 - mae: 0.1315 - val_loss: 0.0188 - val_mae: 0.1380\n",
            "\n",
            "Epoch 00235: loss did not improve from 0.01671\n",
            "Epoch 236/500\n",
            "30/30 [==============================] - 1s 15ms/step - loss: 0.0177 - mae: 0.1371 - val_loss: 0.0204 - val_mae: 0.1475\n",
            "\n",
            "Epoch 00236: loss did not improve from 0.01671\n",
            "Epoch 237/500\n",
            "30/30 [==============================] - 0s 12ms/step - loss: 0.0180 - mae: 0.1343 - val_loss: 0.0203 - val_mae: 0.1490\n",
            "\n",
            "Epoch 00237: loss did not improve from 0.01671\n",
            "Epoch 238/500\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.0167 - mae: 0.1319 - val_loss: 0.0209 - val_mae: 0.1511\n",
            "\n",
            "Epoch 00238: loss did not improve from 0.01671\n",
            "Epoch 239/500\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.0178 - mae: 0.1342 - val_loss: 0.0225 - val_mae: 0.1598\n",
            "\n",
            "Epoch 00239: loss did not improve from 0.01671\n",
            "Epoch 240/500\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.0158 - mae: 0.1308 - val_loss: 0.0200 - val_mae: 0.1506\n",
            "\n",
            "Epoch 00240: loss did not improve from 0.01671\n",
            "Epoch 241/500\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.0193 - mae: 0.1335 - val_loss: 0.0196 - val_mae: 0.1443\n",
            "\n",
            "Epoch 00241: loss did not improve from 0.01671\n",
            "Epoch 242/500\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.0171 - mae: 0.1339 - val_loss: 0.0218 - val_mae: 0.1568\n",
            "\n",
            "Epoch 00242: loss did not improve from 0.01671\n",
            "Epoch 243/500\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.0170 - mae: 0.1320 - val_loss: 0.0191 - val_mae: 0.1441\n",
            "\n",
            "Epoch 00243: loss did not improve from 0.01671\n",
            "Epoch 244/500\n",
            "30/30 [==============================] - 0s 14ms/step - loss: 0.0189 - mae: 0.1392 - val_loss: 0.0183 - val_mae: 0.1402\n",
            "\n",
            "Epoch 00244: loss did not improve from 0.01671\n",
            "Epoch 245/500\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.0159 - mae: 0.1312 - val_loss: 0.0167 - val_mae: 0.1357\n",
            "\n",
            "Epoch 00245: loss did not improve from 0.01671\n",
            "Epoch 246/500\n",
            "30/30 [==============================] - 1s 14ms/step - loss: 0.0189 - mae: 0.1362 - val_loss: 0.0213 - val_mae: 0.1529\n",
            "\n",
            "Epoch 00246: loss did not improve from 0.01671\n",
            "Epoch 247/500\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.0199 - mae: 0.1412 - val_loss: 0.0208 - val_mae: 0.1514\n",
            "\n",
            "Epoch 00247: loss did not improve from 0.01671\n",
            "Epoch 248/500\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.0160 - mae: 0.1298 - val_loss: 0.0195 - val_mae: 0.1438\n",
            "\n",
            "Epoch 00248: loss improved from 0.01671 to 0.01666, saving model to poids.hdf5\n",
            "Epoch 249/500\n",
            "30/30 [==============================] - 1s 14ms/step - loss: 0.0173 - mae: 0.1332 - val_loss: 0.0188 - val_mae: 0.1456\n",
            "\n",
            "Epoch 00249: loss did not improve from 0.01666\n",
            "Epoch 250/500\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.0191 - mae: 0.1393 - val_loss: 0.0218 - val_mae: 0.1561\n",
            "\n",
            "Epoch 00250: loss did not improve from 0.01666\n",
            "Epoch 251/500\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.0189 - mae: 0.1364 - val_loss: 0.0196 - val_mae: 0.1429\n",
            "\n",
            "Epoch 00251: loss did not improve from 0.01666\n",
            "Epoch 252/500\n",
            "30/30 [==============================] - 1s 13ms/step - loss: 0.0169 - mae: 0.1330 - val_loss: 0.0194 - val_mae: 0.1438\n",
            "\n",
            "Epoch 00252: loss did not improve from 0.01666\n",
            "Epoch 253/500\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.0154 - mae: 0.1296 - val_loss: 0.0218 - val_mae: 0.1579\n",
            "\n",
            "Epoch 00253: loss did not improve from 0.01666\n",
            "Epoch 254/500\n",
            "30/30 [==============================] - 1s 14ms/step - loss: 0.0175 - mae: 0.1347 - val_loss: 0.0182 - val_mae: 0.1392\n",
            "\n",
            "Epoch 00254: loss did not improve from 0.01666\n",
            "Epoch 255/500\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.0167 - mae: 0.1305 - val_loss: 0.0200 - val_mae: 0.1455\n",
            "\n",
            "Epoch 00255: loss did not improve from 0.01666\n",
            "Epoch 256/500\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.0160 - mae: 0.1313 - val_loss: 0.0202 - val_mae: 0.1469\n",
            "\n",
            "Epoch 00256: loss did not improve from 0.01666\n",
            "Epoch 257/500\n",
            "30/30 [==============================] - 1s 15ms/step - loss: 0.0187 - mae: 0.1370 - val_loss: 0.0201 - val_mae: 0.1492\n",
            "\n",
            "Epoch 00257: loss did not improve from 0.01666\n",
            "Epoch 258/500\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.0193 - mae: 0.1426 - val_loss: 0.0206 - val_mae: 0.1499\n",
            "\n",
            "Epoch 00258: loss did not improve from 0.01666\n",
            "Epoch 259/500\n",
            "30/30 [==============================] - 1s 14ms/step - loss: 0.0163 - mae: 0.1335 - val_loss: 0.0201 - val_mae: 0.1477\n",
            "\n",
            "Epoch 00259: loss did not improve from 0.01666\n",
            "Epoch 260/500\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.0168 - mae: 0.1359 - val_loss: 0.0195 - val_mae: 0.1438\n",
            "\n",
            "Epoch 00260: loss did not improve from 0.01666\n",
            "Epoch 261/500\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.0191 - mae: 0.1353 - val_loss: 0.0200 - val_mae: 0.1461\n",
            "\n",
            "Epoch 00261: loss did not improve from 0.01666\n",
            "Epoch 262/500\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.0169 - mae: 0.1325 - val_loss: 0.0188 - val_mae: 0.1435\n",
            "\n",
            "Epoch 00262: loss did not improve from 0.01666\n",
            "Epoch 263/500\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.0161 - mae: 0.1292 - val_loss: 0.0207 - val_mae: 0.1504\n",
            "\n",
            "Epoch 00263: loss did not improve from 0.01666\n",
            "Epoch 264/500\n",
            "30/30 [==============================] - 1s 14ms/step - loss: 0.0184 - mae: 0.1349 - val_loss: 0.0198 - val_mae: 0.1451\n",
            "\n",
            "Epoch 00264: loss did not improve from 0.01666\n",
            "Epoch 265/500\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.0213 - mae: 0.1412 - val_loss: 0.0201 - val_mae: 0.1460\n",
            "\n",
            "Epoch 00265: loss did not improve from 0.01666\n",
            "Epoch 266/500\n",
            "30/30 [==============================] - 1s 13ms/step - loss: 0.0187 - mae: 0.1375 - val_loss: 0.0202 - val_mae: 0.1478\n",
            "\n",
            "Epoch 00266: loss did not improve from 0.01666\n",
            "Epoch 267/500\n",
            "30/30 [==============================] - 1s 14ms/step - loss: 0.0167 - mae: 0.1338 - val_loss: 0.0197 - val_mae: 0.1449\n",
            "\n",
            "Epoch 00267: loss did not improve from 0.01666\n",
            "Epoch 268/500\n",
            "30/30 [==============================] - 1s 14ms/step - loss: 0.0166 - mae: 0.1309 - val_loss: 0.0195 - val_mae: 0.1438\n",
            "\n",
            "Epoch 00268: loss did not improve from 0.01666\n",
            "Epoch 269/500\n",
            "30/30 [==============================] - 0s 14ms/step - loss: 0.0164 - mae: 0.1277 - val_loss: 0.0195 - val_mae: 0.1429\n",
            "\n",
            "Epoch 00269: loss did not improve from 0.01666\n",
            "Epoch 270/500\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.0165 - mae: 0.1309 - val_loss: 0.0187 - val_mae: 0.1388\n",
            "\n",
            "Epoch 00270: loss did not improve from 0.01666\n",
            "Epoch 271/500\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.0171 - mae: 0.1334 - val_loss: 0.0195 - val_mae: 0.1433\n",
            "\n",
            "Epoch 00271: loss did not improve from 0.01666\n",
            "Epoch 272/500\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.0165 - mae: 0.1273 - val_loss: 0.0187 - val_mae: 0.1429\n",
            "\n",
            "Epoch 00272: loss did not improve from 0.01666\n",
            "Epoch 273/500\n",
            "30/30 [==============================] - 1s 14ms/step - loss: 0.0197 - mae: 0.1445 - val_loss: 0.0200 - val_mae: 0.1461\n",
            "\n",
            "Epoch 00273: loss did not improve from 0.01666\n",
            "Epoch 274/500\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.0178 - mae: 0.1382 - val_loss: 0.0189 - val_mae: 0.1423\n",
            "\n",
            "Epoch 00274: loss did not improve from 0.01666\n",
            "Epoch 275/500\n",
            "30/30 [==============================] - 1s 14ms/step - loss: 0.0146 - mae: 0.1272 - val_loss: 0.0190 - val_mae: 0.1446\n",
            "\n",
            "Epoch 00275: loss did not improve from 0.01666\n",
            "Epoch 276/500\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.0179 - mae: 0.1315 - val_loss: 0.0196 - val_mae: 0.1436\n",
            "\n",
            "Epoch 00276: loss did not improve from 0.01666\n",
            "Epoch 277/500\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.0185 - mae: 0.1275 - val_loss: 0.0190 - val_mae: 0.1409\n",
            "\n",
            "Epoch 00277: loss did not improve from 0.01666\n",
            "Epoch 278/500\n",
            "30/30 [==============================] - 1s 13ms/step - loss: 0.0193 - mae: 0.1374 - val_loss: 0.0197 - val_mae: 0.1456\n",
            "\n",
            "Epoch 00278: loss did not improve from 0.01666\n",
            "Epoch 279/500\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.0173 - mae: 0.1348 - val_loss: 0.0213 - val_mae: 0.1538\n",
            "\n",
            "Epoch 00279: loss did not improve from 0.01666\n",
            "Epoch 280/500\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.0177 - mae: 0.1367 - val_loss: 0.0199 - val_mae: 0.1470\n",
            "\n",
            "Epoch 00280: loss did not improve from 0.01666\n",
            "Epoch 281/500\n",
            "30/30 [==============================] - 1s 13ms/step - loss: 0.0189 - mae: 0.1376 - val_loss: 0.0188 - val_mae: 0.1448\n",
            "\n",
            "Epoch 00281: loss did not improve from 0.01666\n",
            "Epoch 282/500\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.0168 - mae: 0.1333 - val_loss: 0.0207 - val_mae: 0.1503\n",
            "\n",
            "Epoch 00282: loss did not improve from 0.01666\n",
            "Epoch 283/500\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.0166 - mae: 0.1297 - val_loss: 0.0200 - val_mae: 0.1480\n",
            "\n",
            "Epoch 00283: loss did not improve from 0.01666\n",
            "Epoch 284/500\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.0182 - mae: 0.1357 - val_loss: 0.0200 - val_mae: 0.1466\n",
            "\n",
            "Epoch 00284: loss did not improve from 0.01666\n",
            "Epoch 285/500\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.0204 - mae: 0.1391 - val_loss: 0.0213 - val_mae: 0.1560\n",
            "\n",
            "Epoch 00285: loss did not improve from 0.01666\n",
            "Epoch 286/500\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.0176 - mae: 0.1330 - val_loss: 0.0173 - val_mae: 0.1405\n",
            "\n",
            "Epoch 00286: loss did not improve from 0.01666\n",
            "Epoch 287/500\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.0148 - mae: 0.1248 - val_loss: 0.0194 - val_mae: 0.1453\n",
            "\n",
            "Epoch 00287: loss did not improve from 0.01666\n",
            "Epoch 288/500\n",
            "30/30 [==============================] - 1s 13ms/step - loss: 0.0201 - mae: 0.1430 - val_loss: 0.0192 - val_mae: 0.1454\n",
            "\n",
            "Epoch 00288: loss did not improve from 0.01666\n",
            "Epoch 289/500\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.0189 - mae: 0.1379 - val_loss: 0.0165 - val_mae: 0.1395\n",
            "\n",
            "Epoch 00289: loss did not improve from 0.01666\n",
            "Epoch 290/500\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.0169 - mae: 0.1338 - val_loss: 0.0195 - val_mae: 0.1444\n",
            "\n",
            "Epoch 00290: loss did not improve from 0.01666\n",
            "Epoch 291/500\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.0184 - mae: 0.1396 - val_loss: 0.0205 - val_mae: 0.1498\n",
            "\n",
            "Epoch 00291: loss did not improve from 0.01666\n",
            "Epoch 292/500\n",
            "30/30 [==============================] - 0s 14ms/step - loss: 0.0187 - mae: 0.1351 - val_loss: 0.0185 - val_mae: 0.1375\n",
            "\n",
            "Epoch 00292: loss did not improve from 0.01666\n",
            "Epoch 293/500\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.0193 - mae: 0.1410 - val_loss: 0.0193 - val_mae: 0.1433\n",
            "\n",
            "Epoch 00293: loss did not improve from 0.01666\n",
            "Epoch 294/500\n",
            "30/30 [==============================] - 1s 14ms/step - loss: 0.0173 - mae: 0.1334 - val_loss: 0.0201 - val_mae: 0.1475\n",
            "\n",
            "Epoch 00294: loss did not improve from 0.01666\n",
            "Epoch 295/500\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.0190 - mae: 0.1360 - val_loss: 0.0197 - val_mae: 0.1445\n",
            "\n",
            "Epoch 00295: loss did not improve from 0.01666\n",
            "Epoch 296/500\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.0188 - mae: 0.1382 - val_loss: 0.0180 - val_mae: 0.1371\n",
            "\n",
            "Epoch 00296: loss did not improve from 0.01666\n",
            "Epoch 297/500\n",
            "30/30 [==============================] - 1s 14ms/step - loss: 0.0186 - mae: 0.1362 - val_loss: 0.0195 - val_mae: 0.1443\n",
            "\n",
            "Epoch 00297: loss did not improve from 0.01666\n",
            "Epoch 298/500\n",
            "30/30 [==============================] - 1s 15ms/step - loss: 0.0186 - mae: 0.1391 - val_loss: 0.0194 - val_mae: 0.1423\n",
            "\n",
            "Epoch 00298: loss did not improve from 0.01666\n",
            "Epoch 299/500\n",
            "30/30 [==============================] - 1s 15ms/step - loss: 0.0183 - mae: 0.1347 - val_loss: 0.0182 - val_mae: 0.1396\n",
            "\n",
            "Epoch 00299: loss did not improve from 0.01666\n",
            "Epoch 300/500\n",
            "30/30 [==============================] - 1s 14ms/step - loss: 0.0177 - mae: 0.1355 - val_loss: 0.0199 - val_mae: 0.1462\n",
            "\n",
            "Epoch 00300: loss did not improve from 0.01666\n",
            "Epoch 301/500\n",
            "30/30 [==============================] - 1s 14ms/step - loss: 0.0169 - mae: 0.1366 - val_loss: 0.0178 - val_mae: 0.1398\n",
            "\n",
            "Epoch 00301: loss did not improve from 0.01666\n",
            "Epoch 302/500\n",
            "30/30 [==============================] - 0s 14ms/step - loss: 0.0187 - mae: 0.1366 - val_loss: 0.0194 - val_mae: 0.1457\n",
            "\n",
            "Epoch 00302: loss did not improve from 0.01666\n",
            "Epoch 303/500\n",
            "30/30 [==============================] - 1s 14ms/step - loss: 0.0177 - mae: 0.1341 - val_loss: 0.0187 - val_mae: 0.1455\n",
            "\n",
            "Epoch 00303: loss did not improve from 0.01666\n",
            "Epoch 304/500\n",
            "30/30 [==============================] - 1s 14ms/step - loss: 0.0176 - mae: 0.1355 - val_loss: 0.0205 - val_mae: 0.1510\n",
            "\n",
            "Epoch 00304: loss did not improve from 0.01666\n",
            "Epoch 305/500\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.0195 - mae: 0.1411 - val_loss: 0.0199 - val_mae: 0.1473\n",
            "\n",
            "Epoch 00305: loss did not improve from 0.01666\n",
            "Epoch 306/500\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.0164 - mae: 0.1300 - val_loss: 0.0189 - val_mae: 0.1418\n",
            "\n",
            "Epoch 00306: loss improved from 0.01666 to 0.01622, saving model to poids.hdf5\n",
            "Epoch 307/500\n",
            "30/30 [==============================] - 1s 14ms/step - loss: 0.0187 - mae: 0.1351 - val_loss: 0.0193 - val_mae: 0.1428\n",
            "\n",
            "Epoch 00307: loss did not improve from 0.01622\n",
            "Epoch 308/500\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.0169 - mae: 0.1361 - val_loss: 0.0189 - val_mae: 0.1410\n",
            "\n",
            "Epoch 00308: loss did not improve from 0.01622\n",
            "Epoch 309/500\n",
            "30/30 [==============================] - 1s 14ms/step - loss: 0.0176 - mae: 0.1327 - val_loss: 0.0185 - val_mae: 0.1378\n",
            "\n",
            "Epoch 00309: loss did not improve from 0.01622\n",
            "Epoch 310/500\n",
            "30/30 [==============================] - 1s 14ms/step - loss: 0.0190 - mae: 0.1428 - val_loss: 0.0205 - val_mae: 0.1501\n",
            "\n",
            "Epoch 00310: loss did not improve from 0.01622\n",
            "Epoch 311/500\n",
            "30/30 [==============================] - 1s 14ms/step - loss: 0.0145 - mae: 0.1261 - val_loss: 0.0198 - val_mae: 0.1466\n",
            "\n",
            "Epoch 00311: loss did not improve from 0.01622\n",
            "Epoch 312/500\n",
            "30/30 [==============================] - 1s 13ms/step - loss: 0.0158 - mae: 0.1315 - val_loss: 0.0188 - val_mae: 0.1396\n",
            "\n",
            "Epoch 00312: loss did not improve from 0.01622\n",
            "Epoch 313/500\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.0161 - mae: 0.1315 - val_loss: 0.0184 - val_mae: 0.1376\n",
            "\n",
            "Epoch 00313: loss did not improve from 0.01622\n",
            "Epoch 314/500\n",
            "30/30 [==============================] - 1s 14ms/step - loss: 0.0176 - mae: 0.1345 - val_loss: 0.0187 - val_mae: 0.1395\n",
            "\n",
            "Epoch 00314: loss did not improve from 0.01622\n",
            "Epoch 315/500\n",
            "30/30 [==============================] - 1s 14ms/step - loss: 0.0170 - mae: 0.1323 - val_loss: 0.0194 - val_mae: 0.1432\n",
            "\n",
            "Epoch 00315: loss did not improve from 0.01622\n",
            "Epoch 316/500\n",
            "30/30 [==============================] - 1s 14ms/step - loss: 0.0166 - mae: 0.1319 - val_loss: 0.0190 - val_mae: 0.1418\n",
            "\n",
            "Epoch 00316: loss did not improve from 0.01622\n",
            "Epoch 317/500\n",
            "30/30 [==============================] - 1s 15ms/step - loss: 0.0167 - mae: 0.1314 - val_loss: 0.0195 - val_mae: 0.1504\n",
            "\n",
            "Epoch 00317: loss did not improve from 0.01622\n",
            "Epoch 318/500\n",
            "30/30 [==============================] - 1s 14ms/step - loss: 0.0176 - mae: 0.1369 - val_loss: 0.0196 - val_mae: 0.1447\n",
            "\n",
            "Epoch 00318: loss did not improve from 0.01622\n",
            "Epoch 319/500\n",
            "30/30 [==============================] - 1s 14ms/step - loss: 0.0188 - mae: 0.1378 - val_loss: 0.0179 - val_mae: 0.1366\n",
            "\n",
            "Epoch 00319: loss did not improve from 0.01622\n",
            "Epoch 320/500\n",
            "30/30 [==============================] - 1s 14ms/step - loss: 0.0168 - mae: 0.1323 - val_loss: 0.0184 - val_mae: 0.1380\n",
            "\n",
            "Epoch 00320: loss did not improve from 0.01622\n",
            "Epoch 321/500\n",
            "30/30 [==============================] - 1s 14ms/step - loss: 0.0167 - mae: 0.1297 - val_loss: 0.0191 - val_mae: 0.1420\n",
            "\n",
            "Epoch 00321: loss did not improve from 0.01622\n",
            "Epoch 322/500\n",
            "30/30 [==============================] - 1s 14ms/step - loss: 0.0208 - mae: 0.1408 - val_loss: 0.0180 - val_mae: 0.1350\n",
            "\n",
            "Epoch 00322: loss did not improve from 0.01622\n",
            "Epoch 323/500\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.0187 - mae: 0.1388 - val_loss: 0.0194 - val_mae: 0.1447\n",
            "\n",
            "Epoch 00323: loss did not improve from 0.01622\n",
            "Epoch 324/500\n",
            "30/30 [==============================] - 1s 13ms/step - loss: 0.0192 - mae: 0.1392 - val_loss: 0.0187 - val_mae: 0.1400\n",
            "\n",
            "Epoch 00324: loss did not improve from 0.01622\n",
            "Epoch 325/500\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.0186 - mae: 0.1347 - val_loss: 0.0179 - val_mae: 0.1348\n",
            "\n",
            "Epoch 00325: loss did not improve from 0.01622\n",
            "Epoch 326/500\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.0161 - mae: 0.1304 - val_loss: 0.0197 - val_mae: 0.1457\n",
            "\n",
            "Epoch 00326: loss did not improve from 0.01622\n",
            "Epoch 327/500\n",
            "30/30 [==============================] - 1s 13ms/step - loss: 0.0150 - mae: 0.1261 - val_loss: 0.0196 - val_mae: 0.1449\n",
            "\n",
            "Epoch 00327: loss did not improve from 0.01622\n",
            "Epoch 328/500\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.0177 - mae: 0.1340 - val_loss: 0.0191 - val_mae: 0.1413\n",
            "\n",
            "Epoch 00328: loss did not improve from 0.01622\n",
            "Epoch 329/500\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.0168 - mae: 0.1321 - val_loss: 0.0181 - val_mae: 0.1371\n",
            "\n",
            "Epoch 00329: loss did not improve from 0.01622\n",
            "Epoch 330/500\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.0185 - mae: 0.1365 - val_loss: 0.0168 - val_mae: 0.1330\n",
            "\n",
            "Epoch 00330: loss did not improve from 0.01622\n",
            "Epoch 331/500\n",
            "30/30 [==============================] - 1s 14ms/step - loss: 0.0186 - mae: 0.1386 - val_loss: 0.0188 - val_mae: 0.1397\n",
            "\n",
            "Epoch 00331: loss did not improve from 0.01622\n",
            "Epoch 332/500\n",
            "30/30 [==============================] - 1s 14ms/step - loss: 0.0167 - mae: 0.1352 - val_loss: 0.0173 - val_mae: 0.1405\n",
            "\n",
            "Epoch 00332: loss did not improve from 0.01622\n",
            "Epoch 333/500\n",
            "30/30 [==============================] - 0s 14ms/step - loss: 0.0154 - mae: 0.1270 - val_loss: 0.0186 - val_mae: 0.1427\n",
            "\n",
            "Epoch 00333: loss did not improve from 0.01622\n",
            "Epoch 334/500\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.0173 - mae: 0.1339 - val_loss: 0.0203 - val_mae: 0.1502\n",
            "\n",
            "Epoch 00334: loss did not improve from 0.01622\n",
            "Epoch 335/500\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.0185 - mae: 0.1376 - val_loss: 0.0186 - val_mae: 0.1391\n",
            "\n",
            "Epoch 00335: loss did not improve from 0.01622\n",
            "Epoch 336/500\n",
            "30/30 [==============================] - 0s 14ms/step - loss: 0.0171 - mae: 0.1343 - val_loss: 0.0169 - val_mae: 0.1327\n",
            "\n",
            "Epoch 00336: loss did not improve from 0.01622\n",
            "Epoch 337/500\n",
            "30/30 [==============================] - 1s 14ms/step - loss: 0.0174 - mae: 0.1342 - val_loss: 0.0193 - val_mae: 0.1441\n",
            "\n",
            "Epoch 00337: loss did not improve from 0.01622\n",
            "Epoch 338/500\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.0189 - mae: 0.1395 - val_loss: 0.0187 - val_mae: 0.1394\n",
            "\n",
            "Epoch 00338: loss did not improve from 0.01622\n",
            "Epoch 339/500\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.0156 - mae: 0.1281 - val_loss: 0.0196 - val_mae: 0.1451\n",
            "\n",
            "Epoch 00339: loss did not improve from 0.01622\n",
            "Epoch 340/500\n",
            "30/30 [==============================] - 1s 14ms/step - loss: 0.0164 - mae: 0.1296 - val_loss: 0.0187 - val_mae: 0.1409\n",
            "\n",
            "Epoch 00340: loss did not improve from 0.01622\n",
            "Epoch 341/500\n",
            "30/30 [==============================] - 1s 14ms/step - loss: 0.0176 - mae: 0.1330 - val_loss: 0.0175 - val_mae: 0.1366\n",
            "\n",
            "Epoch 00341: loss did not improve from 0.01622\n",
            "Epoch 342/500\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.0179 - mae: 0.1368 - val_loss: 0.0177 - val_mae: 0.1392\n",
            "\n",
            "Epoch 00342: loss did not improve from 0.01622\n",
            "Epoch 343/500\n",
            "30/30 [==============================] - 1s 13ms/step - loss: 0.0188 - mae: 0.1373 - val_loss: 0.0178 - val_mae: 0.1341\n",
            "\n",
            "Epoch 00343: loss did not improve from 0.01622\n",
            "Epoch 344/500\n",
            "30/30 [==============================] - 1s 15ms/step - loss: 0.0149 - mae: 0.1264 - val_loss: 0.0192 - val_mae: 0.1477\n",
            "\n",
            "Epoch 00344: loss did not improve from 0.01622\n",
            "Epoch 345/500\n",
            "30/30 [==============================] - 1s 14ms/step - loss: 0.0176 - mae: 0.1369 - val_loss: 0.0189 - val_mae: 0.1417\n",
            "\n",
            "Epoch 00345: loss did not improve from 0.01622\n",
            "Epoch 346/500\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.0168 - mae: 0.1331 - val_loss: 0.0175 - val_mae: 0.1381\n",
            "\n",
            "Epoch 00346: loss did not improve from 0.01622\n",
            "Epoch 347/500\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.0182 - mae: 0.1347 - val_loss: 0.0192 - val_mae: 0.1427\n",
            "\n",
            "Epoch 00347: loss did not improve from 0.01622\n",
            "Epoch 348/500\n",
            "30/30 [==============================] - 1s 14ms/step - loss: 0.0181 - mae: 0.1368 - val_loss: 0.0183 - val_mae: 0.1380\n",
            "\n",
            "Epoch 00348: loss did not improve from 0.01622\n",
            "Epoch 349/500\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.0176 - mae: 0.1346 - val_loss: 0.0192 - val_mae: 0.1423\n",
            "\n",
            "Epoch 00349: loss did not improve from 0.01622\n",
            "Epoch 350/500\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.0161 - mae: 0.1304 - val_loss: 0.0179 - val_mae: 0.1350\n",
            "\n",
            "Epoch 00350: loss did not improve from 0.01622\n",
            "Epoch 351/500\n",
            "30/30 [==============================] - 1s 14ms/step - loss: 0.0176 - mae: 0.1337 - val_loss: 0.0190 - val_mae: 0.1410\n",
            "\n",
            "Epoch 00351: loss did not improve from 0.01622\n",
            "Epoch 352/500\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.0181 - mae: 0.1364 - val_loss: 0.0182 - val_mae: 0.1434\n",
            "\n",
            "Epoch 00352: loss did not improve from 0.01622\n",
            "Epoch 353/500\n",
            "30/30 [==============================] - 1s 14ms/step - loss: 0.0202 - mae: 0.1397 - val_loss: 0.0188 - val_mae: 0.1407\n",
            "\n",
            "Epoch 00353: loss did not improve from 0.01622\n",
            "Epoch 354/500\n",
            "30/30 [==============================] - 1s 14ms/step - loss: 0.0162 - mae: 0.1310 - val_loss: 0.0181 - val_mae: 0.1362\n",
            "\n",
            "Epoch 00354: loss did not improve from 0.01622\n",
            "Epoch 355/500\n",
            "30/30 [==============================] - 1s 15ms/step - loss: 0.0160 - mae: 0.1331 - val_loss: 0.0195 - val_mae: 0.1450\n",
            "\n",
            "Epoch 00355: loss did not improve from 0.01622\n",
            "Epoch 356/500\n",
            "30/30 [==============================] - 1s 14ms/step - loss: 0.0172 - mae: 0.1323 - val_loss: 0.0198 - val_mae: 0.1479\n",
            "\n",
            "Epoch 00356: loss did not improve from 0.01622\n",
            "Epoch 357/500\n",
            "30/30 [==============================] - 0s 14ms/step - loss: 0.0171 - mae: 0.1315 - val_loss: 0.0173 - val_mae: 0.1377\n",
            "\n",
            "Epoch 00357: loss did not improve from 0.01622\n",
            "Epoch 358/500\n",
            "30/30 [==============================] - 1s 13ms/step - loss: 0.0168 - mae: 0.1315 - val_loss: 0.0194 - val_mae: 0.1440\n",
            "\n",
            "Epoch 00358: loss did not improve from 0.01622\n",
            "Epoch 359/500\n",
            "30/30 [==============================] - 1s 14ms/step - loss: 0.0185 - mae: 0.1350 - val_loss: 0.0198 - val_mae: 0.1474\n",
            "\n",
            "Epoch 00359: loss did not improve from 0.01622\n",
            "Epoch 360/500\n",
            "30/30 [==============================] - 1s 14ms/step - loss: 0.0152 - mae: 0.1303 - val_loss: 0.0179 - val_mae: 0.1356\n",
            "\n",
            "Epoch 00360: loss did not improve from 0.01622\n",
            "Epoch 361/500\n",
            "30/30 [==============================] - 1s 14ms/step - loss: 0.0147 - mae: 0.1271 - val_loss: 0.0182 - val_mae: 0.1366\n",
            "\n",
            "Epoch 00361: loss did not improve from 0.01622\n",
            "Epoch 362/500\n",
            "30/30 [==============================] - 1s 15ms/step - loss: 0.0157 - mae: 0.1304 - val_loss: 0.0187 - val_mae: 0.1406\n",
            "\n",
            "Epoch 00362: loss did not improve from 0.01622\n",
            "Epoch 363/500\n",
            "30/30 [==============================] - 1s 14ms/step - loss: 0.0174 - mae: 0.1330 - val_loss: 0.0184 - val_mae: 0.1392\n",
            "\n",
            "Epoch 00363: loss did not improve from 0.01622\n",
            "Epoch 364/500\n",
            "30/30 [==============================] - 1s 14ms/step - loss: 0.0171 - mae: 0.1314 - val_loss: 0.0184 - val_mae: 0.1385\n",
            "\n",
            "Epoch 00364: loss did not improve from 0.01622\n",
            "Epoch 365/500\n",
            "30/30 [==============================] - 1s 14ms/step - loss: 0.0175 - mae: 0.1324 - val_loss: 0.0188 - val_mae: 0.1402\n",
            "\n",
            "Epoch 00365: loss did not improve from 0.01622\n",
            "Epoch 366/500\n",
            "30/30 [==============================] - 0s 14ms/step - loss: 0.0169 - mae: 0.1335 - val_loss: 0.0181 - val_mae: 0.1374\n",
            "\n",
            "Epoch 00366: loss did not improve from 0.01622\n",
            "Epoch 367/500\n",
            "30/30 [==============================] - 1s 14ms/step - loss: 0.0178 - mae: 0.1336 - val_loss: 0.0188 - val_mae: 0.1422\n",
            "\n",
            "Epoch 00367: loss did not improve from 0.01622\n",
            "Epoch 368/500\n",
            "30/30 [==============================] - 1s 14ms/step - loss: 0.0188 - mae: 0.1372 - val_loss: 0.0182 - val_mae: 0.1412\n",
            "\n",
            "Epoch 00368: loss did not improve from 0.01622\n",
            "Epoch 369/500\n",
            "30/30 [==============================] - 0s 14ms/step - loss: 0.0176 - mae: 0.1374 - val_loss: 0.0186 - val_mae: 0.1404\n",
            "\n",
            "Epoch 00369: loss did not improve from 0.01622\n",
            "Epoch 370/500\n",
            "30/30 [==============================] - 1s 15ms/step - loss: 0.0154 - mae: 0.1276 - val_loss: 0.0184 - val_mae: 0.1383\n",
            "\n",
            "Epoch 00370: loss did not improve from 0.01622\n",
            "Epoch 371/500\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.0166 - mae: 0.1330 - val_loss: 0.0181 - val_mae: 0.1369\n",
            "\n",
            "Epoch 00371: loss did not improve from 0.01622\n",
            "Epoch 372/500\n",
            "30/30 [==============================] - 1s 14ms/step - loss: 0.0167 - mae: 0.1321 - val_loss: 0.0181 - val_mae: 0.1375\n",
            "\n",
            "Epoch 00372: loss did not improve from 0.01622\n",
            "Epoch 373/500\n",
            "30/30 [==============================] - 0s 14ms/step - loss: 0.0163 - mae: 0.1324 - val_loss: 0.0181 - val_mae: 0.1384\n",
            "\n",
            "Epoch 00373: loss did not improve from 0.01622\n",
            "Epoch 374/500\n",
            "30/30 [==============================] - 1s 14ms/step - loss: 0.0166 - mae: 0.1343 - val_loss: 0.0186 - val_mae: 0.1409\n",
            "\n",
            "Epoch 00374: loss did not improve from 0.01622\n",
            "Epoch 375/500\n",
            "30/30 [==============================] - 1s 14ms/step - loss: 0.0178 - mae: 0.1325 - val_loss: 0.0204 - val_mae: 0.1506\n",
            "\n",
            "Epoch 00375: loss did not improve from 0.01622\n",
            "Epoch 376/500\n",
            "30/30 [==============================] - 1s 15ms/step - loss: 0.0178 - mae: 0.1349 - val_loss: 0.0194 - val_mae: 0.1450\n",
            "\n",
            "Epoch 00376: loss did not improve from 0.01622\n",
            "Epoch 377/500\n",
            "30/30 [==============================] - 1s 15ms/step - loss: 0.0163 - mae: 0.1288 - val_loss: 0.0188 - val_mae: 0.1425\n",
            "\n",
            "Epoch 00377: loss did not improve from 0.01622\n",
            "Epoch 378/500\n",
            "30/30 [==============================] - 1s 15ms/step - loss: 0.0164 - mae: 0.1301 - val_loss: 0.0201 - val_mae: 0.1488\n",
            "\n",
            "Epoch 00378: loss did not improve from 0.01622\n",
            "Epoch 379/500\n",
            "30/30 [==============================] - 0s 14ms/step - loss: 0.0164 - mae: 0.1351 - val_loss: 0.0196 - val_mae: 0.1477\n",
            "\n",
            "Epoch 00379: loss did not improve from 0.01622\n",
            "Epoch 380/500\n",
            "30/30 [==============================] - 1s 14ms/step - loss: 0.0190 - mae: 0.1397 - val_loss: 0.0186 - val_mae: 0.1393\n",
            "\n",
            "Epoch 00380: loss did not improve from 0.01622\n",
            "Epoch 381/500\n",
            "30/30 [==============================] - 1s 14ms/step - loss: 0.0178 - mae: 0.1332 - val_loss: 0.0184 - val_mae: 0.1399\n",
            "\n",
            "Epoch 00381: loss did not improve from 0.01622\n",
            "Epoch 382/500\n",
            "30/30 [==============================] - 0s 14ms/step - loss: 0.0172 - mae: 0.1326 - val_loss: 0.0182 - val_mae: 0.1381\n",
            "\n",
            "Epoch 00382: loss did not improve from 0.01622\n",
            "Epoch 383/500\n",
            "30/30 [==============================] - 1s 15ms/step - loss: 0.0156 - mae: 0.1277 - val_loss: 0.0179 - val_mae: 0.1357\n",
            "\n",
            "Epoch 00383: loss did not improve from 0.01622\n",
            "Epoch 384/500\n",
            "30/30 [==============================] - 0s 14ms/step - loss: 0.0195 - mae: 0.1349 - val_loss: 0.0196 - val_mae: 0.1460\n",
            "\n",
            "Epoch 00384: loss did not improve from 0.01622\n",
            "Epoch 385/500\n",
            "30/30 [==============================] - 1s 14ms/step - loss: 0.0180 - mae: 0.1353 - val_loss: 0.0181 - val_mae: 0.1389\n",
            "\n",
            "Epoch 00385: loss did not improve from 0.01622\n",
            "Epoch 386/500\n",
            "30/30 [==============================] - 1s 14ms/step - loss: 0.0173 - mae: 0.1318 - val_loss: 0.0174 - val_mae: 0.1355\n",
            "\n",
            "Epoch 00386: loss did not improve from 0.01622\n",
            "Epoch 387/500\n",
            "30/30 [==============================] - 1s 14ms/step - loss: 0.0187 - mae: 0.1375 - val_loss: 0.0192 - val_mae: 0.1430\n",
            "\n",
            "Epoch 00387: loss did not improve from 0.01622\n",
            "Epoch 388/500\n",
            "30/30 [==============================] - 1s 14ms/step - loss: 0.0166 - mae: 0.1292 - val_loss: 0.0166 - val_mae: 0.1308\n",
            "\n",
            "Epoch 00388: loss did not improve from 0.01622\n",
            "Epoch 389/500\n",
            "30/30 [==============================] - 0s 14ms/step - loss: 0.0178 - mae: 0.1347 - val_loss: 0.0188 - val_mae: 0.1409\n",
            "\n",
            "Epoch 00389: loss did not improve from 0.01622\n",
            "Epoch 390/500\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.0205 - mae: 0.1394 - val_loss: 0.0177 - val_mae: 0.1347\n",
            "\n",
            "Epoch 00390: loss did not improve from 0.01622\n",
            "Epoch 391/500\n",
            "30/30 [==============================] - 1s 14ms/step - loss: 0.0157 - mae: 0.1307 - val_loss: 0.0175 - val_mae: 0.1326\n",
            "\n",
            "Epoch 00391: loss did not improve from 0.01622\n",
            "Epoch 392/500\n",
            "30/30 [==============================] - 1s 14ms/step - loss: 0.0203 - mae: 0.1364 - val_loss: 0.0189 - val_mae: 0.1412\n",
            "\n",
            "Epoch 00392: loss did not improve from 0.01622\n",
            "Epoch 393/500\n",
            "30/30 [==============================] - 1s 14ms/step - loss: 0.0151 - mae: 0.1271 - val_loss: 0.0186 - val_mae: 0.1400\n",
            "\n",
            "Epoch 00393: loss did not improve from 0.01622\n",
            "Epoch 394/500\n",
            "30/30 [==============================] - 1s 14ms/step - loss: 0.0189 - mae: 0.1337 - val_loss: 0.0193 - val_mae: 0.1446\n",
            "\n",
            "Epoch 00394: loss did not improve from 0.01622\n",
            "Epoch 395/500\n",
            "30/30 [==============================] - 1s 14ms/step - loss: 0.0152 - mae: 0.1265 - val_loss: 0.0181 - val_mae: 0.1371\n",
            "\n",
            "Epoch 00395: loss did not improve from 0.01622\n",
            "Epoch 396/500\n",
            "30/30 [==============================] - 1s 15ms/step - loss: 0.0156 - mae: 0.1244 - val_loss: 0.0175 - val_mae: 0.1371\n",
            "\n",
            "Epoch 00396: loss did not improve from 0.01622\n",
            "Epoch 397/500\n",
            "30/30 [==============================] - 1s 14ms/step - loss: 0.0170 - mae: 0.1344 - val_loss: 0.0190 - val_mae: 0.1441\n",
            "\n",
            "Epoch 00397: loss did not improve from 0.01622\n",
            "Epoch 398/500\n",
            "30/30 [==============================] - 1s 14ms/step - loss: 0.0187 - mae: 0.1364 - val_loss: 0.0186 - val_mae: 0.1402\n",
            "\n",
            "Epoch 00398: loss did not improve from 0.01622\n",
            "Epoch 399/500\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.0152 - mae: 0.1286 - val_loss: 0.0178 - val_mae: 0.1360\n",
            "\n",
            "Epoch 00399: loss did not improve from 0.01622\n",
            "Epoch 400/500\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.0162 - mae: 0.1311 - val_loss: 0.0192 - val_mae: 0.1446\n",
            "\n",
            "Epoch 00400: loss did not improve from 0.01622\n",
            "Epoch 401/500\n",
            "30/30 [==============================] - 0s 14ms/step - loss: 0.0160 - mae: 0.1285 - val_loss: 0.0187 - val_mae: 0.1410\n",
            "\n",
            "Epoch 00401: loss did not improve from 0.01622\n",
            "Epoch 402/500\n",
            "30/30 [==============================] - 1s 14ms/step - loss: 0.0188 - mae: 0.1316 - val_loss: 0.0176 - val_mae: 0.1337\n",
            "\n",
            "Epoch 00402: loss did not improve from 0.01622\n",
            "Epoch 403/500\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.0161 - mae: 0.1322 - val_loss: 0.0170 - val_mae: 0.1358\n",
            "\n",
            "Epoch 00403: loss did not improve from 0.01622\n",
            "Epoch 404/500\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.0157 - mae: 0.1313 - val_loss: 0.0187 - val_mae: 0.1415\n",
            "\n",
            "Epoch 00404: loss did not improve from 0.01622\n",
            "Epoch 405/500\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.0162 - mae: 0.1306 - val_loss: 0.0182 - val_mae: 0.1372\n",
            "\n",
            "Epoch 00405: loss did not improve from 0.01622\n",
            "Epoch 406/500\n",
            "30/30 [==============================] - 1s 13ms/step - loss: 0.0170 - mae: 0.1328 - val_loss: 0.0179 - val_mae: 0.1348\n",
            "\n",
            "Epoch 00406: loss did not improve from 0.01622\n",
            "Epoch 407/500\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.0176 - mae: 0.1360 - val_loss: 0.0192 - val_mae: 0.1436\n",
            "\n",
            "Epoch 00407: loss did not improve from 0.01622\n",
            "Epoch 408/500\n",
            "30/30 [==============================] - 1s 14ms/step - loss: 0.0173 - mae: 0.1327 - val_loss: 0.0181 - val_mae: 0.1373\n",
            "\n",
            "Epoch 00408: loss did not improve from 0.01622\n",
            "Epoch 409/500\n",
            "30/30 [==============================] - 1s 14ms/step - loss: 0.0155 - mae: 0.1268 - val_loss: 0.0182 - val_mae: 0.1372\n",
            "\n",
            "Epoch 00409: loss did not improve from 0.01622\n",
            "Epoch 410/500\n",
            "30/30 [==============================] - 0s 14ms/step - loss: 0.0175 - mae: 0.1342 - val_loss: 0.0159 - val_mae: 0.1318\n",
            "\n",
            "Epoch 00410: loss did not improve from 0.01622\n",
            "Epoch 411/500\n",
            "30/30 [==============================] - 0s 14ms/step - loss: 0.0165 - mae: 0.1347 - val_loss: 0.0180 - val_mae: 0.1364\n",
            "\n",
            "Epoch 00411: loss did not improve from 0.01622\n",
            "Epoch 412/500\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.0169 - mae: 0.1320 - val_loss: 0.0178 - val_mae: 0.1359\n",
            "\n",
            "Epoch 00412: loss did not improve from 0.01622\n",
            "Epoch 413/500\n",
            "30/30 [==============================] - 1s 14ms/step - loss: 0.0161 - mae: 0.1298 - val_loss: 0.0179 - val_mae: 0.1356\n",
            "\n",
            "Epoch 00413: loss did not improve from 0.01622\n",
            "Epoch 414/500\n",
            "30/30 [==============================] - 0s 14ms/step - loss: 0.0169 - mae: 0.1365 - val_loss: 0.0186 - val_mae: 0.1400\n",
            "\n",
            "Epoch 00414: loss did not improve from 0.01622\n",
            "Epoch 415/500\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.0164 - mae: 0.1345 - val_loss: 0.0170 - val_mae: 0.1346\n",
            "\n",
            "Epoch 00415: loss did not improve from 0.01622\n",
            "Epoch 416/500\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.0172 - mae: 0.1337 - val_loss: 0.0184 - val_mae: 0.1388\n",
            "\n",
            "Epoch 00416: loss did not improve from 0.01622\n",
            "Epoch 417/500\n",
            "30/30 [==============================] - 1s 14ms/step - loss: 0.0168 - mae: 0.1318 - val_loss: 0.0180 - val_mae: 0.1359\n",
            "\n",
            "Epoch 00417: loss did not improve from 0.01622\n",
            "Epoch 418/500\n",
            "30/30 [==============================] - 1s 14ms/step - loss: 0.0164 - mae: 0.1330 - val_loss: 0.0168 - val_mae: 0.1331\n",
            "\n",
            "Epoch 00418: loss did not improve from 0.01622\n",
            "Epoch 419/500\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.0195 - mae: 0.1397 - val_loss: 0.0179 - val_mae: 0.1379\n",
            "\n",
            "Epoch 00419: loss did not improve from 0.01622\n",
            "Epoch 420/500\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.0166 - mae: 0.1320 - val_loss: 0.0174 - val_mae: 0.1377\n",
            "\n",
            "Epoch 00420: loss did not improve from 0.01622\n",
            "Epoch 421/500\n",
            "30/30 [==============================] - 1s 14ms/step - loss: 0.0189 - mae: 0.1376 - val_loss: 0.0179 - val_mae: 0.1349\n",
            "\n",
            "Epoch 00421: loss did not improve from 0.01622\n",
            "Epoch 422/500\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.0183 - mae: 0.1326 - val_loss: 0.0179 - val_mae: 0.1361\n",
            "\n",
            "Epoch 00422: loss did not improve from 0.01622\n",
            "Epoch 423/500\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.0159 - mae: 0.1309 - val_loss: 0.0173 - val_mae: 0.1323\n",
            "\n",
            "Epoch 00423: loss did not improve from 0.01622\n",
            "Epoch 424/500\n",
            "30/30 [==============================] - 1s 14ms/step - loss: 0.0146 - mae: 0.1227 - val_loss: 0.0184 - val_mae: 0.1386\n",
            "\n",
            "Epoch 00424: loss did not improve from 0.01622\n",
            "Epoch 425/500\n",
            "30/30 [==============================] - 1s 14ms/step - loss: 0.0167 - mae: 0.1318 - val_loss: 0.0185 - val_mae: 0.1392\n",
            "\n",
            "Epoch 00425: loss did not improve from 0.01622\n",
            "Epoch 426/500\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.0175 - mae: 0.1347 - val_loss: 0.0179 - val_mae: 0.1362\n",
            "\n",
            "Epoch 00426: loss did not improve from 0.01622\n",
            "Epoch 427/500\n",
            "30/30 [==============================] - 1s 14ms/step - loss: 0.0156 - mae: 0.1247 - val_loss: 0.0188 - val_mae: 0.1412\n",
            "\n",
            "Epoch 00427: loss did not improve from 0.01622\n",
            "Epoch 428/500\n",
            "30/30 [==============================] - 1s 14ms/step - loss: 0.0200 - mae: 0.1362 - val_loss: 0.0174 - val_mae: 0.1310\n",
            "\n",
            "Epoch 00428: loss did not improve from 0.01622\n",
            "Epoch 429/500\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.0190 - mae: 0.1415 - val_loss: 0.0180 - val_mae: 0.1374\n",
            "\n",
            "Epoch 00429: loss did not improve from 0.01622\n",
            "Epoch 430/500\n",
            "30/30 [==============================] - 0s 14ms/step - loss: 0.0184 - mae: 0.1336 - val_loss: 0.0169 - val_mae: 0.1328\n",
            "\n",
            "Epoch 00430: loss did not improve from 0.01622\n",
            "Epoch 431/500\n",
            "30/30 [==============================] - 0s 14ms/step - loss: 0.0148 - mae: 0.1248 - val_loss: 0.0173 - val_mae: 0.1335\n",
            "\n",
            "Epoch 00431: loss did not improve from 0.01622\n",
            "Epoch 432/500\n",
            "30/30 [==============================] - 1s 14ms/step - loss: 0.0160 - mae: 0.1280 - val_loss: 0.0171 - val_mae: 0.1359\n",
            "\n",
            "Epoch 00432: loss did not improve from 0.01622\n",
            "Epoch 433/500\n",
            "30/30 [==============================] - 0s 14ms/step - loss: 0.0181 - mae: 0.1354 - val_loss: 0.0184 - val_mae: 0.1387\n",
            "\n",
            "Epoch 00433: loss did not improve from 0.01622\n",
            "Epoch 434/500\n",
            "30/30 [==============================] - 1s 14ms/step - loss: 0.0151 - mae: 0.1266 - val_loss: 0.0188 - val_mae: 0.1411\n",
            "\n",
            "Epoch 00434: loss did not improve from 0.01622\n",
            "Epoch 435/500\n",
            "30/30 [==============================] - 1s 14ms/step - loss: 0.0188 - mae: 0.1355 - val_loss: 0.0181 - val_mae: 0.1366\n",
            "\n",
            "Epoch 00435: loss did not improve from 0.01622\n",
            "Epoch 436/500\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.0153 - mae: 0.1264 - val_loss: 0.0184 - val_mae: 0.1390\n",
            "\n",
            "Epoch 00436: loss improved from 0.01622 to 0.01608, saving model to poids.hdf5\n",
            "Epoch 437/500\n",
            "30/30 [==============================] - 0s 14ms/step - loss: 0.0178 - mae: 0.1351 - val_loss: 0.0180 - val_mae: 0.1379\n",
            "\n",
            "Epoch 00437: loss did not improve from 0.01608\n",
            "Epoch 438/500\n",
            "30/30 [==============================] - 1s 14ms/step - loss: 0.0187 - mae: 0.1379 - val_loss: 0.0182 - val_mae: 0.1376\n",
            "\n",
            "Epoch 00438: loss did not improve from 0.01608\n",
            "Epoch 439/500\n",
            "30/30 [==============================] - 1s 14ms/step - loss: 0.0180 - mae: 0.1347 - val_loss: 0.0166 - val_mae: 0.1327\n",
            "\n",
            "Epoch 00439: loss did not improve from 0.01608\n",
            "Epoch 440/500\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.0153 - mae: 0.1261 - val_loss: 0.0174 - val_mae: 0.1380\n",
            "\n",
            "Epoch 00440: loss did not improve from 0.01608\n",
            "Epoch 441/500\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.0157 - mae: 0.1296 - val_loss: 0.0192 - val_mae: 0.1452\n",
            "\n",
            "Epoch 00441: loss did not improve from 0.01608\n",
            "Epoch 442/500\n",
            "30/30 [==============================] - 1s 14ms/step - loss: 0.0158 - mae: 0.1290 - val_loss: 0.0181 - val_mae: 0.1370\n",
            "\n",
            "Epoch 00442: loss did not improve from 0.01608\n",
            "Epoch 443/500\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.0157 - mae: 0.1316 - val_loss: 0.0172 - val_mae: 0.1310\n",
            "\n",
            "Epoch 00443: loss did not improve from 0.01608\n",
            "Epoch 444/500\n",
            "30/30 [==============================] - 1s 14ms/step - loss: 0.0195 - mae: 0.1437 - val_loss: 0.0178 - val_mae: 0.1354\n",
            "\n",
            "Epoch 00444: loss did not improve from 0.01608\n",
            "Epoch 445/500\n",
            "30/30 [==============================] - 1s 14ms/step - loss: 0.0186 - mae: 0.1345 - val_loss: 0.0171 - val_mae: 0.1339\n",
            "\n",
            "Epoch 00445: loss did not improve from 0.01608\n",
            "Epoch 446/500\n",
            "30/30 [==============================] - 1s 14ms/step - loss: 0.0197 - mae: 0.1401 - val_loss: 0.0179 - val_mae: 0.1355\n",
            "\n",
            "Epoch 00446: loss did not improve from 0.01608\n",
            "Epoch 447/500\n",
            "30/30 [==============================] - 0s 14ms/step - loss: 0.0179 - mae: 0.1348 - val_loss: 0.0183 - val_mae: 0.1375\n",
            "\n",
            "Epoch 00447: loss did not improve from 0.01608\n",
            "Epoch 448/500\n",
            "30/30 [==============================] - 1s 14ms/step - loss: 0.0174 - mae: 0.1351 - val_loss: 0.0180 - val_mae: 0.1365\n",
            "\n",
            "Epoch 00448: loss did not improve from 0.01608\n",
            "Epoch 449/500\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.0181 - mae: 0.1358 - val_loss: 0.0191 - val_mae: 0.1444\n",
            "\n",
            "Epoch 00449: loss did not improve from 0.01608\n",
            "Epoch 450/500\n",
            "30/30 [==============================] - 0s 14ms/step - loss: 0.0169 - mae: 0.1295 - val_loss: 0.0179 - val_mae: 0.1375\n",
            "\n",
            "Epoch 00450: loss did not improve from 0.01608\n",
            "Epoch 451/500\n",
            "30/30 [==============================] - 1s 14ms/step - loss: 0.0175 - mae: 0.1323 - val_loss: 0.0175 - val_mae: 0.1345\n",
            "\n",
            "Epoch 00451: loss did not improve from 0.01608\n",
            "Epoch 452/500\n",
            "30/30 [==============================] - 1s 14ms/step - loss: 0.0177 - mae: 0.1348 - val_loss: 0.0174 - val_mae: 0.1329\n",
            "\n",
            "Epoch 00452: loss did not improve from 0.01608\n",
            "Epoch 453/500\n",
            "30/30 [==============================] - 1s 14ms/step - loss: 0.0206 - mae: 0.1350 - val_loss: 0.0169 - val_mae: 0.1329\n",
            "\n",
            "Epoch 00453: loss did not improve from 0.01608\n",
            "Epoch 454/500\n",
            "30/30 [==============================] - 0s 14ms/step - loss: 0.0180 - mae: 0.1336 - val_loss: 0.0182 - val_mae: 0.1391\n",
            "\n",
            "Epoch 00454: loss did not improve from 0.01608\n",
            "Epoch 455/500\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.0186 - mae: 0.1365 - val_loss: 0.0175 - val_mae: 0.1332\n",
            "\n",
            "Epoch 00455: loss did not improve from 0.01608\n",
            "Epoch 456/500\n",
            "30/30 [==============================] - 0s 14ms/step - loss: 0.0170 - mae: 0.1339 - val_loss: 0.0178 - val_mae: 0.1354\n",
            "\n",
            "Epoch 00456: loss did not improve from 0.01608\n",
            "Epoch 457/500\n",
            "30/30 [==============================] - 0s 14ms/step - loss: 0.0171 - mae: 0.1354 - val_loss: 0.0175 - val_mae: 0.1337\n",
            "\n",
            "Epoch 00457: loss did not improve from 0.01608\n",
            "Epoch 458/500\n",
            "30/30 [==============================] - 0s 14ms/step - loss: 0.0172 - mae: 0.1310 - val_loss: 0.0182 - val_mae: 0.1380\n",
            "\n",
            "Epoch 00458: loss did not improve from 0.01608\n",
            "Epoch 459/500\n",
            "30/30 [==============================] - 1s 14ms/step - loss: 0.0164 - mae: 0.1316 - val_loss: 0.0187 - val_mae: 0.1412\n",
            "\n",
            "Epoch 00459: loss did not improve from 0.01608\n",
            "Epoch 460/500\n",
            "30/30 [==============================] - 1s 14ms/step - loss: 0.0150 - mae: 0.1270 - val_loss: 0.0164 - val_mae: 0.1342\n",
            "\n",
            "Epoch 00460: loss did not improve from 0.01608\n",
            "Epoch 461/500\n",
            "30/30 [==============================] - 1s 15ms/step - loss: 0.0170 - mae: 0.1311 - val_loss: 0.0177 - val_mae: 0.1353\n",
            "\n",
            "Epoch 00461: loss did not improve from 0.01608\n",
            "Epoch 462/500\n",
            "30/30 [==============================] - 1s 16ms/step - loss: 0.0169 - mae: 0.1353 - val_loss: 0.0183 - val_mae: 0.1388\n",
            "\n",
            "Epoch 00462: loss did not improve from 0.01608\n",
            "Epoch 463/500\n",
            "30/30 [==============================] - 1s 14ms/step - loss: 0.0159 - mae: 0.1283 - val_loss: 0.0179 - val_mae: 0.1360\n",
            "\n",
            "Epoch 00463: loss did not improve from 0.01608\n",
            "Epoch 464/500\n",
            "30/30 [==============================] - 1s 15ms/step - loss: 0.0176 - mae: 0.1355 - val_loss: 0.0174 - val_mae: 0.1327\n",
            "\n",
            "Epoch 00464: loss did not improve from 0.01608\n",
            "Epoch 465/500\n",
            "30/30 [==============================] - 1s 14ms/step - loss: 0.0189 - mae: 0.1384 - val_loss: 0.0177 - val_mae: 0.1374\n",
            "\n",
            "Epoch 00465: loss did not improve from 0.01608\n",
            "Epoch 466/500\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.0180 - mae: 0.1373 - val_loss: 0.0171 - val_mae: 0.1323\n",
            "\n",
            "Epoch 00466: loss did not improve from 0.01608\n",
            "Epoch 467/500\n",
            "30/30 [==============================] - 1s 15ms/step - loss: 0.0176 - mae: 0.1318 - val_loss: 0.0174 - val_mae: 0.1335\n",
            "\n",
            "Epoch 00467: loss did not improve from 0.01608\n",
            "Epoch 468/500\n",
            "30/30 [==============================] - 0s 14ms/step - loss: 0.0182 - mae: 0.1310 - val_loss: 0.0179 - val_mae: 0.1360\n",
            "\n",
            "Epoch 00468: loss did not improve from 0.01608\n",
            "Epoch 469/500\n",
            "30/30 [==============================] - 1s 15ms/step - loss: 0.0191 - mae: 0.1382 - val_loss: 0.0181 - val_mae: 0.1376\n",
            "\n",
            "Epoch 00469: loss did not improve from 0.01608\n",
            "Epoch 470/500\n",
            "30/30 [==============================] - 1s 15ms/step - loss: 0.0157 - mae: 0.1271 - val_loss: 0.0167 - val_mae: 0.1330\n",
            "\n",
            "Epoch 00470: loss did not improve from 0.01608\n",
            "Epoch 471/500\n",
            "30/30 [==============================] - 1s 14ms/step - loss: 0.0188 - mae: 0.1403 - val_loss: 0.0176 - val_mae: 0.1337\n",
            "\n",
            "Epoch 00471: loss did not improve from 0.01608\n",
            "Epoch 472/500\n",
            "30/30 [==============================] - 1s 14ms/step - loss: 0.0169 - mae: 0.1324 - val_loss: 0.0166 - val_mae: 0.1342\n",
            "\n",
            "Epoch 00472: loss did not improve from 0.01608\n",
            "Epoch 473/500\n",
            "30/30 [==============================] - 1s 14ms/step - loss: 0.0166 - mae: 0.1330 - val_loss: 0.0179 - val_mae: 0.1362\n",
            "\n",
            "Epoch 00473: loss did not improve from 0.01608\n",
            "Epoch 474/500\n",
            "30/30 [==============================] - 1s 14ms/step - loss: 0.0174 - mae: 0.1347 - val_loss: 0.0161 - val_mae: 0.1310\n",
            "\n",
            "Epoch 00474: loss did not improve from 0.01608\n",
            "Epoch 475/500\n",
            "30/30 [==============================] - 1s 14ms/step - loss: 0.0164 - mae: 0.1309 - val_loss: 0.0162 - val_mae: 0.1325\n",
            "\n",
            "Epoch 00475: loss did not improve from 0.01608\n",
            "Epoch 476/500\n",
            "30/30 [==============================] - 1s 14ms/step - loss: 0.0176 - mae: 0.1341 - val_loss: 0.0175 - val_mae: 0.1339\n",
            "\n",
            "Epoch 00476: loss did not improve from 0.01608\n",
            "Epoch 477/500\n",
            "30/30 [==============================] - 1s 14ms/step - loss: 0.0158 - mae: 0.1288 - val_loss: 0.0180 - val_mae: 0.1374\n",
            "\n",
            "Epoch 00477: loss did not improve from 0.01608\n",
            "Epoch 478/500\n",
            "30/30 [==============================] - 0s 14ms/step - loss: 0.0157 - mae: 0.1302 - val_loss: 0.0174 - val_mae: 0.1333\n",
            "\n",
            "Epoch 00478: loss did not improve from 0.01608\n",
            "Epoch 479/500\n",
            "30/30 [==============================] - 1s 14ms/step - loss: 0.0161 - mae: 0.1309 - val_loss: 0.0167 - val_mae: 0.1317\n",
            "\n",
            "Epoch 00479: loss did not improve from 0.01608\n",
            "Epoch 480/500\n",
            "30/30 [==============================] - 1s 14ms/step - loss: 0.0186 - mae: 0.1357 - val_loss: 0.0183 - val_mae: 0.1379\n",
            "\n",
            "Epoch 00480: loss did not improve from 0.01608\n",
            "Epoch 481/500\n",
            "30/30 [==============================] - 1s 14ms/step - loss: 0.0157 - mae: 0.1310 - val_loss: 0.0166 - val_mae: 0.1337\n",
            "\n",
            "Epoch 00481: loss did not improve from 0.01608\n",
            "Epoch 482/500\n",
            "30/30 [==============================] - 1s 14ms/step - loss: 0.0186 - mae: 0.1389 - val_loss: 0.0171 - val_mae: 0.1353\n",
            "\n",
            "Epoch 00482: loss did not improve from 0.01608\n",
            "Epoch 483/500\n",
            "30/30 [==============================] - 1s 15ms/step - loss: 0.0150 - mae: 0.1240 - val_loss: 0.0176 - val_mae: 0.1339\n",
            "\n",
            "Epoch 00483: loss did not improve from 0.01608\n",
            "Epoch 484/500\n",
            "30/30 [==============================] - 1s 14ms/step - loss: 0.0149 - mae: 0.1262 - val_loss: 0.0181 - val_mae: 0.1432\n",
            "\n",
            "Epoch 00484: loss did not improve from 0.01608\n",
            "Epoch 485/500\n",
            "30/30 [==============================] - 1s 14ms/step - loss: 0.0194 - mae: 0.1386 - val_loss: 0.0160 - val_mae: 0.1301\n",
            "\n",
            "Epoch 00485: loss did not improve from 0.01608\n",
            "Epoch 486/500\n",
            "30/30 [==============================] - 1s 14ms/step - loss: 0.0164 - mae: 0.1315 - val_loss: 0.0175 - val_mae: 0.1344\n",
            "\n",
            "Epoch 00486: loss did not improve from 0.01608\n",
            "Epoch 487/500\n",
            "30/30 [==============================] - 0s 14ms/step - loss: 0.0174 - mae: 0.1338 - val_loss: 0.0173 - val_mae: 0.1334\n",
            "\n",
            "Epoch 00487: loss did not improve from 0.01608\n",
            "Epoch 488/500\n",
            "30/30 [==============================] - 1s 14ms/step - loss: 0.0155 - mae: 0.1278 - val_loss: 0.0190 - val_mae: 0.1434\n",
            "\n",
            "Epoch 00488: loss did not improve from 0.01608\n",
            "Epoch 489/500\n",
            "30/30 [==============================] - 1s 14ms/step - loss: 0.0171 - mae: 0.1367 - val_loss: 0.0188 - val_mae: 0.1411\n",
            "\n",
            "Epoch 00489: loss did not improve from 0.01608\n",
            "Epoch 490/500\n",
            "30/30 [==============================] - 1s 15ms/step - loss: 0.0192 - mae: 0.1386 - val_loss: 0.0179 - val_mae: 0.1364\n",
            "\n",
            "Epoch 00490: loss did not improve from 0.01608\n",
            "Epoch 491/500\n",
            "30/30 [==============================] - 1s 14ms/step - loss: 0.0175 - mae: 0.1343 - val_loss: 0.0170 - val_mae: 0.1319\n",
            "\n",
            "Epoch 00491: loss did not improve from 0.01608\n",
            "Epoch 492/500\n",
            "30/30 [==============================] - 1s 14ms/step - loss: 0.0162 - mae: 0.1315 - val_loss: 0.0176 - val_mae: 0.1344\n",
            "\n",
            "Epoch 00492: loss did not improve from 0.01608\n",
            "Epoch 493/500\n",
            "30/30 [==============================] - 1s 15ms/step - loss: 0.0161 - mae: 0.1313 - val_loss: 0.0177 - val_mae: 0.1362\n",
            "\n",
            "Epoch 00493: loss did not improve from 0.01608\n",
            "Epoch 494/500\n",
            "30/30 [==============================] - 1s 14ms/step - loss: 0.0186 - mae: 0.1396 - val_loss: 0.0174 - val_mae: 0.1307\n",
            "\n",
            "Epoch 00494: loss did not improve from 0.01608\n",
            "Epoch 495/500\n",
            "30/30 [==============================] - 1s 14ms/step - loss: 0.0166 - mae: 0.1289 - val_loss: 0.0175 - val_mae: 0.1350\n",
            "\n",
            "Epoch 00495: loss did not improve from 0.01608\n",
            "Epoch 496/500\n",
            "30/30 [==============================] - 1s 15ms/step - loss: 0.0175 - mae: 0.1338 - val_loss: 0.0174 - val_mae: 0.1333\n",
            "\n",
            "Epoch 00496: loss did not improve from 0.01608\n",
            "Epoch 497/500\n",
            "30/30 [==============================] - 1s 14ms/step - loss: 0.0173 - mae: 0.1363 - val_loss: 0.0173 - val_mae: 0.1375\n",
            "\n",
            "Epoch 00497: loss did not improve from 0.01608\n",
            "Epoch 498/500\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.0194 - mae: 0.1366 - val_loss: 0.0173 - val_mae: 0.1311\n",
            "\n",
            "Epoch 00498: loss did not improve from 0.01608\n",
            "Epoch 499/500\n",
            "30/30 [==============================] - 1s 14ms/step - loss: 0.0171 - mae: 0.1361 - val_loss: 0.0175 - val_mae: 0.1338\n",
            "\n",
            "Epoch 00499: loss did not improve from 0.01608\n",
            "Epoch 500/500\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.0170 - mae: 0.1341 - val_loss: 0.0183 - val_mae: 0.1391\n",
            "\n",
            "Epoch 00500: loss did not improve from 0.01608\n",
            "[2.75411981000002, 0.449437898999804, 0.491880153000011, 0.48626680999996097, 0.45781011999997645, 0.45893632100001014, 0.4670951199998399, 0.4747209679999287, 0.49999841799990463, 0.485127668999894, 0.4557307180000407, 0.45693294099987725, 0.4861086849998628, 0.47921108100013043, 0.4676208719999977, 0.4465729780001766, 0.4668751040001098, 0.45408275699992373, 0.488997554999969, 0.4695683940001345, 0.477165838000019, 0.4893587019998904, 0.4725083379998978, 0.48654671100007363, 0.48245225899995603, 0.4756979470000715, 0.4765451660000508, 0.48426518699989174, 0.46114260600006673, 0.5028907349999372, 0.513203773999976, 0.49006083800009037, 0.5161047999999937, 0.5226131580000128, 0.48211121399981494, 0.49566161899997496, 0.47381143000006887, 0.47586846400008653, 0.48433165200003714, 0.5078695960000914, 0.4577700229999664, 0.4584930250000525, 0.5085712400000375, 0.45822454800008927, 0.4725376009998854, 0.44940503199995874, 0.48914663899995503, 0.46704265199991823, 0.4592797039999823, 0.4839825890001066, 0.49306846899980883, 0.4901730480000879, 0.5105930560000616, 0.5199608599998555, 0.4660590290000073, 0.4541397489999781, 0.4935888879999766, 0.44864184799985196, 0.48162647899994226, 0.5235123209999983, 0.48292934400001286, 0.48562153699981536, 0.48144791599997916, 0.46980599599987727, 0.46142890900000566, 0.48192893100008405, 0.4897878379999838, 0.5180241580001166, 0.47448454699997455, 0.482952245999968, 0.5046874289998868, 0.4587873559999025, 0.4881867270000839, 0.48021864000020287, 0.4777727189998586, 0.5205885620000572, 0.49055178499997965, 0.46738701300000685, 0.4508742180000809, 0.47437020200004554, 0.45878545000005033, 0.4849818249999771, 0.4524297929999648, 0.4963141789999099, 0.5038542080001207, 0.4989065859999755, 0.4589610860000448, 0.4604782100000193, 0.4531164620000254, 0.4979914190000727, 0.4818083640000168, 0.4832965780001359, 0.4717847859999438, 0.4861939729998994, 0.5048158239999339, 0.5247280660000797, 0.4931624539999575, 0.5124256450001212, 0.4798781740000777, 0.4973419630000535, 0.48048228800007564, 0.5129645019999316, 0.4958854670001074, 0.5287960830000884, 0.5064125619999231, 0.5001414150001438, 0.49994541799992476, 0.5014108789998772, 0.5067862669998249, 0.5755431219999991, 0.5006340339998587, 0.4994793529999697, 0.5036591389998648, 0.5008081370001491, 0.5245458740000686, 0.5081888790000448, 0.5178960200000802, 0.5124747059999208, 0.4972102790000008, 0.5174665550000555, 0.5102064870000049, 0.4726158870000745, 0.4819532580002033, 0.49214541299988923, 0.4892803879999974, 0.4766168870000911, 0.5018971050001255, 0.4576600289999533, 0.48801428199999464, 0.4865783319999082, 0.49793252699987534, 0.4607183860000532, 0.4997673510001732, 0.48114280300001155, 0.46915335800008506, 0.47848354200004906, 0.4808574639998824, 0.48532761199999186, 0.4813657070001227, 0.4527872959999968, 0.4948318350000136, 0.4893618810001499, 0.4792379699999856, 0.456745877000003, 0.4754646189999221, 0.4842032599999584, 0.4924318610001137, 0.4702313350001077, 0.5022126740000203, 0.48707241900001463, 0.5468168110000988, 0.5110494199998357, 0.5045167719999881, 0.46541115699983493, 0.4869913150000684, 0.5250554309998279, 0.4727181700000074, 0.5195181579999826, 0.49707882199982123, 0.5185738699999547, 0.49588589299992236, 0.5152402369999436, 0.5121257360001437, 0.5158925409998574, 0.5063129919999483, 0.49431716599997344, 0.47930142099994555, 0.49122030500006986, 0.4853794910000033, 0.4752097479999975, 0.48910571700002947, 0.483365909999975, 0.4870196379999925, 0.5587014869997802, 0.4797525599999517, 0.534720200000038, 0.4877076830000533, 0.4979996669999309, 0.49327786100002413, 0.4695781430000352, 0.4945843049999894, 0.4833816630000456, 0.4921739940000407, 0.5065962339999714, 0.4885383030000412, 0.5171141109999553, 0.472618053999895, 0.47484469799996987, 0.4844160610000472, 0.48910998899987135, 0.48261326099986945, 0.48541699900010826, 0.45900813399998697, 0.5033962519999022, 0.47077913999987686, 0.5145160879999366, 0.48390310900003897, 0.4840229320000162, 0.5134547909999583, 0.482688392, 0.49944563500002914, 0.5175856710000062, 0.4781492889999299, 0.5049579870001253, 0.48725937199992586, 0.5075988720000169, 0.4944956460001322, 0.4899099010001464, 0.49487372800012963, 0.503716501000099, 0.5141486469999563, 0.5067368879999776, 0.518606544000022, 0.5000120610000067, 0.5235618550000254, 0.5467551060000915, 0.516920847999927, 0.5251522490000298, 0.5131643460001669, 0.4928929979998884, 0.5303460109998923, 0.5193950160000895, 0.5106330260000504, 0.5176428860002034, 0.5244367370000873, 0.5103033190000588, 0.5262534210000922, 0.5111799830001473, 0.5123685159999241, 0.5441309899999851, 0.4824217860000317, 0.5142806320000091, 0.4881080360000851, 0.5069608250000783, 0.4856440040000507, 0.5479126540001289, 0.46754602200007866, 0.47780680799996844, 0.4796660100000736, 0.4887535430000298, 0.48935167499985255, 0.48355098000001817, 0.48066861500001323, 0.498649382999929, 0.4918731350001053, 0.5304445100000521, 0.49174069499986217, 0.5130049670001426, 0.5212842490000185, 0.47483185400005823, 0.4885453360000156, 0.5087909549999949, 0.48552239400009967, 0.5193655329999274, 0.49404701899993597, 0.4960151920001863, 0.5267233170000054, 0.49575125299998035, 0.5107858159999523, 0.46381334900002, 0.4868407640001351, 0.49298442300005263, 0.49330868499987446, 0.5117705619998105, 0.49158749599996554, 0.5130451659999835, 0.5061868369998592, 0.5060299790000045, 0.4961623060000875, 0.49061972899994544, 0.5110317979999763, 0.4899732380001751, 0.5138232750000498, 0.48315187999992304, 0.519141874999832, 0.49441321900008006, 0.49618193199989946, 0.5040492059999906, 0.491299508000111, 0.4828771360000701, 0.5110892889999832, 0.46823494699992807, 0.48888972800000374, 0.49746723200019005, 0.49176837400000295, 0.4826040020000164, 0.49667879300000095, 0.501803701999961, 0.47843578799984243, 0.48825623299990184, 0.4979763799999546, 0.48933043600004567, 0.4826347779999196, 0.5049044630000026, 0.48135195800000474, 0.48146007900004406, 0.5113956950001466, 0.5578493259999959, 0.5732730719998926, 0.5180007180001667, 0.5184897999999976, 0.4980992910000168, 0.5254827040000691, 0.5218541079998431, 0.4997409960001278, 0.5086404210001092, 0.5099886020000213, 0.4917727259999083, 0.511606688000029, 0.5216167849998783, 0.5224910459999137, 0.5036535890001232, 0.5008537440000964, 0.5160783999999694, 0.5106760719997965, 0.5232696420000593, 0.5364314039998135, 0.5165282339999067, 0.5236903369998345, 0.5180339099999856, 0.545278862000032, 0.5085013870000239, 0.4897487490000003, 0.5069262629999685, 0.49222269300003063, 0.49942800500002704, 0.5045499240000026, 0.5004870669999946, 0.4871003880000444, 0.48250490200007334, 0.5188188309998623, 0.5274234259998138, 0.48887164399980065, 0.48125280399995063, 0.5016224459998284, 0.49405565600000045, 0.5458631689998583, 0.48741676700001335, 0.4988602759999594, 0.5308423980000043, 0.5206574320000072, 0.4917832080000153, 0.5145389429999341, 0.527393315999916, 0.5058833229998072, 0.49716934000002766, 0.4989571440000873, 0.5498399660000359, 0.49263587399991593, 0.489408080999965, 0.5287923550001778, 0.48537265599998136, 0.5156875249999757, 0.5150645950000126, 0.5404488179999589, 0.5157196579998526, 0.5024538279999433, 0.5073922259998653, 0.5141212270000324, 0.5119078449999961, 0.5417866669999967, 0.529619847000049, 0.5138429319999887, 0.5108847679998689, 0.504874878999999, 0.5009700240000257, 0.5060834820001219, 0.5187554340000133, 0.5022348679999595, 0.5504551199999241, 0.49805752200018105, 0.5366832480001449, 0.4943367670000498, 0.519617541000116, 0.5112425770000755, 0.5389112159998604, 0.5466758590000609, 0.5446740350000709, 0.5053440330000285, 0.5195561959999395, 0.5346078120001039, 0.5009601079998447, 0.5439166419998855, 0.4983785560000342, 0.51659537799992, 0.5103546780001125, 0.5217409770000359, 0.5244682920001651, 0.4933897789999264, 0.4808734099999583, 0.5152477479998652, 0.5140873880000072, 0.5461200029999418, 0.5081258889999845, 0.5025686999999834, 0.5595306479999635, 0.5118486280000525, 0.5036016849999214, 0.4922477959999014, 0.48237813000014285, 0.4866123389999757, 0.5193656939998164, 0.4779654760000085, 0.49706618699997307, 0.48301250500003334, 0.5117872849998548, 0.4757114129999991, 0.5071608480000123, 0.5188436700000238, 0.5002334969999538, 0.49992979900002865, 0.492692057000113, 0.5061660710000524, 0.5011034530000416, 0.4859645770000043, 0.4952479639998728, 0.5071829149999303, 0.508925298000122, 0.4906031289999646, 0.48423084800015204, 0.5171377049998682, 0.509022171999959, 0.48320018799995523, 0.5052003579999109, 0.5094996060001904, 0.47907385300004535, 0.5109346989997903, 0.5056131300000288, 0.49808177800014164, 0.49421798299999864, 0.4921631189999971, 0.5105036530001144, 0.4979241799999272, 0.509495791000063, 0.5131643090001035, 0.49892891600006806, 0.4942130780000298, 0.5105293069998424, 0.5160346360000858, 0.4713199599998461, 0.49964470800000527, 0.5150773069999559, 0.4908944969999993, 0.5273019510000267, 0.5124142439999559, 0.5079554369999641, 0.4951703470001121, 0.5209129430002122, 0.47617990499998086, 0.49587252900005296, 0.5131557429999702, 0.5327226970000538, 0.5067652609998277, 0.4868249660000856, 0.48847815899989655, 0.49119045599991296, 0.49346033100005116, 0.49849868999990576, 0.5038254290000168, 0.5154618310000387, 0.5255338720000964, 0.5548954840000988, 0.5227835959999538, 0.554193074000068, 0.5301170110001294, 0.49852918500005217, 0.5330098890001409, 0.4961809930000527, 0.5323156780000318, 0.5301655960001881, 0.5030661379998946, 0.5353571050000028, 0.5235334249998687, 0.5129970370001047, 0.5191254589999517, 0.506568346999984, 0.5219826869999906, 0.4994686960001218, 0.5090876440001466, 0.5254344340000898, 0.5084079539999493, 0.5170706000001246, 0.5418777659999705, 0.5178876429999946, 0.5343353749999551, 0.5036885399999846, 0.5018398049999178, 0.5368340500001523, 0.5212423220000346, 0.5498442860000523, 0.5277492559998791, 0.5058717160000015, 0.5287764400000015, 0.5063466389999576, 0.5131527319999805, 0.5329306199998882, 0.505362378999962, 0.48079434500004936, 0.541520988000002, 0.49197175500012236]\n",
            "252.17201279999972\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "COP9u4yitvmw",
        "outputId": "ad356f27-9281-4c01-c256-89de8dd9eaed",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        }
      },
      "source": [
        "erreur_entrainement = historique.history[\"loss\"]\n",
        "erreur_validation = historique.history[\"val_loss\"]\n",
        "\n",
        "# Affiche l'erreur en fonction de la période\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(np.arange(0,len(erreur_entrainement)),erreur_entrainement, label=\"Erreurs sur les entrainements\")\n",
        "plt.plot(np.arange(0,len(erreur_entrainement)),erreur_validation, label =\"Erreurs sur les validations\")\n",
        "plt.legend()\n",
        "\n",
        "plt.title(\"Evolution de l'erreur en fonction de la période\")"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, \"Evolution de l'erreur en fonction de la période\")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_o2zh6N9t1b7",
        "outputId": "d0334fb1-662b-4a72-f61e-a4fb05b2f883",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        }
      },
      "source": [
        "erreur_entrainement = historique.history[\"loss\"]\n",
        "erreur_validation = historique.history[\"val_loss\"]\n",
        "\n",
        "# Affiche l'erreur en fonction de la période\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(np.arange(0,len(erreur_entrainement[400:500])),erreur_entrainement[400:500], label=\"Erreurs sur les entrainements\")\n",
        "plt.plot(np.arange(0,len(erreur_entrainement[400:500])),erreur_validation[400:500], label =\"Erreurs sur les validations\")\n",
        "plt.legend()\n",
        "\n",
        "plt.title(\"Evolution de l'erreur en fonction de la période\")"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, \"Evolution de l'erreur en fonction de la période\")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T6Gq2CkeGR_1"
      },
      "source": [
        "**4. Prédictions**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HRxXtHRXGXfF",
        "outputId": "cd759dc8-122a-460d-969c-127fb2c9304b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 433
        }
      },
      "source": [
        "taille_fenetre = 20\n",
        "\n",
        "# Création d'une liste vide pour recevoir les prédictions\n",
        "predictions = []\n",
        "\n",
        "# Calcul des prédiction pour chaque groupe de 20 valeurs consécutives de la série\n",
        "# dans l'intervalle de validation\n",
        "for t in temps[temps_separation:-taille_fenetre]:\n",
        "    X = np.reshape(Serie_Normalisee[t:t+taille_fenetre],(1,taille_fenetre))\n",
        "    predictions.append(model.predict(X))"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "error",
          "ename": "InvalidArgumentError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-49eacaf45e13>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtemps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtemps_separation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mtaille_fenetre\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSerie_Normalisee\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mtaille_fenetre\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtaille_fenetre\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mpredictions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1627\u001b[0m           \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1628\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_predict_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1629\u001b[0;31m             \u001b[0mtmp_batch_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1630\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1631\u001b[0m               \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    893\u001b[0m       \u001b[0;31m# If we did not create any variables the trace we have is good enough.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m       return self._concrete_stateful_fn._call_flat(\n\u001b[0;32m--> 895\u001b[0;31m           filtered_flat_args, self._concrete_stateful_fn.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    896\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfn_with_cond\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minner_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minner_kwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minner_filtered_flat_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1917\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1918\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1919\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1921\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    558\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    561\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mInvalidArgumentError\u001b[0m:    Specified a list with shape [32,1] from a tensor with shape [1,1]\n\t [[{{node TensorArrayUnstack/TensorListFromTensor}}]]\n\t [[sequential_6/gru_2/PartitionedCall]] [Op:__inference_predict_function_137059]\n\nFunction call stack:\npredict_function -> predict_function -> predict_function\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wd2nfDcgG8EO"
      },
      "source": [
        "# Affiche la série et les prédictions\n",
        "plt.figure(figsize=(10, 6))\n",
        "affiche_serie(temps,serie,label=\"Série temporelle\")\n",
        "affiche_serie(temps[temps_separation+taille_fenetre:],np.asarray(predictions*std+mean)[:,0,0],label=\"Prédictions\")\n",
        "plt.title('Prédictions avec le modèle GRU + Attention')\n",
        "plt.show()\n",
        "\n",
        "# Zoom sur l'intervalle de validation\n",
        "plt.figure(figsize=(10, 6))\n",
        "affiche_serie(temps[temps_separation:],serie[temps_separation:],label=\"Série temporelle\")\n",
        "affiche_serie(temps[temps_separation+taille_fenetre:],np.asarray(predictions*std+mean)[:,0,0],label=\"Prédictions\")\n",
        "plt.title(\"Prédictions avec le modèle GRU + Attention (zoom sur l'intervalle de validation)\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PDS7BJvZG_e1"
      },
      "source": [
        "# Calcule de l'erreur quadratique moyenne et de l'erreur absolue moyenne \n",
        "\n",
        "mae = tf.keras.metrics.mean_absolute_error(serie[temps_separation+taille_fenetre:],np.asarray(predictions*std+mean)[:,0,0]).numpy()\n",
        "mse = tf.keras.metrics.mean_squared_error(serie[temps_separation+taille_fenetre:],np.asarray(predictions*std+mean)[:,0,0]).numpy()\n",
        "\n",
        "print(mae)\n",
        "print(mse)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}