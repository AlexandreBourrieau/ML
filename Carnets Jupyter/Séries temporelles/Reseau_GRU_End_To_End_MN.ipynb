{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Reseau_GRU_End_to_End_MN.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPxl5Bdqr/DDFl2wox0dajj",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AlexandreBourrieau/ML/blob/main/Carnets%20Jupyter/S%C3%A9ries%20temporelles/Reseau_GRU_End_To_End_MN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ubCeIvtF6R4W"
      },
      "source": [
        "Dans ce carnet nous allons mettre en place un modèle à réseau de neurones récurrent de type GRU associé à une couche d'attention pour réaliser des prédictions sur notre série temporelle."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RRhtHsNn5fc3"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XFeah3y_6kif"
      },
      "source": [
        "# Création de la série temporelle et du dataset pour l'entrainement"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vJfSLtub6sdc"
      },
      "source": [
        "# Fonction permettant d'afficher une série temporelle\n",
        "def affiche_serie(temps, serie, format=\"-\", debut=0, fin=None, label=None):\n",
        "    plt.plot(temps[debut:fin], serie[debut:fin], format, label=label)\n",
        "    plt.xlabel(\"Temps\")\n",
        "    plt.ylabel(\"Valeur\")\n",
        "    if label:\n",
        "        plt.legend(fontsize=14)\n",
        "    plt.grid(True)\n",
        "\n",
        "# Fonction permettant de créer une tendance\n",
        "def tendance(temps, pente=0):\n",
        "    return pente * temps\n",
        "\n",
        "# Fonction permettant de créer un motif\n",
        "def motif_periodique(instants):\n",
        "    return (np.where(instants < 0.4,                            # Si les instants sont < 0.4\n",
        "                    np.cos(instants * 2 * np.pi),               # Alors on retourne la fonction cos(2*pi*t)\n",
        "                    1 / np.exp(3 * instants)))                  # Sinon, on retourne la fonction exp(-3t)\n",
        "\n",
        "# Fonction permettant de créer une saisonnalité avec un motif\n",
        "def saisonnalite(temps, periode, amplitude=1, phase=0):\n",
        "    \"\"\"Répétition du motif sur la même période\"\"\"\n",
        "    instants = ((temps + phase) % periode) / periode            # Mapping du temps =[0 1 2 ... 1460] => instants = [0.0 ... 1.0]\n",
        "    return amplitude * motif_periodique(instants)\n",
        "\n",
        "# Fonction permettant de générer du bruit gaussien N(0,1)\n",
        "def bruit_blanc(temps, niveau_bruit=1, graine=None):\n",
        "    rnd = np.random.RandomState(graine)\n",
        "    return rnd.randn(len(temps)) * niveau_bruit\n",
        "\n",
        "# Fonction permettant de créer un dataset à partir des données de la série temporelle\n",
        "# au format X(X1,X2,...Xn) / Y(Y1,Y2,...,Yn)\n",
        "# X sont les données d'entrées du réseau\n",
        "# Y sont les labels\n",
        "\n",
        "def data_map(x,y):\n",
        "  x1 = []\n",
        "  x2 = []\n",
        "  ys = []\n",
        "  for i in range(0,batch_size):\n",
        "    x1.append(x)\n",
        "    x2.append(x[i][:])\n",
        "    ys.append(y[i][:])\n",
        "  return [(x1,x2),ys]\n",
        "\n",
        "def prepare_dataset_XY(serie, taille_fenetre, batch_size, buffer_melange):\n",
        "  dataset = tf.data.Dataset.from_tensor_slices(serie)\n",
        "  dataset = dataset.window(taille_fenetre+1, shift=1, drop_remainder=True)\n",
        "  dataset = dataset.flat_map(lambda x: x.batch(taille_fenetre + 1))\n",
        "#  dataset = dataset.shuffle(buffer_melange)\n",
        "  dataset = dataset.map(lambda x: (x[:-1], x[-1:]))\n",
        "  dataset = dataset.batch(batch_size,drop_remainder=True).prefetch(1)\n",
        "  dataset = dataset.map(data_map)\n",
        "  return dataset\n",
        "\n",
        "\n",
        "# Création de la série temporelle\n",
        "temps = np.arange(4 * 365)                # temps = [0 1 2 .... 4*365] = [0 1 2 .... 1460]\n",
        "amplitude = 40                            # Amplitude de la la saisonnalité\n",
        "niveau_bruit = 5                          # Niveau du bruit\n",
        "offset = 10                               # Offset de la série\n",
        "\n",
        "serie = offset + tendance(temps, 0.1) + saisonnalite(temps, periode=365, amplitude=amplitude) + bruit_blanc(temps,niveau_bruit,graine=40)\n",
        "\n",
        "temps_separation = 1000\n",
        "\n",
        "# Extraction des temps et des données d'entrainement\n",
        "temps_entrainement = temps[:temps_separation]\n",
        "x_entrainement = serie[:temps_separation]\n",
        "\n",
        "# Exctraction des temps et des données de valiadation\n",
        "temps_validation = temps[temps_separation:]\n",
        "x_validation = serie[temps_separation:]\n",
        "\n",
        "# Définition des caractéristiques du dataset que l'on souhaite créer\n",
        "taille_fenetre = 20\n",
        "batch_size = 32\n",
        "buffer_melange = 1000\n",
        "\n",
        "# Création du dataset X,Y\n",
        "dataset = prepare_dataset_XY(x_entrainement,taille_fenetre,batch_size,buffer_melange)\n",
        "\n",
        "# Création du dataset X,Y de validation\n",
        "dataset_Val = prepare_dataset_XY(x_validation,taille_fenetre,batch_size,buffer_melange)"
      ],
      "execution_count": 128,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OyndQsxw0wue",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dfaa5438-7e07-4410-9341-a72bf7a7807d"
      },
      "source": [
        "# Calcul de la moyenne et de l'écart type de la série\n",
        "mean = tf.math.reduce_mean(serie)\n",
        "std = tf.math.reduce_std(serie)\n",
        "print(mean.numpy())\n",
        "print(std.numpy())\n",
        "\n",
        "# Normalise les données\n",
        "Serie_Normalisee = (serie-mean)/std\n",
        "min = tf.math.reduce_min(serie)\n",
        "max = tf.math.reduce_max(serie)\n",
        "print(tf.math.reduce_mean(Serie_Normalisee).numpy())\n",
        "print(tf.math.reduce_std(Serie_Normalisee).numpy())\n",
        "\n",
        "# Création des données pour l'entrainement et le test\n",
        "x_entrainement_norm = Serie_Normalisee[:temps_separation]\n",
        "x_validation_norm = Serie_Normalisee[temps_separation:]\n",
        "\n",
        "# Création du dataset X,Y\n",
        "dataset_norm = prepare_dataset_XY(x_entrainement_norm,taille_fenetre,batch_size,buffer_melange)\n",
        "\n",
        "# Création du dataset X,Y de validation\n",
        "dataset_Val_norm = prepare_dataset_XY(x_validation_norm,taille_fenetre,batch_size,buffer_melange)"
      ],
      "execution_count": 129,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "90.49378905192393\n",
            "43.81927756886552\n",
            "2.6736603798507197e-16\n",
            "1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tRxcpFY-wpxJ",
        "outputId": "39b74514-6be5-4f17-dddd-fe2b45f90132",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "for element in dataset_norm.take(1):\n",
        "  print(element)"
      ],
      "execution_count": 130,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "((<tf.Tensor: shape=(32, 32, 20), dtype=float64, numpy=\n",
            "array([[[-0.99343325, -0.93635495, -0.99820278, ..., -0.86781814,\n",
            "         -0.9492108 , -1.07462285],\n",
            "        [-0.93635495, -0.99820278, -0.81250866, ..., -0.9492108 ,\n",
            "         -1.07462285, -0.89854575],\n",
            "        [-0.99820278, -0.81250866, -1.12759919, ..., -1.07462285,\n",
            "         -0.89854575, -0.92275185],\n",
            "        ...,\n",
            "        [-0.81284639, -0.971528  , -1.01684347, ..., -1.08965153,\n",
            "         -1.02651943, -1.12913165],\n",
            "        [-0.971528  , -1.01684347, -1.08266368, ..., -1.02651943,\n",
            "         -1.12913165, -1.03877078],\n",
            "        [-1.01684347, -1.08266368, -1.04162539, ..., -1.12913165,\n",
            "         -1.03877078, -1.26340409]],\n",
            "\n",
            "       [[-0.99343325, -0.93635495, -0.99820278, ..., -0.86781814,\n",
            "         -0.9492108 , -1.07462285],\n",
            "        [-0.93635495, -0.99820278, -0.81250866, ..., -0.9492108 ,\n",
            "         -1.07462285, -0.89854575],\n",
            "        [-0.99820278, -0.81250866, -1.12759919, ..., -1.07462285,\n",
            "         -0.89854575, -0.92275185],\n",
            "        ...,\n",
            "        [-0.81284639, -0.971528  , -1.01684347, ..., -1.08965153,\n",
            "         -1.02651943, -1.12913165],\n",
            "        [-0.971528  , -1.01684347, -1.08266368, ..., -1.02651943,\n",
            "         -1.12913165, -1.03877078],\n",
            "        [-1.01684347, -1.08266368, -1.04162539, ..., -1.12913165,\n",
            "         -1.03877078, -1.26340409]],\n",
            "\n",
            "       [[-0.99343325, -0.93635495, -0.99820278, ..., -0.86781814,\n",
            "         -0.9492108 , -1.07462285],\n",
            "        [-0.93635495, -0.99820278, -0.81250866, ..., -0.9492108 ,\n",
            "         -1.07462285, -0.89854575],\n",
            "        [-0.99820278, -0.81250866, -1.12759919, ..., -1.07462285,\n",
            "         -0.89854575, -0.92275185],\n",
            "        ...,\n",
            "        [-0.81284639, -0.971528  , -1.01684347, ..., -1.08965153,\n",
            "         -1.02651943, -1.12913165],\n",
            "        [-0.971528  , -1.01684347, -1.08266368, ..., -1.02651943,\n",
            "         -1.12913165, -1.03877078],\n",
            "        [-1.01684347, -1.08266368, -1.04162539, ..., -1.12913165,\n",
            "         -1.03877078, -1.26340409]],\n",
            "\n",
            "       ...,\n",
            "\n",
            "       [[-0.99343325, -0.93635495, -0.99820278, ..., -0.86781814,\n",
            "         -0.9492108 , -1.07462285],\n",
            "        [-0.93635495, -0.99820278, -0.81250866, ..., -0.9492108 ,\n",
            "         -1.07462285, -0.89854575],\n",
            "        [-0.99820278, -0.81250866, -1.12759919, ..., -1.07462285,\n",
            "         -0.89854575, -0.92275185],\n",
            "        ...,\n",
            "        [-0.81284639, -0.971528  , -1.01684347, ..., -1.08965153,\n",
            "         -1.02651943, -1.12913165],\n",
            "        [-0.971528  , -1.01684347, -1.08266368, ..., -1.02651943,\n",
            "         -1.12913165, -1.03877078],\n",
            "        [-1.01684347, -1.08266368, -1.04162539, ..., -1.12913165,\n",
            "         -1.03877078, -1.26340409]],\n",
            "\n",
            "       [[-0.99343325, -0.93635495, -0.99820278, ..., -0.86781814,\n",
            "         -0.9492108 , -1.07462285],\n",
            "        [-0.93635495, -0.99820278, -0.81250866, ..., -0.9492108 ,\n",
            "         -1.07462285, -0.89854575],\n",
            "        [-0.99820278, -0.81250866, -1.12759919, ..., -1.07462285,\n",
            "         -0.89854575, -0.92275185],\n",
            "        ...,\n",
            "        [-0.81284639, -0.971528  , -1.01684347, ..., -1.08965153,\n",
            "         -1.02651943, -1.12913165],\n",
            "        [-0.971528  , -1.01684347, -1.08266368, ..., -1.02651943,\n",
            "         -1.12913165, -1.03877078],\n",
            "        [-1.01684347, -1.08266368, -1.04162539, ..., -1.12913165,\n",
            "         -1.03877078, -1.26340409]],\n",
            "\n",
            "       [[-0.99343325, -0.93635495, -0.99820278, ..., -0.86781814,\n",
            "         -0.9492108 , -1.07462285],\n",
            "        [-0.93635495, -0.99820278, -0.81250866, ..., -0.9492108 ,\n",
            "         -1.07462285, -0.89854575],\n",
            "        [-0.99820278, -0.81250866, -1.12759919, ..., -1.07462285,\n",
            "         -0.89854575, -0.92275185],\n",
            "        ...,\n",
            "        [-0.81284639, -0.971528  , -1.01684347, ..., -1.08965153,\n",
            "         -1.02651943, -1.12913165],\n",
            "        [-0.971528  , -1.01684347, -1.08266368, ..., -1.02651943,\n",
            "         -1.12913165, -1.03877078],\n",
            "        [-1.01684347, -1.08266368, -1.04162539, ..., -1.12913165,\n",
            "         -1.03877078, -1.26340409]]])>, <tf.Tensor: shape=(32, 20), dtype=float64, numpy=\n",
            "array([[-0.99343325, -0.93635495, -0.99820278, -0.81250866, -1.12759919,\n",
            "        -0.969365  , -0.65369641, -0.85897787, -0.83344952, -0.7940617 ,\n",
            "        -0.90860967, -0.88588858, -0.84900481, -0.81619298, -1.03458625,\n",
            "        -0.93539519, -0.97200036, -0.86781814, -0.9492108 , -1.07462285],\n",
            "       [-0.93635495, -0.99820278, -0.81250866, -1.12759919, -0.969365  ,\n",
            "        -0.65369641, -0.85897787, -0.83344952, -0.7940617 , -0.90860967,\n",
            "        -0.88588858, -0.84900481, -0.81619298, -1.03458625, -0.93539519,\n",
            "        -0.97200036, -0.86781814, -0.9492108 , -1.07462285, -0.89854575],\n",
            "       [-0.99820278, -0.81250866, -1.12759919, -0.969365  , -0.65369641,\n",
            "        -0.85897787, -0.83344952, -0.7940617 , -0.90860967, -0.88588858,\n",
            "        -0.84900481, -0.81619298, -1.03458625, -0.93539519, -0.97200036,\n",
            "        -0.86781814, -0.9492108 , -1.07462285, -0.89854575, -0.92275185],\n",
            "       [-0.81250866, -1.12759919, -0.969365  , -0.65369641, -0.85897787,\n",
            "        -0.83344952, -0.7940617 , -0.90860967, -0.88588858, -0.84900481,\n",
            "        -0.81619298, -1.03458625, -0.93539519, -0.97200036, -0.86781814,\n",
            "        -0.9492108 , -1.07462285, -0.89854575, -0.92275185, -0.93496518],\n",
            "       [-1.12759919, -0.969365  , -0.65369641, -0.85897787, -0.83344952,\n",
            "        -0.7940617 , -0.90860967, -0.88588858, -0.84900481, -0.81619298,\n",
            "        -1.03458625, -0.93539519, -0.97200036, -0.86781814, -0.9492108 ,\n",
            "        -1.07462285, -0.89854575, -0.92275185, -0.93496518, -0.79702382],\n",
            "       [-0.969365  , -0.65369641, -0.85897787, -0.83344952, -0.7940617 ,\n",
            "        -0.90860967, -0.88588858, -0.84900481, -0.81619298, -1.03458625,\n",
            "        -0.93539519, -0.97200036, -0.86781814, -0.9492108 , -1.07462285,\n",
            "        -0.89854575, -0.92275185, -0.93496518, -0.79702382, -0.82388346],\n",
            "       [-0.65369641, -0.85897787, -0.83344952, -0.7940617 , -0.90860967,\n",
            "        -0.88588858, -0.84900481, -0.81619298, -1.03458625, -0.93539519,\n",
            "        -0.97200036, -0.86781814, -0.9492108 , -1.07462285, -0.89854575,\n",
            "        -0.92275185, -0.93496518, -0.79702382, -0.82388346, -0.90284449],\n",
            "       [-0.85897787, -0.83344952, -0.7940617 , -0.90860967, -0.88588858,\n",
            "        -0.84900481, -0.81619298, -1.03458625, -0.93539519, -0.97200036,\n",
            "        -0.86781814, -0.9492108 , -1.07462285, -0.89854575, -0.92275185,\n",
            "        -0.93496518, -0.79702382, -0.82388346, -0.90284449, -0.77774732],\n",
            "       [-0.83344952, -0.7940617 , -0.90860967, -0.88588858, -0.84900481,\n",
            "        -0.81619298, -1.03458625, -0.93539519, -0.97200036, -0.86781814,\n",
            "        -0.9492108 , -1.07462285, -0.89854575, -0.92275185, -0.93496518,\n",
            "        -0.79702382, -0.82388346, -0.90284449, -0.77774732, -0.99485756],\n",
            "       [-0.7940617 , -0.90860967, -0.88588858, -0.84900481, -0.81619298,\n",
            "        -1.03458625, -0.93539519, -0.97200036, -0.86781814, -0.9492108 ,\n",
            "        -1.07462285, -0.89854575, -0.92275185, -0.93496518, -0.79702382,\n",
            "        -0.82388346, -0.90284449, -0.77774732, -0.99485756, -1.12158772],\n",
            "       [-0.90860967, -0.88588858, -0.84900481, -0.81619298, -1.03458625,\n",
            "        -0.93539519, -0.97200036, -0.86781814, -0.9492108 , -1.07462285,\n",
            "        -0.89854575, -0.92275185, -0.93496518, -0.79702382, -0.82388346,\n",
            "        -0.90284449, -0.77774732, -0.99485756, -1.12158772, -0.81284639],\n",
            "       [-0.88588858, -0.84900481, -0.81619298, -1.03458625, -0.93539519,\n",
            "        -0.97200036, -0.86781814, -0.9492108 , -1.07462285, -0.89854575,\n",
            "        -0.92275185, -0.93496518, -0.79702382, -0.82388346, -0.90284449,\n",
            "        -0.77774732, -0.99485756, -1.12158772, -0.81284639, -0.971528  ],\n",
            "       [-0.84900481, -0.81619298, -1.03458625, -0.93539519, -0.97200036,\n",
            "        -0.86781814, -0.9492108 , -1.07462285, -0.89854575, -0.92275185,\n",
            "        -0.93496518, -0.79702382, -0.82388346, -0.90284449, -0.77774732,\n",
            "        -0.99485756, -1.12158772, -0.81284639, -0.971528  , -1.01684347],\n",
            "       [-0.81619298, -1.03458625, -0.93539519, -0.97200036, -0.86781814,\n",
            "        -0.9492108 , -1.07462285, -0.89854575, -0.92275185, -0.93496518,\n",
            "        -0.79702382, -0.82388346, -0.90284449, -0.77774732, -0.99485756,\n",
            "        -1.12158772, -0.81284639, -0.971528  , -1.01684347, -1.08266368],\n",
            "       [-1.03458625, -0.93539519, -0.97200036, -0.86781814, -0.9492108 ,\n",
            "        -1.07462285, -0.89854575, -0.92275185, -0.93496518, -0.79702382,\n",
            "        -0.82388346, -0.90284449, -0.77774732, -0.99485756, -1.12158772,\n",
            "        -0.81284639, -0.971528  , -1.01684347, -1.08266368, -1.04162539],\n",
            "       [-0.93539519, -0.97200036, -0.86781814, -0.9492108 , -1.07462285,\n",
            "        -0.89854575, -0.92275185, -0.93496518, -0.79702382, -0.82388346,\n",
            "        -0.90284449, -0.77774732, -0.99485756, -1.12158772, -0.81284639,\n",
            "        -0.971528  , -1.01684347, -1.08266368, -1.04162539, -1.15101694],\n",
            "       [-0.97200036, -0.86781814, -0.9492108 , -1.07462285, -0.89854575,\n",
            "        -0.92275185, -0.93496518, -0.79702382, -0.82388346, -0.90284449,\n",
            "        -0.77774732, -0.99485756, -1.12158772, -0.81284639, -0.971528  ,\n",
            "        -1.01684347, -1.08266368, -1.04162539, -1.15101694, -0.98109805],\n",
            "       [-0.86781814, -0.9492108 , -1.07462285, -0.89854575, -0.92275185,\n",
            "        -0.93496518, -0.79702382, -0.82388346, -0.90284449, -0.77774732,\n",
            "        -0.99485756, -1.12158772, -0.81284639, -0.971528  , -1.01684347,\n",
            "        -1.08266368, -1.04162539, -1.15101694, -0.98109805, -1.17422182],\n",
            "       [-0.9492108 , -1.07462285, -0.89854575, -0.92275185, -0.93496518,\n",
            "        -0.79702382, -0.82388346, -0.90284449, -0.77774732, -0.99485756,\n",
            "        -1.12158772, -0.81284639, -0.971528  , -1.01684347, -1.08266368,\n",
            "        -1.04162539, -1.15101694, -0.98109805, -1.17422182, -1.08180822],\n",
            "       [-1.07462285, -0.89854575, -0.92275185, -0.93496518, -0.79702382,\n",
            "        -0.82388346, -0.90284449, -0.77774732, -0.99485756, -1.12158772,\n",
            "        -0.81284639, -0.971528  , -1.01684347, -1.08266368, -1.04162539,\n",
            "        -1.15101694, -0.98109805, -1.17422182, -1.08180822, -1.01729042],\n",
            "       [-0.89854575, -0.92275185, -0.93496518, -0.79702382, -0.82388346,\n",
            "        -0.90284449, -0.77774732, -0.99485756, -1.12158772, -0.81284639,\n",
            "        -0.971528  , -1.01684347, -1.08266368, -1.04162539, -1.15101694,\n",
            "        -0.98109805, -1.17422182, -1.08180822, -1.01729042, -1.09090534],\n",
            "       [-0.92275185, -0.93496518, -0.79702382, -0.82388346, -0.90284449,\n",
            "        -0.77774732, -0.99485756, -1.12158772, -0.81284639, -0.971528  ,\n",
            "        -1.01684347, -1.08266368, -1.04162539, -1.15101694, -0.98109805,\n",
            "        -1.17422182, -1.08180822, -1.01729042, -1.09090534, -0.9207246 ],\n",
            "       [-0.93496518, -0.79702382, -0.82388346, -0.90284449, -0.77774732,\n",
            "        -0.99485756, -1.12158772, -0.81284639, -0.971528  , -1.01684347,\n",
            "        -1.08266368, -1.04162539, -1.15101694, -0.98109805, -1.17422182,\n",
            "        -1.08180822, -1.01729042, -1.09090534, -0.9207246 , -0.93777485],\n",
            "       [-0.79702382, -0.82388346, -0.90284449, -0.77774732, -0.99485756,\n",
            "        -1.12158772, -0.81284639, -0.971528  , -1.01684347, -1.08266368,\n",
            "        -1.04162539, -1.15101694, -0.98109805, -1.17422182, -1.08180822,\n",
            "        -1.01729042, -1.09090534, -0.9207246 , -0.93777485, -1.04786244],\n",
            "       [-0.82388346, -0.90284449, -0.77774732, -0.99485756, -1.12158772,\n",
            "        -0.81284639, -0.971528  , -1.01684347, -1.08266368, -1.04162539,\n",
            "        -1.15101694, -0.98109805, -1.17422182, -1.08180822, -1.01729042,\n",
            "        -1.09090534, -0.9207246 , -0.93777485, -1.04786244, -1.11448069],\n",
            "       [-0.90284449, -0.77774732, -0.99485756, -1.12158772, -0.81284639,\n",
            "        -0.971528  , -1.01684347, -1.08266368, -1.04162539, -1.15101694,\n",
            "        -0.98109805, -1.17422182, -1.08180822, -1.01729042, -1.09090534,\n",
            "        -0.9207246 , -0.93777485, -1.04786244, -1.11448069, -1.01016079],\n",
            "       [-0.77774732, -0.99485756, -1.12158772, -0.81284639, -0.971528  ,\n",
            "        -1.01684347, -1.08266368, -1.04162539, -1.15101694, -0.98109805,\n",
            "        -1.17422182, -1.08180822, -1.01729042, -1.09090534, -0.9207246 ,\n",
            "        -0.93777485, -1.04786244, -1.11448069, -1.01016079, -1.05143842],\n",
            "       [-0.99485756, -1.12158772, -0.81284639, -0.971528  , -1.01684347,\n",
            "        -1.08266368, -1.04162539, -1.15101694, -0.98109805, -1.17422182,\n",
            "        -1.08180822, -1.01729042, -1.09090534, -0.9207246 , -0.93777485,\n",
            "        -1.04786244, -1.11448069, -1.01016079, -1.05143842, -1.08965153],\n",
            "       [-1.12158772, -0.81284639, -0.971528  , -1.01684347, -1.08266368,\n",
            "        -1.04162539, -1.15101694, -0.98109805, -1.17422182, -1.08180822,\n",
            "        -1.01729042, -1.09090534, -0.9207246 , -0.93777485, -1.04786244,\n",
            "        -1.11448069, -1.01016079, -1.05143842, -1.08965153, -1.02651943],\n",
            "       [-0.81284639, -0.971528  , -1.01684347, -1.08266368, -1.04162539,\n",
            "        -1.15101694, -0.98109805, -1.17422182, -1.08180822, -1.01729042,\n",
            "        -1.09090534, -0.9207246 , -0.93777485, -1.04786244, -1.11448069,\n",
            "        -1.01016079, -1.05143842, -1.08965153, -1.02651943, -1.12913165],\n",
            "       [-0.971528  , -1.01684347, -1.08266368, -1.04162539, -1.15101694,\n",
            "        -0.98109805, -1.17422182, -1.08180822, -1.01729042, -1.09090534,\n",
            "        -0.9207246 , -0.93777485, -1.04786244, -1.11448069, -1.01016079,\n",
            "        -1.05143842, -1.08965153, -1.02651943, -1.12913165, -1.03877078],\n",
            "       [-1.01684347, -1.08266368, -1.04162539, -1.15101694, -0.98109805,\n",
            "        -1.17422182, -1.08180822, -1.01729042, -1.09090534, -0.9207246 ,\n",
            "        -0.93777485, -1.04786244, -1.11448069, -1.01016079, -1.05143842,\n",
            "        -1.08965153, -1.02651943, -1.12913165, -1.03877078, -1.26340409]])>), <tf.Tensor: shape=(32, 1), dtype=float64, numpy=\n",
            "array([[-0.89854575],\n",
            "       [-0.92275185],\n",
            "       [-0.93496518],\n",
            "       [-0.79702382],\n",
            "       [-0.82388346],\n",
            "       [-0.90284449],\n",
            "       [-0.77774732],\n",
            "       [-0.99485756],\n",
            "       [-1.12158772],\n",
            "       [-0.81284639],\n",
            "       [-0.971528  ],\n",
            "       [-1.01684347],\n",
            "       [-1.08266368],\n",
            "       [-1.04162539],\n",
            "       [-1.15101694],\n",
            "       [-0.98109805],\n",
            "       [-1.17422182],\n",
            "       [-1.08180822],\n",
            "       [-1.01729042],\n",
            "       [-1.09090534],\n",
            "       [-0.9207246 ],\n",
            "       [-0.93777485],\n",
            "       [-1.04786244],\n",
            "       [-1.11448069],\n",
            "       [-1.01016079],\n",
            "       [-1.05143842],\n",
            "       [-1.08965153],\n",
            "       [-1.02651943],\n",
            "       [-1.12913165],\n",
            "       [-1.03877078],\n",
            "       [-1.26340409],\n",
            "       [-1.17533422]])>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Yt-EgZ3sgPY"
      },
      "source": [
        "# Création du modèle GRU avec couche d'attention personnalisée simple"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dyrcfKcgCsZ7"
      },
      "source": [
        "**1. Création du réseau et adaptation des formats d'entrée et de sortie**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zeJyix8HK7Kt"
      },
      "source": [
        "Sous forme de shéma, notre réseau est donc le suivant :\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1OZkfsmnBNHY"
      },
      "source": [
        "<img src=\"https://github.com/AlexandreBourrieau/ML/blob/main/Carnets%20Jupyter/S%C3%A9ries%20temporelles/images/attention_1_ensemble2.png?raw=true\" width=\"1200\"> "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4kgTrJOQ5DUo"
      },
      "source": [
        "# Remise à zéro de tous les états générés par Keras\n",
        "tf.keras.backend.clear_session()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hLNIAGDlBizT"
      },
      "source": [
        "On créé une classe dérivée de la classe [Layer](https://keras.io/api/layers/base_layer/#layer-class) de Keras. Les méthodes utilisées sont les suivantes :  \n",
        " - [build](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Layer#build) : Permet de créer les variables utilisées par la couche (commes les poids et les offsets)\n",
        " - [call](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Layer#call) : Permet d'implanter la logique de la couche"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3COaR59t5WzJ"
      },
      "source": [
        "<img src=\"https://github.com/AlexandreBourrieau/ML/blob/main/Carnets%20Jupyter/S%C3%A9ries%20temporelles/images/attention_1_Attention2.png?raw=true\" width=\"1200\"> "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hhk0kmPSgqva"
      },
      "source": [
        "# Définition du de la couche du modèle\n",
        "# End-to-End Memory Network\n",
        "from keras import backend as K\n",
        "\n",
        "class Couche_End_to_End_MN(tf.keras.layers.Layer):\n",
        "  # Fonction d'initialisation de la classe d'attention\n",
        "  # dim_GRU : Dimension des vecteurs GRU\n",
        "  # x : Séquences à mémoriser (batch_size, Nbr_Sequence, taille_fenetre)\n",
        "  # Fonction de la couche lambda d'entrée\n",
        "  def __init__(self,dim_GRU):\n",
        "    self.dim_GRU = dim_GRU\n",
        "    super().__init__()          # Appel du __init__() de la classe Layer\n",
        "  \n",
        "  def build(self,input_shape):\n",
        "    # Définition des couches GRU pour traiter les séquences d'entrée\n",
        "    self.couche_GRU_A = tf.keras.layers.GRU(self.dim_GRU)\n",
        "    self.couche_GRU_B = tf.keras.layers.GRU(self.dim_GRU)\n",
        "    self.couche_GRU_C = tf.keras.layers.GRU(self.dim_GRU)\n",
        "    self.dense = tf.keras.layers.Dense(1,use_bias=False,trainable=True)\n",
        "\n",
        "    # Poids d'attention\n",
        "    self.p = self.add_weight(shape=(input_shape[1],1),initializer=\"zeros\",name=\"p\")\n",
        "    super().build(input_shape)        # Appel de la méthode build()\n",
        "\n",
        "  # Définit la logique de la couche d'attention\n",
        "  # Arguments :     x : (batch_size, Nbr_Sequence, taille_fenetre)\n",
        "  #                 y : (batch_size, taille_fenetre)\n",
        "  # Exemple :   batch_size = 32\n",
        "  #             Nbr_Sequence =30\n",
        "  #             taille_fenetre = 20\n",
        "  #             dim_GRU = 40 \n",
        "  def call(self,x,y):\n",
        "    # Création des vecteurs mi dans le tenseur M\n",
        "    M = tf.expand_dims(x,axis=-1)                                   # (32,30,20) => (32,30,20,1)\n",
        "    M = tf.keras.layers.TimeDistributed(self.couche_GRU_A)(M)       # (32,30,20,1) => (32,30,40) : TimeStep = 30 : (32,20,1) envoyé\n",
        "    M = K.tanh(M)\n",
        "\n",
        "    # Création du vecteur d'état u\n",
        "    u = tf.expand_dims(y,axis=-1)                                   # (32,20) => (32,20,1)\n",
        "    u = self.couche_GRU_B(u)                                        # (32,20,1) => (32,40)\n",
        "    u = tf.expand_dims(u,axis=-1)                                   # (32,40) => (32,40,1)\n",
        "    u = K.tanh(u)                                                   # (32,40,1)\n",
        "\n",
        "    # Calcul des poids d'attention\n",
        "    p = tf.keras.layers.Dot(axes=(2,1))([M,u])                      # (32,30,1)\n",
        "    p = tf.keras.activations.softmax(p,axis=1)                      # (32,30,1)\n",
        "\n",
        "    # Création des vecteurs ci dans le tenseur C\n",
        "    C = tf.expand_dims(x,axis=-1)                                   # (32,30,20) => (32,30,20,1)\n",
        "    C = tf.keras.layers.TimeDistributed(self.couche_GRU_C)(C)       # (32,30,20,1) => (32,30,40) : TimeStep = 30 : (32,20,1) envoyé\n",
        "    C = K.tanh(C)\n",
        "\n",
        "    # Calcul du vecteur réponse issu de la mémoire\n",
        "    o = tf.multiply(C,p)                                            # (32,30,40)_x_(32,30,1) = (32,30,40)\n",
        "    o = K.sum(o, axis=1)                                            # (32,40)\n",
        "    o = K.tanh(o)                                                   # (32,40)\n",
        "    \n",
        "    # Retourne le vecteur d'attention\n",
        "    return (o+tf.squeeze(u,axis=2))\n"
      ],
      "execution_count": 272,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d7XILboq5vwZ",
        "outputId": "189f9bca-1404-411b-ea22-27d6de1ea62d"
      },
      "source": [
        "# batch_size = 3\n",
        "# Nbr_Sequence = 4\n",
        "# taille_fenetre = 5\n",
        "\n",
        "x = tf.Variable([[[1,2,3,4,5],[6,7,8,9,10],[1,3,3,4,5],[1,2,3,4,5]],[[1,2,3,4,5],[1,2,3,4,5],[1,2,3,4,5],[1,2,3,4,5]],[[1,2,3,4,5],[1,2,3,4,5],[1,2,3,4,5],[1,2,3,4,5]]],dtype=tf.float32)\n",
        "y = tf.Variable([[1,2,3,4,5],[1,2,3,4,5],[1,2,3,4,5]],dtype=tf.float32)\n",
        "u = tf.Variable([[1,2,3,4,5],[1,2,3,4,5],[1,2,3,4,5]],dtype=tf.float32)\n",
        "u = tf.expand_dims(u,axis=-1)\n",
        "print(x.shape)\n",
        "print(y.shape)\n",
        "print(u.shape)"
      ],
      "execution_count": 219,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(3, 4, 5)\n",
            "(3, 5)\n",
            "(3, 5, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uxX7GIdnz-3Z",
        "outputId": "97569fef-d5ef-4c07-badf-604d762ff463"
      },
      "source": [
        "Couche_End_to_End_MN(dim_GRU=5)(x,y)"
      ],
      "execution_count": 230,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(3, 5), dtype=float32, numpy=\n",
              "array([[ 0.3545347 , -1.0084188 ,  1.025198  ,  0.11606383, -0.7543726 ],\n",
              "       [ 0.35414153, -0.9908039 ,  1.0980637 ,  0.11775899, -0.74373114],\n",
              "       [ 0.35414153, -0.9908039 ,  1.0980637 ,  0.11775899, -0.74373114]],\n",
              "      dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 230
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RTqdYAsF_ici",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 236
        },
        "outputId": "6c686a21-177c-498d-f85f-290c40735360"
      },
      "source": [
        "Nbr_Sequences = len(list(dataset_norm.as_numpy_iterator()))\n",
        "dim_GRU = 40\n",
        "\n",
        "entrees_sequences = tf.keras.layers.Input(shape=(Nbr_Sequences,taille_fenetre),batch_size=batch_size)\n",
        "entrees_entrainement = tf.keras.layers.Input(shape=(taille_fenetre),batch_size=batch_size)\n",
        "sortie = Couche_End_to_End_MN(dim_GRU=dim_GRU)(entrees_sequences,entrees_entrainement)\n",
        "pred = tf.keras.layers.Dense(units=dim_GRU)(sortie)\n",
        "\n",
        "model = tf.keras.Model([entrees_sequences,entrees_entrainement],pred)\n",
        "model.summary()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-9cd159c5fd64>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mNbr_Sequences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_norm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_numpy_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdim_GRU\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m40\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mentrees_sequences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNbr_Sequences\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtaille_fenetre\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mentrees_entrainement\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtaille_fenetre\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'dataset_norm' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 696
        },
        "id": "yxKcm8DitCKs",
        "outputId": "697b2e27-c5d8-4b07-b0a5-62a8e4efe737"
      },
      "source": [
        "# Définition de l'optimiseur à utiliser\n",
        "optimiseur=tf.keras.optimizers.SGD(lr=1e-4)\n",
        "\n",
        "\n",
        "# Compile le modèle\n",
        "model.compile(loss=tf.keras.losses.Huber(), optimizer=optimiseur, metrics=\"mae\")\n",
        "\n",
        "# Entraine le modèle en utilisant notre fonction personnelle de régulation du taux d'apprentissage\n",
        "historique = model.fit(dataset_norm,epochs=100,verbose=1)"
      ],
      "execution_count": 289,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "WARNING:tensorflow:Model was constructed with shape (32, 30, 20) for input KerasTensor(type_spec=TensorSpec(shape=(32, 30, 20), dtype=tf.float32, name='input_48'), name='input_48', description=\"created by layer 'input_48'\"), but it was called on an input with incompatible shape (32, None).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-289-d45bc3900618>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# Entraine le modèle en utilisant notre fonction personnelle de régulation du taux d'apprentissage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mhistorique\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_norm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 _r=1):\n\u001b[1;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    869\u001b[0m       \u001b[0;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    870\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 871\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    872\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    873\u001b[0m       \u001b[0;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    724\u001b[0m     self._concrete_stateful_fn = (\n\u001b[1;32m    725\u001b[0m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0;32m--> 726\u001b[0;31m             *args, **kwds))\n\u001b[0m\u001b[1;32m    727\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    728\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minvalid_creator_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0munused_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0munused_kwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2967\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2968\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2969\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2970\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2971\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3360\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3361\u001b[0;31m           \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3362\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3363\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3204\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3205\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3206\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   3207\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3208\u001b[0m         \u001b[0mfunction_spec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_spec\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    988\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    989\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 990\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    991\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    992\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    632\u001b[0m             \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 634\u001b[0;31m           \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    635\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    975\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    976\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 977\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    978\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    979\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:805 train_function  *\n        return step_function(self, iterator)\n    <ipython-input-272-4bb310bdfb3d>:35 call  *\n        M = tf.keras.layers.TimeDistributed(self.couche_GRU_A)(M)       # (32,30,20,1) => (32,30,40) : TimeStep = 30 : (32,20,1) envoyé\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer.py:1012 __call__  **\n        outputs = call_fn(inputs, *args, **kwargs)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/layers/wrappers.py:241 call\n        y = self.layer(inputs, **kwargs)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/layers/recurrent.py:660 __call__\n        return super(RNN, self).__call__(inputs, **kwargs)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer.py:998 __call__\n        input_spec.assert_input_compatibility(self.input_spec, inputs, self.name)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/input_spec.py:223 assert_input_compatibility\n        str(tuple(shape)))\n\n    ValueError: Input 0 of layer gru is incompatible with the layer: expected ndim=3, found ndim=2. Full shape received: (None, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MUM0-SSXGLIQ"
      },
      "source": [
        "**2. Optimisation du taux d'apprentissage**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jejCBhXVuNQ4"
      },
      "source": [
        "# Définition de la fonction de régulation du taux d'apprentissage\n",
        "def RegulationTauxApprentissage(periode, taux):\n",
        "  return 1e-8*10**(periode/10)\n",
        "\n",
        "# Définition de l'optimiseur à utiliser\n",
        "optimiseur=tf.keras.optimizers.SGD(lr=1e-8)\n",
        "\n",
        "# Utilisation de la méthode ModelCheckPoint\n",
        "CheckPoint = tf.keras.callbacks.ModelCheckpoint(\"poids.hdf5\", monitor='loss', verbose=1, save_best_only=True, save_weights_only = True, mode='auto', save_freq='epoch')\n",
        "\n",
        "# Compile le modèle\n",
        "model.compile(loss=tf.keras.losses.Huber(), optimizer=optimiseur, metrics=\"mae\")\n",
        "\n",
        "# Entraine le modèle en utilisant notre fonction personnelle de régulation du taux d'apprentissage\n",
        "historique = model.fit(dataset_norm,epochs=100,verbose=1, callbacks=[tf.keras.callbacks.LearningRateScheduler(RegulationTauxApprentissage), CheckPoint])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q1_WMNlzu2B4"
      },
      "source": [
        "# Construit un vecteur avec les valeurs du taux d'apprentissage à chaque période \n",
        "taux = 1e-8*(10**(np.arange(100)/10))\n",
        "\n",
        "# Affiche l'erreur en fonction du taux d'apprentissage\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.semilogx(taux,historique.history[\"loss\"])\n",
        "plt.axis([ taux[0], taux[99], 0, 1])\n",
        "plt.title(\"Evolution de l'erreur en fonction du taux d'apprentissage\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6XdXh_b0GP_F"
      },
      "source": [
        "**3. Entrainement du modèle**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "80pEtJ10wIfY"
      },
      "source": [
        "# Charge les meilleurs poids\n",
        "model.load_weights(\"poids.hdf5\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "16ujUiELwR33"
      },
      "source": [
        "from timeit import default_timer as timer\n",
        "\n",
        "class TimingCallback(keras.callbacks.Callback):\n",
        "    def __init__(self, logs={}):\n",
        "        self.logs=[]\n",
        "    def on_epoch_begin(self, epoch, logs={}):\n",
        "        self.starttime = timer()\n",
        "    def on_epoch_end(self, epoch, logs={}):\n",
        "        self.logs.append(timer()-self.starttime)\n",
        "\n",
        "cb = TimingCallback()\n",
        "\n",
        "# Définition de l'optimiseur à utiliser\n",
        "optimiseur=tf.keras.optimizers.SGD(lr=2e-2,momentum=0.9)\n",
        "\n",
        "# Utilisation de la méthode ModelCheckPoint\n",
        "CheckPoint = tf.keras.callbacks.ModelCheckpoint(\"poids.hdf5\", monitor='loss', verbose=1, save_best_only=True, save_weights_only = True, mode='auto', save_freq='epoch')\n",
        "\n",
        "# Compile le modèle\n",
        "model.compile(loss=tf.keras.losses.Huber(), optimizer=optimiseur,metrics=\"mae\")\n",
        "\n",
        "# Entraine le modèle\n",
        "historique = model.fit(dataset_norm,validation_data=dataset_Val_norm, epochs=500,verbose=1, callbacks=[CheckPoint,cb])\n",
        "\n",
        "print(cb.logs)\n",
        "print(sum(cb.logs))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "COP9u4yitvmw"
      },
      "source": [
        "erreur_entrainement = historique.history[\"loss\"]\n",
        "erreur_validation = historique.history[\"val_loss\"]\n",
        "\n",
        "# Affiche l'erreur en fonction de la période\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(np.arange(0,len(erreur_entrainement)),erreur_entrainement, label=\"Erreurs sur les entrainements\")\n",
        "plt.plot(np.arange(0,len(erreur_entrainement)),erreur_validation, label =\"Erreurs sur les validations\")\n",
        "plt.legend()\n",
        "\n",
        "plt.title(\"Evolution de l'erreur en fonction de la période\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_o2zh6N9t1b7"
      },
      "source": [
        "erreur_entrainement = historique.history[\"loss\"]\n",
        "erreur_validation = historique.history[\"val_loss\"]\n",
        "\n",
        "# Affiche l'erreur en fonction de la période\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(np.arange(0,len(erreur_entrainement[400:500])),erreur_entrainement[400:500], label=\"Erreurs sur les entrainements\")\n",
        "plt.plot(np.arange(0,len(erreur_entrainement[400:500])),erreur_validation[400:500], label =\"Erreurs sur les validations\")\n",
        "plt.legend()\n",
        "\n",
        "plt.title(\"Evolution de l'erreur en fonction de la période\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T6Gq2CkeGR_1"
      },
      "source": [
        "**4. Prédictions**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HRxXtHRXGXfF"
      },
      "source": [
        "taille_fenetre = 20\n",
        "\n",
        "# Création d'une liste vide pour recevoir les prédictions\n",
        "predictions = []\n",
        "\n",
        "# Calcul des prédiction pour chaque groupe de 20 valeurs consécutives de la série\n",
        "# dans l'intervalle de validation\n",
        "for t in temps[temps_separation:-taille_fenetre]:\n",
        "    X = np.reshape(Serie_Normalisee[t:t+taille_fenetre],(1,taille_fenetre))\n",
        "    predictions.append(model.predict(X))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wd2nfDcgG8EO"
      },
      "source": [
        "# Affiche la série et les prédictions\n",
        "plt.figure(figsize=(10, 6))\n",
        "affiche_serie(temps,serie,label=\"Série temporelle\")\n",
        "affiche_serie(temps[temps_separation+taille_fenetre:],np.asarray(predictions*std+mean)[:,0,0],label=\"Prédictions\")\n",
        "plt.title('Prédictions avec le modèle GRU + Attention')\n",
        "plt.show()\n",
        "\n",
        "# Zoom sur l'intervalle de validation\n",
        "plt.figure(figsize=(10, 6))\n",
        "affiche_serie(temps[temps_separation:],serie[temps_separation:],label=\"Série temporelle\")\n",
        "affiche_serie(temps[temps_separation+taille_fenetre:],np.asarray(predictions*std+mean)[:,0,0],label=\"Prédictions\")\n",
        "plt.title(\"Prédictions avec le modèle GRU + Attention (zoom sur l'intervalle de validation)\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PDS7BJvZG_e1"
      },
      "source": [
        "# Calcule de l'erreur quadratique moyenne et de l'erreur absolue moyenne \n",
        "\n",
        "mae = tf.keras.metrics.mean_absolute_error(serie[temps_separation+taille_fenetre:],np.asarray(predictions*std+mean)[:,0,0]).numpy()\n",
        "mse = tf.keras.metrics.mean_squared_error(serie[temps_separation+taille_fenetre:],np.asarray(predictions*std+mean)[:,0,0]).numpy()\n",
        "\n",
        "print(mae)\n",
        "print(mse)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}