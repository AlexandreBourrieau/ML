{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Reseau_GRU_Avec_Attention.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPtg+2e9q1T4XsPCRCPOG5l",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AlexandreBourrieau/ML/blob/main/Carnets%20Jupyter/S%C3%A9ries%20temporelles/Reseau_GRU_Avec_Attention_Tests.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ubCeIvtF6R4W"
      },
      "source": [
        "Dans ce carnet nous allons mettre en place un modèle à réseau de neurones récurrent de type GRU associé à une couche d'attention pour réaliser des prédictions sur notre série temporelle."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RRhtHsNn5fc3"
      },
      "source": [
        "import tensorflow as tf\r\n",
        "from tensorflow import keras\r\n",
        "\r\n",
        "import numpy as np\r\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XFeah3y_6kif"
      },
      "source": [
        "# Création de la série temporelle et du dataset pour l'entrainement"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vJfSLtub6sdc"
      },
      "source": [
        "# Fonction permettant d'afficher une série temporelle\r\n",
        "def affiche_serie(temps, serie, format=\"-\", debut=0, fin=None, label=None):\r\n",
        "    plt.plot(temps[debut:fin], serie[debut:fin], format, label=label)\r\n",
        "    plt.xlabel(\"Temps\")\r\n",
        "    plt.ylabel(\"Valeur\")\r\n",
        "    if label:\r\n",
        "        plt.legend(fontsize=14)\r\n",
        "    plt.grid(True)\r\n",
        "\r\n",
        "# Fonction permettant de créer une tendance\r\n",
        "def tendance(temps, pente=0):\r\n",
        "    return pente * temps\r\n",
        "\r\n",
        "# Fonction permettant de créer un motif\r\n",
        "def motif_periodique(instants):\r\n",
        "    return (np.where(instants < 0.4,                            # Si les instants sont < 0.4\r\n",
        "                    np.cos(instants * 2 * np.pi),               # Alors on retourne la fonction cos(2*pi*t)\r\n",
        "                    1 / np.exp(3 * instants)))                  # Sinon, on retourne la fonction exp(-3t)\r\n",
        "\r\n",
        "# Fonction permettant de créer une saisonnalité avec un motif\r\n",
        "def saisonnalite(temps, periode, amplitude=1, phase=0):\r\n",
        "    \"\"\"Répétition du motif sur la même période\"\"\"\r\n",
        "    instants = ((temps + phase) % periode) / periode            # Mapping du temps =[0 1 2 ... 1460] => instants = [0.0 ... 1.0]\r\n",
        "    return amplitude * motif_periodique(instants)\r\n",
        "\r\n",
        "# Fonction permettant de générer du bruit gaussien N(0,1)\r\n",
        "def bruit_blanc(temps, niveau_bruit=1, graine=None):\r\n",
        "    rnd = np.random.RandomState(graine)\r\n",
        "    return rnd.randn(len(temps)) * niveau_bruit\r\n",
        "\r\n",
        "# Fonction permettant de créer un dataset à partir des données de la série temporelle\r\n",
        "# au format X(X1,X2,...Xn) / Y(Y1,Y2,...,Yn)\r\n",
        "# X sont les données d'entrées du réseau\r\n",
        "# Y sont les labels\r\n",
        "\r\n",
        "def prepare_dataset_XY(serie, taille_fenetre, batch_size, buffer_melange):\r\n",
        "  dataset = tf.data.Dataset.from_tensor_slices(serie)\r\n",
        "  dataset = dataset.window(taille_fenetre+1, shift=1, drop_remainder=True)\r\n",
        "  dataset = dataset.flat_map(lambda x: x.batch(taille_fenetre + 1))\r\n",
        "  dataset = dataset.shuffle(buffer_melange).map(lambda x: (x[:-1], x[-1:]))\r\n",
        "  dataset = dataset.batch(batch_size,drop_remainder=True).prefetch(1)\r\n",
        "  return dataset\r\n",
        "\r\n",
        "\r\n",
        "# Création de la série temporelle\r\n",
        "temps = np.arange(4 * 365)                # temps = [0 1 2 .... 4*365] = [0 1 2 .... 1460]\r\n",
        "amplitude = 40                            # Amplitude de la la saisonnalité\r\n",
        "niveau_bruit = 5                          # Niveau du bruit\r\n",
        "offset = 10                               # Offset de la série\r\n",
        "\r\n",
        "serie = offset + tendance(temps, 0.1) + saisonnalite(temps, periode=365, amplitude=amplitude) + bruit_blanc(temps,niveau_bruit)\r\n",
        "\r\n",
        "temps_separation = 1000\r\n",
        "\r\n",
        "# Extraction des temps et des données d'entrainement\r\n",
        "temps_entrainement = temps[:temps_separation]\r\n",
        "x_entrainement = serie[:temps_separation]\r\n",
        "\r\n",
        "# Exctraction des temps et des données de valiadation\r\n",
        "temps_validation = temps[temps_separation:]\r\n",
        "x_validation = serie[temps_separation:]\r\n",
        "\r\n",
        "# Définition des caractéristiques du dataset que l'on souhaite créer\r\n",
        "taille_fenetre = 20\r\n",
        "batch_size = 32\r\n",
        "buffer_melange = 1000\r\n",
        "\r\n",
        "# Création du dataset X,Y\r\n",
        "dataset = prepare_dataset_XY(serie,taille_fenetre,batch_size,buffer_melange)\r\n",
        "\r\n",
        "# Création du dataset X,Y de validation\r\n",
        "dataset_Val = prepare_dataset_XY(x_validation,taille_fenetre,batch_size,buffer_melange)"
      ],
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Yt-EgZ3sgPY"
      },
      "source": [
        "# Création du modèle GRU avec couche d'attention personnalisée simple"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dyrcfKcgCsZ7"
      },
      "source": [
        "**1. Création du réseau et adaptation des formats d'entrée et de sortie**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zeJyix8HK7Kt"
      },
      "source": [
        "Sous forme de shéma, notre réseau est donc le suivant :\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1OZkfsmnBNHY"
      },
      "source": [
        "<img src=\"https://github.com/AlexandreBourrieau/ML/blob/main/Carnets%20Jupyter/S%C3%A9ries%20temporelles/images/attention_1_ensemble.png?raw=true\" width=\"1200\"> "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4kgTrJOQ5DUo"
      },
      "source": [
        "# Remise à zéro de tous les états générés par Keras\r\n",
        "tf.keras.backend.clear_session()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hLNIAGDlBizT"
      },
      "source": [
        "On créé une classe dérivée de la classe [Layer](https://keras.io/api/layers/base_layer/#layer-class) de Keras. Les méthodes utilisées sont les suivantes :  \r\n",
        " - [build](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Layer#build) : Permet de créer les variables utilisées par la couche (commes les poids et les offsets)\r\n",
        " - [call](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Layer#call) : Permet d'implanter la logique de la couche"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3COaR59t5WzJ"
      },
      "source": [
        "<img src=\"https://github.com/AlexandreBourrieau/ML/blob/main/Carnets%20Jupyter/S%C3%A9ries%20temporelles/images/attention_1_Attention.png?raw=true\" width=\"1200\"> "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FkseSQGFp56u"
      },
      "source": [
        "# Classe d'attention simple\r\n",
        "# Applique les poids d'attention sur les vecteurs de la couche récurrente\r\n",
        "\r\n",
        "# Importe le Backend de Keras\r\n",
        "from keras import backend as K\r\n",
        "\r\n",
        "# Définit une nouvelle classe Couche_Attention\r\n",
        "# Héritée de la classe Layer de Keras\r\n",
        "\r\n",
        "class Couche_Attention(tf.keras.layers.Layer):\r\n",
        "  # Fonction d'initialisation de la classe d'attention\r\n",
        "  def __init__(self,dim):\r\n",
        "    self.dense_layer = tf.keras.layers.Dense(units=1,activation=\"tanh\",trainable=True)\r\n",
        "    self.dim = dim              # Dimension des vecteurs cachés de la couche récurrente\r\n",
        "    super().__init__()          # Appel du __init__() de la classe Layer\r\n",
        "  \r\n",
        "  def build(self,input_shape):\r\n",
        "    super().build(input_shape)        # Appel de la méthode build()\r\n",
        "\r\n",
        "  # Définit la logique de la couche d'attention\r\n",
        "  # Arguments :   x : Tenseur d'entrée de dimension (None, nbr_v,dim)\r\n",
        "  def call(self,x):\r\n",
        "    e = self.dense_layer(x)\r\n",
        "    a = tf.keras.activations.softmax(e,axis=1)\r\n",
        "    xa = tf.multiply(x,a)\r\n",
        "    sortie = K.sum(xa,axis=1)\r\n",
        "    return sortie"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RTqdYAsF_ici"
      },
      "source": [
        "dim_GRU = 40\r\n",
        "\r\n",
        "# Fonction de la couche lambda d'entrée\r\n",
        "def Traitement_Entrees(x):\r\n",
        "  return tf.expand_dims(x,axis=-1)\r\n",
        "\r\n",
        "# Fonction dela couche lambda de sortie\r\n",
        "def Traitement_Sorties(x):\r\n",
        "  return(x*100.0)\r\n",
        "\r\n",
        "model = tf.keras.models.Sequential()\r\n",
        "model.add(tf.keras.Input(shape=(None,)))\r\n",
        "model.add(tf.keras.layers.Lambda(Traitement_Entrees))\r\n",
        "model.add(tf.keras.layers.GRU(dim_GRU,return_sequences=True))\r\n",
        "model.add(Couche_Attention(dim=dim_GRU))\r\n",
        "model.add(tf.keras.layers.Dense(1))\r\n",
        "model.add(tf.keras.layers.Lambda(Traitement_Sorties))\r\n",
        "\r\n",
        "model.save_weights('model_initial.h5')\r\n",
        "\r\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MUM0-SSXGLIQ"
      },
      "source": [
        "**2. Optimisation du taux d'apprentissage**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jejCBhXVuNQ4"
      },
      "source": [
        "# Définition de la fonction de régulation du taux d'apprentissage\r\n",
        "def RegulationTauxApprentissage(periode, taux):\r\n",
        "  return 1e-8*10**(periode/10)\r\n",
        "\r\n",
        "# Définition de l'optimiseur à utiliser\r\n",
        "optimiseur=tf.keras.optimizers.Adam()\r\n",
        "\r\n",
        "# Utilisation de la méthode ModelCheckPoint\r\n",
        "CheckPoint = tf.keras.callbacks.ModelCheckpoint(\"poids.hdf5\", monitor='loss', verbose=1, save_best_only=True, save_weights_only = True, mode='auto', save_freq='epoch')\r\n",
        "\r\n",
        "# Compile le modèle\r\n",
        "model.compile(loss=tf.keras.losses.Huber(), optimizer=optimiseur, metrics=\"mae\")\r\n",
        "\r\n",
        "# Entraine le modèle en utilisant notre fonction personnelle de régulation du taux d'apprentissage\r\n",
        "historique = model.fit(dataset,epochs=100,verbose=1, callbacks=[tf.keras.callbacks.LearningRateScheduler(RegulationTauxApprentissage), CheckPoint])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q1_WMNlzu2B4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 411
        },
        "outputId": "683b11a1-d14e-4643-fbce-2012ad77558f"
      },
      "source": [
        "# Construit un vecteur avec les valeurs du taux d'apprentissage à chaque période \r\n",
        "taux = 1e-8*(10**(np.arange(100)/10))\r\n",
        "\r\n",
        "# Affiche l'erreur en fonction du taux d'apprentissage\r\n",
        "plt.figure(figsize=(10, 6))\r\n",
        "plt.semilogx(taux,historique.history[\"loss\"])\r\n",
        "plt.axis([ taux[0], taux[99], 0, 100])\r\n",
        "plt.title(\"Evolution de l'erreur en fonction du taux d'apprentissage\")"
      ],
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, \"Evolution de l'erreur en fonction du taux d'apprentissage\")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 118
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6XdXh_b0GP_F"
      },
      "source": [
        "**3. Entrainement du modèle**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "80pEtJ10wIfY"
      },
      "source": [
        "# Charge les meilleurs poids\r\n",
        "model.load_weights(\"poids.hdf5\")"
      ],
      "execution_count": 119,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "16ujUiELwR33",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b553debf-55ec-4984-81b9-049dce1b912a"
      },
      "source": [
        "# Définition de l'optimiseur à utiliser\r\n",
        "optimiseur=tf.keras.optimizers.Adam(lr=1e-3)\r\n",
        "\r\n",
        "\r\n",
        "# Utilisation de la méthode ModelCheckPoint\r\n",
        "CheckPoint = tf.keras.callbacks.ModelCheckpoint(\"poids.hdf5\", monitor='loss', verbose=1, save_best_only=True, save_weights_only = True, mode='auto', save_freq='epoch')\r\n",
        "\r\n",
        "# Compile le modèle\r\n",
        "model.compile(loss=tf.keras.losses.Huber(), optimizer=optimiseur,metrics=\"mae\")\r\n",
        "\r\n",
        "# Entraine le modèle\r\n",
        "historique = model.fit(dataset,validation_data=dataset_Val, epochs=500,verbose=1, callbacks=[CheckPoint])"
      ],
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/500\n",
            "45/45 [==============================] - 3s 28ms/step - loss: 8.2063 - mae: 8.6913 - val_loss: 7.3042 - val_mae: 7.7880\n",
            "\n",
            "Epoch 00001: loss improved from inf to 7.65154, saving model to poids.hdf5\n",
            "Epoch 2/500\n",
            "45/45 [==============================] - 1s 10ms/step - loss: 6.8837 - mae: 7.3660 - val_loss: 6.9709 - val_mae: 7.4520\n",
            "\n",
            "Epoch 00002: loss improved from 7.65154 to 7.08160, saving model to poids.hdf5\n",
            "Epoch 3/500\n",
            "45/45 [==============================] - 1s 10ms/step - loss: 6.5834 - mae: 7.0645 - val_loss: 6.6621 - val_mae: 7.1430\n",
            "\n",
            "Epoch 00003: loss improved from 7.08160 to 6.82560, saving model to poids.hdf5\n",
            "Epoch 4/500\n",
            "45/45 [==============================] - 1s 11ms/step - loss: 6.8649 - mae: 7.3469 - val_loss: 6.8858 - val_mae: 7.3663\n",
            "\n",
            "Epoch 00004: loss did not improve from 6.82560\n",
            "Epoch 5/500\n",
            "45/45 [==============================] - 1s 11ms/step - loss: 7.5527 - mae: 8.0364 - val_loss: 6.7904 - val_mae: 7.2719\n",
            "\n",
            "Epoch 00005: loss did not improve from 6.82560\n",
            "Epoch 6/500\n",
            "45/45 [==============================] - 1s 11ms/step - loss: 6.9545 - mae: 7.4369 - val_loss: 7.1826 - val_mae: 7.6646\n",
            "\n",
            "Epoch 00006: loss did not improve from 6.82560\n",
            "Epoch 7/500\n",
            "45/45 [==============================] - 1s 11ms/step - loss: 6.9125 - mae: 7.3947 - val_loss: 6.6268 - val_mae: 7.1097\n",
            "\n",
            "Epoch 00007: loss improved from 6.82560 to 6.82033, saving model to poids.hdf5\n",
            "Epoch 8/500\n",
            "45/45 [==============================] - 1s 10ms/step - loss: 7.1167 - mae: 7.6002 - val_loss: 6.8095 - val_mae: 7.2927\n",
            "\n",
            "Epoch 00008: loss did not improve from 6.82033\n",
            "Epoch 9/500\n",
            "45/45 [==============================] - 1s 11ms/step - loss: 7.4274 - mae: 7.9120 - val_loss: 7.0866 - val_mae: 7.5683\n",
            "\n",
            "Epoch 00009: loss did not improve from 6.82033\n",
            "Epoch 10/500\n",
            "45/45 [==============================] - 1s 10ms/step - loss: 6.7717 - mae: 7.2543 - val_loss: 6.7424 - val_mae: 7.2226\n",
            "\n",
            "Epoch 00010: loss improved from 6.82033 to 6.78569, saving model to poids.hdf5\n",
            "Epoch 11/500\n",
            "45/45 [==============================] - 1s 11ms/step - loss: 6.6269 - mae: 7.1086 - val_loss: 6.7943 - val_mae: 7.2757\n",
            "\n",
            "Epoch 00011: loss did not improve from 6.78569\n",
            "Epoch 12/500\n",
            "45/45 [==============================] - 1s 11ms/step - loss: 6.9216 - mae: 7.4036 - val_loss: 6.6247 - val_mae: 7.1060\n",
            "\n",
            "Epoch 00012: loss improved from 6.78569 to 6.71194, saving model to poids.hdf5\n",
            "Epoch 13/500\n",
            "45/45 [==============================] - 1s 11ms/step - loss: 6.7274 - mae: 7.2076 - val_loss: 8.5030 - val_mae: 8.9912\n",
            "\n",
            "Epoch 00013: loss did not improve from 6.71194\n",
            "Epoch 14/500\n",
            "45/45 [==============================] - 1s 10ms/step - loss: 7.2550 - mae: 7.7364 - val_loss: 7.0238 - val_mae: 7.5072\n",
            "\n",
            "Epoch 00014: loss did not improve from 6.71194\n",
            "Epoch 15/500\n",
            "45/45 [==============================] - 1s 11ms/step - loss: 6.7367 - mae: 7.2191 - val_loss: 6.6684 - val_mae: 7.1492\n",
            "\n",
            "Epoch 00015: loss did not improve from 6.71194\n",
            "Epoch 16/500\n",
            "45/45 [==============================] - 1s 11ms/step - loss: 6.9365 - mae: 7.4187 - val_loss: 8.7094 - val_mae: 9.1976\n",
            "\n",
            "Epoch 00016: loss did not improve from 6.71194\n",
            "Epoch 17/500\n",
            "45/45 [==============================] - 1s 10ms/step - loss: 7.0261 - mae: 7.5090 - val_loss: 6.6665 - val_mae: 7.1484\n",
            "\n",
            "Epoch 00017: loss did not improve from 6.71194\n",
            "Epoch 18/500\n",
            "45/45 [==============================] - 1s 11ms/step - loss: 7.1625 - mae: 7.6453 - val_loss: 6.6294 - val_mae: 7.1083\n",
            "\n",
            "Epoch 00018: loss did not improve from 6.71194\n",
            "Epoch 19/500\n",
            "45/45 [==============================] - 1s 11ms/step - loss: 6.7795 - mae: 7.2612 - val_loss: 7.8650 - val_mae: 8.3512\n",
            "\n",
            "Epoch 00019: loss did not improve from 6.71194\n",
            "Epoch 20/500\n",
            "45/45 [==============================] - 1s 11ms/step - loss: 6.9581 - mae: 7.4394 - val_loss: 6.5127 - val_mae: 6.9949\n",
            "\n",
            "Epoch 00020: loss did not improve from 6.71194\n",
            "Epoch 21/500\n",
            "45/45 [==============================] - 1s 11ms/step - loss: 6.6557 - mae: 7.1374 - val_loss: 6.6942 - val_mae: 7.1754\n",
            "\n",
            "Epoch 00021: loss did not improve from 6.71194\n",
            "Epoch 22/500\n",
            "45/45 [==============================] - 1s 11ms/step - loss: 6.7761 - mae: 7.2583 - val_loss: 6.6719 - val_mae: 7.1528\n",
            "\n",
            "Epoch 00022: loss did not improve from 6.71194\n",
            "Epoch 23/500\n",
            "45/45 [==============================] - 1s 11ms/step - loss: 7.0898 - mae: 7.5726 - val_loss: 7.4410 - val_mae: 7.9258\n",
            "\n",
            "Epoch 00023: loss did not improve from 6.71194\n",
            "Epoch 24/500\n",
            "45/45 [==============================] - 1s 11ms/step - loss: 7.1567 - mae: 7.6404 - val_loss: 6.9924 - val_mae: 7.4760\n",
            "\n",
            "Epoch 00024: loss did not improve from 6.71194\n",
            "Epoch 25/500\n",
            "45/45 [==============================] - 1s 11ms/step - loss: 6.6523 - mae: 7.1335 - val_loss: 6.7900 - val_mae: 7.2720\n",
            "\n",
            "Epoch 00025: loss improved from 6.71194 to 6.70883, saving model to poids.hdf5\n",
            "Epoch 26/500\n",
            "45/45 [==============================] - 1s 11ms/step - loss: 6.9679 - mae: 7.4493 - val_loss: 6.5744 - val_mae: 7.0570\n",
            "\n",
            "Epoch 00026: loss did not improve from 6.70883\n",
            "Epoch 27/500\n",
            "45/45 [==============================] - 1s 11ms/step - loss: 6.7133 - mae: 7.1932 - val_loss: 7.1831 - val_mae: 7.6670\n",
            "\n",
            "Epoch 00027: loss did not improve from 6.70883\n",
            "Epoch 28/500\n",
            "45/45 [==============================] - 1s 11ms/step - loss: 6.7428 - mae: 7.2255 - val_loss: 6.9763 - val_mae: 7.4578\n",
            "\n",
            "Epoch 00028: loss did not improve from 6.70883\n",
            "Epoch 29/500\n",
            "45/45 [==============================] - 1s 11ms/step - loss: 6.8851 - mae: 7.3664 - val_loss: 6.5732 - val_mae: 7.0536\n",
            "\n",
            "Epoch 00029: loss did not improve from 6.70883\n",
            "Epoch 30/500\n",
            "45/45 [==============================] - 1s 11ms/step - loss: 6.9644 - mae: 7.4460 - val_loss: 6.6169 - val_mae: 7.0975\n",
            "\n",
            "Epoch 00030: loss did not improve from 6.70883\n",
            "Epoch 31/500\n",
            "45/45 [==============================] - 1s 10ms/step - loss: 6.7274 - mae: 7.2099 - val_loss: 7.0397 - val_mae: 7.5234\n",
            "\n",
            "Epoch 00031: loss did not improve from 6.70883\n",
            "Epoch 32/500\n",
            "45/45 [==============================] - 1s 11ms/step - loss: 6.9393 - mae: 7.4206 - val_loss: 6.6178 - val_mae: 7.1001\n",
            "\n",
            "Epoch 00032: loss did not improve from 6.70883\n",
            "Epoch 33/500\n",
            "45/45 [==============================] - 1s 11ms/step - loss: 6.8160 - mae: 7.2988 - val_loss: 7.2143 - val_mae: 7.6970\n",
            "\n",
            "Epoch 00033: loss did not improve from 6.70883\n",
            "Epoch 34/500\n",
            "45/45 [==============================] - 1s 11ms/step - loss: 6.7057 - mae: 7.1865 - val_loss: 7.0047 - val_mae: 7.4877\n",
            "\n",
            "Epoch 00034: loss did not improve from 6.70883\n",
            "Epoch 35/500\n",
            "45/45 [==============================] - 1s 11ms/step - loss: 7.0124 - mae: 7.4939 - val_loss: 6.5064 - val_mae: 6.9880\n",
            "\n",
            "Epoch 00035: loss improved from 6.70883 to 6.69312, saving model to poids.hdf5\n",
            "Epoch 36/500\n",
            "45/45 [==============================] - 1s 11ms/step - loss: 6.7191 - mae: 7.1986 - val_loss: 6.7131 - val_mae: 7.1931\n",
            "\n",
            "Epoch 00036: loss improved from 6.69312 to 6.68516, saving model to poids.hdf5\n",
            "Epoch 37/500\n",
            "45/45 [==============================] - 1s 11ms/step - loss: 6.8865 - mae: 7.3667 - val_loss: 6.6122 - val_mae: 7.0921\n",
            "\n",
            "Epoch 00037: loss did not improve from 6.68516\n",
            "Epoch 38/500\n",
            "45/45 [==============================] - 1s 11ms/step - loss: 6.8879 - mae: 7.3691 - val_loss: 6.6915 - val_mae: 7.1719\n",
            "\n",
            "Epoch 00038: loss did not improve from 6.68516\n",
            "Epoch 39/500\n",
            "45/45 [==============================] - 1s 11ms/step - loss: 6.8772 - mae: 7.3592 - val_loss: 7.0924 - val_mae: 7.5745\n",
            "\n",
            "Epoch 00039: loss did not improve from 6.68516\n",
            "Epoch 40/500\n",
            "45/45 [==============================] - 1s 11ms/step - loss: 6.9616 - mae: 7.4433 - val_loss: 7.2475 - val_mae: 7.7313\n",
            "\n",
            "Epoch 00040: loss did not improve from 6.68516\n",
            "Epoch 41/500\n",
            "45/45 [==============================] - 1s 11ms/step - loss: 7.0997 - mae: 7.5834 - val_loss: 8.2808 - val_mae: 8.7679\n",
            "\n",
            "Epoch 00041: loss did not improve from 6.68516\n",
            "Epoch 42/500\n",
            "45/45 [==============================] - 1s 11ms/step - loss: 7.3015 - mae: 7.7844 - val_loss: 6.7196 - val_mae: 7.1997\n",
            "\n",
            "Epoch 00042: loss did not improve from 6.68516\n",
            "Epoch 43/500\n",
            "45/45 [==============================] - 1s 11ms/step - loss: 6.4863 - mae: 6.9672 - val_loss: 6.6975 - val_mae: 7.1794\n",
            "\n",
            "Epoch 00043: loss did not improve from 6.68516\n",
            "Epoch 44/500\n",
            "45/45 [==============================] - 1s 11ms/step - loss: 6.6860 - mae: 7.1667 - val_loss: 6.8907 - val_mae: 7.3733\n",
            "\n",
            "Epoch 00044: loss did not improve from 6.68516\n",
            "Epoch 45/500\n",
            "45/45 [==============================] - 1s 11ms/step - loss: 7.0254 - mae: 7.5075 - val_loss: 6.5173 - val_mae: 6.9971\n",
            "\n",
            "Epoch 00045: loss did not improve from 6.68516\n",
            "Epoch 46/500\n",
            "45/45 [==============================] - 1s 11ms/step - loss: 6.7144 - mae: 7.1944 - val_loss: 6.6426 - val_mae: 7.1246\n",
            "\n",
            "Epoch 00046: loss improved from 6.68516 to 6.67608, saving model to poids.hdf5\n",
            "Epoch 47/500\n",
            "45/45 [==============================] - 1s 11ms/step - loss: 6.4858 - mae: 6.9673 - val_loss: 6.8744 - val_mae: 7.3569\n",
            "\n",
            "Epoch 00047: loss did not improve from 6.67608\n",
            "Epoch 48/500\n",
            "45/45 [==============================] - 1s 11ms/step - loss: 7.0779 - mae: 7.5588 - val_loss: 6.5724 - val_mae: 7.0541\n",
            "\n",
            "Epoch 00048: loss did not improve from 6.67608\n",
            "Epoch 49/500\n",
            "45/45 [==============================] - 1s 12ms/step - loss: 6.8347 - mae: 7.3158 - val_loss: 6.9164 - val_mae: 7.3990\n",
            "\n",
            "Epoch 00049: loss did not improve from 6.67608\n",
            "Epoch 50/500\n",
            "45/45 [==============================] - 1s 11ms/step - loss: 6.6342 - mae: 7.1150 - val_loss: 7.1919 - val_mae: 7.6753\n",
            "\n",
            "Epoch 00050: loss did not improve from 6.67608\n",
            "Epoch 51/500\n",
            "45/45 [==============================] - 1s 11ms/step - loss: 6.7208 - mae: 7.2030 - val_loss: 6.9483 - val_mae: 7.4306\n",
            "\n",
            "Epoch 00051: loss did not improve from 6.67608\n",
            "Epoch 52/500\n",
            "45/45 [==============================] - 1s 11ms/step - loss: 6.7828 - mae: 7.2639 - val_loss: 6.7332 - val_mae: 7.2142\n",
            "\n",
            "Epoch 00052: loss improved from 6.67608 to 6.60080, saving model to poids.hdf5\n",
            "Epoch 53/500\n",
            "45/45 [==============================] - 1s 11ms/step - loss: 6.9649 - mae: 7.4472 - val_loss: 6.6332 - val_mae: 7.1140\n",
            "\n",
            "Epoch 00053: loss did not improve from 6.60080\n",
            "Epoch 54/500\n",
            "45/45 [==============================] - 1s 11ms/step - loss: 6.6769 - mae: 7.1593 - val_loss: 6.7155 - val_mae: 7.1975\n",
            "\n",
            "Epoch 00054: loss did not improve from 6.60080\n",
            "Epoch 55/500\n",
            "45/45 [==============================] - 1s 11ms/step - loss: 6.9997 - mae: 7.4804 - val_loss: 6.6437 - val_mae: 7.1233\n",
            "\n",
            "Epoch 00055: loss did not improve from 6.60080\n",
            "Epoch 56/500\n",
            "45/45 [==============================] - 1s 11ms/step - loss: 6.7510 - mae: 7.2319 - val_loss: 7.1581 - val_mae: 7.6418\n",
            "\n",
            "Epoch 00056: loss did not improve from 6.60080\n",
            "Epoch 57/500\n",
            "45/45 [==============================] - 1s 11ms/step - loss: 6.8505 - mae: 7.3318 - val_loss: 7.0576 - val_mae: 7.5417\n",
            "\n",
            "Epoch 00057: loss did not improve from 6.60080\n",
            "Epoch 58/500\n",
            "45/45 [==============================] - 1s 11ms/step - loss: 6.4986 - mae: 6.9786 - val_loss: 6.5751 - val_mae: 7.0563\n",
            "\n",
            "Epoch 00058: loss did not improve from 6.60080\n",
            "Epoch 59/500\n",
            "45/45 [==============================] - 1s 11ms/step - loss: 6.9417 - mae: 7.4238 - val_loss: 6.7186 - val_mae: 7.2003\n",
            "\n",
            "Epoch 00059: loss did not improve from 6.60080\n",
            "Epoch 60/500\n",
            "45/45 [==============================] - 1s 11ms/step - loss: 6.9928 - mae: 7.4747 - val_loss: 6.3678 - val_mae: 6.8484\n",
            "\n",
            "Epoch 00060: loss did not improve from 6.60080\n",
            "Epoch 61/500\n",
            "45/45 [==============================] - 1s 11ms/step - loss: 6.6072 - mae: 7.0877 - val_loss: 6.7612 - val_mae: 7.2428\n",
            "\n",
            "Epoch 00061: loss did not improve from 6.60080\n",
            "Epoch 62/500\n",
            "45/45 [==============================] - 1s 11ms/step - loss: 6.3645 - mae: 6.8450 - val_loss: 6.4963 - val_mae: 6.9779\n",
            "\n",
            "Epoch 00062: loss did not improve from 6.60080\n",
            "Epoch 63/500\n",
            "45/45 [==============================] - 1s 10ms/step - loss: 6.3465 - mae: 6.8275 - val_loss: 6.8837 - val_mae: 7.3662\n",
            "\n",
            "Epoch 00063: loss did not improve from 6.60080\n",
            "Epoch 64/500\n",
            "45/45 [==============================] - 1s 11ms/step - loss: 6.3897 - mae: 6.8703 - val_loss: 7.4025 - val_mae: 7.8855\n",
            "\n",
            "Epoch 00064: loss did not improve from 6.60080\n",
            "Epoch 65/500\n",
            "45/45 [==============================] - 1s 11ms/step - loss: 6.9376 - mae: 7.4186 - val_loss: 7.5102 - val_mae: 7.9953\n",
            "\n",
            "Epoch 00065: loss did not improve from 6.60080\n",
            "Epoch 66/500\n",
            "45/45 [==============================] - 1s 11ms/step - loss: 7.2271 - mae: 7.7105 - val_loss: 6.6175 - val_mae: 7.0993\n",
            "\n",
            "Epoch 00066: loss did not improve from 6.60080\n",
            "Epoch 67/500\n",
            "45/45 [==============================] - 1s 11ms/step - loss: 6.4353 - mae: 6.9148 - val_loss: 6.4462 - val_mae: 6.9279\n",
            "\n",
            "Epoch 00067: loss did not improve from 6.60080\n",
            "Epoch 68/500\n",
            "45/45 [==============================] - 1s 11ms/step - loss: 6.6150 - mae: 7.0960 - val_loss: 6.5451 - val_mae: 7.0262\n",
            "\n",
            "Epoch 00068: loss did not improve from 6.60080\n",
            "Epoch 69/500\n",
            "45/45 [==============================] - 1s 11ms/step - loss: 6.5615 - mae: 7.0431 - val_loss: 6.6063 - val_mae: 7.0887\n",
            "\n",
            "Epoch 00069: loss did not improve from 6.60080\n",
            "Epoch 70/500\n",
            "45/45 [==============================] - 1s 10ms/step - loss: 6.9167 - mae: 7.3987 - val_loss: 6.6503 - val_mae: 7.1306\n",
            "\n",
            "Epoch 00070: loss did not improve from 6.60080\n",
            "Epoch 71/500\n",
            "45/45 [==============================] - 1s 11ms/step - loss: 6.8193 - mae: 7.3010 - val_loss: 6.5692 - val_mae: 7.0492\n",
            "\n",
            "Epoch 00071: loss did not improve from 6.60080\n",
            "Epoch 72/500\n",
            "45/45 [==============================] - 1s 11ms/step - loss: 6.5818 - mae: 7.0615 - val_loss: 6.6736 - val_mae: 7.1556\n",
            "\n",
            "Epoch 00072: loss improved from 6.60080 to 6.59061, saving model to poids.hdf5\n",
            "Epoch 73/500\n",
            "45/45 [==============================] - 1s 11ms/step - loss: 7.3793 - mae: 7.8625 - val_loss: 6.8536 - val_mae: 7.3341\n",
            "\n",
            "Epoch 00073: loss did not improve from 6.59061\n",
            "Epoch 74/500\n",
            "45/45 [==============================] - 1s 11ms/step - loss: 6.9072 - mae: 7.3892 - val_loss: 6.4564 - val_mae: 6.9368\n",
            "\n",
            "Epoch 00074: loss did not improve from 6.59061\n",
            "Epoch 75/500\n",
            "45/45 [==============================] - 1s 11ms/step - loss: 6.8061 - mae: 7.2880 - val_loss: 6.5592 - val_mae: 7.0399\n",
            "\n",
            "Epoch 00075: loss did not improve from 6.59061\n",
            "Epoch 76/500\n",
            "45/45 [==============================] - 1s 11ms/step - loss: 6.5298 - mae: 7.0104 - val_loss: 6.7137 - val_mae: 7.1957\n",
            "\n",
            "Epoch 00076: loss did not improve from 6.59061\n",
            "Epoch 77/500\n",
            "45/45 [==============================] - 1s 11ms/step - loss: 6.8740 - mae: 7.3557 - val_loss: 7.2132 - val_mae: 7.6966\n",
            "\n",
            "Epoch 00077: loss did not improve from 6.59061\n",
            "Epoch 78/500\n",
            "45/45 [==============================] - 1s 11ms/step - loss: 6.5234 - mae: 7.0041 - val_loss: 6.7712 - val_mae: 7.2529\n",
            "\n",
            "Epoch 00078: loss did not improve from 6.59061\n",
            "Epoch 79/500\n",
            "45/45 [==============================] - 1s 11ms/step - loss: 6.5184 - mae: 6.9993 - val_loss: 6.6890 - val_mae: 7.1708\n",
            "\n",
            "Epoch 00079: loss did not improve from 6.59061\n",
            "Epoch 80/500\n",
            "45/45 [==============================] - 1s 11ms/step - loss: 6.5598 - mae: 7.0407 - val_loss: 6.6939 - val_mae: 7.1745\n",
            "\n",
            "Epoch 00080: loss did not improve from 6.59061\n",
            "Epoch 81/500\n",
            "45/45 [==============================] - 1s 12ms/step - loss: 6.9888 - mae: 7.4706 - val_loss: 6.6661 - val_mae: 7.1472\n",
            "\n",
            "Epoch 00081: loss did not improve from 6.59061\n",
            "Epoch 82/500\n",
            "45/45 [==============================] - 1s 11ms/step - loss: 6.7729 - mae: 7.2548 - val_loss: 6.6057 - val_mae: 7.0860\n",
            "\n",
            "Epoch 00082: loss did not improve from 6.59061\n",
            "Epoch 83/500\n",
            "45/45 [==============================] - 1s 12ms/step - loss: 7.0774 - mae: 7.5591 - val_loss: 6.7237 - val_mae: 7.2054\n",
            "\n",
            "Epoch 00083: loss did not improve from 6.59061\n",
            "Epoch 84/500\n",
            "45/45 [==============================] - 1s 12ms/step - loss: 6.5262 - mae: 7.0064 - val_loss: 6.7120 - val_mae: 7.1937\n",
            "\n",
            "Epoch 00084: loss did not improve from 6.59061\n",
            "Epoch 85/500\n",
            "45/45 [==============================] - 1s 11ms/step - loss: 7.1104 - mae: 7.5925 - val_loss: 6.5635 - val_mae: 7.0435\n",
            "\n",
            "Epoch 00085: loss did not improve from 6.59061\n",
            "Epoch 86/500\n",
            "45/45 [==============================] - 1s 12ms/step - loss: 7.0329 - mae: 7.5160 - val_loss: 6.6055 - val_mae: 7.0855\n",
            "\n",
            "Epoch 00086: loss did not improve from 6.59061\n",
            "Epoch 87/500\n",
            "45/45 [==============================] - 1s 11ms/step - loss: 6.5442 - mae: 7.0252 - val_loss: 6.6932 - val_mae: 7.1746\n",
            "\n",
            "Epoch 00087: loss did not improve from 6.59061\n",
            "Epoch 88/500\n",
            "45/45 [==============================] - 1s 11ms/step - loss: 6.9327 - mae: 7.4141 - val_loss: 6.6063 - val_mae: 7.0876\n",
            "\n",
            "Epoch 00088: loss did not improve from 6.59061\n",
            "Epoch 89/500\n",
            "45/45 [==============================] - 1s 11ms/step - loss: 6.9480 - mae: 7.4283 - val_loss: 7.1964 - val_mae: 7.6798\n",
            "\n",
            "Epoch 00089: loss did not improve from 6.59061\n",
            "Epoch 90/500\n",
            "45/45 [==============================] - 1s 11ms/step - loss: 6.4982 - mae: 6.9787 - val_loss: 6.6443 - val_mae: 7.1252\n",
            "\n",
            "Epoch 00090: loss did not improve from 6.59061\n",
            "Epoch 91/500\n",
            "45/45 [==============================] - 1s 11ms/step - loss: 6.8454 - mae: 7.3270 - val_loss: 6.7198 - val_mae: 7.2016\n",
            "\n",
            "Epoch 00091: loss did not improve from 6.59061\n",
            "Epoch 92/500\n",
            "45/45 [==============================] - 1s 11ms/step - loss: 6.5369 - mae: 7.0200 - val_loss: 6.6409 - val_mae: 7.1207\n",
            "\n",
            "Epoch 00092: loss did not improve from 6.59061\n",
            "Epoch 93/500\n",
            "45/45 [==============================] - 1s 11ms/step - loss: 6.7187 - mae: 7.1997 - val_loss: 6.7552 - val_mae: 7.2367\n",
            "\n",
            "Epoch 00093: loss did not improve from 6.59061\n",
            "Epoch 94/500\n",
            "45/45 [==============================] - 1s 11ms/step - loss: 6.6963 - mae: 7.1783 - val_loss: 6.7826 - val_mae: 7.2641\n",
            "\n",
            "Epoch 00094: loss did not improve from 6.59061\n",
            "Epoch 95/500\n",
            "45/45 [==============================] - 1s 11ms/step - loss: 6.7270 - mae: 7.2077 - val_loss: 6.7570 - val_mae: 7.2386\n",
            "\n",
            "Epoch 00095: loss did not improve from 6.59061\n",
            "Epoch 96/500\n",
            "45/45 [==============================] - 1s 11ms/step - loss: 6.5075 - mae: 6.9879 - val_loss: 6.6898 - val_mae: 7.1717\n",
            "\n",
            "Epoch 00096: loss did not improve from 6.59061\n",
            "Epoch 97/500\n",
            "45/45 [==============================] - 1s 11ms/step - loss: 6.5898 - mae: 7.0705 - val_loss: 6.8052 - val_mae: 7.2867\n",
            "\n",
            "Epoch 00097: loss did not improve from 6.59061\n",
            "Epoch 98/500\n",
            "45/45 [==============================] - 1s 13ms/step - loss: 6.6947 - mae: 7.1767 - val_loss: 6.4792 - val_mae: 6.9603\n",
            "\n",
            "Epoch 00098: loss did not improve from 6.59061\n",
            "Epoch 99/500\n",
            "45/45 [==============================] - 1s 11ms/step - loss: 6.4454 - mae: 6.9268 - val_loss: 6.5261 - val_mae: 7.0064\n",
            "\n",
            "Epoch 00099: loss improved from 6.59061 to 6.54541, saving model to poids.hdf5\n",
            "Epoch 100/500\n",
            "45/45 [==============================] - 1s 12ms/step - loss: 6.5630 - mae: 7.0424 - val_loss: 6.5305 - val_mae: 7.0118\n",
            "\n",
            "Epoch 00100: loss did not improve from 6.54541\n",
            "Epoch 101/500\n",
            "45/45 [==============================] - 1s 11ms/step - loss: 6.5009 - mae: 6.9814 - val_loss: 7.3652 - val_mae: 7.8495\n",
            "\n",
            "Epoch 00101: loss did not improve from 6.54541\n",
            "Epoch 102/500\n",
            "45/45 [==============================] - 1s 12ms/step - loss: 6.7864 - mae: 7.2682 - val_loss: 6.8427 - val_mae: 7.3251\n",
            "\n",
            "Epoch 00102: loss did not improve from 6.54541\n",
            "Epoch 103/500\n",
            "45/45 [==============================] - 1s 11ms/step - loss: 6.7350 - mae: 7.2161 - val_loss: 7.2679 - val_mae: 7.7509\n",
            "\n",
            "Epoch 00103: loss did not improve from 6.54541\n",
            "Epoch 104/500\n",
            "45/45 [==============================] - 1s 11ms/step - loss: 6.8301 - mae: 7.3119 - val_loss: 6.9110 - val_mae: 7.3932\n",
            "\n",
            "Epoch 00104: loss did not improve from 6.54541\n",
            "Epoch 105/500\n",
            "45/45 [==============================] - 1s 11ms/step - loss: 6.4262 - mae: 6.9072 - val_loss: 7.0456 - val_mae: 7.5292\n",
            "\n",
            "Epoch 00105: loss did not improve from 6.54541\n",
            "Epoch 106/500\n",
            "45/45 [==============================] - 1s 11ms/step - loss: 6.7460 - mae: 7.2272 - val_loss: 7.0552 - val_mae: 7.5385\n",
            "\n",
            "Epoch 00106: loss did not improve from 6.54541\n",
            "Epoch 107/500\n",
            "45/45 [==============================] - 1s 11ms/step - loss: 6.8912 - mae: 7.3717 - val_loss: 6.5485 - val_mae: 7.0297\n",
            "\n",
            "Epoch 00107: loss did not improve from 6.54541\n",
            "Epoch 108/500\n",
            "45/45 [==============================] - 1s 11ms/step - loss: 6.3061 - mae: 6.7861 - val_loss: 6.4382 - val_mae: 6.9183\n",
            "\n",
            "Epoch 00108: loss improved from 6.54541 to 6.49652, saving model to poids.hdf5\n",
            "Epoch 109/500\n",
            "45/45 [==============================] - 1s 11ms/step - loss: 6.7235 - mae: 7.2043 - val_loss: 6.6288 - val_mae: 7.1095\n",
            "\n",
            "Epoch 00109: loss did not improve from 6.49652\n",
            "Epoch 110/500\n",
            "45/45 [==============================] - 1s 11ms/step - loss: 6.5171 - mae: 6.9987 - val_loss: 6.7696 - val_mae: 7.2500\n",
            "\n",
            "Epoch 00110: loss did not improve from 6.49652\n",
            "Epoch 111/500\n",
            "45/45 [==============================] - 1s 11ms/step - loss: 6.2980 - mae: 6.7777 - val_loss: 6.5582 - val_mae: 7.0403\n",
            "\n",
            "Epoch 00111: loss did not improve from 6.49652\n",
            "Epoch 112/500\n",
            "45/45 [==============================] - 1s 11ms/step - loss: 6.9626 - mae: 7.4446 - val_loss: 6.5678 - val_mae: 7.0495\n",
            "\n",
            "Epoch 00112: loss did not improve from 6.49652\n",
            "Epoch 113/500\n",
            "45/45 [==============================] - 1s 11ms/step - loss: 6.5360 - mae: 7.0175 - val_loss: 6.4399 - val_mae: 6.9201\n",
            "\n",
            "Epoch 00113: loss did not improve from 6.49652\n",
            "Epoch 114/500\n",
            "45/45 [==============================] - 1s 11ms/step - loss: 6.7337 - mae: 7.2146 - val_loss: 6.5176 - val_mae: 6.9980\n",
            "\n",
            "Epoch 00114: loss did not improve from 6.49652\n",
            "Epoch 115/500\n",
            "45/45 [==============================] - 1s 11ms/step - loss: 6.5795 - mae: 7.0620 - val_loss: 6.8513 - val_mae: 7.3332\n",
            "\n",
            "Epoch 00115: loss did not improve from 6.49652\n",
            "Epoch 116/500\n",
            "45/45 [==============================] - 1s 12ms/step - loss: 7.0651 - mae: 7.5462 - val_loss: 7.3590 - val_mae: 7.8427\n",
            "\n",
            "Epoch 00116: loss did not improve from 6.49652\n",
            "Epoch 117/500\n",
            "45/45 [==============================] - 1s 11ms/step - loss: 6.7525 - mae: 7.2340 - val_loss: 6.4740 - val_mae: 6.9550\n",
            "\n",
            "Epoch 00117: loss did not improve from 6.49652\n",
            "Epoch 118/500\n",
            "45/45 [==============================] - 1s 12ms/step - loss: 6.5809 - mae: 7.0615 - val_loss: 6.7684 - val_mae: 7.2490\n",
            "\n",
            "Epoch 00118: loss did not improve from 6.49652\n",
            "Epoch 119/500\n",
            "45/45 [==============================] - 1s 11ms/step - loss: 6.9145 - mae: 7.3962 - val_loss: 7.7839 - val_mae: 8.2690\n",
            "\n",
            "Epoch 00119: loss did not improve from 6.49652\n",
            "Epoch 120/500\n",
            "45/45 [==============================] - 1s 11ms/step - loss: 6.7947 - mae: 7.2768 - val_loss: 6.8126 - val_mae: 7.2933\n",
            "\n",
            "Epoch 00120: loss did not improve from 6.49652\n",
            "Epoch 121/500\n",
            "45/45 [==============================] - 1s 11ms/step - loss: 6.7320 - mae: 7.2131 - val_loss: 7.5697 - val_mae: 8.0557\n",
            "\n",
            "Epoch 00121: loss did not improve from 6.49652\n",
            "Epoch 122/500\n",
            "45/45 [==============================] - 1s 11ms/step - loss: 6.5265 - mae: 7.0060 - val_loss: 6.5851 - val_mae: 7.0668\n",
            "\n",
            "Epoch 00122: loss did not improve from 6.49652\n",
            "Epoch 123/500\n",
            "45/45 [==============================] - 1s 12ms/step - loss: 6.8243 - mae: 7.3043 - val_loss: 7.0498 - val_mae: 7.5329\n",
            "\n",
            "Epoch 00123: loss did not improve from 6.49652\n",
            "Epoch 124/500\n",
            "45/45 [==============================] - 1s 11ms/step - loss: 6.8033 - mae: 7.2838 - val_loss: 7.3174 - val_mae: 7.8023\n",
            "\n",
            "Epoch 00124: loss did not improve from 6.49652\n",
            "Epoch 125/500\n",
            "45/45 [==============================] - 1s 11ms/step - loss: 6.7583 - mae: 7.2396 - val_loss: 6.5416 - val_mae: 7.0231\n",
            "\n",
            "Epoch 00125: loss did not improve from 6.49652\n",
            "Epoch 126/500\n",
            "45/45 [==============================] - 1s 12ms/step - loss: 6.2900 - mae: 6.7702 - val_loss: 6.6925 - val_mae: 7.1735\n",
            "\n",
            "Epoch 00126: loss did not improve from 6.49652\n",
            "Epoch 127/500\n",
            "45/45 [==============================] - 1s 11ms/step - loss: 6.6686 - mae: 7.1481 - val_loss: 7.0777 - val_mae: 7.5603\n",
            "\n",
            "Epoch 00127: loss did not improve from 6.49652\n",
            "Epoch 128/500\n",
            "45/45 [==============================] - 1s 11ms/step - loss: 6.7152 - mae: 7.1970 - val_loss: 7.1348 - val_mae: 7.6182\n",
            "\n",
            "Epoch 00128: loss did not improve from 6.49652\n",
            "Epoch 129/500\n",
            "45/45 [==============================] - 1s 11ms/step - loss: 6.6138 - mae: 7.0946 - val_loss: 7.3197 - val_mae: 7.8034\n",
            "\n",
            "Epoch 00129: loss did not improve from 6.49652\n",
            "Epoch 130/500\n",
            "45/45 [==============================] - 1s 11ms/step - loss: 6.8630 - mae: 7.3442 - val_loss: 6.5148 - val_mae: 6.9954\n",
            "\n",
            "Epoch 00130: loss did not improve from 6.49652\n",
            "Epoch 131/500\n",
            "45/45 [==============================] - 1s 11ms/step - loss: 6.4907 - mae: 6.9715 - val_loss: 6.6108 - val_mae: 7.0912\n",
            "\n",
            "Epoch 00131: loss improved from 6.49652 to 6.48941, saving model to poids.hdf5\n",
            "Epoch 132/500\n",
            "45/45 [==============================] - 1s 11ms/step - loss: 6.8306 - mae: 7.3114 - val_loss: 6.7234 - val_mae: 7.2049\n",
            "\n",
            "Epoch 00132: loss did not improve from 6.48941\n",
            "Epoch 133/500\n",
            "45/45 [==============================] - 1s 12ms/step - loss: 7.1038 - mae: 7.5841 - val_loss: 6.4776 - val_mae: 6.9585\n",
            "\n",
            "Epoch 00133: loss did not improve from 6.48941\n",
            "Epoch 134/500\n",
            "45/45 [==============================] - 1s 11ms/step - loss: 6.5387 - mae: 7.0188 - val_loss: 7.3651 - val_mae: 7.8505\n",
            "\n",
            "Epoch 00134: loss did not improve from 6.48941\n",
            "Epoch 135/500\n",
            "45/45 [==============================] - 1s 11ms/step - loss: 6.9825 - mae: 7.4647 - val_loss: 6.4017 - val_mae: 6.8825\n",
            "\n",
            "Epoch 00135: loss did not improve from 6.48941\n",
            "Epoch 136/500\n",
            "45/45 [==============================] - 1s 11ms/step - loss: 6.4471 - mae: 6.9285 - val_loss: 6.6103 - val_mae: 7.0916\n",
            "\n",
            "Epoch 00136: loss did not improve from 6.48941\n",
            "Epoch 137/500\n",
            "45/45 [==============================] - 1s 11ms/step - loss: 6.3648 - mae: 6.8446 - val_loss: 6.9553 - val_mae: 7.4371\n",
            "\n",
            "Epoch 00137: loss did not improve from 6.48941\n",
            "Epoch 138/500\n",
            "45/45 [==============================] - 1s 11ms/step - loss: 6.8434 - mae: 7.3246 - val_loss: 6.7179 - val_mae: 7.1995\n",
            "\n",
            "Epoch 00138: loss did not improve from 6.48941\n",
            "Epoch 139/500\n",
            "45/45 [==============================] - 1s 11ms/step - loss: 6.5642 - mae: 7.0449 - val_loss: 6.8926 - val_mae: 7.3747\n",
            "\n",
            "Epoch 00139: loss did not improve from 6.48941\n",
            "Epoch 140/500\n",
            "45/45 [==============================] - 1s 12ms/step - loss: 6.7847 - mae: 7.2652 - val_loss: 6.6526 - val_mae: 7.1347\n",
            "\n",
            "Epoch 00140: loss did not improve from 6.48941\n",
            "Epoch 141/500\n",
            "45/45 [==============================] - 1s 11ms/step - loss: 6.4942 - mae: 6.9734 - val_loss: 7.1322 - val_mae: 7.6157\n",
            "\n",
            "Epoch 00141: loss did not improve from 6.48941\n",
            "Epoch 142/500\n",
            "45/45 [==============================] - 1s 11ms/step - loss: 6.9197 - mae: 7.4017 - val_loss: 6.6349 - val_mae: 7.1151\n",
            "\n",
            "Epoch 00142: loss did not improve from 6.48941\n",
            "Epoch 143/500\n",
            "45/45 [==============================] - 1s 11ms/step - loss: 6.7262 - mae: 7.2069 - val_loss: 6.5981 - val_mae: 7.0784\n",
            "\n",
            "Epoch 00143: loss did not improve from 6.48941\n",
            "Epoch 144/500\n",
            "45/45 [==============================] - 1s 11ms/step - loss: 6.5592 - mae: 7.0396 - val_loss: 6.5642 - val_mae: 7.0459\n",
            "\n",
            "Epoch 00144: loss did not improve from 6.48941\n",
            "Epoch 145/500\n",
            "45/45 [==============================] - 1s 11ms/step - loss: 6.3612 - mae: 6.8409 - val_loss: 6.9441 - val_mae: 7.4268\n",
            "\n",
            "Epoch 00145: loss did not improve from 6.48941\n",
            "Epoch 146/500\n",
            "45/45 [==============================] - 1s 11ms/step - loss: 6.9000 - mae: 7.3820 - val_loss: 6.6381 - val_mae: 7.1194\n",
            "\n",
            "Epoch 00146: loss did not improve from 6.48941\n",
            "Epoch 147/500\n",
            "45/45 [==============================] - 1s 11ms/step - loss: 6.6252 - mae: 7.1058 - val_loss: 6.4589 - val_mae: 6.9401\n",
            "\n",
            "Epoch 00147: loss did not improve from 6.48941\n",
            "Epoch 148/500\n",
            "45/45 [==============================] - 1s 12ms/step - loss: 6.6936 - mae: 7.1754 - val_loss: 6.5940 - val_mae: 7.0750\n",
            "\n",
            "Epoch 00148: loss did not improve from 6.48941\n",
            "Epoch 149/500\n",
            "45/45 [==============================] - 1s 11ms/step - loss: 6.3690 - mae: 6.8504 - val_loss: 6.9349 - val_mae: 7.4167\n",
            "\n",
            "Epoch 00149: loss did not improve from 6.48941\n",
            "Epoch 150/500\n",
            "45/45 [==============================] - 1s 12ms/step - loss: 6.4497 - mae: 6.9301 - val_loss: 6.4366 - val_mae: 6.9177\n",
            "\n",
            "Epoch 00150: loss did not improve from 6.48941\n",
            "Epoch 151/500\n",
            "45/45 [==============================] - 1s 11ms/step - loss: 6.7147 - mae: 7.1957 - val_loss: 8.6853 - val_mae: 9.1730\n",
            "\n",
            "Epoch 00151: loss did not improve from 6.48941\n",
            "Epoch 152/500\n",
            "45/45 [==============================] - 1s 11ms/step - loss: 6.9348 - mae: 7.4166 - val_loss: 6.5377 - val_mae: 7.0191\n",
            "\n",
            "Epoch 00152: loss did not improve from 6.48941\n",
            "Epoch 153/500\n",
            "45/45 [==============================] - 1s 12ms/step - loss: 6.4634 - mae: 6.9438 - val_loss: 6.4718 - val_mae: 6.9528\n",
            "\n",
            "Epoch 00153: loss did not improve from 6.48941\n",
            "Epoch 154/500\n",
            "45/45 [==============================] - 1s 11ms/step - loss: 6.2504 - mae: 6.7299 - val_loss: 7.4684 - val_mae: 7.9532\n",
            "\n",
            "Epoch 00154: loss did not improve from 6.48941\n",
            "Epoch 155/500\n",
            "45/45 [==============================] - 1s 12ms/step - loss: 6.8653 - mae: 7.3460 - val_loss: 6.6682 - val_mae: 7.1496\n",
            "\n",
            "Epoch 00155: loss did not improve from 6.48941\n",
            "Epoch 156/500\n",
            "45/45 [==============================] - 1s 11ms/step - loss: 6.7723 - mae: 7.2541 - val_loss: 6.6105 - val_mae: 7.0917\n",
            "\n",
            "Epoch 00156: loss did not improve from 6.48941\n",
            "Epoch 157/500\n",
            "45/45 [==============================] - 1s 11ms/step - loss: 6.6571 - mae: 7.1381 - val_loss: 6.5845 - val_mae: 7.0645\n",
            "\n",
            "Epoch 00157: loss did not improve from 6.48941\n",
            "Epoch 158/500\n",
            "45/45 [==============================] - 1s 12ms/step - loss: 6.8382 - mae: 7.3181 - val_loss: 6.7326 - val_mae: 7.2144\n",
            "\n",
            "Epoch 00158: loss did not improve from 6.48941\n",
            "Epoch 159/500\n",
            "45/45 [==============================] - 1s 11ms/step - loss: 6.5792 - mae: 7.0604 - val_loss: 6.5438 - val_mae: 7.0249\n",
            "\n",
            "Epoch 00159: loss did not improve from 6.48941\n",
            "Epoch 160/500\n",
            "45/45 [==============================] - 1s 11ms/step - loss: 6.7335 - mae: 7.2146 - val_loss: 6.5939 - val_mae: 7.0750\n",
            "\n",
            "Epoch 00160: loss did not improve from 6.48941\n",
            "Epoch 161/500\n",
            "45/45 [==============================] - 1s 11ms/step - loss: 6.8117 - mae: 7.2929 - val_loss: 6.6350 - val_mae: 7.1159\n",
            "\n",
            "Epoch 00161: loss did not improve from 6.48941\n",
            "Epoch 162/500\n",
            "45/45 [==============================] - 1s 12ms/step - loss: 6.5142 - mae: 6.9941 - val_loss: 6.5184 - val_mae: 6.9981\n",
            "\n",
            "Epoch 00162: loss did not improve from 6.48941\n",
            "Epoch 163/500\n",
            "45/45 [==============================] - 1s 11ms/step - loss: 6.4791 - mae: 6.9587 - val_loss: 6.7783 - val_mae: 7.2594\n",
            "\n",
            "Epoch 00163: loss did not improve from 6.48941\n",
            "Epoch 164/500\n",
            "45/45 [==============================] - 1s 13ms/step - loss: 6.6633 - mae: 7.1466 - val_loss: 7.6873 - val_mae: 8.1730\n",
            "\n",
            "Epoch 00164: loss did not improve from 6.48941\n",
            "Epoch 165/500\n",
            "45/45 [==============================] - 1s 11ms/step - loss: 6.9144 - mae: 7.3968 - val_loss: 6.5666 - val_mae: 7.0465\n",
            "\n",
            "Epoch 00165: loss did not improve from 6.48941\n",
            "Epoch 166/500\n",
            "45/45 [==============================] - 1s 12ms/step - loss: 6.6428 - mae: 7.1214 - val_loss: 7.3599 - val_mae: 7.8438\n",
            "\n",
            "Epoch 00166: loss did not improve from 6.48941\n",
            "Epoch 167/500\n",
            "45/45 [==============================] - 1s 12ms/step - loss: 6.3147 - mae: 6.7949 - val_loss: 6.5410 - val_mae: 7.0230\n",
            "\n",
            "Epoch 00167: loss did not improve from 6.48941\n",
            "Epoch 168/500\n",
            "45/45 [==============================] - 1s 11ms/step - loss: 6.4330 - mae: 6.9136 - val_loss: 6.4046 - val_mae: 6.8858\n",
            "\n",
            "Epoch 00168: loss did not improve from 6.48941\n",
            "Epoch 169/500\n",
            "45/45 [==============================] - 1s 11ms/step - loss: 6.4412 - mae: 6.9211 - val_loss: 6.6672 - val_mae: 7.1477\n",
            "\n",
            "Epoch 00169: loss improved from 6.48941 to 6.44946, saving model to poids.hdf5\n",
            "Epoch 170/500\n",
            "45/45 [==============================] - 1s 11ms/step - loss: 6.5171 - mae: 6.9961 - val_loss: 6.5505 - val_mae: 7.0313\n",
            "\n",
            "Epoch 00170: loss did not improve from 6.44946\n",
            "Epoch 171/500\n",
            "45/45 [==============================] - 1s 12ms/step - loss: 6.5657 - mae: 7.0458 - val_loss: 7.2500 - val_mae: 7.7321\n",
            "\n",
            "Epoch 00171: loss did not improve from 6.44946\n",
            "Epoch 172/500\n",
            "45/45 [==============================] - 1s 12ms/step - loss: 6.6292 - mae: 7.1107 - val_loss: 6.6896 - val_mae: 7.1707\n",
            "\n",
            "Epoch 00172: loss did not improve from 6.44946\n",
            "Epoch 173/500\n",
            "45/45 [==============================] - 1s 12ms/step - loss: 7.1357 - mae: 7.6166 - val_loss: 6.5108 - val_mae: 6.9912\n",
            "\n",
            "Epoch 00173: loss did not improve from 6.44946\n",
            "Epoch 174/500\n",
            "45/45 [==============================] - 1s 11ms/step - loss: 6.6281 - mae: 7.1093 - val_loss: 6.7212 - val_mae: 7.2031\n",
            "\n",
            "Epoch 00174: loss did not improve from 6.44946\n",
            "Epoch 175/500\n",
            "45/45 [==============================] - 1s 11ms/step - loss: 6.5407 - mae: 7.0226 - val_loss: 6.5371 - val_mae: 7.0184\n",
            "\n",
            "Epoch 00175: loss did not improve from 6.44946\n",
            "Epoch 176/500\n",
            "45/45 [==============================] - 1s 12ms/step - loss: 6.5320 - mae: 7.0135 - val_loss: 6.6072 - val_mae: 7.0890\n",
            "\n",
            "Epoch 00176: loss did not improve from 6.44946\n",
            "Epoch 177/500\n",
            "45/45 [==============================] - 1s 11ms/step - loss: 6.7101 - mae: 7.1923 - val_loss: 6.3305 - val_mae: 6.8113\n",
            "\n",
            "Epoch 00177: loss did not improve from 6.44946\n",
            "Epoch 178/500\n",
            "45/45 [==============================] - 1s 12ms/step - loss: 6.4804 - mae: 6.9595 - val_loss: 6.6154 - val_mae: 7.0975\n",
            "\n",
            "Epoch 00178: loss did not improve from 6.44946\n",
            "Epoch 179/500\n",
            "45/45 [==============================] - 1s 12ms/step - loss: 6.8599 - mae: 7.3409 - val_loss: 6.5916 - val_mae: 7.0736\n",
            "\n",
            "Epoch 00179: loss did not improve from 6.44946\n",
            "Epoch 180/500\n",
            "45/45 [==============================] - 1s 12ms/step - loss: 6.6681 - mae: 7.1488 - val_loss: 6.5974 - val_mae: 7.0781\n",
            "\n",
            "Epoch 00180: loss did not improve from 6.44946\n",
            "Epoch 181/500\n",
            "45/45 [==============================] - 1s 11ms/step - loss: 6.2021 - mae: 6.6828 - val_loss: 6.4441 - val_mae: 6.9243\n",
            "\n",
            "Epoch 00181: loss did not improve from 6.44946\n",
            "Epoch 182/500\n",
            "45/45 [==============================] - 1s 12ms/step - loss: 6.6165 - mae: 7.0965 - val_loss: 6.4291 - val_mae: 6.9111\n",
            "\n",
            "Epoch 00182: loss did not improve from 6.44946\n",
            "Epoch 183/500\n",
            "45/45 [==============================] - 1s 12ms/step - loss: 6.3373 - mae: 6.8178 - val_loss: 6.6713 - val_mae: 7.1527\n",
            "\n",
            "Epoch 00183: loss did not improve from 6.44946\n",
            "Epoch 184/500\n",
            "45/45 [==============================] - 1s 11ms/step - loss: 6.6268 - mae: 7.1078 - val_loss: 6.8343 - val_mae: 7.3152\n",
            "\n",
            "Epoch 00184: loss did not improve from 6.44946\n",
            "Epoch 185/500\n",
            "45/45 [==============================] - 1s 12ms/step - loss: 6.4111 - mae: 6.8914 - val_loss: 6.5018 - val_mae: 6.9829\n",
            "\n",
            "Epoch 00185: loss did not improve from 6.44946\n",
            "Epoch 186/500\n",
            "45/45 [==============================] - 1s 12ms/step - loss: 6.7490 - mae: 7.2295 - val_loss: 6.9133 - val_mae: 7.3945\n",
            "\n",
            "Epoch 00186: loss did not improve from 6.44946\n",
            "Epoch 187/500\n",
            "45/45 [==============================] - 1s 12ms/step - loss: 6.5295 - mae: 7.0110 - val_loss: 7.1562 - val_mae: 7.6389\n",
            "\n",
            "Epoch 00187: loss did not improve from 6.44946\n",
            "Epoch 188/500\n",
            "45/45 [==============================] - 1s 12ms/step - loss: 6.3918 - mae: 6.8711 - val_loss: 7.4282 - val_mae: 7.9120\n",
            "\n",
            "Epoch 00188: loss did not improve from 6.44946\n",
            "Epoch 189/500\n",
            "45/45 [==============================] - 1s 11ms/step - loss: 6.6111 - mae: 7.0926 - val_loss: 6.4958 - val_mae: 6.9770\n",
            "\n",
            "Epoch 00189: loss did not improve from 6.44946\n",
            "Epoch 190/500\n",
            "45/45 [==============================] - 1s 12ms/step - loss: 6.4983 - mae: 6.9789 - val_loss: 6.5625 - val_mae: 7.0440\n",
            "\n",
            "Epoch 00190: loss did not improve from 6.44946\n",
            "Epoch 191/500\n",
            "45/45 [==============================] - 1s 13ms/step - loss: 6.4776 - mae: 6.9586 - val_loss: 6.6998 - val_mae: 7.1807\n",
            "\n",
            "Epoch 00191: loss did not improve from 6.44946\n",
            "Epoch 192/500\n",
            "45/45 [==============================] - 1s 12ms/step - loss: 6.4353 - mae: 6.9153 - val_loss: 6.5622 - val_mae: 7.0434\n",
            "\n",
            "Epoch 00192: loss did not improve from 6.44946\n",
            "Epoch 193/500\n",
            "45/45 [==============================] - 1s 11ms/step - loss: 6.3563 - mae: 6.8363 - val_loss: 6.8070 - val_mae: 7.2878\n",
            "\n",
            "Epoch 00193: loss did not improve from 6.44946\n",
            "Epoch 194/500\n",
            "45/45 [==============================] - 1s 12ms/step - loss: 6.4387 - mae: 6.9176 - val_loss: 6.6572 - val_mae: 7.1384\n",
            "\n",
            "Epoch 00194: loss did not improve from 6.44946\n",
            "Epoch 195/500\n",
            "45/45 [==============================] - 1s 11ms/step - loss: 6.4760 - mae: 6.9578 - val_loss: 6.7255 - val_mae: 7.2067\n",
            "\n",
            "Epoch 00195: loss did not improve from 6.44946\n",
            "Epoch 196/500\n",
            "45/45 [==============================] - 1s 12ms/step - loss: 6.6697 - mae: 7.1517 - val_loss: 6.9947 - val_mae: 7.4774\n",
            "\n",
            "Epoch 00196: loss did not improve from 6.44946\n",
            "Epoch 197/500\n",
            "45/45 [==============================] - 1s 12ms/step - loss: 6.5755 - mae: 7.0554 - val_loss: 6.5624 - val_mae: 7.0432\n",
            "\n",
            "Epoch 00197: loss did not improve from 6.44946\n",
            "Epoch 198/500\n",
            "45/45 [==============================] - 1s 12ms/step - loss: 6.6537 - mae: 7.1348 - val_loss: 6.5783 - val_mae: 7.0593\n",
            "\n",
            "Epoch 00198: loss did not improve from 6.44946\n",
            "Epoch 199/500\n",
            "45/45 [==============================] - 1s 12ms/step - loss: 6.6113 - mae: 7.0924 - val_loss: 6.5268 - val_mae: 7.0083\n",
            "\n",
            "Epoch 00199: loss did not improve from 6.44946\n",
            "Epoch 200/500\n",
            "45/45 [==============================] - 1s 12ms/step - loss: 6.3875 - mae: 6.8678 - val_loss: 6.6750 - val_mae: 7.1563\n",
            "\n",
            "Epoch 00200: loss did not improve from 6.44946\n",
            "Epoch 201/500\n",
            "45/45 [==============================] - 1s 11ms/step - loss: 6.6800 - mae: 7.1608 - val_loss: 6.3293 - val_mae: 6.8095\n",
            "\n",
            "Epoch 00201: loss did not improve from 6.44946\n",
            "Epoch 202/500\n",
            "45/45 [==============================] - 1s 11ms/step - loss: 6.2983 - mae: 6.7776 - val_loss: 6.5810 - val_mae: 7.0632\n",
            "\n",
            "Epoch 00202: loss did not improve from 6.44946\n",
            "Epoch 203/500\n",
            "45/45 [==============================] - 1s 12ms/step - loss: 6.2787 - mae: 6.7583 - val_loss: 7.0494 - val_mae: 7.5328\n",
            "\n",
            "Epoch 00203: loss did not improve from 6.44946\n",
            "Epoch 204/500\n",
            "45/45 [==============================] - 1s 11ms/step - loss: 6.6926 - mae: 7.1731 - val_loss: 6.8376 - val_mae: 7.3200\n",
            "\n",
            "Epoch 00204: loss did not improve from 6.44946\n",
            "Epoch 205/500\n",
            "45/45 [==============================] - 1s 12ms/step - loss: 6.9193 - mae: 7.4015 - val_loss: 7.2356 - val_mae: 7.7191\n",
            "\n",
            "Epoch 00205: loss did not improve from 6.44946\n",
            "Epoch 206/500\n",
            "45/45 [==============================] - 1s 11ms/step - loss: 6.2157 - mae: 6.6960 - val_loss: 6.6088 - val_mae: 7.0904\n",
            "\n",
            "Epoch 00206: loss improved from 6.44946 to 6.44663, saving model to poids.hdf5\n",
            "Epoch 207/500\n",
            "45/45 [==============================] - 1s 12ms/step - loss: 6.3887 - mae: 6.8681 - val_loss: 6.4185 - val_mae: 6.8997\n",
            "\n",
            "Epoch 00207: loss did not improve from 6.44663\n",
            "Epoch 208/500\n",
            "45/45 [==============================] - 1s 12ms/step - loss: 6.7307 - mae: 7.2113 - val_loss: 6.6703 - val_mae: 7.1505\n",
            "\n",
            "Epoch 00208: loss did not improve from 6.44663\n",
            "Epoch 209/500\n",
            "45/45 [==============================] - 1s 11ms/step - loss: 6.5891 - mae: 7.0706 - val_loss: 7.0305 - val_mae: 7.5133\n",
            "\n",
            "Epoch 00209: loss did not improve from 6.44663\n",
            "Epoch 210/500\n",
            "45/45 [==============================] - 1s 12ms/step - loss: 6.6154 - mae: 7.0948 - val_loss: 6.8396 - val_mae: 7.3201\n",
            "\n",
            "Epoch 00210: loss did not improve from 6.44663\n",
            "Epoch 211/500\n",
            "45/45 [==============================] - 1s 13ms/step - loss: 6.3766 - mae: 6.8564 - val_loss: 6.4564 - val_mae: 6.9365\n",
            "\n",
            "Epoch 00211: loss did not improve from 6.44663\n",
            "Epoch 212/500\n",
            "45/45 [==============================] - 1s 12ms/step - loss: 6.4877 - mae: 6.9688 - val_loss: 7.1936 - val_mae: 7.6776\n",
            "\n",
            "Epoch 00212: loss did not improve from 6.44663\n",
            "Epoch 213/500\n",
            "45/45 [==============================] - 1s 12ms/step - loss: 6.7980 - mae: 7.2799 - val_loss: 6.5638 - val_mae: 7.0448\n",
            "\n",
            "Epoch 00213: loss did not improve from 6.44663\n",
            "Epoch 214/500\n",
            "45/45 [==============================] - 1s 13ms/step - loss: 6.6904 - mae: 7.1703 - val_loss: 6.4302 - val_mae: 6.9116\n",
            "\n",
            "Epoch 00214: loss did not improve from 6.44663\n",
            "Epoch 215/500\n",
            "45/45 [==============================] - 1s 11ms/step - loss: 6.5024 - mae: 6.9830 - val_loss: 7.1382 - val_mae: 7.6224\n",
            "\n",
            "Epoch 00215: loss did not improve from 6.44663\n",
            "Epoch 216/500\n",
            "45/45 [==============================] - 1s 12ms/step - loss: 6.3917 - mae: 6.8720 - val_loss: 7.1891 - val_mae: 7.6739\n",
            "\n",
            "Epoch 00216: loss did not improve from 6.44663\n",
            "Epoch 217/500\n",
            "45/45 [==============================] - 1s 12ms/step - loss: 6.5511 - mae: 7.0324 - val_loss: 6.4333 - val_mae: 6.9138\n",
            "\n",
            "Epoch 00217: loss did not improve from 6.44663\n",
            "Epoch 218/500\n",
            "45/45 [==============================] - 1s 12ms/step - loss: 6.6800 - mae: 7.1591 - val_loss: 6.3836 - val_mae: 6.8639\n",
            "\n",
            "Epoch 00218: loss did not improve from 6.44663\n",
            "Epoch 219/500\n",
            "45/45 [==============================] - 1s 12ms/step - loss: 6.7987 - mae: 7.2788 - val_loss: 6.5194 - val_mae: 7.0005\n",
            "\n",
            "Epoch 00219: loss did not improve from 6.44663\n",
            "Epoch 220/500\n",
            "45/45 [==============================] - 1s 12ms/step - loss: 6.5999 - mae: 7.0804 - val_loss: 6.6946 - val_mae: 7.1753\n",
            "\n",
            "Epoch 00220: loss did not improve from 6.44663\n",
            "Epoch 221/500\n",
            "45/45 [==============================] - 1s 12ms/step - loss: 6.4358 - mae: 6.9158 - val_loss: 6.5252 - val_mae: 7.0063\n",
            "\n",
            "Epoch 00221: loss did not improve from 6.44663\n",
            "Epoch 222/500\n",
            "45/45 [==============================] - 1s 12ms/step - loss: 6.2856 - mae: 6.7645 - val_loss: 6.9063 - val_mae: 7.3880\n",
            "\n",
            "Epoch 00222: loss did not improve from 6.44663\n",
            "Epoch 223/500\n",
            "45/45 [==============================] - 1s 12ms/step - loss: 6.7603 - mae: 7.2412 - val_loss: 6.4608 - val_mae: 6.9426\n",
            "\n",
            "Epoch 00223: loss did not improve from 6.44663\n",
            "Epoch 224/500\n",
            "45/45 [==============================] - 1s 12ms/step - loss: 6.6842 - mae: 7.1637 - val_loss: 6.6265 - val_mae: 7.1071\n",
            "\n",
            "Epoch 00224: loss did not improve from 6.44663\n",
            "Epoch 225/500\n",
            "45/45 [==============================] - 1s 12ms/step - loss: 6.7026 - mae: 7.1829 - val_loss: 6.4935 - val_mae: 6.9743\n",
            "\n",
            "Epoch 00225: loss did not improve from 6.44663\n",
            "Epoch 226/500\n",
            "45/45 [==============================] - 1s 12ms/step - loss: 6.2452 - mae: 6.7236 - val_loss: 7.7823 - val_mae: 8.2688\n",
            "\n",
            "Epoch 00226: loss did not improve from 6.44663\n",
            "Epoch 227/500\n",
            "45/45 [==============================] - 1s 12ms/step - loss: 6.6765 - mae: 7.1578 - val_loss: 6.5895 - val_mae: 7.0703\n",
            "\n",
            "Epoch 00227: loss did not improve from 6.44663\n",
            "Epoch 228/500\n",
            "45/45 [==============================] - 1s 12ms/step - loss: 6.7002 - mae: 7.1803 - val_loss: 6.8423 - val_mae: 7.3232\n",
            "\n",
            "Epoch 00228: loss did not improve from 6.44663\n",
            "Epoch 229/500\n",
            "45/45 [==============================] - 1s 12ms/step - loss: 6.6576 - mae: 7.1384 - val_loss: 6.5704 - val_mae: 7.0516\n",
            "\n",
            "Epoch 00229: loss did not improve from 6.44663\n",
            "Epoch 230/500\n",
            "45/45 [==============================] - 1s 12ms/step - loss: 6.4975 - mae: 6.9773 - val_loss: 6.5422 - val_mae: 7.0241\n",
            "\n",
            "Epoch 00230: loss did not improve from 6.44663\n",
            "Epoch 231/500\n",
            "45/45 [==============================] - 1s 11ms/step - loss: 6.9252 - mae: 7.4079 - val_loss: 6.4318 - val_mae: 6.9122\n",
            "\n",
            "Epoch 00231: loss did not improve from 6.44663\n",
            "Epoch 232/500\n",
            "45/45 [==============================] - 1s 12ms/step - loss: 6.4720 - mae: 6.9534 - val_loss: 6.5915 - val_mae: 7.0721\n",
            "\n",
            "Epoch 00232: loss did not improve from 6.44663\n",
            "Epoch 233/500\n",
            "45/45 [==============================] - 1s 12ms/step - loss: 6.6745 - mae: 7.1543 - val_loss: 6.7049 - val_mae: 7.1853\n",
            "\n",
            "Epoch 00233: loss did not improve from 6.44663\n",
            "Epoch 234/500\n",
            "45/45 [==============================] - 1s 12ms/step - loss: 6.5657 - mae: 7.0459 - val_loss: 6.6433 - val_mae: 7.1242\n",
            "\n",
            "Epoch 00234: loss did not improve from 6.44663\n",
            "Epoch 235/500\n",
            "45/45 [==============================] - 1s 12ms/step - loss: 6.5330 - mae: 7.0135 - val_loss: 6.5075 - val_mae: 6.9889\n",
            "\n",
            "Epoch 00235: loss did not improve from 6.44663\n",
            "Epoch 236/500\n",
            "45/45 [==============================] - 1s 12ms/step - loss: 6.6650 - mae: 7.1455 - val_loss: 6.9145 - val_mae: 7.3960\n",
            "\n",
            "Epoch 00236: loss did not improve from 6.44663\n",
            "Epoch 237/500\n",
            "45/45 [==============================] - 1s 12ms/step - loss: 6.7294 - mae: 7.2083 - val_loss: 6.4879 - val_mae: 6.9686\n",
            "\n",
            "Epoch 00237: loss did not improve from 6.44663\n",
            "Epoch 238/500\n",
            "45/45 [==============================] - 1s 12ms/step - loss: 6.3324 - mae: 6.8138 - val_loss: 6.5924 - val_mae: 7.0728\n",
            "\n",
            "Epoch 00238: loss did not improve from 6.44663\n",
            "Epoch 239/500\n",
            "45/45 [==============================] - 1s 12ms/step - loss: 6.6765 - mae: 7.1570 - val_loss: 6.9826 - val_mae: 7.4654\n",
            "\n",
            "Epoch 00239: loss did not improve from 6.44663\n",
            "Epoch 240/500\n",
            "45/45 [==============================] - 1s 12ms/step - loss: 6.5325 - mae: 7.0117 - val_loss: 7.2597 - val_mae: 7.7424\n",
            "\n",
            "Epoch 00240: loss did not improve from 6.44663\n",
            "Epoch 241/500\n",
            "45/45 [==============================] - 1s 12ms/step - loss: 6.7863 - mae: 7.2679 - val_loss: 6.6500 - val_mae: 7.1322\n",
            "\n",
            "Epoch 00241: loss did not improve from 6.44663\n",
            "Epoch 242/500\n",
            "45/45 [==============================] - 1s 11ms/step - loss: 6.2291 - mae: 6.7068 - val_loss: 6.5525 - val_mae: 7.0337\n",
            "\n",
            "Epoch 00242: loss did not improve from 6.44663\n",
            "Epoch 243/500\n",
            "45/45 [==============================] - 1s 14ms/step - loss: 6.7177 - mae: 7.1988 - val_loss: 6.8895 - val_mae: 7.3706\n",
            "\n",
            "Epoch 00243: loss did not improve from 6.44663\n",
            "Epoch 244/500\n",
            "45/45 [==============================] - 1s 12ms/step - loss: 6.5360 - mae: 7.0163 - val_loss: 6.5752 - val_mae: 7.0578\n",
            "\n",
            "Epoch 00244: loss did not improve from 6.44663\n",
            "Epoch 245/500\n",
            "45/45 [==============================] - 1s 13ms/step - loss: 6.5667 - mae: 7.0472 - val_loss: 6.7523 - val_mae: 7.2344\n",
            "\n",
            "Epoch 00245: loss did not improve from 6.44663\n",
            "Epoch 246/500\n",
            "45/45 [==============================] - 1s 12ms/step - loss: 6.3552 - mae: 6.8369 - val_loss: 6.8897 - val_mae: 7.3709\n",
            "\n",
            "Epoch 00246: loss did not improve from 6.44663\n",
            "Epoch 247/500\n",
            "45/45 [==============================] - 1s 12ms/step - loss: 6.5874 - mae: 7.0670 - val_loss: 6.7720 - val_mae: 7.2533\n",
            "\n",
            "Epoch 00247: loss did not improve from 6.44663\n",
            "Epoch 248/500\n",
            "45/45 [==============================] - 1s 11ms/step - loss: 6.8099 - mae: 7.2908 - val_loss: 7.3616 - val_mae: 7.8444\n",
            "\n",
            "Epoch 00248: loss did not improve from 6.44663\n",
            "Epoch 249/500\n",
            "45/45 [==============================] - 1s 12ms/step - loss: 6.5970 - mae: 7.0776 - val_loss: 6.6343 - val_mae: 7.1157\n",
            "\n",
            "Epoch 00249: loss did not improve from 6.44663\n",
            "Epoch 250/500\n",
            "45/45 [==============================] - 1s 12ms/step - loss: 6.6868 - mae: 7.1681 - val_loss: 6.6268 - val_mae: 7.1086\n",
            "\n",
            "Epoch 00250: loss did not improve from 6.44663\n",
            "Epoch 251/500\n",
            "45/45 [==============================] - 1s 12ms/step - loss: 6.2260 - mae: 6.7065 - val_loss: 6.4782 - val_mae: 6.9582\n",
            "\n",
            "Epoch 00251: loss did not improve from 6.44663\n",
            "Epoch 252/500\n",
            "45/45 [==============================] - 1s 12ms/step - loss: 6.4493 - mae: 6.9292 - val_loss: 6.6721 - val_mae: 7.1530\n",
            "\n",
            "Epoch 00252: loss did not improve from 6.44663\n",
            "Epoch 253/500\n",
            "45/45 [==============================] - 1s 12ms/step - loss: 6.5273 - mae: 7.0061 - val_loss: 6.5656 - val_mae: 7.0462\n",
            "\n",
            "Epoch 00253: loss improved from 6.44663 to 6.42902, saving model to poids.hdf5\n",
            "Epoch 254/500\n",
            "45/45 [==============================] - 1s 12ms/step - loss: 6.8314 - mae: 7.3124 - val_loss: 6.9118 - val_mae: 7.3935\n",
            "\n",
            "Epoch 00254: loss did not improve from 6.42902\n",
            "Epoch 255/500\n",
            "45/45 [==============================] - 1s 13ms/step - loss: 6.7738 - mae: 7.2555 - val_loss: 6.7172 - val_mae: 7.1975\n",
            "\n",
            "Epoch 00255: loss did not improve from 6.42902\n",
            "Epoch 256/500\n",
            "45/45 [==============================] - 1s 12ms/step - loss: 6.6309 - mae: 7.1094 - val_loss: 6.5821 - val_mae: 7.0635\n",
            "\n",
            "Epoch 00256: loss did not improve from 6.42902\n",
            "Epoch 257/500\n",
            "45/45 [==============================] - 1s 12ms/step - loss: 6.4032 - mae: 6.8826 - val_loss: 6.5833 - val_mae: 7.0643\n",
            "\n",
            "Epoch 00257: loss did not improve from 6.42902\n",
            "Epoch 258/500\n",
            "45/45 [==============================] - 1s 12ms/step - loss: 6.3326 - mae: 6.8110 - val_loss: 6.7945 - val_mae: 7.2761\n",
            "\n",
            "Epoch 00258: loss did not improve from 6.42902\n",
            "Epoch 259/500\n",
            "45/45 [==============================] - 1s 12ms/step - loss: 6.6181 - mae: 7.0983 - val_loss: 6.5797 - val_mae: 7.0602\n",
            "\n",
            "Epoch 00259: loss did not improve from 6.42902\n",
            "Epoch 260/500\n",
            "45/45 [==============================] - 1s 12ms/step - loss: 6.6563 - mae: 7.1361 - val_loss: 6.8277 - val_mae: 7.3083\n",
            "\n",
            "Epoch 00260: loss improved from 6.42902 to 6.42442, saving model to poids.hdf5\n",
            "Epoch 261/500\n",
            "45/45 [==============================] - 1s 13ms/step - loss: 6.2910 - mae: 6.7705 - val_loss: 6.5805 - val_mae: 7.0610\n",
            "\n",
            "Epoch 00261: loss did not improve from 6.42442\n",
            "Epoch 262/500\n",
            "45/45 [==============================] - 1s 12ms/step - loss: 6.4878 - mae: 6.9683 - val_loss: 6.4609 - val_mae: 6.9416\n",
            "\n",
            "Epoch 00262: loss improved from 6.42442 to 6.39127, saving model to poids.hdf5\n",
            "Epoch 263/500\n",
            "45/45 [==============================] - 1s 12ms/step - loss: 6.5438 - mae: 7.0242 - val_loss: 7.2035 - val_mae: 7.6879\n",
            "\n",
            "Epoch 00263: loss did not improve from 6.39127\n",
            "Epoch 264/500\n",
            "45/45 [==============================] - 1s 12ms/step - loss: 6.3965 - mae: 6.8763 - val_loss: 6.8016 - val_mae: 7.2833\n",
            "\n",
            "Epoch 00264: loss did not improve from 6.39127\n",
            "Epoch 265/500\n",
            "45/45 [==============================] - 1s 12ms/step - loss: 6.5839 - mae: 7.0654 - val_loss: 6.5573 - val_mae: 7.0374\n",
            "\n",
            "Epoch 00265: loss did not improve from 6.39127\n",
            "Epoch 266/500\n",
            "45/45 [==============================] - 1s 12ms/step - loss: 6.4347 - mae: 6.9148 - val_loss: 6.4534 - val_mae: 6.9347\n",
            "\n",
            "Epoch 00266: loss did not improve from 6.39127\n",
            "Epoch 267/500\n",
            "45/45 [==============================] - 1s 12ms/step - loss: 6.5859 - mae: 7.0662 - val_loss: 6.3330 - val_mae: 6.8140\n",
            "\n",
            "Epoch 00267: loss did not improve from 6.39127\n",
            "Epoch 268/500\n",
            "45/45 [==============================] - 1s 13ms/step - loss: 6.4152 - mae: 6.8935 - val_loss: 6.5185 - val_mae: 7.0004\n",
            "\n",
            "Epoch 00268: loss did not improve from 6.39127\n",
            "Epoch 269/500\n",
            "45/45 [==============================] - 1s 13ms/step - loss: 6.7768 - mae: 7.2581 - val_loss: 6.9661 - val_mae: 7.4481\n",
            "\n",
            "Epoch 00269: loss did not improve from 6.39127\n",
            "Epoch 270/500\n",
            "45/45 [==============================] - 1s 13ms/step - loss: 6.5920 - mae: 7.0720 - val_loss: 6.4555 - val_mae: 6.9360\n",
            "\n",
            "Epoch 00270: loss did not improve from 6.39127\n",
            "Epoch 271/500\n",
            "45/45 [==============================] - 1s 13ms/step - loss: 6.3961 - mae: 6.8760 - val_loss: 6.4100 - val_mae: 6.8921\n",
            "\n",
            "Epoch 00271: loss did not improve from 6.39127\n",
            "Epoch 272/500\n",
            "45/45 [==============================] - 1s 13ms/step - loss: 6.7662 - mae: 7.2464 - val_loss: 6.7438 - val_mae: 7.2260\n",
            "\n",
            "Epoch 00272: loss did not improve from 6.39127\n",
            "Epoch 273/500\n",
            "45/45 [==============================] - 1s 13ms/step - loss: 6.4955 - mae: 6.9743 - val_loss: 6.7179 - val_mae: 7.1992\n",
            "\n",
            "Epoch 00273: loss did not improve from 6.39127\n",
            "Epoch 274/500\n",
            "45/45 [==============================] - 1s 15ms/step - loss: 6.5184 - mae: 6.9974 - val_loss: 6.6160 - val_mae: 7.0957\n",
            "\n",
            "Epoch 00274: loss did not improve from 6.39127\n",
            "Epoch 275/500\n",
            "45/45 [==============================] - 1s 12ms/step - loss: 6.5675 - mae: 7.0474 - val_loss: 6.8122 - val_mae: 7.2927\n",
            "\n",
            "Epoch 00275: loss did not improve from 6.39127\n",
            "Epoch 276/500\n",
            "45/45 [==============================] - 1s 13ms/step - loss: 6.3121 - mae: 6.7932 - val_loss: 6.4811 - val_mae: 6.9616\n",
            "\n",
            "Epoch 00276: loss did not improve from 6.39127\n",
            "Epoch 277/500\n",
            "45/45 [==============================] - 1s 13ms/step - loss: 6.8487 - mae: 7.3302 - val_loss: 6.5521 - val_mae: 7.0329\n",
            "\n",
            "Epoch 00277: loss did not improve from 6.39127\n",
            "Epoch 278/500\n",
            "45/45 [==============================] - 1s 12ms/step - loss: 6.2947 - mae: 6.7738 - val_loss: 6.4130 - val_mae: 6.8947\n",
            "\n",
            "Epoch 00278: loss did not improve from 6.39127\n",
            "Epoch 279/500\n",
            "45/45 [==============================] - 1s 12ms/step - loss: 6.6963 - mae: 7.1774 - val_loss: 6.3789 - val_mae: 6.8592\n",
            "\n",
            "Epoch 00279: loss did not improve from 6.39127\n",
            "Epoch 280/500\n",
            "45/45 [==============================] - 1s 12ms/step - loss: 6.4501 - mae: 6.9307 - val_loss: 6.5985 - val_mae: 7.0799\n",
            "\n",
            "Epoch 00280: loss did not improve from 6.39127\n",
            "Epoch 281/500\n",
            "45/45 [==============================] - 1s 12ms/step - loss: 6.3274 - mae: 6.8061 - val_loss: 6.7193 - val_mae: 7.2013\n",
            "\n",
            "Epoch 00281: loss did not improve from 6.39127\n",
            "Epoch 282/500\n",
            "45/45 [==============================] - 1s 12ms/step - loss: 6.6226 - mae: 7.1015 - val_loss: 6.4263 - val_mae: 6.9063\n",
            "\n",
            "Epoch 00282: loss did not improve from 6.39127\n",
            "Epoch 283/500\n",
            "45/45 [==============================] - 1s 13ms/step - loss: 6.3211 - mae: 6.8009 - val_loss: 6.5591 - val_mae: 7.0399\n",
            "\n",
            "Epoch 00283: loss did not improve from 6.39127\n",
            "Epoch 284/500\n",
            "45/45 [==============================] - 1s 12ms/step - loss: 6.3877 - mae: 6.8677 - val_loss: 6.6148 - val_mae: 7.0960\n",
            "\n",
            "Epoch 00284: loss did not improve from 6.39127\n",
            "Epoch 285/500\n",
            "45/45 [==============================] - 1s 12ms/step - loss: 6.3817 - mae: 6.8606 - val_loss: 7.1965 - val_mae: 7.6803\n",
            "\n",
            "Epoch 00285: loss did not improve from 6.39127\n",
            "Epoch 286/500\n",
            "45/45 [==============================] - 1s 13ms/step - loss: 6.7779 - mae: 7.2588 - val_loss: 6.4639 - val_mae: 6.9461\n",
            "\n",
            "Epoch 00286: loss did not improve from 6.39127\n",
            "Epoch 287/500\n",
            "45/45 [==============================] - 1s 12ms/step - loss: 6.6290 - mae: 7.1101 - val_loss: 6.6439 - val_mae: 7.1252\n",
            "\n",
            "Epoch 00287: loss did not improve from 6.39127\n",
            "Epoch 288/500\n",
            "45/45 [==============================] - 1s 12ms/step - loss: 6.3435 - mae: 6.8239 - val_loss: 6.5505 - val_mae: 7.0317\n",
            "\n",
            "Epoch 00288: loss did not improve from 6.39127\n",
            "Epoch 289/500\n",
            "45/45 [==============================] - 1s 13ms/step - loss: 6.5230 - mae: 7.0030 - val_loss: 6.4120 - val_mae: 6.8931\n",
            "\n",
            "Epoch 00289: loss did not improve from 6.39127\n",
            "Epoch 290/500\n",
            "45/45 [==============================] - 1s 13ms/step - loss: 6.4157 - mae: 6.8952 - val_loss: 6.8781 - val_mae: 7.3606\n",
            "\n",
            "Epoch 00290: loss did not improve from 6.39127\n",
            "Epoch 291/500\n",
            "45/45 [==============================] - 1s 13ms/step - loss: 6.5109 - mae: 6.9908 - val_loss: 6.9822 - val_mae: 7.4644\n",
            "\n",
            "Epoch 00291: loss did not improve from 6.39127\n",
            "Epoch 292/500\n",
            "45/45 [==============================] - 1s 13ms/step - loss: 6.9312 - mae: 7.4124 - val_loss: 6.3356 - val_mae: 6.8157\n",
            "\n",
            "Epoch 00292: loss did not improve from 6.39127\n",
            "Epoch 293/500\n",
            "45/45 [==============================] - 1s 12ms/step - loss: 6.5578 - mae: 7.0382 - val_loss: 7.5526 - val_mae: 8.0382\n",
            "\n",
            "Epoch 00293: loss did not improve from 6.39127\n",
            "Epoch 294/500\n",
            "45/45 [==============================] - 1s 13ms/step - loss: 6.8078 - mae: 7.2878 - val_loss: 6.3561 - val_mae: 6.8369\n",
            "\n",
            "Epoch 00294: loss did not improve from 6.39127\n",
            "Epoch 295/500\n",
            "45/45 [==============================] - 1s 12ms/step - loss: 6.4308 - mae: 6.9103 - val_loss: 6.5607 - val_mae: 7.0427\n",
            "\n",
            "Epoch 00295: loss improved from 6.39127 to 6.38383, saving model to poids.hdf5\n",
            "Epoch 296/500\n",
            "45/45 [==============================] - 1s 12ms/step - loss: 6.3017 - mae: 6.7803 - val_loss: 6.2725 - val_mae: 6.7543\n",
            "\n",
            "Epoch 00296: loss did not improve from 6.38383\n",
            "Epoch 297/500\n",
            "45/45 [==============================] - 1s 13ms/step - loss: 6.8737 - mae: 7.3548 - val_loss: 6.5269 - val_mae: 7.0076\n",
            "\n",
            "Epoch 00297: loss did not improve from 6.38383\n",
            "Epoch 298/500\n",
            "45/45 [==============================] - 1s 13ms/step - loss: 6.4932 - mae: 6.9740 - val_loss: 6.4449 - val_mae: 6.9254\n",
            "\n",
            "Epoch 00298: loss did not improve from 6.38383\n",
            "Epoch 299/500\n",
            "45/45 [==============================] - 1s 12ms/step - loss: 6.4645 - mae: 6.9448 - val_loss: 6.4797 - val_mae: 6.9606\n",
            "\n",
            "Epoch 00299: loss did not improve from 6.38383\n",
            "Epoch 300/500\n",
            "45/45 [==============================] - 1s 12ms/step - loss: 6.4292 - mae: 6.9095 - val_loss: 6.9670 - val_mae: 7.4486\n",
            "\n",
            "Epoch 00300: loss did not improve from 6.38383\n",
            "Epoch 301/500\n",
            "45/45 [==============================] - 1s 12ms/step - loss: 6.6142 - mae: 7.0937 - val_loss: 6.4330 - val_mae: 6.9138\n",
            "\n",
            "Epoch 00301: loss did not improve from 6.38383\n",
            "Epoch 302/500\n",
            "45/45 [==============================] - 1s 12ms/step - loss: 6.5450 - mae: 7.0257 - val_loss: 6.5466 - val_mae: 7.0286\n",
            "\n",
            "Epoch 00302: loss did not improve from 6.38383\n",
            "Epoch 303/500\n",
            "45/45 [==============================] - 1s 13ms/step - loss: 6.3352 - mae: 6.8145 - val_loss: 6.5610 - val_mae: 7.0418\n",
            "\n",
            "Epoch 00303: loss did not improve from 6.38383\n",
            "Epoch 304/500\n",
            "45/45 [==============================] - 1s 12ms/step - loss: 6.8144 - mae: 7.2952 - val_loss: 6.3673 - val_mae: 6.8481\n",
            "\n",
            "Epoch 00304: loss did not improve from 6.38383\n",
            "Epoch 305/500\n",
            "45/45 [==============================] - 1s 13ms/step - loss: 6.5730 - mae: 7.0544 - val_loss: 6.3932 - val_mae: 6.8743\n",
            "\n",
            "Epoch 00305: loss did not improve from 6.38383\n",
            "Epoch 306/500\n",
            "45/45 [==============================] - 1s 12ms/step - loss: 6.3186 - mae: 6.7978 - val_loss: 6.2648 - val_mae: 6.7456\n",
            "\n",
            "Epoch 00306: loss did not improve from 6.38383\n",
            "Epoch 307/500\n",
            "45/45 [==============================] - 1s 14ms/step - loss: 6.4184 - mae: 6.8977 - val_loss: 6.4777 - val_mae: 6.9588\n",
            "\n",
            "Epoch 00307: loss did not improve from 6.38383\n",
            "Epoch 308/500\n",
            "45/45 [==============================] - 1s 12ms/step - loss: 6.4828 - mae: 6.9629 - val_loss: 6.3424 - val_mae: 6.8233\n",
            "\n",
            "Epoch 00308: loss did not improve from 6.38383\n",
            "Epoch 309/500\n",
            "45/45 [==============================] - 1s 12ms/step - loss: 6.4168 - mae: 6.8962 - val_loss: 6.4522 - val_mae: 6.9328\n",
            "\n",
            "Epoch 00309: loss did not improve from 6.38383\n",
            "Epoch 310/500\n",
            "45/45 [==============================] - 1s 12ms/step - loss: 6.3290 - mae: 6.8068 - val_loss: 6.6287 - val_mae: 7.1102\n",
            "\n",
            "Epoch 00310: loss did not improve from 6.38383\n",
            "Epoch 311/500\n",
            "45/45 [==============================] - 1s 12ms/step - loss: 6.4489 - mae: 6.9286 - val_loss: 6.4105 - val_mae: 6.8915\n",
            "\n",
            "Epoch 00311: loss did not improve from 6.38383\n",
            "Epoch 312/500\n",
            "45/45 [==============================] - 1s 12ms/step - loss: 6.4803 - mae: 6.9587 - val_loss: 6.7511 - val_mae: 7.2314\n",
            "\n",
            "Epoch 00312: loss did not improve from 6.38383\n",
            "Epoch 313/500\n",
            "45/45 [==============================] - 1s 14ms/step - loss: 6.9146 - mae: 7.3961 - val_loss: 6.4954 - val_mae: 6.9767\n",
            "\n",
            "Epoch 00313: loss did not improve from 6.38383\n",
            "Epoch 314/500\n",
            "45/45 [==============================] - 1s 12ms/step - loss: 6.2736 - mae: 6.7529 - val_loss: 7.0572 - val_mae: 7.5396\n",
            "\n",
            "Epoch 00314: loss did not improve from 6.38383\n",
            "Epoch 315/500\n",
            "45/45 [==============================] - 1s 12ms/step - loss: 6.3063 - mae: 6.7851 - val_loss: 6.5174 - val_mae: 6.9974\n",
            "\n",
            "Epoch 00315: loss did not improve from 6.38383\n",
            "Epoch 316/500\n",
            "45/45 [==============================] - 1s 13ms/step - loss: 6.4973 - mae: 6.9774 - val_loss: 6.5587 - val_mae: 7.0407\n",
            "\n",
            "Epoch 00316: loss did not improve from 6.38383\n",
            "Epoch 317/500\n",
            "45/45 [==============================] - 1s 13ms/step - loss: 6.3972 - mae: 6.8765 - val_loss: 6.6449 - val_mae: 7.1258\n",
            "\n",
            "Epoch 00317: loss did not improve from 6.38383\n",
            "Epoch 318/500\n",
            "45/45 [==============================] - 1s 12ms/step - loss: 6.5441 - mae: 7.0244 - val_loss: 7.3063 - val_mae: 7.7909\n",
            "\n",
            "Epoch 00318: loss did not improve from 6.38383\n",
            "Epoch 319/500\n",
            "45/45 [==============================] - 1s 12ms/step - loss: 6.3579 - mae: 6.8371 - val_loss: 6.5369 - val_mae: 7.0184\n",
            "\n",
            "Epoch 00319: loss did not improve from 6.38383\n",
            "Epoch 320/500\n",
            "45/45 [==============================] - 1s 12ms/step - loss: 6.2927 - mae: 6.7737 - val_loss: 6.3596 - val_mae: 6.8405\n",
            "\n",
            "Epoch 00320: loss did not improve from 6.38383\n",
            "Epoch 321/500\n",
            "45/45 [==============================] - 1s 12ms/step - loss: 6.4154 - mae: 6.8950 - val_loss: 6.6589 - val_mae: 7.1404\n",
            "\n",
            "Epoch 00321: loss did not improve from 6.38383\n",
            "Epoch 322/500\n",
            "45/45 [==============================] - 1s 13ms/step - loss: 6.9366 - mae: 7.4183 - val_loss: 7.2496 - val_mae: 7.7347\n",
            "\n",
            "Epoch 00322: loss did not improve from 6.38383\n",
            "Epoch 323/500\n",
            "45/45 [==============================] - 1s 12ms/step - loss: 6.5624 - mae: 7.0430 - val_loss: 6.6473 - val_mae: 7.1282\n",
            "\n",
            "Epoch 00323: loss did not improve from 6.38383\n",
            "Epoch 324/500\n",
            "45/45 [==============================] - 1s 12ms/step - loss: 6.4532 - mae: 6.9325 - val_loss: 6.5205 - val_mae: 7.0024\n",
            "\n",
            "Epoch 00324: loss did not improve from 6.38383\n",
            "Epoch 325/500\n",
            "45/45 [==============================] - 1s 13ms/step - loss: 6.3786 - mae: 6.8593 - val_loss: 6.5521 - val_mae: 7.0323\n",
            "\n",
            "Epoch 00325: loss did not improve from 6.38383\n",
            "Epoch 326/500\n",
            "45/45 [==============================] - 1s 12ms/step - loss: 6.6654 - mae: 7.1477 - val_loss: 6.5698 - val_mae: 7.0511\n",
            "\n",
            "Epoch 00326: loss did not improve from 6.38383\n",
            "Epoch 327/500\n",
            "45/45 [==============================] - 1s 12ms/step - loss: 6.4348 - mae: 6.9147 - val_loss: 7.8467 - val_mae: 8.3323\n",
            "\n",
            "Epoch 00327: loss did not improve from 6.38383\n",
            "Epoch 328/500\n",
            "45/45 [==============================] - 1s 13ms/step - loss: 6.5586 - mae: 7.0398 - val_loss: 7.1189 - val_mae: 7.6021\n",
            "\n",
            "Epoch 00328: loss did not improve from 6.38383\n",
            "Epoch 329/500\n",
            "45/45 [==============================] - 1s 12ms/step - loss: 6.4132 - mae: 6.8925 - val_loss: 6.4797 - val_mae: 6.9606\n",
            "\n",
            "Epoch 00329: loss did not improve from 6.38383\n",
            "Epoch 330/500\n",
            "45/45 [==============================] - 1s 12ms/step - loss: 6.6817 - mae: 7.1610 - val_loss: 6.5457 - val_mae: 7.0268\n",
            "\n",
            "Epoch 00330: loss did not improve from 6.38383\n",
            "Epoch 331/500\n",
            "45/45 [==============================] - 1s 12ms/step - loss: 6.4104 - mae: 6.8887 - val_loss: 6.4353 - val_mae: 6.9166\n",
            "\n",
            "Epoch 00331: loss did not improve from 6.38383\n",
            "Epoch 332/500\n",
            "45/45 [==============================] - 1s 11ms/step - loss: 6.5224 - mae: 7.0010 - val_loss: 6.3945 - val_mae: 6.8746\n",
            "\n",
            "Epoch 00332: loss did not improve from 6.38383\n",
            "Epoch 333/500\n",
            "45/45 [==============================] - 1s 13ms/step - loss: 6.4727 - mae: 6.9535 - val_loss: 6.2924 - val_mae: 6.7727\n",
            "\n",
            "Epoch 00333: loss did not improve from 6.38383\n",
            "Epoch 334/500\n",
            "45/45 [==============================] - 1s 12ms/step - loss: 6.3152 - mae: 6.7937 - val_loss: 6.1575 - val_mae: 6.6379\n",
            "\n",
            "Epoch 00334: loss did not improve from 6.38383\n",
            "Epoch 335/500\n",
            "45/45 [==============================] - 1s 12ms/step - loss: 6.2631 - mae: 6.7414 - val_loss: 6.5348 - val_mae: 7.0161\n",
            "\n",
            "Epoch 00335: loss did not improve from 6.38383\n",
            "Epoch 336/500\n",
            "45/45 [==============================] - 1s 12ms/step - loss: 6.4005 - mae: 6.8804 - val_loss: 6.9479 - val_mae: 7.4287\n",
            "\n",
            "Epoch 00336: loss did not improve from 6.38383\n",
            "Epoch 337/500\n",
            "45/45 [==============================] - 1s 12ms/step - loss: 6.4859 - mae: 6.9665 - val_loss: 6.5579 - val_mae: 7.0400\n",
            "\n",
            "Epoch 00337: loss did not improve from 6.38383\n",
            "Epoch 338/500\n",
            "45/45 [==============================] - 1s 13ms/step - loss: 6.6577 - mae: 7.1385 - val_loss: 6.3904 - val_mae: 6.8720\n",
            "\n",
            "Epoch 00338: loss did not improve from 6.38383\n",
            "Epoch 339/500\n",
            "45/45 [==============================] - 1s 12ms/step - loss: 6.6631 - mae: 7.1441 - val_loss: 6.6195 - val_mae: 7.1014\n",
            "\n",
            "Epoch 00339: loss did not improve from 6.38383\n",
            "Epoch 340/500\n",
            "45/45 [==============================] - 1s 12ms/step - loss: 6.7666 - mae: 7.2482 - val_loss: 6.4278 - val_mae: 6.9094\n",
            "\n",
            "Epoch 00340: loss did not improve from 6.38383\n",
            "Epoch 341/500\n",
            "45/45 [==============================] - 1s 12ms/step - loss: 6.2025 - mae: 6.6820 - val_loss: 6.6765 - val_mae: 7.1575\n",
            "\n",
            "Epoch 00341: loss did not improve from 6.38383\n",
            "Epoch 342/500\n",
            "45/45 [==============================] - 1s 12ms/step - loss: 6.7307 - mae: 7.2111 - val_loss: 6.3674 - val_mae: 6.8478\n",
            "\n",
            "Epoch 00342: loss did not improve from 6.38383\n",
            "Epoch 343/500\n",
            "45/45 [==============================] - 1s 12ms/step - loss: 6.7381 - mae: 7.2177 - val_loss: 6.6267 - val_mae: 7.1080\n",
            "\n",
            "Epoch 00343: loss did not improve from 6.38383\n",
            "Epoch 344/500\n",
            "45/45 [==============================] - 1s 12ms/step - loss: 6.3695 - mae: 6.8478 - val_loss: 6.6667 - val_mae: 7.1487\n",
            "\n",
            "Epoch 00344: loss did not improve from 6.38383\n",
            "Epoch 345/500\n",
            "45/45 [==============================] - 1s 12ms/step - loss: 6.4348 - mae: 6.9138 - val_loss: 6.3882 - val_mae: 6.8697\n",
            "\n",
            "Epoch 00345: loss improved from 6.38383 to 6.38257, saving model to poids.hdf5\n",
            "Epoch 346/500\n",
            "45/45 [==============================] - 1s 12ms/step - loss: 6.3706 - mae: 6.8504 - val_loss: 6.5215 - val_mae: 7.0036\n",
            "\n",
            "Epoch 00346: loss did not improve from 6.38257\n",
            "Epoch 347/500\n",
            "45/45 [==============================] - 1s 12ms/step - loss: 6.6283 - mae: 7.1097 - val_loss: 6.3910 - val_mae: 6.8729\n",
            "\n",
            "Epoch 00347: loss did not improve from 6.38257\n",
            "Epoch 348/500\n",
            "45/45 [==============================] - 1s 12ms/step - loss: 6.6600 - mae: 7.1395 - val_loss: 6.8192 - val_mae: 7.3007\n",
            "\n",
            "Epoch 00348: loss did not improve from 6.38257\n",
            "Epoch 349/500\n",
            "45/45 [==============================] - 1s 12ms/step - loss: 6.6776 - mae: 7.1587 - val_loss: 6.8679 - val_mae: 7.3478\n",
            "\n",
            "Epoch 00349: loss did not improve from 6.38257\n",
            "Epoch 350/500\n",
            "45/45 [==============================] - 1s 12ms/step - loss: 6.4369 - mae: 6.9170 - val_loss: 6.9490 - val_mae: 7.4329\n",
            "\n",
            "Epoch 00350: loss did not improve from 6.38257\n",
            "Epoch 351/500\n",
            "45/45 [==============================] - 1s 13ms/step - loss: 6.4606 - mae: 6.9419 - val_loss: 7.4776 - val_mae: 7.9633\n",
            "\n",
            "Epoch 00351: loss did not improve from 6.38257\n",
            "Epoch 352/500\n",
            "45/45 [==============================] - 1s 12ms/step - loss: 6.6677 - mae: 7.1480 - val_loss: 6.6528 - val_mae: 7.1339\n",
            "\n",
            "Epoch 00352: loss did not improve from 6.38257\n",
            "Epoch 353/500\n",
            "45/45 [==============================] - 1s 12ms/step - loss: 6.3845 - mae: 6.8654 - val_loss: 6.5458 - val_mae: 7.0280\n",
            "\n",
            "Epoch 00353: loss did not improve from 6.38257\n",
            "Epoch 354/500\n",
            "45/45 [==============================] - 1s 12ms/step - loss: 6.9721 - mae: 7.4545 - val_loss: 6.6155 - val_mae: 7.0966\n",
            "\n",
            "Epoch 00354: loss did not improve from 6.38257\n",
            "Epoch 355/500\n",
            "45/45 [==============================] - 1s 12ms/step - loss: 6.3505 - mae: 6.8308 - val_loss: 6.6167 - val_mae: 7.0972\n",
            "\n",
            "Epoch 00355: loss did not improve from 6.38257\n",
            "Epoch 356/500\n",
            "45/45 [==============================] - 1s 13ms/step - loss: 6.2375 - mae: 6.7172 - val_loss: 7.0367 - val_mae: 7.5201\n",
            "\n",
            "Epoch 00356: loss did not improve from 6.38257\n",
            "Epoch 357/500\n",
            "45/45 [==============================] - 1s 12ms/step - loss: 6.4830 - mae: 6.9624 - val_loss: 6.4205 - val_mae: 6.9012\n",
            "\n",
            "Epoch 00357: loss did not improve from 6.38257\n",
            "Epoch 358/500\n",
            "45/45 [==============================] - 1s 12ms/step - loss: 6.3719 - mae: 6.8498 - val_loss: 6.6899 - val_mae: 7.1714\n",
            "\n",
            "Epoch 00358: loss did not improve from 6.38257\n",
            "Epoch 359/500\n",
            "45/45 [==============================] - 1s 12ms/step - loss: 6.6972 - mae: 7.1776 - val_loss: 6.4642 - val_mae: 6.9465\n",
            "\n",
            "Epoch 00359: loss did not improve from 6.38257\n",
            "Epoch 360/500\n",
            "45/45 [==============================] - 1s 13ms/step - loss: 6.5467 - mae: 7.0277 - val_loss: 6.2688 - val_mae: 6.7490\n",
            "\n",
            "Epoch 00360: loss did not improve from 6.38257\n",
            "Epoch 361/500\n",
            "45/45 [==============================] - 1s 14ms/step - loss: 6.3481 - mae: 6.8275 - val_loss: 6.5185 - val_mae: 6.9990\n",
            "\n",
            "Epoch 00361: loss did not improve from 6.38257\n",
            "Epoch 362/500\n",
            "45/45 [==============================] - 1s 12ms/step - loss: 6.6399 - mae: 7.1218 - val_loss: 6.5128 - val_mae: 6.9925\n",
            "\n",
            "Epoch 00362: loss did not improve from 6.38257\n",
            "Epoch 363/500\n",
            "45/45 [==============================] - 1s 13ms/step - loss: 6.2854 - mae: 6.7651 - val_loss: 6.5692 - val_mae: 7.0510\n",
            "\n",
            "Epoch 00363: loss did not improve from 6.38257\n",
            "Epoch 364/500\n",
            "45/45 [==============================] - 1s 12ms/step - loss: 6.5070 - mae: 6.9863 - val_loss: 6.4625 - val_mae: 6.9437\n",
            "\n",
            "Epoch 00364: loss did not improve from 6.38257\n",
            "Epoch 365/500\n",
            "45/45 [==============================] - 1s 12ms/step - loss: 6.4979 - mae: 6.9784 - val_loss: 6.7225 - val_mae: 7.2033\n",
            "\n",
            "Epoch 00365: loss did not improve from 6.38257\n",
            "Epoch 366/500\n",
            "45/45 [==============================] - 1s 14ms/step - loss: 6.7338 - mae: 7.2132 - val_loss: 6.8225 - val_mae: 7.3038\n",
            "\n",
            "Epoch 00366: loss did not improve from 6.38257\n",
            "Epoch 367/500\n",
            "45/45 [==============================] - 1s 12ms/step - loss: 6.5801 - mae: 7.0607 - val_loss: 6.4341 - val_mae: 6.9156\n",
            "\n",
            "Epoch 00367: loss did not improve from 6.38257\n",
            "Epoch 368/500\n",
            "45/45 [==============================] - 1s 13ms/step - loss: 6.4924 - mae: 6.9722 - val_loss: 6.6922 - val_mae: 7.1737\n",
            "\n",
            "Epoch 00368: loss improved from 6.38257 to 6.37490, saving model to poids.hdf5\n",
            "Epoch 369/500\n",
            "45/45 [==============================] - 1s 12ms/step - loss: 6.4649 - mae: 6.9451 - val_loss: 6.4198 - val_mae: 6.9009\n",
            "\n",
            "Epoch 00369: loss did not improve from 6.37490\n",
            "Epoch 370/500\n",
            "45/45 [==============================] - 1s 12ms/step - loss: 6.4389 - mae: 6.9172 - val_loss: 6.8550 - val_mae: 7.3356\n",
            "\n",
            "Epoch 00370: loss did not improve from 6.37490\n",
            "Epoch 371/500\n",
            "45/45 [==============================] - 1s 12ms/step - loss: 6.2889 - mae: 6.7683 - val_loss: 6.4241 - val_mae: 6.9056\n",
            "\n",
            "Epoch 00371: loss did not improve from 6.37490\n",
            "Epoch 372/500\n",
            "45/45 [==============================] - 1s 13ms/step - loss: 6.4651 - mae: 6.9457 - val_loss: 6.7762 - val_mae: 7.2578\n",
            "\n",
            "Epoch 00372: loss did not improve from 6.37490\n",
            "Epoch 373/500\n",
            "45/45 [==============================] - 1s 12ms/step - loss: 6.3006 - mae: 6.7809 - val_loss: 6.4550 - val_mae: 6.9352\n",
            "\n",
            "Epoch 00373: loss did not improve from 6.37490\n",
            "Epoch 374/500\n",
            "45/45 [==============================] - 1s 13ms/step - loss: 6.5871 - mae: 7.0679 - val_loss: 6.6432 - val_mae: 7.1244\n",
            "\n",
            "Epoch 00374: loss did not improve from 6.37490\n",
            "Epoch 375/500\n",
            "45/45 [==============================] - 1s 13ms/step - loss: 6.1968 - mae: 6.6756 - val_loss: 7.5291 - val_mae: 8.0135\n",
            "\n",
            "Epoch 00375: loss did not improve from 6.37490\n",
            "Epoch 376/500\n",
            "45/45 [==============================] - 1s 13ms/step - loss: 6.8018 - mae: 7.2836 - val_loss: 6.4088 - val_mae: 6.8903\n",
            "\n",
            "Epoch 00376: loss did not improve from 6.37490\n",
            "Epoch 377/500\n",
            "45/45 [==============================] - 1s 12ms/step - loss: 6.3286 - mae: 6.8090 - val_loss: 7.1431 - val_mae: 7.6280\n",
            "\n",
            "Epoch 00377: loss did not improve from 6.37490\n",
            "Epoch 378/500\n",
            "45/45 [==============================] - 1s 13ms/step - loss: 6.8597 - mae: 7.3395 - val_loss: 6.1602 - val_mae: 6.6408\n",
            "\n",
            "Epoch 00378: loss did not improve from 6.37490\n",
            "Epoch 379/500\n",
            "45/45 [==============================] - 1s 13ms/step - loss: 6.6430 - mae: 7.1234 - val_loss: 6.4983 - val_mae: 6.9792\n",
            "\n",
            "Epoch 00379: loss did not improve from 6.37490\n",
            "Epoch 380/500\n",
            "45/45 [==============================] - 1s 13ms/step - loss: 6.7125 - mae: 7.1921 - val_loss: 6.6498 - val_mae: 7.1318\n",
            "\n",
            "Epoch 00380: loss did not improve from 6.37490\n",
            "Epoch 381/500\n",
            "45/45 [==============================] - 1s 13ms/step - loss: 6.0868 - mae: 6.5644 - val_loss: 6.3609 - val_mae: 6.8427\n",
            "\n",
            "Epoch 00381: loss did not improve from 6.37490\n",
            "Epoch 382/500\n",
            "45/45 [==============================] - 1s 13ms/step - loss: 6.2453 - mae: 6.7239 - val_loss: 6.2507 - val_mae: 6.7308\n",
            "\n",
            "Epoch 00382: loss did not improve from 6.37490\n",
            "Epoch 383/500\n",
            "45/45 [==============================] - 1s 13ms/step - loss: 6.4655 - mae: 6.9473 - val_loss: 6.4354 - val_mae: 6.9164\n",
            "\n",
            "Epoch 00383: loss did not improve from 6.37490\n",
            "Epoch 384/500\n",
            "45/45 [==============================] - 1s 12ms/step - loss: 6.0175 - mae: 6.4964 - val_loss: 6.8095 - val_mae: 7.2910\n",
            "\n",
            "Epoch 00384: loss did not improve from 6.37490\n",
            "Epoch 385/500\n",
            "45/45 [==============================] - 1s 12ms/step - loss: 6.8031 - mae: 7.2834 - val_loss: 6.4666 - val_mae: 6.9480\n",
            "\n",
            "Epoch 00385: loss did not improve from 6.37490\n",
            "Epoch 386/500\n",
            "45/45 [==============================] - 1s 13ms/step - loss: 6.4589 - mae: 6.9385 - val_loss: 6.4718 - val_mae: 6.9530\n",
            "\n",
            "Epoch 00386: loss did not improve from 6.37490\n",
            "Epoch 387/500\n",
            "45/45 [==============================] - 1s 12ms/step - loss: 6.4554 - mae: 6.9348 - val_loss: 6.6014 - val_mae: 7.0817\n",
            "\n",
            "Epoch 00387: loss did not improve from 6.37490\n",
            "Epoch 388/500\n",
            "45/45 [==============================] - 1s 12ms/step - loss: 6.7078 - mae: 7.1888 - val_loss: 6.5110 - val_mae: 6.9914\n",
            "\n",
            "Epoch 00388: loss did not improve from 6.37490\n",
            "Epoch 389/500\n",
            "45/45 [==============================] - 1s 13ms/step - loss: 6.5225 - mae: 7.0012 - val_loss: 6.7917 - val_mae: 7.2730\n",
            "\n",
            "Epoch 00389: loss did not improve from 6.37490\n",
            "Epoch 390/500\n",
            "45/45 [==============================] - 1s 14ms/step - loss: 6.5184 - mae: 6.9967 - val_loss: 6.6631 - val_mae: 7.1442\n",
            "\n",
            "Epoch 00390: loss improved from 6.37490 to 6.35863, saving model to poids.hdf5\n",
            "Epoch 391/500\n",
            "45/45 [==============================] - 1s 12ms/step - loss: 6.5109 - mae: 6.9898 - val_loss: 6.4211 - val_mae: 6.9023\n",
            "\n",
            "Epoch 00391: loss did not improve from 6.35863\n",
            "Epoch 392/500\n",
            "45/45 [==============================] - 1s 13ms/step - loss: 6.3356 - mae: 6.8129 - val_loss: 6.8166 - val_mae: 7.2986\n",
            "\n",
            "Epoch 00392: loss did not improve from 6.35863\n",
            "Epoch 393/500\n",
            "45/45 [==============================] - 1s 13ms/step - loss: 6.5636 - mae: 7.0441 - val_loss: 6.3832 - val_mae: 6.8635\n",
            "\n",
            "Epoch 00393: loss did not improve from 6.35863\n",
            "Epoch 394/500\n",
            "45/45 [==============================] - 1s 12ms/step - loss: 6.4444 - mae: 6.9217 - val_loss: 6.8681 - val_mae: 7.3503\n",
            "\n",
            "Epoch 00394: loss did not improve from 6.35863\n",
            "Epoch 395/500\n",
            "45/45 [==============================] - 1s 13ms/step - loss: 6.5077 - mae: 6.9883 - val_loss: 7.9922 - val_mae: 8.4790\n",
            "\n",
            "Epoch 00395: loss did not improve from 6.35863\n",
            "Epoch 396/500\n",
            "45/45 [==============================] - 1s 12ms/step - loss: 6.9489 - mae: 7.4306 - val_loss: 6.6511 - val_mae: 7.1330\n",
            "\n",
            "Epoch 00396: loss did not improve from 6.35863\n",
            "Epoch 397/500\n",
            "45/45 [==============================] - 1s 13ms/step - loss: 6.6064 - mae: 7.0863 - val_loss: 7.0678 - val_mae: 7.5492\n",
            "\n",
            "Epoch 00397: loss did not improve from 6.35863\n",
            "Epoch 398/500\n",
            "45/45 [==============================] - 1s 13ms/step - loss: 6.3213 - mae: 6.8015 - val_loss: 6.8470 - val_mae: 7.3292\n",
            "\n",
            "Epoch 00398: loss did not improve from 6.35863\n",
            "Epoch 399/500\n",
            "45/45 [==============================] - 1s 12ms/step - loss: 6.5184 - mae: 6.9984 - val_loss: 6.8492 - val_mae: 7.3317\n",
            "\n",
            "Epoch 00399: loss did not improve from 6.35863\n",
            "Epoch 400/500\n",
            "45/45 [==============================] - 1s 13ms/step - loss: 6.4114 - mae: 6.8911 - val_loss: 6.3524 - val_mae: 6.8331\n",
            "\n",
            "Epoch 00400: loss did not improve from 6.35863\n",
            "Epoch 401/500\n",
            "45/45 [==============================] - 1s 12ms/step - loss: 6.2857 - mae: 6.7646 - val_loss: 6.3930 - val_mae: 6.8754\n",
            "\n",
            "Epoch 00401: loss did not improve from 6.35863\n",
            "Epoch 402/500\n",
            "45/45 [==============================] - 1s 13ms/step - loss: 6.5078 - mae: 6.9863 - val_loss: 6.8721 - val_mae: 7.3550\n",
            "\n",
            "Epoch 00402: loss did not improve from 6.35863\n",
            "Epoch 403/500\n",
            "45/45 [==============================] - 1s 13ms/step - loss: 6.3671 - mae: 6.8476 - val_loss: 6.6559 - val_mae: 7.1373\n",
            "\n",
            "Epoch 00403: loss did not improve from 6.35863\n",
            "Epoch 404/500\n",
            "45/45 [==============================] - 1s 13ms/step - loss: 6.3492 - mae: 6.8296 - val_loss: 6.3722 - val_mae: 6.8529\n",
            "\n",
            "Epoch 00404: loss did not improve from 6.35863\n",
            "Epoch 405/500\n",
            "45/45 [==============================] - 1s 12ms/step - loss: 6.6721 - mae: 7.1529 - val_loss: 6.5359 - val_mae: 7.0167\n",
            "\n",
            "Epoch 00405: loss did not improve from 6.35863\n",
            "Epoch 406/500\n",
            "45/45 [==============================] - 1s 12ms/step - loss: 6.5829 - mae: 7.0625 - val_loss: 6.4930 - val_mae: 6.9736\n",
            "\n",
            "Epoch 00406: loss did not improve from 6.35863\n",
            "Epoch 407/500\n",
            "45/45 [==============================] - 1s 12ms/step - loss: 6.5325 - mae: 7.0128 - val_loss: 6.7171 - val_mae: 7.1975\n",
            "\n",
            "Epoch 00407: loss did not improve from 6.35863\n",
            "Epoch 408/500\n",
            "45/45 [==============================] - 1s 12ms/step - loss: 6.2418 - mae: 6.7197 - val_loss: 6.6134 - val_mae: 7.0937\n",
            "\n",
            "Epoch 00408: loss did not improve from 6.35863\n",
            "Epoch 409/500\n",
            "45/45 [==============================] - 1s 12ms/step - loss: 6.3409 - mae: 6.8209 - val_loss: 6.3798 - val_mae: 6.8605\n",
            "\n",
            "Epoch 00409: loss did not improve from 6.35863\n",
            "Epoch 410/500\n",
            "45/45 [==============================] - 1s 13ms/step - loss: 7.1062 - mae: 7.5876 - val_loss: 6.4926 - val_mae: 6.9730\n",
            "\n",
            "Epoch 00410: loss did not improve from 6.35863\n",
            "Epoch 411/500\n",
            "45/45 [==============================] - 1s 13ms/step - loss: 6.5535 - mae: 7.0330 - val_loss: 7.7380 - val_mae: 8.2235\n",
            "\n",
            "Epoch 00411: loss did not improve from 6.35863\n",
            "Epoch 412/500\n",
            "45/45 [==============================] - 1s 12ms/step - loss: 6.1827 - mae: 6.6635 - val_loss: 6.3051 - val_mae: 6.7855\n",
            "\n",
            "Epoch 00412: loss did not improve from 6.35863\n",
            "Epoch 413/500\n",
            "45/45 [==============================] - 1s 13ms/step - loss: 6.1783 - mae: 6.6565 - val_loss: 6.3421 - val_mae: 6.8226\n",
            "\n",
            "Epoch 00413: loss did not improve from 6.35863\n",
            "Epoch 414/500\n",
            "45/45 [==============================] - 1s 12ms/step - loss: 6.1445 - mae: 6.6248 - val_loss: 6.6215 - val_mae: 7.1024\n",
            "\n",
            "Epoch 00414: loss did not improve from 6.35863\n",
            "Epoch 415/500\n",
            "45/45 [==============================] - 1s 12ms/step - loss: 6.7269 - mae: 7.2081 - val_loss: 6.4668 - val_mae: 6.9483\n",
            "\n",
            "Epoch 00415: loss did not improve from 6.35863\n",
            "Epoch 416/500\n",
            "45/45 [==============================] - 1s 13ms/step - loss: 6.8368 - mae: 7.3184 - val_loss: 6.5325 - val_mae: 7.0138\n",
            "\n",
            "Epoch 00416: loss did not improve from 6.35863\n",
            "Epoch 417/500\n",
            "45/45 [==============================] - 1s 13ms/step - loss: 6.3990 - mae: 6.8781 - val_loss: 6.8263 - val_mae: 7.3076\n",
            "\n",
            "Epoch 00417: loss did not improve from 6.35863\n",
            "Epoch 418/500\n",
            "45/45 [==============================] - 1s 12ms/step - loss: 6.7013 - mae: 7.1824 - val_loss: 6.5982 - val_mae: 7.0792\n",
            "\n",
            "Epoch 00418: loss did not improve from 6.35863\n",
            "Epoch 419/500\n",
            "45/45 [==============================] - 1s 13ms/step - loss: 6.5810 - mae: 7.0598 - val_loss: 6.6309 - val_mae: 7.1122\n",
            "\n",
            "Epoch 00419: loss did not improve from 6.35863\n",
            "Epoch 420/500\n",
            "45/45 [==============================] - 1s 13ms/step - loss: 6.5537 - mae: 7.0332 - val_loss: 6.6241 - val_mae: 7.1057\n",
            "\n",
            "Epoch 00420: loss did not improve from 6.35863\n",
            "Epoch 421/500\n",
            "45/45 [==============================] - 1s 13ms/step - loss: 6.6931 - mae: 7.1722 - val_loss: 6.6789 - val_mae: 7.1594\n",
            "\n",
            "Epoch 00421: loss did not improve from 6.35863\n",
            "Epoch 422/500\n",
            "45/45 [==============================] - 1s 13ms/step - loss: 6.2263 - mae: 6.7074 - val_loss: 6.4468 - val_mae: 6.9291\n",
            "\n",
            "Epoch 00422: loss did not improve from 6.35863\n",
            "Epoch 423/500\n",
            "45/45 [==============================] - 1s 13ms/step - loss: 6.3829 - mae: 6.8621 - val_loss: 6.5312 - val_mae: 7.0140\n",
            "\n",
            "Epoch 00423: loss did not improve from 6.35863\n",
            "Epoch 424/500\n",
            "45/45 [==============================] - 1s 13ms/step - loss: 6.3107 - mae: 6.7901 - val_loss: 6.3828 - val_mae: 6.8637\n",
            "\n",
            "Epoch 00424: loss did not improve from 6.35863\n",
            "Epoch 425/500\n",
            "45/45 [==============================] - 1s 13ms/step - loss: 6.5298 - mae: 7.0104 - val_loss: 6.6845 - val_mae: 7.1661\n",
            "\n",
            "Epoch 00425: loss did not improve from 6.35863\n",
            "Epoch 426/500\n",
            "45/45 [==============================] - 1s 12ms/step - loss: 6.4196 - mae: 6.8988 - val_loss: 6.8461 - val_mae: 7.3280\n",
            "\n",
            "Epoch 00426: loss did not improve from 6.35863\n",
            "Epoch 427/500\n",
            "45/45 [==============================] - 1s 12ms/step - loss: 6.3454 - mae: 6.8251 - val_loss: 6.4224 - val_mae: 6.9019\n",
            "\n",
            "Epoch 00427: loss did not improve from 6.35863\n",
            "Epoch 428/500\n",
            "45/45 [==============================] - 1s 13ms/step - loss: 6.1395 - mae: 6.6196 - val_loss: 6.4532 - val_mae: 6.9331\n",
            "\n",
            "Epoch 00428: loss did not improve from 6.35863\n",
            "Epoch 429/500\n",
            "45/45 [==============================] - 1s 12ms/step - loss: 6.5006 - mae: 6.9809 - val_loss: 6.4022 - val_mae: 6.8839\n",
            "\n",
            "Epoch 00429: loss improved from 6.35863 to 6.34941, saving model to poids.hdf5\n",
            "Epoch 430/500\n",
            "45/45 [==============================] - 1s 12ms/step - loss: 6.1686 - mae: 6.6483 - val_loss: 6.7348 - val_mae: 7.2165\n",
            "\n",
            "Epoch 00430: loss did not improve from 6.34941\n",
            "Epoch 431/500\n",
            "45/45 [==============================] - 1s 13ms/step - loss: 6.5850 - mae: 7.0642 - val_loss: 6.4186 - val_mae: 6.8991\n",
            "\n",
            "Epoch 00431: loss did not improve from 6.34941\n",
            "Epoch 432/500\n",
            "45/45 [==============================] - 1s 13ms/step - loss: 6.7122 - mae: 7.1917 - val_loss: 6.3604 - val_mae: 6.8410\n",
            "\n",
            "Epoch 00432: loss did not improve from 6.34941\n",
            "Epoch 433/500\n",
            "45/45 [==============================] - 1s 12ms/step - loss: 6.7688 - mae: 7.2485 - val_loss: 6.7383 - val_mae: 7.2192\n",
            "\n",
            "Epoch 00433: loss did not improve from 6.34941\n",
            "Epoch 434/500\n",
            "45/45 [==============================] - 1s 13ms/step - loss: 6.8150 - mae: 7.2965 - val_loss: 6.5993 - val_mae: 7.0806\n",
            "\n",
            "Epoch 00434: loss did not improve from 6.34941\n",
            "Epoch 435/500\n",
            "45/45 [==============================] - 1s 12ms/step - loss: 6.4360 - mae: 6.9157 - val_loss: 6.5528 - val_mae: 7.0348\n",
            "\n",
            "Epoch 00435: loss did not improve from 6.34941\n",
            "Epoch 436/500\n",
            "45/45 [==============================] - 1s 13ms/step - loss: 6.3610 - mae: 6.8417 - val_loss: 6.6276 - val_mae: 7.1088\n",
            "\n",
            "Epoch 00436: loss did not improve from 6.34941\n",
            "Epoch 437/500\n",
            "45/45 [==============================] - 1s 12ms/step - loss: 6.3485 - mae: 6.8277 - val_loss: 6.6110 - val_mae: 7.0930\n",
            "\n",
            "Epoch 00437: loss did not improve from 6.34941\n",
            "Epoch 438/500\n",
            "45/45 [==============================] - 1s 12ms/step - loss: 6.2437 - mae: 6.7245 - val_loss: 6.3382 - val_mae: 6.8197\n",
            "\n",
            "Epoch 00438: loss did not improve from 6.34941\n",
            "Epoch 439/500\n",
            "45/45 [==============================] - 1s 13ms/step - loss: 6.3981 - mae: 6.8774 - val_loss: 6.4054 - val_mae: 6.8873\n",
            "\n",
            "Epoch 00439: loss did not improve from 6.34941\n",
            "Epoch 440/500\n",
            "45/45 [==============================] - 1s 13ms/step - loss: 6.2390 - mae: 6.7183 - val_loss: 6.7295 - val_mae: 7.2099\n",
            "\n",
            "Epoch 00440: loss did not improve from 6.34941\n",
            "Epoch 441/500\n",
            "45/45 [==============================] - 1s 12ms/step - loss: 6.2883 - mae: 6.7674 - val_loss: 6.4903 - val_mae: 6.9705\n",
            "\n",
            "Epoch 00441: loss did not improve from 6.34941\n",
            "Epoch 442/500\n",
            "45/45 [==============================] - 1s 12ms/step - loss: 6.2585 - mae: 6.7381 - val_loss: 6.3167 - val_mae: 6.7981\n",
            "\n",
            "Epoch 00442: loss did not improve from 6.34941\n",
            "Epoch 443/500\n",
            "45/45 [==============================] - 1s 13ms/step - loss: 6.1154 - mae: 6.5951 - val_loss: 6.4472 - val_mae: 6.9297\n",
            "\n",
            "Epoch 00443: loss did not improve from 6.34941\n",
            "Epoch 444/500\n",
            "45/45 [==============================] - 1s 13ms/step - loss: 6.7782 - mae: 7.2570 - val_loss: 6.5419 - val_mae: 7.0230\n",
            "\n",
            "Epoch 00444: loss did not improve from 6.34941\n",
            "Epoch 445/500\n",
            "45/45 [==============================] - 1s 12ms/step - loss: 6.3440 - mae: 6.8211 - val_loss: 6.8853 - val_mae: 7.3660\n",
            "\n",
            "Epoch 00445: loss did not improve from 6.34941\n",
            "Epoch 446/500\n",
            "45/45 [==============================] - 1s 13ms/step - loss: 6.4162 - mae: 6.8945 - val_loss: 6.6747 - val_mae: 7.1554\n",
            "\n",
            "Epoch 00446: loss did not improve from 6.34941\n",
            "Epoch 447/500\n",
            "45/45 [==============================] - 1s 13ms/step - loss: 6.0768 - mae: 6.5549 - val_loss: 6.3844 - val_mae: 6.8654\n",
            "\n",
            "Epoch 00447: loss did not improve from 6.34941\n",
            "Epoch 448/500\n",
            "45/45 [==============================] - 1s 13ms/step - loss: 5.9624 - mae: 6.4397 - val_loss: 6.4157 - val_mae: 6.8961\n",
            "\n",
            "Epoch 00448: loss did not improve from 6.34941\n",
            "Epoch 449/500\n",
            "45/45 [==============================] - 1s 14ms/step - loss: 6.4158 - mae: 6.8947 - val_loss: 6.9179 - val_mae: 7.3997\n",
            "\n",
            "Epoch 00449: loss did not improve from 6.34941\n",
            "Epoch 450/500\n",
            "45/45 [==============================] - 1s 13ms/step - loss: 6.5196 - mae: 6.9996 - val_loss: 6.4299 - val_mae: 6.9121\n",
            "\n",
            "Epoch 00450: loss did not improve from 6.34941\n",
            "Epoch 451/500\n",
            "45/45 [==============================] - 1s 13ms/step - loss: 6.3634 - mae: 6.8410 - val_loss: 6.3826 - val_mae: 6.8629\n",
            "\n",
            "Epoch 00451: loss did not improve from 6.34941\n",
            "Epoch 452/500\n",
            "45/45 [==============================] - 1s 13ms/step - loss: 6.6935 - mae: 7.1726 - val_loss: 6.3255 - val_mae: 6.8061\n",
            "\n",
            "Epoch 00452: loss did not improve from 6.34941\n",
            "Epoch 453/500\n",
            "45/45 [==============================] - 1s 13ms/step - loss: 6.5538 - mae: 7.0340 - val_loss: 6.9076 - val_mae: 7.3883\n",
            "\n",
            "Epoch 00453: loss did not improve from 6.34941\n",
            "Epoch 454/500\n",
            "45/45 [==============================] - 1s 13ms/step - loss: 6.3535 - mae: 6.8321 - val_loss: 6.4573 - val_mae: 6.9383\n",
            "\n",
            "Epoch 00454: loss did not improve from 6.34941\n",
            "Epoch 455/500\n",
            "45/45 [==============================] - 1s 13ms/step - loss: 6.4502 - mae: 6.9300 - val_loss: 6.3842 - val_mae: 6.8646\n",
            "\n",
            "Epoch 00455: loss did not improve from 6.34941\n",
            "Epoch 456/500\n",
            "45/45 [==============================] - 1s 12ms/step - loss: 6.3713 - mae: 6.8515 - val_loss: 6.3664 - val_mae: 6.8475\n",
            "\n",
            "Epoch 00456: loss improved from 6.34941 to 6.34043, saving model to poids.hdf5\n",
            "Epoch 457/500\n",
            "45/45 [==============================] - 1s 12ms/step - loss: 6.5056 - mae: 6.9844 - val_loss: 6.3262 - val_mae: 6.8067\n",
            "\n",
            "Epoch 00457: loss did not improve from 6.34043\n",
            "Epoch 458/500\n",
            "45/45 [==============================] - 1s 12ms/step - loss: 6.3330 - mae: 6.8139 - val_loss: 6.4797 - val_mae: 6.9614\n",
            "\n",
            "Epoch 00458: loss did not improve from 6.34043\n",
            "Epoch 459/500\n",
            "45/45 [==============================] - 1s 12ms/step - loss: 6.4916 - mae: 6.9699 - val_loss: 6.3000 - val_mae: 6.7808\n",
            "\n",
            "Epoch 00459: loss did not improve from 6.34043\n",
            "Epoch 460/500\n",
            "45/45 [==============================] - 1s 12ms/step - loss: 6.5157 - mae: 6.9960 - val_loss: 6.4436 - val_mae: 6.9258\n",
            "\n",
            "Epoch 00460: loss did not improve from 6.34043\n",
            "Epoch 461/500\n",
            "45/45 [==============================] - 1s 12ms/step - loss: 6.2580 - mae: 6.7345 - val_loss: 6.8596 - val_mae: 7.3418\n",
            "\n",
            "Epoch 00461: loss did not improve from 6.34043\n",
            "Epoch 462/500\n",
            "45/45 [==============================] - 1s 13ms/step - loss: 6.3327 - mae: 6.8100 - val_loss: 6.4709 - val_mae: 6.9520\n",
            "\n",
            "Epoch 00462: loss did not improve from 6.34043\n",
            "Epoch 463/500\n",
            "45/45 [==============================] - 1s 12ms/step - loss: 6.6209 - mae: 7.1000 - val_loss: 6.5711 - val_mae: 7.0538\n",
            "\n",
            "Epoch 00463: loss did not improve from 6.34043\n",
            "Epoch 464/500\n",
            "45/45 [==============================] - 1s 13ms/step - loss: 6.0225 - mae: 6.5004 - val_loss: 6.4522 - val_mae: 6.9336\n",
            "\n",
            "Epoch 00464: loss did not improve from 6.34043\n",
            "Epoch 465/500\n",
            "45/45 [==============================] - 1s 12ms/step - loss: 6.3728 - mae: 6.8530 - val_loss: 6.5257 - val_mae: 7.0061\n",
            "\n",
            "Epoch 00465: loss did not improve from 6.34043\n",
            "Epoch 466/500\n",
            "45/45 [==============================] - 1s 13ms/step - loss: 6.4225 - mae: 6.9025 - val_loss: 6.3730 - val_mae: 6.8534\n",
            "\n",
            "Epoch 00466: loss did not improve from 6.34043\n",
            "Epoch 467/500\n",
            "45/45 [==============================] - 1s 13ms/step - loss: 6.2918 - mae: 6.7711 - val_loss: 6.5702 - val_mae: 7.0526\n",
            "\n",
            "Epoch 00467: loss did not improve from 6.34043\n",
            "Epoch 468/500\n",
            "45/45 [==============================] - 1s 13ms/step - loss: 6.4718 - mae: 6.9495 - val_loss: 6.7225 - val_mae: 7.2036\n",
            "\n",
            "Epoch 00468: loss did not improve from 6.34043\n",
            "Epoch 469/500\n",
            "45/45 [==============================] - 1s 14ms/step - loss: 6.4886 - mae: 6.9681 - val_loss: 6.3266 - val_mae: 6.8067\n",
            "\n",
            "Epoch 00469: loss did not improve from 6.34043\n",
            "Epoch 470/500\n",
            "45/45 [==============================] - 1s 12ms/step - loss: 6.3630 - mae: 6.8415 - val_loss: 6.6294 - val_mae: 7.1102\n",
            "\n",
            "Epoch 00470: loss did not improve from 6.34043\n",
            "Epoch 471/500\n",
            "45/45 [==============================] - 1s 13ms/step - loss: 6.4047 - mae: 6.8846 - val_loss: 6.4742 - val_mae: 6.9564\n",
            "\n",
            "Epoch 00471: loss did not improve from 6.34043\n",
            "Epoch 472/500\n",
            "45/45 [==============================] - 1s 13ms/step - loss: 6.2730 - mae: 6.7510 - val_loss: 7.0551 - val_mae: 7.5372\n",
            "\n",
            "Epoch 00472: loss did not improve from 6.34043\n",
            "Epoch 473/500\n",
            "45/45 [==============================] - 1s 12ms/step - loss: 6.3786 - mae: 6.8590 - val_loss: 6.6423 - val_mae: 7.1242\n",
            "\n",
            "Epoch 00473: loss did not improve from 6.34043\n",
            "Epoch 474/500\n",
            "45/45 [==============================] - 1s 12ms/step - loss: 6.4175 - mae: 6.8954 - val_loss: 6.5941 - val_mae: 7.0762\n",
            "\n",
            "Epoch 00474: loss did not improve from 6.34043\n",
            "Epoch 475/500\n",
            "45/45 [==============================] - 1s 13ms/step - loss: 6.3735 - mae: 6.8539 - val_loss: 6.3493 - val_mae: 6.8292\n",
            "\n",
            "Epoch 00475: loss did not improve from 6.34043\n",
            "Epoch 476/500\n",
            "45/45 [==============================] - 1s 12ms/step - loss: 6.2590 - mae: 6.7382 - val_loss: 6.4704 - val_mae: 6.9503\n",
            "\n",
            "Epoch 00476: loss did not improve from 6.34043\n",
            "Epoch 477/500\n",
            "45/45 [==============================] - 1s 13ms/step - loss: 6.4412 - mae: 6.9207 - val_loss: 7.0126 - val_mae: 7.4980\n",
            "\n",
            "Epoch 00477: loss did not improve from 6.34043\n",
            "Epoch 478/500\n",
            "45/45 [==============================] - 1s 13ms/step - loss: 6.4410 - mae: 6.9210 - val_loss: 6.5343 - val_mae: 7.0164\n",
            "\n",
            "Epoch 00478: loss did not improve from 6.34043\n",
            "Epoch 479/500\n",
            "45/45 [==============================] - 1s 13ms/step - loss: 6.3888 - mae: 6.8679 - val_loss: 6.4125 - val_mae: 6.8937\n",
            "\n",
            "Epoch 00479: loss improved from 6.34043 to 6.33832, saving model to poids.hdf5\n",
            "Epoch 480/500\n",
            "45/45 [==============================] - 1s 12ms/step - loss: 6.3058 - mae: 6.7838 - val_loss: 6.4123 - val_mae: 6.8927\n",
            "\n",
            "Epoch 00480: loss did not improve from 6.33832\n",
            "Epoch 481/500\n",
            "45/45 [==============================] - 1s 12ms/step - loss: 6.5210 - mae: 6.9985 - val_loss: 6.4027 - val_mae: 6.8846\n",
            "\n",
            "Epoch 00481: loss did not improve from 6.33832\n",
            "Epoch 482/500\n",
            "45/45 [==============================] - 1s 12ms/step - loss: 6.6693 - mae: 7.1500 - val_loss: 6.8258 - val_mae: 7.3070\n",
            "\n",
            "Epoch 00482: loss did not improve from 6.33832\n",
            "Epoch 483/500\n",
            "45/45 [==============================] - 1s 12ms/step - loss: 6.3982 - mae: 6.8767 - val_loss: 6.7940 - val_mae: 7.2744\n",
            "\n",
            "Epoch 00483: loss did not improve from 6.33832\n",
            "Epoch 484/500\n",
            "45/45 [==============================] - 1s 13ms/step - loss: 6.6653 - mae: 7.1447 - val_loss: 6.5434 - val_mae: 7.0241\n",
            "\n",
            "Epoch 00484: loss did not improve from 6.33832\n",
            "Epoch 485/500\n",
            "45/45 [==============================] - 1s 12ms/step - loss: 6.5236 - mae: 7.0011 - val_loss: 6.5249 - val_mae: 7.0063\n",
            "\n",
            "Epoch 00485: loss did not improve from 6.33832\n",
            "Epoch 486/500\n",
            "45/45 [==============================] - 1s 12ms/step - loss: 6.3846 - mae: 6.8667 - val_loss: 6.4888 - val_mae: 6.9695\n",
            "\n",
            "Epoch 00486: loss did not improve from 6.33832\n",
            "Epoch 487/500\n",
            "45/45 [==============================] - 1s 12ms/step - loss: 6.7468 - mae: 7.2260 - val_loss: 6.5527 - val_mae: 7.0336\n",
            "\n",
            "Epoch 00487: loss did not improve from 6.33832\n",
            "Epoch 488/500\n",
            "45/45 [==============================] - 1s 13ms/step - loss: 6.3761 - mae: 6.8560 - val_loss: 6.7265 - val_mae: 7.2079\n",
            "\n",
            "Epoch 00488: loss did not improve from 6.33832\n",
            "Epoch 489/500\n",
            "45/45 [==============================] - 1s 13ms/step - loss: 6.6714 - mae: 7.1517 - val_loss: 6.3076 - val_mae: 6.7889\n",
            "\n",
            "Epoch 00489: loss did not improve from 6.33832\n",
            "Epoch 490/500\n",
            "45/45 [==============================] - 1s 13ms/step - loss: 6.6636 - mae: 7.1414 - val_loss: 6.4496 - val_mae: 6.9312\n",
            "\n",
            "Epoch 00490: loss did not improve from 6.33832\n",
            "Epoch 491/500\n",
            "45/45 [==============================] - 1s 13ms/step - loss: 6.3753 - mae: 6.8566 - val_loss: 6.9114 - val_mae: 7.3928\n",
            "\n",
            "Epoch 00491: loss did not improve from 6.33832\n",
            "Epoch 492/500\n",
            "45/45 [==============================] - 1s 13ms/step - loss: 6.2429 - mae: 6.7227 - val_loss: 6.5595 - val_mae: 7.0410\n",
            "\n",
            "Epoch 00492: loss did not improve from 6.33832\n",
            "Epoch 493/500\n",
            "45/45 [==============================] - 1s 12ms/step - loss: 6.4776 - mae: 6.9580 - val_loss: 6.5219 - val_mae: 7.0033\n",
            "\n",
            "Epoch 00493: loss did not improve from 6.33832\n",
            "Epoch 494/500\n",
            "45/45 [==============================] - 1s 13ms/step - loss: 6.6810 - mae: 7.1625 - val_loss: 6.2572 - val_mae: 6.7381\n",
            "\n",
            "Epoch 00494: loss did not improve from 6.33832\n",
            "Epoch 495/500\n",
            "45/45 [==============================] - 1s 12ms/step - loss: 6.4351 - mae: 6.9148 - val_loss: 6.3357 - val_mae: 6.8174\n",
            "\n",
            "Epoch 00495: loss did not improve from 6.33832\n",
            "Epoch 496/500\n",
            "45/45 [==============================] - 1s 13ms/step - loss: 6.3383 - mae: 6.8180 - val_loss: 6.4979 - val_mae: 6.9793\n",
            "\n",
            "Epoch 00496: loss improved from 6.33832 to 6.31755, saving model to poids.hdf5\n",
            "Epoch 497/500\n",
            "45/45 [==============================] - 1s 13ms/step - loss: 6.6565 - mae: 7.1354 - val_loss: 6.3182 - val_mae: 6.7997\n",
            "\n",
            "Epoch 00497: loss did not improve from 6.31755\n",
            "Epoch 498/500\n",
            "45/45 [==============================] - 1s 13ms/step - loss: 6.2601 - mae: 6.7386 - val_loss: 6.3492 - val_mae: 6.8298\n",
            "\n",
            "Epoch 00498: loss did not improve from 6.31755\n",
            "Epoch 499/500\n",
            "45/45 [==============================] - 1s 12ms/step - loss: 6.4308 - mae: 6.9103 - val_loss: 6.2997 - val_mae: 6.7803\n",
            "\n",
            "Epoch 00499: loss did not improve from 6.31755\n",
            "Epoch 500/500\n",
            "45/45 [==============================] - 1s 13ms/step - loss: 6.5710 - mae: 7.0491 - val_loss: 6.3437 - val_mae: 6.8255\n",
            "\n",
            "Epoch 00500: loss did not improve from 6.31755\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "COP9u4yitvmw"
      },
      "source": [
        "erreur_entrainement = historique.history[\"loss\"]\r\n",
        "erreur_validation = historique.history[\"val_loss\"]\r\n",
        "\r\n",
        "# Affiche l'erreur en fonction de la période\r\n",
        "plt.figure(figsize=(10, 6))\r\n",
        "plt.plot(np.arange(0,len(erreur_entrainement)),erreur_entrainement, label=\"Erreurs sur les entrainements\")\r\n",
        "plt.plot(np.arange(0,len(erreur_entrainement)),erreur_validation, label =\"Erreurs sur les validations\")\r\n",
        "plt.legend()\r\n",
        "\r\n",
        "plt.title(\"Evolution de l'erreur en fonction de la période\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_o2zh6N9t1b7"
      },
      "source": [
        "erreur_entrainement = historique.history[\"loss\"]\r\n",
        "erreur_validation = historique.history[\"val_loss\"]\r\n",
        "\r\n",
        "# Affiche l'erreur en fonction de la période\r\n",
        "plt.figure(figsize=(10, 6))\r\n",
        "plt.plot(np.arange(0,len(erreur_entrainement[400:500])),erreur_entrainement[400:500], label=\"Erreurs sur les entrainements\")\r\n",
        "plt.plot(np.arange(0,len(erreur_entrainement[400:500])),erreur_validation[400:500], label =\"Erreurs sur les validations\")\r\n",
        "plt.legend()\r\n",
        "\r\n",
        "plt.title(\"Evolution de l'erreur en fonction de la période\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T6Gq2CkeGR_1"
      },
      "source": [
        "**4. Prédictions**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OcGnqie_GVNE"
      },
      "source": [
        "# Charge les meilleurs poids\r\n",
        "model.load_weights(\"poids.hdf5\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HRxXtHRXGXfF"
      },
      "source": [
        "taille_fenetre = 20\r\n",
        "\r\n",
        "# Création d'une liste vide pour recevoir les prédictions\r\n",
        "predictions = []\r\n",
        "\r\n",
        "# Calcul des prédiction pour chaque groupe de 20 valeurs consécutives de la série\r\n",
        "# dans l'intervalle de validation\r\n",
        "for t in temps[temps_separation:-taille_fenetre]:\r\n",
        "    X = np.reshape(serie[t:t+taille_fenetre],(1,taille_fenetre))\r\n",
        "    predictions.append(model.predict(X))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wd2nfDcgG8EO"
      },
      "source": [
        "# Affiche la série et les prédictions\r\n",
        "plt.figure(figsize=(10, 6))\r\n",
        "affiche_serie(temps,serie,label=\"Série temporelle\")\r\n",
        "affiche_serie(temps[temps_separation+taille_fenetre:],np.asarray(predictions)[:,0,0],label=\"Prédictions\")\r\n",
        "plt.title('Prédictions avec le modèle de régression linéaire')\r\n",
        "plt.show()\r\n",
        "\r\n",
        "# Zoom sur l'intervalle de validation\r\n",
        "plt.figure(figsize=(10, 6))\r\n",
        "affiche_serie(temps[temps_separation:],serie[temps_separation:],label=\"Série temporelle\")\r\n",
        "affiche_serie(temps[temps_separation+taille_fenetre:],np.asarray(predictions)[:,0,0],label=\"Prédictions\")\r\n",
        "plt.title(\"Prédictions avec le modèle de régression linéaire (zoom sur l'intervalle de validation)\")\r\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PDS7BJvZG_e1"
      },
      "source": [
        "# Calcule de l'erreur quadratique moyenne et de l'erreur absolue moyenne \r\n",
        "\r\n",
        "mae = tf.keras.metrics.mean_absolute_error(serie[temps_separation+taille_fenetre:],np.asarray(predictions)[:,0,0]).numpy()\r\n",
        "mse = tf.keras.metrics.mean_squared_error(serie[temps_separation+taille_fenetre:],np.asarray(predictions)[:,0,0]).numpy()\r\n",
        "\r\n",
        "print(mae)\r\n",
        "print(mse)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cq93j2rGQf0X"
      },
      "source": [
        "# Création de la série temporelle et du dataset pour l'entrainement"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xbo7H57bQchB",
        "outputId": "03033cff-d2b9-4f64-9189-9e6196cc1be5"
      },
      "source": [
        "!wget \"https://raw.githubusercontent.com/uzaymacar/attention-mechanisms/master/layers.py\""
      ],
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-03-13 15:44:24--  https://raw.githubusercontent.com/uzaymacar/attention-mechanisms/master/layers.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.110.133, 185.199.109.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 21419 (21K) [text/plain]\n",
            "Saving to: ‘layers.py’\n",
            "\n",
            "layers.py           100%[===================>]  20.92K  --.-KB/s    in 0.001s  \n",
            "\n",
            "2021-03-13 15:44:24 (18.0 MB/s) - ‘layers.py’ saved [21419/21419]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vPuDzZEUQqqJ",
        "outputId": "91e7f84f-f2ed-4ed3-c3fa-240dcc4f2357",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from layers import Attention\r\n",
        "\r\n",
        "dim_GRU = 40\r\n",
        "\r\n",
        "# Fonction de la couche lambda d'entrée\r\n",
        "def Traitement_Entrees(x):\r\n",
        "  return tf.expand_dims(x,axis=-1)\r\n",
        "\r\n",
        "# Fonction dela couche lambda de sortie\r\n",
        "def Traitement_Sorties(x):\r\n",
        "  return(x*100.0)\r\n",
        "\r\n",
        "X = tf.keras.Input(shape=(taille_fenetre,), batch_size=batch_size)\r\n",
        "encoder_output, hidden_state = tf.keras.layers.GRU(dim_GRU,return_sequences=True, return_state=True)(tf.keras.layers.Lambda(Traitement_Entrees)(X))\r\n",
        "attention_input = [encoder_output, hidden_state]\r\n",
        "encoder_output, attention_weights = Attention(context='many-to-one',alignment_type='global')(attention_input)\r\n",
        "Y = tf.keras.layers.Dense(units=1)(encoder_output)\r\n",
        "encoder_output = tf.keras.layers.Lambda(Traitement_Sorties)(Y)\r\n",
        "\r\n",
        "model = tf.keras.Model(inputs = X, outputs=encoder_output)\r\n",
        "model.summary()"
      ],
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_4\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_31 (InputLayer)           [(32, 20)]           0                                            \n",
            "__________________________________________________________________________________________________\n",
            "lambda_45 (Lambda)              (32, 20, 1)          0           input_31[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "gru_28 (GRU)                    [(32, 20, 40), (32,  5160        lambda_45[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "attention_7 (Attention)         ((32, 20, 40), (32,  1600        gru_28[0][0]                     \n",
            "                                                                 gru_28[0][1]                     \n",
            "__________________________________________________________________________________________________\n",
            "dense_33 (Dense)                (32, 20, 1)          41          attention_7[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lambda_46 (Lambda)              (32, 20, 1)          0           dense_33[0][0]                   \n",
            "==================================================================================================\n",
            "Total params: 6,801\n",
            "Trainable params: 6,801\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RHEI0wE6UG4x",
        "outputId": "cbffb2d5-7c7e-4427-ac0f-4f2b0068456e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Définition de la fonction de régulation du taux d'apprentissage\r\n",
        "def RegulationTauxApprentissage(periode, taux):\r\n",
        "  return 1e-8*10**(periode/10)\r\n",
        "\r\n",
        "# Définition de l'optimiseur à utiliser\r\n",
        "optimiseur=tf.keras.optimizers.Adam()\r\n",
        "\r\n",
        "# Utilisation de la méthode ModelCheckPoint\r\n",
        "CheckPoint = tf.keras.callbacks.ModelCheckpoint(\"poids.hdf5\", monitor='loss', verbose=1, save_best_only=True, save_weights_only = True, mode='auto', save_freq='epoch')\r\n",
        "\r\n",
        "# Compile le modèle\r\n",
        "model.compile(loss=tf.keras.losses.Huber(), optimizer=optimiseur, metrics=\"mae\")\r\n",
        "\r\n",
        "# Entraine le modèle en utilisant notre fonction personnelle de régulation du taux d'apprentissage\r\n",
        "historique = model.fit(dataset,epochs=100,verbose=1, callbacks=[tf.keras.callbacks.LearningRateScheduler(RegulationTauxApprentissage), CheckPoint])"
      ],
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "45/45 [==============================] - 2s 8ms/step - loss: 56.1044 - mae: 56.6021\n",
            "\n",
            "Epoch 00001: loss improved from inf to 64.33557, saving model to poids.hdf5\n",
            "Epoch 2/100\n",
            "45/45 [==============================] - 0s 8ms/step - loss: 58.2435 - mae: 58.7408\n",
            "\n",
            "Epoch 00002: loss improved from 64.33557 to 64.33254, saving model to poids.hdf5\n",
            "Epoch 3/100\n",
            "45/45 [==============================] - 0s 8ms/step - loss: 59.2234 - mae: 59.7214\n",
            "\n",
            "Epoch 00003: loss improved from 64.33254 to 64.32859, saving model to poids.hdf5\n",
            "Epoch 4/100\n",
            "45/45 [==============================] - 0s 8ms/step - loss: 58.3124 - mae: 58.8100\n",
            "\n",
            "Epoch 00004: loss improved from 64.32859 to 64.32350, saving model to poids.hdf5\n",
            "Epoch 5/100\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 56.8155 - mae: 57.3125\n",
            "\n",
            "Epoch 00005: loss improved from 64.32350 to 64.31718, saving model to poids.hdf5\n",
            "Epoch 6/100\n",
            "45/45 [==============================] - 0s 8ms/step - loss: 59.2258 - mae: 59.7234\n",
            "\n",
            "Epoch 00006: loss improved from 64.31718 to 64.30936, saving model to poids.hdf5\n",
            "Epoch 7/100\n",
            "45/45 [==============================] - 0s 8ms/step - loss: 58.3499 - mae: 58.8481\n",
            "\n",
            "Epoch 00007: loss improved from 64.30936 to 64.29962, saving model to poids.hdf5\n",
            "Epoch 8/100\n",
            "45/45 [==============================] - 0s 8ms/step - loss: 58.3080 - mae: 58.8055\n",
            "\n",
            "Epoch 00008: loss improved from 64.29962 to 64.28723, saving model to poids.hdf5\n",
            "Epoch 9/100\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 57.3695 - mae: 57.8669\n",
            "\n",
            "Epoch 00009: loss improved from 64.28723 to 64.27172, saving model to poids.hdf5\n",
            "Epoch 10/100\n",
            "45/45 [==============================] - 0s 8ms/step - loss: 58.7879 - mae: 59.2858\n",
            "\n",
            "Epoch 00010: loss improved from 64.27172 to 64.25213, saving model to poids.hdf5\n",
            "Epoch 11/100\n",
            "45/45 [==============================] - 0s 8ms/step - loss: 56.3141 - mae: 56.8116\n",
            "\n",
            "Epoch 00011: loss improved from 64.25213 to 64.22742, saving model to poids.hdf5\n",
            "Epoch 12/100\n",
            "45/45 [==============================] - 0s 8ms/step - loss: 57.5040 - mae: 58.0017\n",
            "\n",
            "Epoch 00012: loss improved from 64.22742 to 64.19650, saving model to poids.hdf5\n",
            "Epoch 13/100\n",
            "45/45 [==============================] - 0s 8ms/step - loss: 57.9402 - mae: 58.4378\n",
            "\n",
            "Epoch 00013: loss improved from 64.19650 to 64.15752, saving model to poids.hdf5\n",
            "Epoch 14/100\n",
            "45/45 [==============================] - 0s 8ms/step - loss: 59.1032 - mae: 59.6006\n",
            "\n",
            "Epoch 00014: loss improved from 64.15752 to 64.10837, saving model to poids.hdf5\n",
            "Epoch 15/100\n",
            "45/45 [==============================] - 0s 8ms/step - loss: 57.5100 - mae: 58.0077\n",
            "\n",
            "Epoch 00015: loss improved from 64.10837 to 64.04667, saving model to poids.hdf5\n",
            "Epoch 16/100\n",
            "45/45 [==============================] - 0s 8ms/step - loss: 57.4944 - mae: 57.9921\n",
            "\n",
            "Epoch 00016: loss improved from 64.04667 to 63.96885, saving model to poids.hdf5\n",
            "Epoch 17/100\n",
            "45/45 [==============================] - 0s 8ms/step - loss: 57.0181 - mae: 57.5155\n",
            "\n",
            "Epoch 00017: loss improved from 63.96885 to 63.87130, saving model to poids.hdf5\n",
            "Epoch 18/100\n",
            "45/45 [==============================] - 0s 8ms/step - loss: 56.9233 - mae: 57.4202\n",
            "\n",
            "Epoch 00018: loss improved from 63.87130 to 63.74860, saving model to poids.hdf5\n",
            "Epoch 19/100\n",
            "45/45 [==============================] - 0s 8ms/step - loss: 57.8182 - mae: 58.3160\n",
            "\n",
            "Epoch 00019: loss improved from 63.74860 to 63.59481, saving model to poids.hdf5\n",
            "Epoch 20/100\n",
            "45/45 [==============================] - 0s 8ms/step - loss: 57.3908 - mae: 57.8882\n",
            "\n",
            "Epoch 00020: loss improved from 63.59481 to 63.40157, saving model to poids.hdf5\n",
            "Epoch 21/100\n",
            "45/45 [==============================] - 0s 8ms/step - loss: 57.0778 - mae: 57.5748\n",
            "\n",
            "Epoch 00021: loss improved from 63.40157 to 63.15947, saving model to poids.hdf5\n",
            "Epoch 22/100\n",
            "45/45 [==============================] - 0s 8ms/step - loss: 57.0548 - mae: 57.5523\n",
            "\n",
            "Epoch 00022: loss improved from 63.15947 to 62.85727, saving model to poids.hdf5\n",
            "Epoch 23/100\n",
            "45/45 [==============================] - 0s 8ms/step - loss: 56.7213 - mae: 57.2183\n",
            "\n",
            "Epoch 00023: loss improved from 62.85727 to 62.47931, saving model to poids.hdf5\n",
            "Epoch 24/100\n",
            "45/45 [==============================] - 0s 8ms/step - loss: 56.5377 - mae: 57.0351\n",
            "\n",
            "Epoch 00024: loss improved from 62.47931 to 62.00715, saving model to poids.hdf5\n",
            "Epoch 25/100\n",
            "45/45 [==============================] - 0s 8ms/step - loss: 56.6514 - mae: 57.1487\n",
            "\n",
            "Epoch 00025: loss improved from 62.00715 to 61.42273, saving model to poids.hdf5\n",
            "Epoch 26/100\n",
            "45/45 [==============================] - 0s 8ms/step - loss: 54.1567 - mae: 54.6536\n",
            "\n",
            "Epoch 00026: loss improved from 61.42273 to 60.69469, saving model to poids.hdf5\n",
            "Epoch 27/100\n",
            "45/45 [==============================] - 0s 8ms/step - loss: 53.4088 - mae: 53.9056\n",
            "\n",
            "Epoch 00027: loss improved from 60.69469 to 59.80173, saving model to poids.hdf5\n",
            "Epoch 28/100\n",
            "45/45 [==============================] - 0s 8ms/step - loss: 52.9963 - mae: 53.4926\n",
            "\n",
            "Epoch 00028: loss improved from 59.80173 to 58.70304, saving model to poids.hdf5\n",
            "Epoch 29/100\n",
            "45/45 [==============================] - 0s 8ms/step - loss: 52.2635 - mae: 52.7599\n",
            "\n",
            "Epoch 00029: loss improved from 58.70304 to 57.37238, saving model to poids.hdf5\n",
            "Epoch 30/100\n",
            "45/45 [==============================] - 0s 8ms/step - loss: 51.2584 - mae: 51.7533\n",
            "\n",
            "Epoch 00030: loss improved from 57.37238 to 55.77066, saving model to poids.hdf5\n",
            "Epoch 31/100\n",
            "45/45 [==============================] - 0s 8ms/step - loss: 50.0334 - mae: 50.5292\n",
            "\n",
            "Epoch 00031: loss improved from 55.77066 to 53.86618, saving model to poids.hdf5\n",
            "Epoch 32/100\n",
            "45/45 [==============================] - 0s 8ms/step - loss: 45.9495 - mae: 46.4449\n",
            "\n",
            "Epoch 00032: loss improved from 53.86618 to 51.61482, saving model to poids.hdf5\n",
            "Epoch 33/100\n",
            "45/45 [==============================] - 0s 8ms/step - loss: 44.5277 - mae: 45.0236\n",
            "\n",
            "Epoch 00033: loss improved from 51.61482 to 48.96616, saving model to poids.hdf5\n",
            "Epoch 34/100\n",
            "45/45 [==============================] - 0s 8ms/step - loss: 42.2124 - mae: 42.7082\n",
            "\n",
            "Epoch 00034: loss improved from 48.96616 to 45.87392, saving model to poids.hdf5\n",
            "Epoch 35/100\n",
            "45/45 [==============================] - 0s 8ms/step - loss: 37.2914 - mae: 37.7884\n",
            "\n",
            "Epoch 00035: loss improved from 45.87392 to 42.24797, saving model to poids.hdf5\n",
            "Epoch 36/100\n",
            "45/45 [==============================] - 0s 8ms/step - loss: 34.3403 - mae: 34.8380\n",
            "\n",
            "Epoch 00036: loss improved from 42.24797 to 37.98523, saving model to poids.hdf5\n",
            "Epoch 37/100\n",
            "45/45 [==============================] - 0s 8ms/step - loss: 30.0844 - mae: 30.5809\n",
            "\n",
            "Epoch 00037: loss improved from 37.98523 to 32.90061, saving model to poids.hdf5\n",
            "Epoch 38/100\n",
            "45/45 [==============================] - 0s 8ms/step - loss: 24.8201 - mae: 25.3134\n",
            "\n",
            "Epoch 00038: loss improved from 32.90061 to 27.33676, saving model to poids.hdf5\n",
            "Epoch 39/100\n",
            "45/45 [==============================] - 0s 8ms/step - loss: 19.4293 - mae: 19.9249\n",
            "\n",
            "Epoch 00039: loss improved from 27.33676 to 20.51948, saving model to poids.hdf5\n",
            "Epoch 40/100\n",
            "45/45 [==============================] - 0s 8ms/step - loss: 15.1144 - mae: 15.6075\n",
            "\n",
            "Epoch 00040: loss improved from 20.51948 to 15.42651, saving model to poids.hdf5\n",
            "Epoch 41/100\n",
            "45/45 [==============================] - 0s 8ms/step - loss: 13.2823 - mae: 13.7745\n",
            "\n",
            "Epoch 00041: loss improved from 15.42651 to 13.35215, saving model to poids.hdf5\n",
            "Epoch 42/100\n",
            "45/45 [==============================] - 0s 7ms/step - loss: 11.5001 - mae: 11.9888\n",
            "\n",
            "Epoch 00042: loss improved from 13.35215 to 11.78044, saving model to poids.hdf5\n",
            "Epoch 43/100\n",
            "45/45 [==============================] - 0s 8ms/step - loss: 10.1257 - mae: 10.6141\n",
            "\n",
            "Epoch 00043: loss improved from 11.78044 to 10.64736, saving model to poids.hdf5\n",
            "Epoch 44/100\n",
            "45/45 [==============================] - 0s 8ms/step - loss: 9.6037 - mae: 10.0914\n",
            "\n",
            "Epoch 00044: loss improved from 10.64736 to 9.67203, saving model to poids.hdf5\n",
            "Epoch 45/100\n",
            "45/45 [==============================] - 0s 8ms/step - loss: 8.5713 - mae: 9.0566\n",
            "\n",
            "Epoch 00045: loss improved from 9.67203 to 8.86524, saving model to poids.hdf5\n",
            "Epoch 46/100\n",
            "45/45 [==============================] - 0s 7ms/step - loss: 8.3006 - mae: 8.7853\n",
            "\n",
            "Epoch 00046: loss improved from 8.86524 to 8.30544, saving model to poids.hdf5\n",
            "Epoch 47/100\n",
            "45/45 [==============================] - 0s 8ms/step - loss: 8.1636 - mae: 8.6478\n",
            "\n",
            "Epoch 00047: loss improved from 8.30544 to 7.93718, saving model to poids.hdf5\n",
            "Epoch 48/100\n",
            "45/45 [==============================] - 1s 9ms/step - loss: 7.5454 - mae: 8.0283\n",
            "\n",
            "Epoch 00048: loss improved from 7.93718 to 7.93470, saving model to poids.hdf5\n",
            "Epoch 49/100\n",
            "45/45 [==============================] - 0s 8ms/step - loss: 7.6119 - mae: 8.0956\n",
            "\n",
            "Epoch 00049: loss improved from 7.93470 to 7.64057, saving model to poids.hdf5\n",
            "Epoch 50/100\n",
            "45/45 [==============================] - 0s 8ms/step - loss: 7.5598 - mae: 8.0430\n",
            "\n",
            "Epoch 00050: loss improved from 7.64057 to 7.46905, saving model to poids.hdf5\n",
            "Epoch 51/100\n",
            "45/45 [==============================] - 0s 8ms/step - loss: 7.5670 - mae: 8.0507\n",
            "\n",
            "Epoch 00051: loss improved from 7.46905 to 7.26795, saving model to poids.hdf5\n",
            "Epoch 52/100\n",
            "45/45 [==============================] - 0s 7ms/step - loss: 7.3108 - mae: 7.7932\n",
            "\n",
            "Epoch 00052: loss did not improve from 7.26795\n",
            "Epoch 53/100\n",
            "45/45 [==============================] - 0s 8ms/step - loss: 7.4896 - mae: 7.9728\n",
            "\n",
            "Epoch 00053: loss improved from 7.26795 to 7.11381, saving model to poids.hdf5\n",
            "Epoch 54/100\n",
            "45/45 [==============================] - 0s 7ms/step - loss: 7.2483 - mae: 7.7314\n",
            "\n",
            "Epoch 00054: loss did not improve from 7.11381\n",
            "Epoch 55/100\n",
            "45/45 [==============================] - 0s 8ms/step - loss: 7.2732 - mae: 7.7565\n",
            "\n",
            "Epoch 00055: loss did not improve from 7.11381\n",
            "Epoch 56/100\n",
            "45/45 [==============================] - 0s 8ms/step - loss: 7.2087 - mae: 7.6916\n",
            "\n",
            "Epoch 00056: loss did not improve from 7.11381\n",
            "Epoch 57/100\n",
            "45/45 [==============================] - 0s 8ms/step - loss: 8.2137 - mae: 8.6992\n",
            "\n",
            "Epoch 00057: loss did not improve from 7.11381\n",
            "Epoch 58/100\n",
            "45/45 [==============================] - 0s 8ms/step - loss: 8.2949 - mae: 8.7818\n",
            "\n",
            "Epoch 00058: loss did not improve from 7.11381\n",
            "Epoch 59/100\n",
            "45/45 [==============================] - 0s 8ms/step - loss: 7.3877 - mae: 7.8725\n",
            "\n",
            "Epoch 00059: loss did not improve from 7.11381\n",
            "Epoch 60/100\n",
            "45/45 [==============================] - 0s 8ms/step - loss: 8.4893 - mae: 8.9757\n",
            "\n",
            "Epoch 00060: loss did not improve from 7.11381\n",
            "Epoch 61/100\n",
            "45/45 [==============================] - 0s 8ms/step - loss: 8.0476 - mae: 8.5333\n",
            "\n",
            "Epoch 00061: loss did not improve from 7.11381\n",
            "Epoch 62/100\n",
            "45/45 [==============================] - 0s 8ms/step - loss: 9.3370 - mae: 9.8245\n",
            "\n",
            "Epoch 00062: loss did not improve from 7.11381\n",
            "Epoch 63/100\n",
            "45/45 [==============================] - 0s 8ms/step - loss: 9.9308 - mae: 10.4196\n",
            "\n",
            "Epoch 00063: loss did not improve from 7.11381\n",
            "Epoch 64/100\n",
            "45/45 [==============================] - 0s 8ms/step - loss: 11.1293 - mae: 11.6195\n",
            "\n",
            "Epoch 00064: loss did not improve from 7.11381\n",
            "Epoch 65/100\n",
            "45/45 [==============================] - 0s 8ms/step - loss: 11.2767 - mae: 11.7672\n",
            "\n",
            "Epoch 00065: loss did not improve from 7.11381\n",
            "Epoch 66/100\n",
            "45/45 [==============================] - 0s 8ms/step - loss: 10.1505 - mae: 10.6388\n",
            "\n",
            "Epoch 00066: loss did not improve from 7.11381\n",
            "Epoch 67/100\n",
            "45/45 [==============================] - 0s 8ms/step - loss: 15.1158 - mae: 15.6084\n",
            "\n",
            "Epoch 00067: loss did not improve from 7.11381\n",
            "Epoch 68/100\n",
            "45/45 [==============================] - 0s 8ms/step - loss: 17.3199 - mae: 17.8130\n",
            "\n",
            "Epoch 00068: loss did not improve from 7.11381\n",
            "Epoch 69/100\n",
            "45/45 [==============================] - 0s 8ms/step - loss: 26.5933 - mae: 27.0900\n",
            "\n",
            "Epoch 00069: loss did not improve from 7.11381\n",
            "Epoch 70/100\n",
            "45/45 [==============================] - 0s 8ms/step - loss: 48.8712 - mae: 49.3700\n",
            "\n",
            "Epoch 00070: loss did not improve from 7.11381\n",
            "Epoch 71/100\n",
            "45/45 [==============================] - 0s 8ms/step - loss: 30.7572 - mae: 31.2528\n",
            "\n",
            "Epoch 00071: loss did not improve from 7.11381\n",
            "Epoch 72/100\n",
            "45/45 [==============================] - 0s 8ms/step - loss: 33.0979 - mae: 33.5961\n",
            "\n",
            "Epoch 00072: loss did not improve from 7.11381\n",
            "Epoch 73/100\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 27.2254 - mae: 27.7217\n",
            "\n",
            "Epoch 00073: loss did not improve from 7.11381\n",
            "Epoch 74/100\n",
            "45/45 [==============================] - 0s 7ms/step - loss: 38.5356 - mae: 39.0336\n",
            "\n",
            "Epoch 00074: loss did not improve from 7.11381\n",
            "Epoch 75/100\n",
            "45/45 [==============================] - 0s 8ms/step - loss: 42.5659 - mae: 43.0635\n",
            "\n",
            "Epoch 00075: loss did not improve from 7.11381\n",
            "Epoch 76/100\n",
            "45/45 [==============================] - 0s 8ms/step - loss: 38.8267 - mae: 39.3236\n",
            "\n",
            "Epoch 00076: loss did not improve from 7.11381\n",
            "Epoch 77/100\n",
            "45/45 [==============================] - 0s 8ms/step - loss: 77.1570 - mae: 77.6561\n",
            "\n",
            "Epoch 00077: loss did not improve from 7.11381\n",
            "Epoch 78/100\n",
            "45/45 [==============================] - 0s 8ms/step - loss: 191.1900 - mae: 191.6897\n",
            "\n",
            "Epoch 00078: loss did not improve from 7.11381\n",
            "Epoch 79/100\n",
            "45/45 [==============================] - 0s 9ms/step - loss: 203.4166 - mae: 203.9163\n",
            "\n",
            "Epoch 00079: loss did not improve from 7.11381\n",
            "Epoch 80/100\n",
            "45/45 [==============================] - 0s 8ms/step - loss: 409.0417 - mae: 409.5417\n",
            "\n",
            "Epoch 00080: loss did not improve from 7.11381\n",
            "Epoch 81/100\n",
            "45/45 [==============================] - 0s 8ms/step - loss: 611.7933 - mae: 612.2933\n",
            "\n",
            "Epoch 00081: loss did not improve from 7.11381\n",
            "Epoch 82/100\n",
            "45/45 [==============================] - 0s 8ms/step - loss: 462.1523 - mae: 462.6523\n",
            "\n",
            "Epoch 00082: loss did not improve from 7.11381\n",
            "Epoch 83/100\n",
            "45/45 [==============================] - 0s 8ms/step - loss: 377.5064 - mae: 378.0064\n",
            "\n",
            "Epoch 00083: loss did not improve from 7.11381\n",
            "Epoch 84/100\n",
            "45/45 [==============================] - 0s 8ms/step - loss: 268.6574 - mae: 269.1571\n",
            "\n",
            "Epoch 00084: loss did not improve from 7.11381\n",
            "Epoch 85/100\n",
            "45/45 [==============================] - 0s 7ms/step - loss: 812.4846 - mae: 812.9846\n",
            "\n",
            "Epoch 00085: loss did not improve from 7.11381\n",
            "Epoch 86/100\n",
            "45/45 [==============================] - 0s 8ms/step - loss: 931.2603 - mae: 931.7603\n",
            "\n",
            "Epoch 00086: loss did not improve from 7.11381\n",
            "Epoch 87/100\n",
            "45/45 [==============================] - 0s 8ms/step - loss: 957.9417 - mae: 958.4417\n",
            "\n",
            "Epoch 00087: loss did not improve from 7.11381\n",
            "Epoch 88/100\n",
            "45/45 [==============================] - 0s 8ms/step - loss: 1465.4572 - mae: 1465.9572\n",
            "\n",
            "Epoch 00088: loss did not improve from 7.11381\n",
            "Epoch 89/100\n",
            "45/45 [==============================] - 0s 8ms/step - loss: 2451.7021 - mae: 2452.2021\n",
            "\n",
            "Epoch 00089: loss did not improve from 7.11381\n",
            "Epoch 90/100\n",
            "45/45 [==============================] - 0s 8ms/step - loss: 2588.8087 - mae: 2589.3087\n",
            "\n",
            "Epoch 00090: loss did not improve from 7.11381\n",
            "Epoch 91/100\n",
            "45/45 [==============================] - 0s 8ms/step - loss: 2457.9864 - mae: 2458.4864\n",
            "\n",
            "Epoch 00091: loss did not improve from 7.11381\n",
            "Epoch 92/100\n",
            "45/45 [==============================] - 0s 8ms/step - loss: 3465.3670 - mae: 3465.8670\n",
            "\n",
            "Epoch 00092: loss did not improve from 7.11381\n",
            "Epoch 93/100\n",
            "45/45 [==============================] - 0s 8ms/step - loss: 8445.4353 - mae: 8445.9353\n",
            "\n",
            "Epoch 00093: loss did not improve from 7.11381\n",
            "Epoch 94/100\n",
            "45/45 [==============================] - 1s 8ms/step - loss: 6972.7553 - mae: 6973.2553\n",
            "\n",
            "Epoch 00094: loss did not improve from 7.11381\n",
            "Epoch 95/100\n",
            "45/45 [==============================] - 0s 8ms/step - loss: 5382.0009 - mae: 5382.5009\n",
            "\n",
            "Epoch 00095: loss did not improve from 7.11381\n",
            "Epoch 96/100\n",
            "45/45 [==============================] - 0s 8ms/step - loss: 9890.6044 - mae: 9891.1044\n",
            "\n",
            "Epoch 00096: loss did not improve from 7.11381\n",
            "Epoch 97/100\n",
            "45/45 [==============================] - 0s 8ms/step - loss: 9433.2460 - mae: 9433.7460\n",
            "\n",
            "Epoch 00097: loss did not improve from 7.11381\n",
            "Epoch 98/100\n",
            "45/45 [==============================] - 0s 8ms/step - loss: 17508.6266 - mae: 17509.1266\n",
            "\n",
            "Epoch 00098: loss did not improve from 7.11381\n",
            "Epoch 99/100\n",
            "45/45 [==============================] - 0s 8ms/step - loss: 25344.4023 - mae: 25344.9023\n",
            "\n",
            "Epoch 00099: loss did not improve from 7.11381\n",
            "Epoch 100/100\n",
            "45/45 [==============================] - 0s 8ms/step - loss: 39803.6153 - mae: 39804.1153\n",
            "\n",
            "Epoch 00100: loss did not improve from 7.11381\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}