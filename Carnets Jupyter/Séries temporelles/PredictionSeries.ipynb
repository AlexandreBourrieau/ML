{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PredictionsSeries.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AlexandreBourrieau/ML/blob/main/Carnets%20Jupyter/S%C3%A9ries%20temporelles/PredictionSeries.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TVuCzMYKDp3z"
      },
      "source": [
        "# Chargement des données"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i3nLyKtnliCW"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import plotly.express as px\n",
        "import pandas as pd"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fln1XUm2bxPx",
        "outputId": "7f4772e4-9a23-4ce5-bb69-1486d2128d2b"
      },
      "source": [
        "!wget --no-check-certificate --content-disposition \"https://raw.githubusercontent.com/AlexandreBourrieau/ML/main/Carnets%20Jupyter/S%C3%A9ries%20temporelles/data/table-indicateurs-open-data-dep-serie.csv\""
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-04-24 08:53:40--  https://raw.githubusercontent.com/AlexandreBourrieau/ML/main/Carnets%20Jupyter/S%C3%A9ries%20temporelles/data/table-indicateurs-open-data-dep-serie.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.110.133, 185.199.109.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4340764 (4.1M) [text/plain]\n",
            "Saving to: ‘table-indicateurs-open-data-dep-serie.csv’\n",
            "\n",
            "table-indicateurs-o 100%[===================>]   4.14M  --.-KB/s    in 0.1s    \n",
            "\n",
            "2021-04-24 08:53:41 (34.0 MB/s) - ‘table-indicateurs-open-data-dep-serie.csv’ saved [4340764/4340764]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MPJ6nnrRsUBm"
      },
      "source": [
        "Charge la série sous Pandas et affiche les informations du fichier :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VEB_JjihEYTP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 695
        },
        "outputId": "293f27e4-6334-4315-a9db-3dd41d3f5880"
      },
      "source": [
        "# Création de la série sous Pandas\n",
        "serie = pd.read_csv(\"table-indicateurs-open-data-dep-serie.csv\")\n",
        "serie"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>extract_date</th>\n",
              "      <th>departement</th>\n",
              "      <th>region</th>\n",
              "      <th>libelle_reg</th>\n",
              "      <th>libelle_dep</th>\n",
              "      <th>tx_incid</th>\n",
              "      <th>R</th>\n",
              "      <th>taux_occupation_sae</th>\n",
              "      <th>tx_pos</th>\n",
              "      <th>tx_incid_couleur</th>\n",
              "      <th>R_couleur</th>\n",
              "      <th>taux_occupation_sae_couleur</th>\n",
              "      <th>tx_pos_couleur</th>\n",
              "      <th>nb_orange</th>\n",
              "      <th>nb_rouge</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2020-03-20</td>\n",
              "      <td>01</td>\n",
              "      <td>84</td>\n",
              "      <td>Auvergne Rhône Alpes</td>\n",
              "      <td>Ain</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>15.6</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>vert</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2020-03-21</td>\n",
              "      <td>01</td>\n",
              "      <td>84</td>\n",
              "      <td>Auvergne Rhône Alpes</td>\n",
              "      <td>Ain</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>15.7</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>vert</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2020-03-19</td>\n",
              "      <td>01</td>\n",
              "      <td>84</td>\n",
              "      <td>Auvergne Rhône Alpes</td>\n",
              "      <td>Ain</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>14.1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>vert</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2020-03-18</td>\n",
              "      <td>01</td>\n",
              "      <td>84</td>\n",
              "      <td>Auvergne Rhône Alpes</td>\n",
              "      <td>Ain</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>6.3</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>vert</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2020-04-28</td>\n",
              "      <td>01</td>\n",
              "      <td>84</td>\n",
              "      <td>Auvergne Rhône Alpes</td>\n",
              "      <td>Ain</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>72.6</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>rouge</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40496</th>\n",
              "      <td>2021-04-15</td>\n",
              "      <td>84</td>\n",
              "      <td>93</td>\n",
              "      <td>Provence Alpes Côte d'Azur</td>\n",
              "      <td>Vaucluse</td>\n",
              "      <td>403.39</td>\n",
              "      <td>0.92</td>\n",
              "      <td>124.6</td>\n",
              "      <td>12.075129</td>\n",
              "      <td>rouge</td>\n",
              "      <td>vert</td>\n",
              "      <td>rouge</td>\n",
              "      <td>rouge</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40497</th>\n",
              "      <td>2021-04-16</td>\n",
              "      <td>84</td>\n",
              "      <td>93</td>\n",
              "      <td>Provence Alpes Côte d'Azur</td>\n",
              "      <td>Vaucluse</td>\n",
              "      <td>408.38</td>\n",
              "      <td>NaN</td>\n",
              "      <td>127.4</td>\n",
              "      <td>12.472100</td>\n",
              "      <td>rouge</td>\n",
              "      <td>NaN</td>\n",
              "      <td>rouge</td>\n",
              "      <td>rouge</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40498</th>\n",
              "      <td>2021-04-13</td>\n",
              "      <td>84</td>\n",
              "      <td>93</td>\n",
              "      <td>Provence Alpes Côte d'Azur</td>\n",
              "      <td>Vaucluse</td>\n",
              "      <td>434.58</td>\n",
              "      <td>NaN</td>\n",
              "      <td>124.3</td>\n",
              "      <td>12.066320</td>\n",
              "      <td>rouge</td>\n",
              "      <td>NaN</td>\n",
              "      <td>rouge</td>\n",
              "      <td>rouge</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40499</th>\n",
              "      <td>2021-04-18</td>\n",
              "      <td>84</td>\n",
              "      <td>93</td>\n",
              "      <td>Provence Alpes Côte d'Azur</td>\n",
              "      <td>Vaucluse</td>\n",
              "      <td>396.26</td>\n",
              "      <td>NaN</td>\n",
              "      <td>124.3</td>\n",
              "      <td>12.487361</td>\n",
              "      <td>rouge</td>\n",
              "      <td>NaN</td>\n",
              "      <td>rouge</td>\n",
              "      <td>rouge</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40500</th>\n",
              "      <td>2021-04-17</td>\n",
              "      <td>84</td>\n",
              "      <td>93</td>\n",
              "      <td>Provence Alpes Côte d'Azur</td>\n",
              "      <td>Vaucluse</td>\n",
              "      <td>403.75</td>\n",
              "      <td>NaN</td>\n",
              "      <td>124.3</td>\n",
              "      <td>12.593128</td>\n",
              "      <td>rouge</td>\n",
              "      <td>NaN</td>\n",
              "      <td>rouge</td>\n",
              "      <td>rouge</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>40501 rows × 15 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      extract_date departement  region  ... tx_pos_couleur nb_orange  nb_rouge\n",
              "0       2020-03-20          01      84  ...            NaN         0         0\n",
              "1       2020-03-21          01      84  ...            NaN         0         0\n",
              "2       2020-03-19          01      84  ...            NaN         0         0\n",
              "3       2020-03-18          01      84  ...            NaN         0         0\n",
              "4       2020-04-28          01      84  ...            NaN         0         1\n",
              "...            ...         ...     ...  ...            ...       ...       ...\n",
              "40496   2021-04-15          84      93  ...          rouge         0         3\n",
              "40497   2021-04-16          84      93  ...          rouge         0         3\n",
              "40498   2021-04-13          84      93  ...          rouge         0         3\n",
              "40499   2021-04-18          84      93  ...          rouge         0         3\n",
              "40500   2021-04-17          84      93  ...          rouge         0         3\n",
              "\n",
              "[40501 rows x 15 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 662
        },
        "id": "cbYvPt63d-GS",
        "outputId": "1dbd00a8-8017-489b-90aa-d7dde8839689"
      },
      "source": [
        "serie.groupby(by=\"region\").agg(['count'])"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead tr th {\n",
              "        text-align: left;\n",
              "    }\n",
              "\n",
              "    .dataframe thead tr:last-of-type th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th>extract_date</th>\n",
              "      <th>departement</th>\n",
              "      <th>libelle_reg</th>\n",
              "      <th>libelle_dep</th>\n",
              "      <th>tx_incid</th>\n",
              "      <th>R</th>\n",
              "      <th>taux_occupation_sae</th>\n",
              "      <th>tx_pos</th>\n",
              "      <th>tx_incid_couleur</th>\n",
              "      <th>R_couleur</th>\n",
              "      <th>taux_occupation_sae_couleur</th>\n",
              "      <th>tx_pos_couleur</th>\n",
              "      <th>nb_orange</th>\n",
              "      <th>nb_rouge</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "      <th>count</th>\n",
              "      <th>count</th>\n",
              "      <th>count</th>\n",
              "      <th>count</th>\n",
              "      <th>count</th>\n",
              "      <th>count</th>\n",
              "      <th>count</th>\n",
              "      <th>count</th>\n",
              "      <th>count</th>\n",
              "      <th>count</th>\n",
              "      <th>count</th>\n",
              "      <th>count</th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>region</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>401</td>\n",
              "      <td>401</td>\n",
              "      <td>401</td>\n",
              "      <td>401</td>\n",
              "      <td>342</td>\n",
              "      <td>54</td>\n",
              "      <td>401</td>\n",
              "      <td>336</td>\n",
              "      <td>342</td>\n",
              "      <td>54</td>\n",
              "      <td>401</td>\n",
              "      <td>336</td>\n",
              "      <td>401</td>\n",
              "      <td>401</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>401</td>\n",
              "      <td>401</td>\n",
              "      <td>401</td>\n",
              "      <td>401</td>\n",
              "      <td>342</td>\n",
              "      <td>56</td>\n",
              "      <td>401</td>\n",
              "      <td>336</td>\n",
              "      <td>342</td>\n",
              "      <td>56</td>\n",
              "      <td>401</td>\n",
              "      <td>336</td>\n",
              "      <td>401</td>\n",
              "      <td>401</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>401</td>\n",
              "      <td>401</td>\n",
              "      <td>401</td>\n",
              "      <td>401</td>\n",
              "      <td>342</td>\n",
              "      <td>68</td>\n",
              "      <td>401</td>\n",
              "      <td>336</td>\n",
              "      <td>342</td>\n",
              "      <td>68</td>\n",
              "      <td>401</td>\n",
              "      <td>336</td>\n",
              "      <td>401</td>\n",
              "      <td>401</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>401</td>\n",
              "      <td>401</td>\n",
              "      <td>401</td>\n",
              "      <td>401</td>\n",
              "      <td>342</td>\n",
              "      <td>55</td>\n",
              "      <td>401</td>\n",
              "      <td>336</td>\n",
              "      <td>342</td>\n",
              "      <td>55</td>\n",
              "      <td>401</td>\n",
              "      <td>336</td>\n",
              "      <td>401</td>\n",
              "      <td>401</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>401</td>\n",
              "      <td>401</td>\n",
              "      <td>401</td>\n",
              "      <td>401</td>\n",
              "      <td>342</td>\n",
              "      <td>35</td>\n",
              "      <td>401</td>\n",
              "      <td>336</td>\n",
              "      <td>342</td>\n",
              "      <td>35</td>\n",
              "      <td>401</td>\n",
              "      <td>336</td>\n",
              "      <td>401</td>\n",
              "      <td>401</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>3208</td>\n",
              "      <td>3208</td>\n",
              "      <td>3208</td>\n",
              "      <td>3208</td>\n",
              "      <td>2736</td>\n",
              "      <td>544</td>\n",
              "      <td>3208</td>\n",
              "      <td>2688</td>\n",
              "      <td>2736</td>\n",
              "      <td>544</td>\n",
              "      <td>3208</td>\n",
              "      <td>2688</td>\n",
              "      <td>3208</td>\n",
              "      <td>3208</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>2406</td>\n",
              "      <td>2406</td>\n",
              "      <td>2406</td>\n",
              "      <td>2406</td>\n",
              "      <td>2052</td>\n",
              "      <td>408</td>\n",
              "      <td>2406</td>\n",
              "      <td>2016</td>\n",
              "      <td>2052</td>\n",
              "      <td>408</td>\n",
              "      <td>2406</td>\n",
              "      <td>2016</td>\n",
              "      <td>2406</td>\n",
              "      <td>2406</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>3208</td>\n",
              "      <td>3208</td>\n",
              "      <td>3208</td>\n",
              "      <td>3208</td>\n",
              "      <td>2736</td>\n",
              "      <td>544</td>\n",
              "      <td>3208</td>\n",
              "      <td>2688</td>\n",
              "      <td>2736</td>\n",
              "      <td>544</td>\n",
              "      <td>3208</td>\n",
              "      <td>2688</td>\n",
              "      <td>3208</td>\n",
              "      <td>3208</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>2005</td>\n",
              "      <td>2005</td>\n",
              "      <td>2005</td>\n",
              "      <td>2005</td>\n",
              "      <td>1710</td>\n",
              "      <td>340</td>\n",
              "      <td>2005</td>\n",
              "      <td>1680</td>\n",
              "      <td>1710</td>\n",
              "      <td>340</td>\n",
              "      <td>2005</td>\n",
              "      <td>1680</td>\n",
              "      <td>2005</td>\n",
              "      <td>2005</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>2005</td>\n",
              "      <td>2005</td>\n",
              "      <td>2005</td>\n",
              "      <td>2005</td>\n",
              "      <td>1710</td>\n",
              "      <td>340</td>\n",
              "      <td>2005</td>\n",
              "      <td>1680</td>\n",
              "      <td>1710</td>\n",
              "      <td>340</td>\n",
              "      <td>2005</td>\n",
              "      <td>1680</td>\n",
              "      <td>2005</td>\n",
              "      <td>2005</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44</th>\n",
              "      <td>4010</td>\n",
              "      <td>4010</td>\n",
              "      <td>4010</td>\n",
              "      <td>4010</td>\n",
              "      <td>3420</td>\n",
              "      <td>680</td>\n",
              "      <td>4010</td>\n",
              "      <td>3360</td>\n",
              "      <td>3420</td>\n",
              "      <td>680</td>\n",
              "      <td>4010</td>\n",
              "      <td>3360</td>\n",
              "      <td>4010</td>\n",
              "      <td>4010</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>52</th>\n",
              "      <td>2005</td>\n",
              "      <td>2005</td>\n",
              "      <td>2005</td>\n",
              "      <td>2005</td>\n",
              "      <td>1710</td>\n",
              "      <td>340</td>\n",
              "      <td>2005</td>\n",
              "      <td>1680</td>\n",
              "      <td>1710</td>\n",
              "      <td>340</td>\n",
              "      <td>2005</td>\n",
              "      <td>1680</td>\n",
              "      <td>2005</td>\n",
              "      <td>2005</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>53</th>\n",
              "      <td>1604</td>\n",
              "      <td>1604</td>\n",
              "      <td>1604</td>\n",
              "      <td>1604</td>\n",
              "      <td>1368</td>\n",
              "      <td>272</td>\n",
              "      <td>1604</td>\n",
              "      <td>1344</td>\n",
              "      <td>1368</td>\n",
              "      <td>272</td>\n",
              "      <td>1604</td>\n",
              "      <td>1344</td>\n",
              "      <td>1604</td>\n",
              "      <td>1604</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75</th>\n",
              "      <td>4812</td>\n",
              "      <td>4812</td>\n",
              "      <td>4812</td>\n",
              "      <td>4812</td>\n",
              "      <td>4104</td>\n",
              "      <td>816</td>\n",
              "      <td>4812</td>\n",
              "      <td>4032</td>\n",
              "      <td>4104</td>\n",
              "      <td>816</td>\n",
              "      <td>4812</td>\n",
              "      <td>4032</td>\n",
              "      <td>4812</td>\n",
              "      <td>4812</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>76</th>\n",
              "      <td>5213</td>\n",
              "      <td>5213</td>\n",
              "      <td>5213</td>\n",
              "      <td>5213</td>\n",
              "      <td>4446</td>\n",
              "      <td>884</td>\n",
              "      <td>5213</td>\n",
              "      <td>4368</td>\n",
              "      <td>4446</td>\n",
              "      <td>884</td>\n",
              "      <td>5213</td>\n",
              "      <td>4368</td>\n",
              "      <td>5213</td>\n",
              "      <td>5213</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>84</th>\n",
              "      <td>4812</td>\n",
              "      <td>4812</td>\n",
              "      <td>4812</td>\n",
              "      <td>4812</td>\n",
              "      <td>4104</td>\n",
              "      <td>816</td>\n",
              "      <td>4812</td>\n",
              "      <td>4032</td>\n",
              "      <td>4104</td>\n",
              "      <td>816</td>\n",
              "      <td>4812</td>\n",
              "      <td>4032</td>\n",
              "      <td>4812</td>\n",
              "      <td>4812</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>93</th>\n",
              "      <td>2406</td>\n",
              "      <td>2406</td>\n",
              "      <td>2406</td>\n",
              "      <td>2406</td>\n",
              "      <td>2052</td>\n",
              "      <td>408</td>\n",
              "      <td>2406</td>\n",
              "      <td>2016</td>\n",
              "      <td>2052</td>\n",
              "      <td>408</td>\n",
              "      <td>2406</td>\n",
              "      <td>2016</td>\n",
              "      <td>2406</td>\n",
              "      <td>2406</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>94</th>\n",
              "      <td>802</td>\n",
              "      <td>802</td>\n",
              "      <td>802</td>\n",
              "      <td>802</td>\n",
              "      <td>684</td>\n",
              "      <td>104</td>\n",
              "      <td>802</td>\n",
              "      <td>672</td>\n",
              "      <td>684</td>\n",
              "      <td>104</td>\n",
              "      <td>802</td>\n",
              "      <td>672</td>\n",
              "      <td>802</td>\n",
              "      <td>802</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       extract_date departement libelle_reg  ... tx_pos_couleur nb_orange nb_rouge\n",
              "              count       count       count  ...          count     count    count\n",
              "region                                       ...                                  \n",
              "1               401         401         401  ...            336       401      401\n",
              "2               401         401         401  ...            336       401      401\n",
              "3               401         401         401  ...            336       401      401\n",
              "4               401         401         401  ...            336       401      401\n",
              "6               401         401         401  ...            336       401      401\n",
              "11             3208        3208        3208  ...           2688      3208     3208\n",
              "24             2406        2406        2406  ...           2016      2406     2406\n",
              "27             3208        3208        3208  ...           2688      3208     3208\n",
              "28             2005        2005        2005  ...           1680      2005     2005\n",
              "32             2005        2005        2005  ...           1680      2005     2005\n",
              "44             4010        4010        4010  ...           3360      4010     4010\n",
              "52             2005        2005        2005  ...           1680      2005     2005\n",
              "53             1604        1604        1604  ...           1344      1604     1604\n",
              "75             4812        4812        4812  ...           4032      4812     4812\n",
              "76             5213        5213        5213  ...           4368      5213     5213\n",
              "84             4812        4812        4812  ...           4032      4812     4812\n",
              "93             2406        2406        2406  ...           2016      2406     2406\n",
              "94              802         802         802  ...            672       802      802\n",
              "\n",
              "[18 rows x 14 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EJLcuFiNevyy"
      },
      "source": [
        "Regardons l'évolution du taux d'incidence sur paris :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 415
        },
        "id": "Q17wIXPLe2i_",
        "outputId": "94d00339-3f8d-401a-dab0-96f7c7f383be"
      },
      "source": [
        "serie_paris = serie.loc[serie['region']==84]\n",
        "serie_paris = serie_paris[['extract_date','tx_incid']]\n",
        "\n",
        "serie_paris"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>extract_date</th>\n",
              "      <th>tx_incid</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2020-03-20</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2020-03-21</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2020-03-19</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2020-03-18</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2020-04-28</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4807</th>\n",
              "      <td>2021-04-16</td>\n",
              "      <td>291.40</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4808</th>\n",
              "      <td>2021-04-13</td>\n",
              "      <td>330.15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4809</th>\n",
              "      <td>2021-04-18</td>\n",
              "      <td>281.02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4810</th>\n",
              "      <td>2021-04-19</td>\n",
              "      <td>264.48</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4811</th>\n",
              "      <td>2021-04-17</td>\n",
              "      <td>280.78</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4812 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     extract_date  tx_incid\n",
              "0      2020-03-20       NaN\n",
              "1      2020-03-21       NaN\n",
              "2      2020-03-19       NaN\n",
              "3      2020-03-18       NaN\n",
              "4      2020-04-28       NaN\n",
              "...           ...       ...\n",
              "4807   2021-04-16    291.40\n",
              "4808   2021-04-13    330.15\n",
              "4809   2021-04-18    281.02\n",
              "4810   2021-04-19    264.48\n",
              "4811   2021-04-17    280.78\n",
              "\n",
              "[4812 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 446
        },
        "id": "cTSg8XwLknp9",
        "outputId": "f844b4eb-58ca-4266-ce16-de72727c65e4"
      },
      "source": [
        "df_paris = pd.DataFrame(data={'taux' : serie_paris['tx_incid'].values},index=serie_paris['extract_date'])\n",
        "df_paris.index = pd.to_datetime(df_paris.index)\n",
        "df_paris = df_paris[~df_paris.index.duplicated(keep='first')]\n",
        "df_paris"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>taux</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>extract_date</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2020-03-20</th>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2020-03-21</th>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2020-03-19</th>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2020-03-18</th>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2020-04-28</th>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2020-09-27</th>\n",
              "      <td>80.22</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2020-09-28</th>\n",
              "      <td>75.20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2020-09-29</th>\n",
              "      <td>75.50</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2020-09-30</th>\n",
              "      <td>74.59</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2020-10-01</th>\n",
              "      <td>77.78</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>401 rows × 1 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "               taux\n",
              "extract_date       \n",
              "2020-03-20      NaN\n",
              "2020-03-21      NaN\n",
              "2020-03-19      NaN\n",
              "2020-03-18      NaN\n",
              "2020-04-28      NaN\n",
              "...             ...\n",
              "2020-09-27    80.22\n",
              "2020-09-28    75.20\n",
              "2020-09-29    75.50\n",
              "2020-09-30    74.59\n",
              "2020-10-01    77.78\n",
              "\n",
              "[401 rows x 1 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 446
        },
        "id": "m23cEXjcny_q",
        "outputId": "4ebda16d-2ddd-4506-a142-66b1bc1af086"
      },
      "source": [
        "df_paris.index = df_paris.index.sort_values()\n",
        "df_paris"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>taux</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>extract_date</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2020-03-18</th>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2020-03-19</th>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2020-03-20</th>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2020-03-21</th>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2020-03-22</th>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2021-04-18</th>\n",
              "      <td>80.22</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2021-04-19</th>\n",
              "      <td>75.20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2021-04-20</th>\n",
              "      <td>75.50</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2021-04-21</th>\n",
              "      <td>74.59</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2021-04-22</th>\n",
              "      <td>77.78</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>401 rows × 1 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "               taux\n",
              "extract_date       \n",
              "2020-03-18      NaN\n",
              "2020-03-19      NaN\n",
              "2020-03-20      NaN\n",
              "2020-03-21      NaN\n",
              "2020-03-22      NaN\n",
              "...             ...\n",
              "2021-04-18    80.22\n",
              "2021-04-19    75.20\n",
              "2021-04-20    75.50\n",
              "2021-04-21    74.59\n",
              "2021-04-22    77.78\n",
              "\n",
              "[401 rows x 1 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "qYpzzcbGi5FE",
        "outputId": "d15d503e-0d4f-463b-dbe0-ce1224b3b924"
      },
      "source": [
        "plt.plot(df_paris)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7fe6352b70d0>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WF62FumBty9H"
      },
      "source": [
        "# Pré-traitement des données"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NUzjd-qN2s-T",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0b04d743-fb0a-4743-8e71-c60483722894"
      },
      "source": [
        "# Affichage du nombre total de données manquantes\n",
        "\n",
        "data_manquantes = sum(np.isnan(df_paris['taux']))\n",
        "print (\"Nombre de données manquantes : %s\" %data_manquantes)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Nombre de données manquantes : 59\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tkbi7uuBnUD3"
      },
      "source": [
        "**3. Correction des données**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8IQuSqAknduG"
      },
      "source": [
        "Pour corriger les données, on va tout simplement utiliser la fonction [fillna](https://pandas.pydata.org/docs/reference/api/pandas.Series.fillna.html) de Pandas avec la fonctionnalité de type `backfill` :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p2Oav6gin5aP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "42d2dddc-9b75-4a3d-8e0f-018147db83e8"
      },
      "source": [
        "# Applique la fonction de remplissage automatique des données non numérique avec l'option backfill\n",
        "df_paris = df_paris.interpolate(method=\"slinear\")\n",
        "data_manquantes = sum(np.isnan(df_paris['taux']))\n",
        "print (\"Nombre de données manquantes : %s\" %data_manquantes)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Nombre de données manquantes : 44\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n84L5raJo72w",
        "outputId": "adf29dfe-d6d1-4cb0-9fd4-de193aca58ac"
      },
      "source": [
        "df_paris = df_paris.fillna(method=\"backfill\")\n",
        "data_manquantes = sum(np.isnan(df_paris['taux']))\n",
        "print (\"Nombre de données manquantes : %s\" %data_manquantes)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Nombre de données manquantes : 0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v05rWWccJI26"
      },
      "source": [
        "**4. Affichage des données**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T1QKMBThNQni",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        },
        "outputId": "43fe626a-a5bd-41ec-d95c-491ba29e8cba"
      },
      "source": [
        "# Affiche la série\n",
        "plt.figure(figsize=(15,5))\n",
        "plt.plot(df_paris)\n",
        "plt.title(\"Evolution du prix du BTC\")"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'Evolution du prix du BTC')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1080x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zU7u1mA1E6jk"
      },
      "source": [
        "# Préparation des données"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_IbnwRJJF4Ox",
        "outputId": "8731d705-378d-4b5d-accb-14545cba9ee4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 446
        }
      },
      "source": [
        "# Définition des dates de début et de fin\n",
        "\n",
        "date_debut = \"2020-03-18\"\n",
        "date_fin = \"2021-04-22\"\n",
        "\n",
        "serie_etude = df_paris.loc[date_debut:date_fin].copy()\n",
        "serie_etude"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>taux</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>extract_date</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2020-03-18</th>\n",
              "      <td>108.53</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2020-03-19</th>\n",
              "      <td>108.53</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2020-03-20</th>\n",
              "      <td>108.53</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2020-03-21</th>\n",
              "      <td>108.53</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2020-03-22</th>\n",
              "      <td>108.53</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2021-04-18</th>\n",
              "      <td>80.22</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2021-04-19</th>\n",
              "      <td>75.20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2021-04-20</th>\n",
              "      <td>75.50</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2021-04-21</th>\n",
              "      <td>74.59</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2021-04-22</th>\n",
              "      <td>77.78</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>401 rows × 1 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                taux\n",
              "extract_date        \n",
              "2020-03-18    108.53\n",
              "2020-03-19    108.53\n",
              "2020-03-20    108.53\n",
              "2020-03-21    108.53\n",
              "2020-03-22    108.53\n",
              "...              ...\n",
              "2021-04-18     80.22\n",
              "2021-04-19     75.20\n",
              "2021-04-20     75.50\n",
              "2021-04-21     74.59\n",
              "2021-04-22     77.78\n",
              "\n",
              "[401 rows x 1 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fwOeFLtLSPnv"
      },
      "source": [
        "**2. Détection des anomalies dans la série \"horaire\"**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y1joYv2Kd7Js"
      },
      "source": [
        "Les anomalies sont fréquentes dans les séries temporelles, et la performance des prédictions est souvent améliorée lorsque ces anomalies sont traitées.  \n",
        "Pour avoir un apperçu de ces éventuelles anomalies, nous allons utiliser la méthode [\"Isolation Forest\"](https://scikit-learn.org/stable/modules/outlier_detection.html#isolation-forest) disponnible dans Scikit-learn.  \n",
        "\n",
        "Les paramètres utilisés sont les suivants :\n",
        " - **n_estimators** : C'est le nombre de sous-groupes d'échantillons à utiliser. Une valeur de 128 ou 256 est préconnisée dans le document de recherche.\n",
        " - **max_samples** : C'est le nombre d'échantillons maximum à utiliser. Nous utiliserons l'ensemble des échantillons.\n",
        " - **max_features** :  C'est le nombre de motifs aléatoirement choisis sur chaque noeud de l'arbre. Nous choisirons un seul motif.\n",
        " - **contamination** : C'est le pourcentage estimé d'anomalies dans les données. Ce paramètre permet de régler la sensibilité de l'algorithme. On va commencer avec 5% et affiner si nécessaire par la suite."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yHag65S4dH7x",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d692ae8a-1629-4ef5-a8df-7724f30963d7"
      },
      "source": [
        "# Initialise le modèle\n",
        "from sklearn.ensemble import IsolationForest\n",
        "\n",
        "clf = IsolationForest(n_estimators=256,max_samples=df_paris['taux'].size, contamination=0.01,max_features=1, verbose=1)\n",
        "clf.fit(df_paris['taux'].values.reshape(-1,1))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.3s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "IsolationForest(behaviour='deprecated', bootstrap=False, contamination=0.01,\n",
              "                max_features=1, max_samples=401, n_estimators=256, n_jobs=None,\n",
              "                random_state=None, verbose=1, warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 221
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HAPFfAaffb4h",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f58e3100-2138-4c20-d770-6f295f3b6037"
      },
      "source": [
        "# Réalise les prédictions\n",
        "pred = clf.predict(df_paris['taux'].values.reshape(-1,1))\n",
        "pred"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
              "        1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
              "        1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
              "        1,  1,  1,  1,  1,  1,  1,  1,  1,  1, -1,  1,  1,  1,  1, -1,  1,\n",
              "        1,  1,  1,  1, -1, -1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
              "        1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
              "        1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
              "        1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
              "        1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
              "        1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
              "        1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
              "        1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
              "        1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
              "        1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
              "        1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
              "        1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
              "        1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
              "        1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
              "        1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
              "        1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
              "        1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
              "        1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
              "        1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
              "        1,  1,  1,  1,  1,  1,  1,  1,  1,  1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 222
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OU0TN1UEBqR2"
      },
      "source": [
        "On ajoute maintenant ces informations dans la série journalière et on affiche les informations :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IWg0uUb9G5Ws",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 446
        },
        "outputId": "d153748e-0a25-4baf-bb60-3c38c01bd28c"
      },
      "source": [
        "# Ajoute une colonne \"Anomalie\" dans la série\n",
        "df_paris['Anomalies']=pred\n",
        "df_paris['Anomalies'] = df_paris['Anomalies'].apply(lambda x: 1 if (x==-1) else 0)\n",
        "df_paris"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>taux</th>\n",
              "      <th>Anomalies</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>extract_date</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2020-03-18</th>\n",
              "      <td>108.53</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2020-03-19</th>\n",
              "      <td>108.53</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2020-03-20</th>\n",
              "      <td>108.53</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2020-03-21</th>\n",
              "      <td>108.53</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2020-03-22</th>\n",
              "      <td>108.53</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2021-04-18</th>\n",
              "      <td>80.22</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2021-04-19</th>\n",
              "      <td>75.20</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2021-04-20</th>\n",
              "      <td>75.50</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2021-04-21</th>\n",
              "      <td>74.59</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2021-04-22</th>\n",
              "      <td>77.78</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>401 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                taux  Anomalies\n",
              "extract_date                   \n",
              "2020-03-18    108.53          0\n",
              "2020-03-19    108.53          0\n",
              "2020-03-20    108.53          0\n",
              "2020-03-21    108.53          0\n",
              "2020-03-22    108.53          0\n",
              "...              ...        ...\n",
              "2021-04-18     80.22          0\n",
              "2021-04-19     75.20          0\n",
              "2021-04-20     75.50          0\n",
              "2021-04-21     74.59          0\n",
              "2021-04-22     77.78          0\n",
              "\n",
              "[401 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 223
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "105qNoy1EwWd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "601ff73b-c009-4c42-bc82-13b085516c0e"
      },
      "source": [
        "# Affiche les informations sur les anomalies\n",
        "print(df_paris['Anomalies'].value_counts())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0    397\n",
            "1      4\n",
            "Name: Anomalies, dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HaV_MfJyFXkF"
      },
      "source": [
        "**3. Affichage des anomalies sur le graphique**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2idYKYImFh8v",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "outputId": "08e15cca-91bf-4f40-cabb-19d12301e390"
      },
      "source": [
        "# Affiche la série\n",
        "\n",
        "fig = px.line(x=df_paris.index,y=df_paris['taux'],title=\"Evolution du prix du BTC\")\n",
        "fig.add_trace(px.scatter(x=df_paris.index,y=df_paris['Anomalies']*df_paris['taux'],color=df_paris['Anomalies'].astype(np.bool)).data[0])\n",
        "\n",
        "fig.update_xaxes(rangeslider_visible=True)\n",
        "yaxis=dict(autorange = True,fixedrange= False)\n",
        "fig.update_yaxes(yaxis)\n",
        "fig.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>\n",
              "            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>\n",
              "                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-latest.min.js\"></script>    \n",
              "            <div id=\"d761acf0-dc52-4b7e-9227-37df53b1147a\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>\n",
              "            <script type=\"text/javascript\">\n",
              "                \n",
              "                    window.PLOTLYENV=window.PLOTLYENV || {};\n",
              "                    \n",
              "                if (document.getElementById(\"d761acf0-dc52-4b7e-9227-37df53b1147a\")) {\n",
              "                    Plotly.newPlot(\n",
              "                        'd761acf0-dc52-4b7e-9227-37df53b1147a',\n",
              "                        [{\"hoverlabel\": {\"namelength\": 0}, \"hovertemplate\": \"x=%{x}<br>y=%{y}\", \"legendgroup\": \"\", \"line\": {\"color\": \"#636efa\", \"dash\": \"solid\"}, \"mode\": \"lines\", \"name\": \"\", \"showlegend\": false, \"type\": \"scatter\", \"x\": [\"2020-03-18T00:00:00\", \"2020-03-19T00:00:00\", \"2020-03-20T00:00:00\", \"2020-03-21T00:00:00\", \"2020-03-22T00:00:00\", \"2020-03-23T00:00:00\", \"2020-03-24T00:00:00\", \"2020-03-25T00:00:00\", \"2020-03-26T00:00:00\", \"2020-03-27T00:00:00\", \"2020-03-28T00:00:00\", \"2020-03-29T00:00:00\", \"2020-03-30T00:00:00\", \"2020-03-31T00:00:00\", \"2020-04-01T00:00:00\", \"2020-04-02T00:00:00\", \"2020-04-03T00:00:00\", \"2020-04-04T00:00:00\", \"2020-04-05T00:00:00\", \"2020-04-06T00:00:00\", \"2020-04-07T00:00:00\", \"2020-04-08T00:00:00\", \"2020-04-09T00:00:00\", \"2020-04-10T00:00:00\", \"2020-04-11T00:00:00\", \"2020-04-12T00:00:00\", \"2020-04-13T00:00:00\", \"2020-04-14T00:00:00\", \"2020-04-15T00:00:00\", \"2020-04-16T00:00:00\", \"2020-04-17T00:00:00\", \"2020-04-18T00:00:00\", \"2020-04-19T00:00:00\", \"2020-04-20T00:00:00\", \"2020-04-21T00:00:00\", \"2020-04-22T00:00:00\", \"2020-04-23T00:00:00\", \"2020-04-24T00:00:00\", \"2020-04-25T00:00:00\", \"2020-04-26T00:00:00\", \"2020-04-27T00:00:00\", \"2020-04-28T00:00:00\", \"2020-04-29T00:00:00\", \"2020-04-30T00:00:00\", \"2020-05-01T00:00:00\", \"2020-05-02T00:00:00\", \"2020-05-03T00:00:00\", \"2020-05-04T00:00:00\", \"2020-05-05T00:00:00\", \"2020-05-06T00:00:00\", \"2020-05-07T00:00:00\", \"2020-05-08T00:00:00\", \"2020-05-09T00:00:00\", \"2020-05-10T00:00:00\", \"2020-05-11T00:00:00\", \"2020-05-12T00:00:00\", \"2020-05-13T00:00:00\", \"2020-05-14T00:00:00\", \"2020-05-15T00:00:00\", \"2020-05-16T00:00:00\", \"2020-05-17T00:00:00\", \"2020-05-18T00:00:00\", \"2020-05-19T00:00:00\", \"2020-05-20T00:00:00\", \"2020-05-21T00:00:00\", \"2020-05-22T00:00:00\", \"2020-05-23T00:00:00\", \"2020-05-24T00:00:00\", \"2020-05-25T00:00:00\", \"2020-05-26T00:00:00\", \"2020-05-27T00:00:00\", \"2020-05-28T00:00:00\", \"2020-05-29T00:00:00\", \"2020-05-30T00:00:00\", \"2020-05-31T00:00:00\", \"2020-06-01T00:00:00\", \"2020-06-02T00:00:00\", \"2020-06-03T00:00:00\", \"2020-06-04T00:00:00\", \"2020-06-05T00:00:00\", \"2020-06-06T00:00:00\", \"2020-06-07T00:00:00\", \"2020-06-08T00:00:00\", \"2020-06-09T00:00:00\", \"2020-06-10T00:00:00\", \"2020-06-11T00:00:00\", \"2020-06-12T00:00:00\", \"2020-06-13T00:00:00\", \"2020-06-14T00:00:00\", \"2020-06-15T00:00:00\", \"2020-06-16T00:00:00\", \"2020-06-17T00:00:00\", \"2020-06-18T00:00:00\", \"2020-06-19T00:00:00\", \"2020-06-20T00:00:00\", \"2020-06-21T00:00:00\", \"2020-06-22T00:00:00\", \"2020-06-23T00:00:00\", \"2020-06-24T00:00:00\", \"2020-06-25T00:00:00\", \"2020-06-26T00:00:00\", \"2020-06-27T00:00:00\", \"2020-06-28T00:00:00\", \"2020-06-29T00:00:00\", \"2020-06-30T00:00:00\", \"2020-07-01T00:00:00\", \"2020-07-02T00:00:00\", \"2020-07-03T00:00:00\", \"2020-07-04T00:00:00\", \"2020-07-05T00:00:00\", \"2020-07-06T00:00:00\", \"2020-07-07T00:00:00\", \"2020-07-08T00:00:00\", \"2020-07-09T00:00:00\", \"2020-07-10T00:00:00\", \"2020-07-11T00:00:00\", \"2020-07-12T00:00:00\", \"2020-07-13T00:00:00\", \"2020-07-14T00:00:00\", \"2020-07-15T00:00:00\", \"2020-07-16T00:00:00\", \"2020-07-17T00:00:00\", \"2020-07-18T00:00:00\", \"2020-07-19T00:00:00\", \"2020-07-20T00:00:00\", \"2020-07-21T00:00:00\", \"2020-07-22T00:00:00\", \"2020-07-23T00:00:00\", \"2020-07-24T00:00:00\", \"2020-07-25T00:00:00\", \"2020-07-26T00:00:00\", \"2020-07-27T00:00:00\", \"2020-07-28T00:00:00\", \"2020-07-29T00:00:00\", \"2020-07-30T00:00:00\", \"2020-07-31T00:00:00\", \"2020-08-01T00:00:00\", \"2020-08-02T00:00:00\", \"2020-08-03T00:00:00\", \"2020-08-04T00:00:00\", \"2020-08-05T00:00:00\", \"2020-08-06T00:00:00\", \"2020-08-07T00:00:00\", \"2020-08-08T00:00:00\", \"2020-08-09T00:00:00\", \"2020-08-10T00:00:00\", \"2020-08-11T00:00:00\", \"2020-08-12T00:00:00\", \"2020-08-13T00:00:00\", \"2020-08-14T00:00:00\", \"2020-08-15T00:00:00\", \"2020-08-16T00:00:00\", \"2020-08-17T00:00:00\", \"2020-08-18T00:00:00\", \"2020-08-19T00:00:00\", \"2020-08-20T00:00:00\", \"2020-08-21T00:00:00\", \"2020-08-22T00:00:00\", \"2020-08-23T00:00:00\", \"2020-08-24T00:00:00\", \"2020-08-25T00:00:00\", \"2020-08-26T00:00:00\", \"2020-08-27T00:00:00\", \"2020-08-28T00:00:00\", \"2020-08-29T00:00:00\", \"2020-08-30T00:00:00\", \"2020-08-31T00:00:00\", \"2020-09-01T00:00:00\", \"2020-09-02T00:00:00\", \"2020-09-03T00:00:00\", \"2020-09-04T00:00:00\", \"2020-09-05T00:00:00\", \"2020-09-06T00:00:00\", \"2020-09-07T00:00:00\", \"2020-09-08T00:00:00\", \"2020-09-09T00:00:00\", \"2020-09-10T00:00:00\", \"2020-09-11T00:00:00\", \"2020-09-12T00:00:00\", \"2020-09-13T00:00:00\", \"2020-09-14T00:00:00\", \"2020-09-15T00:00:00\", \"2020-09-16T00:00:00\", \"2020-09-17T00:00:00\", \"2020-09-18T00:00:00\", \"2020-09-19T00:00:00\", \"2020-09-20T00:00:00\", \"2020-09-21T00:00:00\", \"2020-09-22T00:00:00\", \"2020-09-23T00:00:00\", \"2020-09-24T00:00:00\", \"2020-09-25T00:00:00\", \"2020-09-26T00:00:00\", \"2020-09-27T00:00:00\", \"2020-09-28T00:00:00\", \"2020-09-29T00:00:00\", \"2020-09-30T00:00:00\", \"2020-10-01T00:00:00\", \"2020-10-02T00:00:00\", \"2020-10-03T00:00:00\", \"2020-10-04T00:00:00\", \"2020-10-05T00:00:00\", \"2020-10-06T00:00:00\", \"2020-10-07T00:00:00\", \"2020-10-08T00:00:00\", \"2020-10-09T00:00:00\", \"2020-10-10T00:00:00\", \"2020-10-11T00:00:00\", \"2020-10-12T00:00:00\", \"2020-10-13T00:00:00\", \"2020-10-14T00:00:00\", \"2020-10-15T00:00:00\", \"2020-10-16T00:00:00\", \"2020-10-17T00:00:00\", \"2020-10-18T00:00:00\", \"2020-10-19T00:00:00\", \"2020-10-20T00:00:00\", \"2020-10-21T00:00:00\", \"2020-10-22T00:00:00\", \"2020-10-23T00:00:00\", \"2020-10-24T00:00:00\", \"2020-10-25T00:00:00\", \"2020-10-26T00:00:00\", \"2020-10-27T00:00:00\", \"2020-10-28T00:00:00\", \"2020-10-29T00:00:00\", \"2020-10-30T00:00:00\", \"2020-10-31T00:00:00\", \"2020-11-01T00:00:00\", \"2020-11-02T00:00:00\", \"2020-11-03T00:00:00\", \"2020-11-04T00:00:00\", \"2020-11-05T00:00:00\", \"2020-11-06T00:00:00\", \"2020-11-07T00:00:00\", \"2020-11-08T00:00:00\", \"2020-11-09T00:00:00\", \"2020-11-10T00:00:00\", \"2020-11-11T00:00:00\", \"2020-11-12T00:00:00\", \"2020-11-13T00:00:00\", \"2020-11-14T00:00:00\", \"2020-11-15T00:00:00\", \"2020-11-16T00:00:00\", \"2020-11-17T00:00:00\", \"2020-11-18T00:00:00\", \"2020-11-19T00:00:00\", \"2020-11-20T00:00:00\", \"2020-11-21T00:00:00\", \"2020-11-22T00:00:00\", \"2020-11-23T00:00:00\", \"2020-11-24T00:00:00\", \"2020-11-25T00:00:00\", \"2020-11-26T00:00:00\", \"2020-11-27T00:00:00\", \"2020-11-28T00:00:00\", \"2020-11-29T00:00:00\", \"2020-11-30T00:00:00\", \"2020-12-01T00:00:00\", \"2020-12-02T00:00:00\", \"2020-12-03T00:00:00\", \"2020-12-04T00:00:00\", \"2020-12-05T00:00:00\", \"2020-12-06T00:00:00\", \"2020-12-07T00:00:00\", \"2020-12-08T00:00:00\", \"2020-12-09T00:00:00\", \"2020-12-10T00:00:00\", \"2020-12-11T00:00:00\", \"2020-12-12T00:00:00\", \"2020-12-13T00:00:00\", \"2020-12-14T00:00:00\", \"2020-12-15T00:00:00\", \"2020-12-16T00:00:00\", \"2020-12-17T00:00:00\", \"2020-12-18T00:00:00\", \"2020-12-19T00:00:00\", \"2020-12-20T00:00:00\", \"2020-12-21T00:00:00\", \"2020-12-22T00:00:00\", \"2020-12-23T00:00:00\", \"2020-12-24T00:00:00\", \"2020-12-25T00:00:00\", \"2020-12-26T00:00:00\", \"2020-12-27T00:00:00\", \"2020-12-28T00:00:00\", \"2020-12-29T00:00:00\", \"2020-12-30T00:00:00\", \"2020-12-31T00:00:00\", \"2021-01-01T00:00:00\", \"2021-01-02T00:00:00\", \"2021-01-03T00:00:00\", \"2021-01-04T00:00:00\", \"2021-01-05T00:00:00\", \"2021-01-06T00:00:00\", \"2021-01-07T00:00:00\", \"2021-01-08T00:00:00\", \"2021-01-09T00:00:00\", \"2021-01-10T00:00:00\", \"2021-01-11T00:00:00\", \"2021-01-12T00:00:00\", \"2021-01-13T00:00:00\", \"2021-01-14T00:00:00\", \"2021-01-15T00:00:00\", \"2021-01-16T00:00:00\", \"2021-01-17T00:00:00\", \"2021-01-18T00:00:00\", \"2021-01-19T00:00:00\", \"2021-01-20T00:00:00\", \"2021-01-21T00:00:00\", \"2021-01-22T00:00:00\", \"2021-01-23T00:00:00\", \"2021-01-24T00:00:00\", \"2021-01-25T00:00:00\", \"2021-01-26T00:00:00\", \"2021-01-27T00:00:00\", \"2021-01-28T00:00:00\", \"2021-01-29T00:00:00\", \"2021-01-30T00:00:00\", \"2021-01-31T00:00:00\", \"2021-02-01T00:00:00\", \"2021-02-02T00:00:00\", \"2021-02-03T00:00:00\", \"2021-02-04T00:00:00\", \"2021-02-05T00:00:00\", \"2021-02-06T00:00:00\", \"2021-02-07T00:00:00\", \"2021-02-08T00:00:00\", \"2021-02-09T00:00:00\", \"2021-02-10T00:00:00\", \"2021-02-11T00:00:00\", \"2021-02-12T00:00:00\", \"2021-02-13T00:00:00\", \"2021-02-14T00:00:00\", \"2021-02-15T00:00:00\", \"2021-02-16T00:00:00\", \"2021-02-17T00:00:00\", \"2021-02-18T00:00:00\", \"2021-02-19T00:00:00\", \"2021-02-20T00:00:00\", \"2021-02-21T00:00:00\", \"2021-02-22T00:00:00\", \"2021-02-23T00:00:00\", \"2021-02-24T00:00:00\", \"2021-02-25T00:00:00\", \"2021-02-26T00:00:00\", \"2021-02-27T00:00:00\", \"2021-02-28T00:00:00\", \"2021-03-01T00:00:00\", \"2021-03-02T00:00:00\", \"2021-03-03T00:00:00\", \"2021-03-04T00:00:00\", \"2021-03-05T00:00:00\", \"2021-03-06T00:00:00\", \"2021-03-07T00:00:00\", \"2021-03-08T00:00:00\", \"2021-03-09T00:00:00\", \"2021-03-10T00:00:00\", \"2021-03-11T00:00:00\", \"2021-03-12T00:00:00\", \"2021-03-13T00:00:00\", \"2021-03-14T00:00:00\", \"2021-03-15T00:00:00\", \"2021-03-16T00:00:00\", \"2021-03-17T00:00:00\", \"2021-03-18T00:00:00\", \"2021-03-19T00:00:00\", \"2021-03-20T00:00:00\", \"2021-03-21T00:00:00\", \"2021-03-22T00:00:00\", \"2021-03-23T00:00:00\", \"2021-03-24T00:00:00\", \"2021-03-25T00:00:00\", \"2021-03-26T00:00:00\", \"2021-03-27T00:00:00\", \"2021-03-28T00:00:00\", \"2021-03-29T00:00:00\", \"2021-03-30T00:00:00\", \"2021-03-31T00:00:00\", \"2021-04-01T00:00:00\", \"2021-04-02T00:00:00\", \"2021-04-03T00:00:00\", \"2021-04-04T00:00:00\", \"2021-04-05T00:00:00\", \"2021-04-06T00:00:00\", \"2021-04-07T00:00:00\", \"2021-04-08T00:00:00\", \"2021-04-09T00:00:00\", \"2021-04-10T00:00:00\", \"2021-04-11T00:00:00\", \"2021-04-12T00:00:00\", \"2021-04-13T00:00:00\", \"2021-04-14T00:00:00\", \"2021-04-15T00:00:00\", \"2021-04-16T00:00:00\", \"2021-04-17T00:00:00\", \"2021-04-18T00:00:00\", \"2021-04-19T00:00:00\", \"2021-04-20T00:00:00\", \"2021-04-21T00:00:00\", \"2021-04-22T00:00:00\"], \"xaxis\": \"x\", \"y\": [108.53, 108.53, 108.53, 108.53, 108.53, 108.53, 108.53, 108.53, 108.53, 108.53, 108.53, 108.53, 108.53, 108.53, 108.53, 108.53, 108.53, 108.53, 108.53, 108.53, 108.53, 108.53, 108.53, 108.53, 108.53, 108.53, 108.53, 108.53, 108.53, 108.53, 108.53, 108.53, 108.53, 108.53, 108.53, 108.53, 108.53, 108.53, 108.53, 108.53, 108.53, 108.53, 108.53, 108.53, 108.53, 121.47, 141.71, 165.16, 189.97, 196.36, 196.82, 237.61, 264.25, 290.58, 333.2, 369.58, 384.96, 387.09, 428.8, 494.1, 554.07, 608.41, 681.63, 705.83, 712.99, 779.51, 838.11, 889.25, 926.24, 933.25, 939.03, 939.79, 961.71, 972.36, 943.29, 916.35, 879.51, 859.57, 854.09, 783.62, 694.57, 558.94, 504.75, 459.09, 443.71, 442.04, 397.29, 349.64, 386.78, 338.53, 299.87, 286.17, 284.04, 246.29, 221.17, 203.36, 197.12, 186.31, 188.9, 188.29, 172.92, 166.07, 167.59, 152.67, 148.26, 145.06, 145.06, 149.93, 156.78, 153.28, 156.33, 157.09, 158.91, 159.22, 158.31, 161.35, 161.96, 167.74, 182.97, 198.95, 215.69, 213.41, 220.87, 223.3, 212.04, 173.22, 159.83, 144.3, 147.96, 142.17, 148.87, 156.48, 155.41, 157.39, 158.61, 170.79, 178.25, 174.75, 180.99, 218.89, 215.39, 218.13, 209.91, 202.3, 206.71, 206.1, 203.36, 205.49, 200.17, 208.84, 214.32, 214.78, 218.58, 218.28, 223.46, 225.59, 231.98, 238.98, 238.98, 238.37, 244.77, 245.53, 244.61, 246.29, 241.87, 249.94, 253.9, 249.79, 243.55, 242.63, 224.06, 224.06, 215.69, 206.71, 200.01, 199.86, 200.01, 202.14, 193.77, 188.14, 191.34, 190.88, 191.95, 193.32, 200.17, 202.45, 209.91, 206.1, 209.15, 208.84, 206.71, 196.06, 189.05, 179.01, 173.68, 169.42, 169.11, 169.57, 170.64, 178.09, 179.62, 187.68, 197.27, 200.93, 202.6, 213.87, 228.48, 237.0, 247.2, 254.2, 259.84, 260.44, 272.32, 274.9, 293.63, 307.94, 327.42, 335.33, 335.64, 354.21, 371.26, 381.0, 398.35, 401.85, 403.99, 405.05, 329.86, 350.4, 345.84, 324.68, 314.79, 313.26, 313.57, 379.33, 340.21, 334.42, 331.68, 318.29, 314.18, 312.35, 305.04, 235.66750000000002, 166.29500000000002, 96.92250000000001, 27.55, 31.36, 33.64, 38.05, 46.43, 48.1, 49.17, 45.49307692307692, 41.81615384615384, 38.139230769230764, 34.46230769230769, 30.78538461538461, 27.108461538461537, 23.43153846153846, 19.75461538461538, 16.077692307692306, 12.40076923076923, 8.723846153846154, 5.046923076923076, 1.37, 2.74, 3.5, 3.5, 3.5, 5.18, 6.55, 6.85, 5.63, 5.94, 6.24, 6.24, 5.02, 3.96, 2.89, 2.89, 2.74, 2.74, 2.89, 3.04, 3.2, 2.89, 2.74, 2.59, 2.74, 2.74, 2.13, 1.83, 1.67, 2.89, 2.74, 2.28, 2.28, 2.28, 2.59, 3.2, 2.59, 2.44, 3.04, 2.89, 3.65, 4.72, 4.26, 4.41, 5.18, 5.48, 5.48, 5.63, 5.33, 5.48, 4.72, 3.96, 3.2, 3.2, 2.59, 2.13, 2.13, 2.59, 2.59, 2.44, 2.59, 2.28, 1.52, 1.52, 1.07, 1.52, 2.13, 1.98, 2.44, 3.96, 4.26, 5.18, 7.46, 7.15, 7.46, 8.98, 8.98, 9.29, 10.96, 10.35, 10.81, 10.81, 10.2, 10.81, 11.26, 10.96, 9.74, 10.2, 10.05, 12.03, 11.57, 12.33, 12.48, 14.92, 13.85, 13.7, 14.77, 16.59, 18.42, 21.01, 24.81, 27.25, 84.79, 90.26, 91.48, 72.0, 71.85, 72.0, 75.35, 49.17, 56.02, 61.34, 63.17, 65.3, 67.89, 70.32, 70.48, 69.11, 102.14, 94.53, 86.61, 84.48, 75.8, 76.11, 80.37, 89.81, 102.9, 102.29, 102.75, 100.62, 100.46, 81.28, 80.68, 80.22, 75.2, 75.5, 74.59, 77.78], \"yaxis\": \"y\"}, {\"hoverlabel\": {\"namelength\": 0}, \"hovertemplate\": \"x=%{x}<br>y=%{y}<br>color=%{marker.color}\", \"legendgroup\": \"\", \"marker\": {\"color\": [false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, true, false, false, false, false, true, false, false, false, false, false, true, true, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false], \"coloraxis\": \"coloraxis\", \"symbol\": \"circle\"}, \"mode\": \"markers\", \"name\": \"\", \"showlegend\": false, \"type\": \"scatter\", \"x\": [\"2020-03-18T00:00:00\", \"2020-03-19T00:00:00\", \"2020-03-20T00:00:00\", \"2020-03-21T00:00:00\", \"2020-03-22T00:00:00\", \"2020-03-23T00:00:00\", \"2020-03-24T00:00:00\", \"2020-03-25T00:00:00\", \"2020-03-26T00:00:00\", \"2020-03-27T00:00:00\", \"2020-03-28T00:00:00\", \"2020-03-29T00:00:00\", \"2020-03-30T00:00:00\", \"2020-03-31T00:00:00\", \"2020-04-01T00:00:00\", \"2020-04-02T00:00:00\", \"2020-04-03T00:00:00\", \"2020-04-04T00:00:00\", \"2020-04-05T00:00:00\", \"2020-04-06T00:00:00\", \"2020-04-07T00:00:00\", \"2020-04-08T00:00:00\", \"2020-04-09T00:00:00\", \"2020-04-10T00:00:00\", \"2020-04-11T00:00:00\", \"2020-04-12T00:00:00\", \"2020-04-13T00:00:00\", \"2020-04-14T00:00:00\", \"2020-04-15T00:00:00\", \"2020-04-16T00:00:00\", \"2020-04-17T00:00:00\", \"2020-04-18T00:00:00\", \"2020-04-19T00:00:00\", \"2020-04-20T00:00:00\", \"2020-04-21T00:00:00\", \"2020-04-22T00:00:00\", \"2020-04-23T00:00:00\", \"2020-04-24T00:00:00\", \"2020-04-25T00:00:00\", \"2020-04-26T00:00:00\", \"2020-04-27T00:00:00\", \"2020-04-28T00:00:00\", \"2020-04-29T00:00:00\", \"2020-04-30T00:00:00\", \"2020-05-01T00:00:00\", \"2020-05-02T00:00:00\", \"2020-05-03T00:00:00\", \"2020-05-04T00:00:00\", \"2020-05-05T00:00:00\", \"2020-05-06T00:00:00\", \"2020-05-07T00:00:00\", \"2020-05-08T00:00:00\", \"2020-05-09T00:00:00\", \"2020-05-10T00:00:00\", \"2020-05-11T00:00:00\", \"2020-05-12T00:00:00\", \"2020-05-13T00:00:00\", \"2020-05-14T00:00:00\", \"2020-05-15T00:00:00\", \"2020-05-16T00:00:00\", \"2020-05-17T00:00:00\", \"2020-05-18T00:00:00\", \"2020-05-19T00:00:00\", \"2020-05-20T00:00:00\", \"2020-05-21T00:00:00\", \"2020-05-22T00:00:00\", \"2020-05-23T00:00:00\", \"2020-05-24T00:00:00\", \"2020-05-25T00:00:00\", \"2020-05-26T00:00:00\", \"2020-05-27T00:00:00\", \"2020-05-28T00:00:00\", \"2020-05-29T00:00:00\", \"2020-05-30T00:00:00\", \"2020-05-31T00:00:00\", \"2020-06-01T00:00:00\", \"2020-06-02T00:00:00\", \"2020-06-03T00:00:00\", \"2020-06-04T00:00:00\", \"2020-06-05T00:00:00\", \"2020-06-06T00:00:00\", \"2020-06-07T00:00:00\", \"2020-06-08T00:00:00\", \"2020-06-09T00:00:00\", \"2020-06-10T00:00:00\", \"2020-06-11T00:00:00\", \"2020-06-12T00:00:00\", \"2020-06-13T00:00:00\", \"2020-06-14T00:00:00\", \"2020-06-15T00:00:00\", \"2020-06-16T00:00:00\", \"2020-06-17T00:00:00\", \"2020-06-18T00:00:00\", \"2020-06-19T00:00:00\", \"2020-06-20T00:00:00\", \"2020-06-21T00:00:00\", \"2020-06-22T00:00:00\", \"2020-06-23T00:00:00\", \"2020-06-24T00:00:00\", \"2020-06-25T00:00:00\", \"2020-06-26T00:00:00\", \"2020-06-27T00:00:00\", \"2020-06-28T00:00:00\", \"2020-06-29T00:00:00\", \"2020-06-30T00:00:00\", \"2020-07-01T00:00:00\", \"2020-07-02T00:00:00\", \"2020-07-03T00:00:00\", \"2020-07-04T00:00:00\", \"2020-07-05T00:00:00\", \"2020-07-06T00:00:00\", \"2020-07-07T00:00:00\", \"2020-07-08T00:00:00\", \"2020-07-09T00:00:00\", \"2020-07-10T00:00:00\", \"2020-07-11T00:00:00\", \"2020-07-12T00:00:00\", \"2020-07-13T00:00:00\", \"2020-07-14T00:00:00\", \"2020-07-15T00:00:00\", \"2020-07-16T00:00:00\", \"2020-07-17T00:00:00\", \"2020-07-18T00:00:00\", \"2020-07-19T00:00:00\", \"2020-07-20T00:00:00\", \"2020-07-21T00:00:00\", \"2020-07-22T00:00:00\", \"2020-07-23T00:00:00\", \"2020-07-24T00:00:00\", \"2020-07-25T00:00:00\", \"2020-07-26T00:00:00\", \"2020-07-27T00:00:00\", \"2020-07-28T00:00:00\", \"2020-07-29T00:00:00\", \"2020-07-30T00:00:00\", \"2020-07-31T00:00:00\", \"2020-08-01T00:00:00\", \"2020-08-02T00:00:00\", \"2020-08-03T00:00:00\", \"2020-08-04T00:00:00\", \"2020-08-05T00:00:00\", \"2020-08-06T00:00:00\", \"2020-08-07T00:00:00\", \"2020-08-08T00:00:00\", \"2020-08-09T00:00:00\", \"2020-08-10T00:00:00\", \"2020-08-11T00:00:00\", \"2020-08-12T00:00:00\", \"2020-08-13T00:00:00\", \"2020-08-14T00:00:00\", \"2020-08-15T00:00:00\", \"2020-08-16T00:00:00\", \"2020-08-17T00:00:00\", \"2020-08-18T00:00:00\", \"2020-08-19T00:00:00\", \"2020-08-20T00:00:00\", \"2020-08-21T00:00:00\", \"2020-08-22T00:00:00\", \"2020-08-23T00:00:00\", \"2020-08-24T00:00:00\", \"2020-08-25T00:00:00\", \"2020-08-26T00:00:00\", \"2020-08-27T00:00:00\", \"2020-08-28T00:00:00\", \"2020-08-29T00:00:00\", \"2020-08-30T00:00:00\", \"2020-08-31T00:00:00\", \"2020-09-01T00:00:00\", \"2020-09-02T00:00:00\", \"2020-09-03T00:00:00\", \"2020-09-04T00:00:00\", \"2020-09-05T00:00:00\", \"2020-09-06T00:00:00\", \"2020-09-07T00:00:00\", \"2020-09-08T00:00:00\", \"2020-09-09T00:00:00\", \"2020-09-10T00:00:00\", \"2020-09-11T00:00:00\", \"2020-09-12T00:00:00\", \"2020-09-13T00:00:00\", \"2020-09-14T00:00:00\", \"2020-09-15T00:00:00\", \"2020-09-16T00:00:00\", \"2020-09-17T00:00:00\", \"2020-09-18T00:00:00\", \"2020-09-19T00:00:00\", \"2020-09-20T00:00:00\", \"2020-09-21T00:00:00\", \"2020-09-22T00:00:00\", \"2020-09-23T00:00:00\", \"2020-09-24T00:00:00\", \"2020-09-25T00:00:00\", \"2020-09-26T00:00:00\", \"2020-09-27T00:00:00\", \"2020-09-28T00:00:00\", \"2020-09-29T00:00:00\", \"2020-09-30T00:00:00\", \"2020-10-01T00:00:00\", \"2020-10-02T00:00:00\", \"2020-10-03T00:00:00\", \"2020-10-04T00:00:00\", \"2020-10-05T00:00:00\", \"2020-10-06T00:00:00\", \"2020-10-07T00:00:00\", \"2020-10-08T00:00:00\", \"2020-10-09T00:00:00\", \"2020-10-10T00:00:00\", \"2020-10-11T00:00:00\", \"2020-10-12T00:00:00\", \"2020-10-13T00:00:00\", \"2020-10-14T00:00:00\", \"2020-10-15T00:00:00\", \"2020-10-16T00:00:00\", \"2020-10-17T00:00:00\", \"2020-10-18T00:00:00\", \"2020-10-19T00:00:00\", \"2020-10-20T00:00:00\", \"2020-10-21T00:00:00\", \"2020-10-22T00:00:00\", \"2020-10-23T00:00:00\", \"2020-10-24T00:00:00\", \"2020-10-25T00:00:00\", \"2020-10-26T00:00:00\", \"2020-10-27T00:00:00\", \"2020-10-28T00:00:00\", \"2020-10-29T00:00:00\", \"2020-10-30T00:00:00\", \"2020-10-31T00:00:00\", \"2020-11-01T00:00:00\", \"2020-11-02T00:00:00\", \"2020-11-03T00:00:00\", \"2020-11-04T00:00:00\", \"2020-11-05T00:00:00\", \"2020-11-06T00:00:00\", \"2020-11-07T00:00:00\", \"2020-11-08T00:00:00\", \"2020-11-09T00:00:00\", \"2020-11-10T00:00:00\", \"2020-11-11T00:00:00\", \"2020-11-12T00:00:00\", \"2020-11-13T00:00:00\", \"2020-11-14T00:00:00\", \"2020-11-15T00:00:00\", \"2020-11-16T00:00:00\", \"2020-11-17T00:00:00\", \"2020-11-18T00:00:00\", \"2020-11-19T00:00:00\", \"2020-11-20T00:00:00\", \"2020-11-21T00:00:00\", \"2020-11-22T00:00:00\", \"2020-11-23T00:00:00\", \"2020-11-24T00:00:00\", \"2020-11-25T00:00:00\", \"2020-11-26T00:00:00\", \"2020-11-27T00:00:00\", \"2020-11-28T00:00:00\", \"2020-11-29T00:00:00\", \"2020-11-30T00:00:00\", \"2020-12-01T00:00:00\", \"2020-12-02T00:00:00\", \"2020-12-03T00:00:00\", \"2020-12-04T00:00:00\", \"2020-12-05T00:00:00\", \"2020-12-06T00:00:00\", \"2020-12-07T00:00:00\", \"2020-12-08T00:00:00\", \"2020-12-09T00:00:00\", \"2020-12-10T00:00:00\", \"2020-12-11T00:00:00\", \"2020-12-12T00:00:00\", \"2020-12-13T00:00:00\", \"2020-12-14T00:00:00\", \"2020-12-15T00:00:00\", \"2020-12-16T00:00:00\", \"2020-12-17T00:00:00\", \"2020-12-18T00:00:00\", \"2020-12-19T00:00:00\", \"2020-12-20T00:00:00\", \"2020-12-21T00:00:00\", \"2020-12-22T00:00:00\", \"2020-12-23T00:00:00\", \"2020-12-24T00:00:00\", \"2020-12-25T00:00:00\", \"2020-12-26T00:00:00\", \"2020-12-27T00:00:00\", \"2020-12-28T00:00:00\", \"2020-12-29T00:00:00\", \"2020-12-30T00:00:00\", \"2020-12-31T00:00:00\", \"2021-01-01T00:00:00\", \"2021-01-02T00:00:00\", \"2021-01-03T00:00:00\", \"2021-01-04T00:00:00\", \"2021-01-05T00:00:00\", \"2021-01-06T00:00:00\", \"2021-01-07T00:00:00\", \"2021-01-08T00:00:00\", \"2021-01-09T00:00:00\", \"2021-01-10T00:00:00\", \"2021-01-11T00:00:00\", \"2021-01-12T00:00:00\", \"2021-01-13T00:00:00\", \"2021-01-14T00:00:00\", \"2021-01-15T00:00:00\", \"2021-01-16T00:00:00\", \"2021-01-17T00:00:00\", \"2021-01-18T00:00:00\", \"2021-01-19T00:00:00\", \"2021-01-20T00:00:00\", \"2021-01-21T00:00:00\", \"2021-01-22T00:00:00\", \"2021-01-23T00:00:00\", \"2021-01-24T00:00:00\", \"2021-01-25T00:00:00\", \"2021-01-26T00:00:00\", \"2021-01-27T00:00:00\", \"2021-01-28T00:00:00\", \"2021-01-29T00:00:00\", \"2021-01-30T00:00:00\", \"2021-01-31T00:00:00\", \"2021-02-01T00:00:00\", \"2021-02-02T00:00:00\", \"2021-02-03T00:00:00\", \"2021-02-04T00:00:00\", \"2021-02-05T00:00:00\", \"2021-02-06T00:00:00\", \"2021-02-07T00:00:00\", \"2021-02-08T00:00:00\", \"2021-02-09T00:00:00\", \"2021-02-10T00:00:00\", \"2021-02-11T00:00:00\", \"2021-02-12T00:00:00\", \"2021-02-13T00:00:00\", \"2021-02-14T00:00:00\", \"2021-02-15T00:00:00\", \"2021-02-16T00:00:00\", \"2021-02-17T00:00:00\", \"2021-02-18T00:00:00\", \"2021-02-19T00:00:00\", \"2021-02-20T00:00:00\", \"2021-02-21T00:00:00\", \"2021-02-22T00:00:00\", \"2021-02-23T00:00:00\", \"2021-02-24T00:00:00\", \"2021-02-25T00:00:00\", \"2021-02-26T00:00:00\", \"2021-02-27T00:00:00\", \"2021-02-28T00:00:00\", \"2021-03-01T00:00:00\", \"2021-03-02T00:00:00\", \"2021-03-03T00:00:00\", \"2021-03-04T00:00:00\", \"2021-03-05T00:00:00\", \"2021-03-06T00:00:00\", \"2021-03-07T00:00:00\", \"2021-03-08T00:00:00\", \"2021-03-09T00:00:00\", \"2021-03-10T00:00:00\", \"2021-03-11T00:00:00\", \"2021-03-12T00:00:00\", \"2021-03-13T00:00:00\", \"2021-03-14T00:00:00\", \"2021-03-15T00:00:00\", \"2021-03-16T00:00:00\", \"2021-03-17T00:00:00\", \"2021-03-18T00:00:00\", \"2021-03-19T00:00:00\", \"2021-03-20T00:00:00\", \"2021-03-21T00:00:00\", \"2021-03-22T00:00:00\", \"2021-03-23T00:00:00\", \"2021-03-24T00:00:00\", \"2021-03-25T00:00:00\", \"2021-03-26T00:00:00\", \"2021-03-27T00:00:00\", \"2021-03-28T00:00:00\", \"2021-03-29T00:00:00\", \"2021-03-30T00:00:00\", \"2021-03-31T00:00:00\", \"2021-04-01T00:00:00\", \"2021-04-02T00:00:00\", \"2021-04-03T00:00:00\", \"2021-04-04T00:00:00\", \"2021-04-05T00:00:00\", \"2021-04-06T00:00:00\", \"2021-04-07T00:00:00\", \"2021-04-08T00:00:00\", \"2021-04-09T00:00:00\", \"2021-04-10T00:00:00\", \"2021-04-11T00:00:00\", \"2021-04-12T00:00:00\", \"2021-04-13T00:00:00\", \"2021-04-14T00:00:00\", \"2021-04-15T00:00:00\", \"2021-04-16T00:00:00\", \"2021-04-17T00:00:00\", \"2021-04-18T00:00:00\", \"2021-04-19T00:00:00\", \"2021-04-20T00:00:00\", \"2021-04-21T00:00:00\", \"2021-04-22T00:00:00\"], \"xaxis\": \"x\", \"y\": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 608.41, 0.0, 0.0, 0.0, 0.0, 838.11, 0.0, 0.0, 0.0, 0.0, 0.0, 961.71, 972.36, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], \"yaxis\": \"y\"}],\n",
              "                        {\"legend\": {\"tracegroupgap\": 0}, \"template\": {\"data\": {\"bar\": [{\"error_x\": {\"color\": \"#2a3f5f\"}, \"error_y\": {\"color\": \"#2a3f5f\"}, \"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"bar\"}], \"barpolar\": [{\"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"barpolar\"}], \"carpet\": [{\"aaxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"baxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"type\": \"carpet\"}], \"choropleth\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"choropleth\"}], \"contour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"contour\"}], \"contourcarpet\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"contourcarpet\"}], \"heatmap\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmap\"}], \"heatmapgl\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmapgl\"}], \"histogram\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"histogram\"}], \"histogram2d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2d\"}], \"histogram2dcontour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2dcontour\"}], \"mesh3d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"mesh3d\"}], \"parcoords\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"parcoords\"}], \"pie\": [{\"automargin\": true, \"type\": \"pie\"}], \"scatter\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter\"}], \"scatter3d\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter3d\"}], \"scattercarpet\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattercarpet\"}], \"scattergeo\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergeo\"}], \"scattergl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergl\"}], \"scattermapbox\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattermapbox\"}], \"scatterpolar\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolar\"}], \"scatterpolargl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolargl\"}], \"scatterternary\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterternary\"}], \"surface\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"surface\"}], \"table\": [{\"cells\": {\"fill\": {\"color\": \"#EBF0F8\"}, \"line\": {\"color\": \"white\"}}, \"header\": {\"fill\": {\"color\": \"#C8D4E3\"}, \"line\": {\"color\": \"white\"}}, \"type\": \"table\"}]}, \"layout\": {\"annotationdefaults\": {\"arrowcolor\": \"#2a3f5f\", \"arrowhead\": 0, \"arrowwidth\": 1}, \"coloraxis\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"colorscale\": {\"diverging\": [[0, \"#8e0152\"], [0.1, \"#c51b7d\"], [0.2, \"#de77ae\"], [0.3, \"#f1b6da\"], [0.4, \"#fde0ef\"], [0.5, \"#f7f7f7\"], [0.6, \"#e6f5d0\"], [0.7, \"#b8e186\"], [0.8, \"#7fbc41\"], [0.9, \"#4d9221\"], [1, \"#276419\"]], \"sequential\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"sequentialminus\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}, \"colorway\": [\"#636efa\", \"#EF553B\", \"#00cc96\", \"#ab63fa\", \"#FFA15A\", \"#19d3f3\", \"#FF6692\", \"#B6E880\", \"#FF97FF\", \"#FECB52\"], \"font\": {\"color\": \"#2a3f5f\"}, \"geo\": {\"bgcolor\": \"white\", \"lakecolor\": \"white\", \"landcolor\": \"#E5ECF6\", \"showlakes\": true, \"showland\": true, \"subunitcolor\": \"white\"}, \"hoverlabel\": {\"align\": \"left\"}, \"hovermode\": \"closest\", \"mapbox\": {\"style\": \"light\"}, \"paper_bgcolor\": \"white\", \"plot_bgcolor\": \"#E5ECF6\", \"polar\": {\"angularaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"radialaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"scene\": {\"xaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"yaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"zaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}}, \"shapedefaults\": {\"line\": {\"color\": \"#2a3f5f\"}}, \"ternary\": {\"aaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"baxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"caxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"title\": {\"x\": 0.05}, \"xaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}, \"yaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}}}, \"title\": {\"text\": \"Evolution du prix du BTC\"}, \"xaxis\": {\"anchor\": \"y\", \"domain\": [0.0, 1.0], \"rangeslider\": {\"visible\": true}, \"title\": {\"text\": \"x\"}}, \"yaxis\": {\"anchor\": \"x\", \"autorange\": true, \"domain\": [0.0, 1.0], \"fixedrange\": false, \"title\": {\"text\": \"y\"}}},\n",
              "                        {\"responsive\": true}\n",
              "                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('d761acf0-dc52-4b7e-9227-37df53b1147a');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })\n",
              "                };\n",
              "                \n",
              "            </script>\n",
              "        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zVAWVQioe-kS"
      },
      "source": [
        "Comme les anomalies détectées ne sembles pas cohérentes, nous n'allons pas les traiter..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7vDYEK-cxE0C"
      },
      "source": [
        "# Analyse de la série"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mGY4fCB3xdUx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 446
        },
        "outputId": "89d1ab50-bfa2-402c-be37-c9da63377843"
      },
      "source": [
        "df_paris"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>taux</th>\n",
              "      <th>Anomalies</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>extract_date</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2020-03-18</th>\n",
              "      <td>108.53</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2020-03-19</th>\n",
              "      <td>108.53</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2020-03-20</th>\n",
              "      <td>108.53</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2020-03-21</th>\n",
              "      <td>108.53</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2020-03-22</th>\n",
              "      <td>108.53</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2021-04-18</th>\n",
              "      <td>80.22</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2021-04-19</th>\n",
              "      <td>75.20</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2021-04-20</th>\n",
              "      <td>75.50</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2021-04-21</th>\n",
              "      <td>74.59</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2021-04-22</th>\n",
              "      <td>77.78</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>401 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                taux  Anomalies\n",
              "extract_date                   \n",
              "2020-03-18    108.53          0\n",
              "2020-03-19    108.53          0\n",
              "2020-03-20    108.53          0\n",
              "2020-03-21    108.53          0\n",
              "2020-03-22    108.53          0\n",
              "...              ...        ...\n",
              "2021-04-18     80.22          0\n",
              "2021-04-19     75.20          0\n",
              "2021-04-20     75.50          0\n",
              "2021-04-21     74.59          0\n",
              "2021-04-22     77.78          0\n",
              "\n",
              "[401 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 226
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kBCbjPSNxWXy"
      },
      "source": [
        "**1. ACF & PACF**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CleN4htOxYqZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "outputId": "9475a8ce-da01-412b-f3c2-f7a298297cf3"
      },
      "source": [
        "# ACF & PACF du bruit blanc\n",
        "\n",
        "serie = serie_etude\n",
        "\n",
        "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
        "\n",
        "f1, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
        "f1.subplots_adjust(hspace=0.3,wspace=0.2)\n",
        "\n",
        "plot_acf(serie, ax=ax1, lags = range(0,15))\n",
        "ax1.set_title(\"Autocorrélation du bruit blanc\")\n",
        "\n",
        "plot_pacf(serie, ax=ax2, lags = range(0, 15))\n",
        "ax2.set_title(\"Autocorrélation partielle du bruit blanc\")"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/statsmodels/regression/linear_model.py:1358: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in sqrt\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'Autocorrélation partielle du bruit blanc')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1080x360 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o66MqHZTyHX5"
      },
      "source": [
        "**2. Test de Dickey-Fuller**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fm5VXMhkyLSN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b308f77f-468a-4ea8-b763-98e964bf9ce1"
      },
      "source": [
        "import statsmodels.api as sm\n",
        "\n",
        "serie_test = serie_etude['taux']\n",
        "\n",
        "adf, p, usedlag, nobs, cvs, aic = sm.tsa.stattools.adfuller(serie_test)\n",
        "\n",
        "adf_results_string = 'ADF: {}\\np-value: {},\\nN: {}, \\ncritical values: {}'\n",
        "print(adf_results_string.format(adf, p, nobs, cvs))"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ADF: -2.564352316207272\n",
            "p-value: 0.10059098552499757,\n",
            "N: 113, \n",
            "critical values: {'1%': -3.489589552580676, '5%': -2.887477210140433, '10%': -2.580604145195395}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "moHyQgGfyTi4"
      },
      "source": [
        "**3. Suppression de la tendance non linéaire et test de sationnarité**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "43AcGds6y0pI"
      },
      "source": [
        "from scipy.stats import boxcox\n",
        "\n",
        "serie_log, lam = boxcox(serie)\n",
        "\n",
        "f1, (ax1,ax2) = plt.subplots(2, 1, figsize=(15, 5))\n",
        "ax1.plot(serie_etude.index,serie_log)\n",
        "ax2.plot(serie_etude.index,serie)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1fRPXCkO0DUh"
      },
      "source": [
        "import statsmodels.api as sm\n",
        "\n",
        "serie_test = serie_log\n",
        "\n",
        "adf, p, usedlag, nobs, cvs, aic = sm.tsa.stattools.adfuller(serie_test)\n",
        "\n",
        "adf_results_string = 'ADF: {}\\np-value: {},\\nN: {}, \\ncritical values: {}'\n",
        "print(adf_results_string.format(adf, p, nobs, cvs))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wI8sp_Rlz6GT"
      },
      "source": [
        "***4. Suppression de la tendance linéaire et test de stationnarité***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1iHrAWJH0TdT"
      },
      "source": [
        "f1, (ax1, ax2) = plt.subplots(2, 1, figsize=(15, 5))\n",
        "\n",
        "# Calcul des coefficients\n",
        "x = np.linspace(0,len(serie_log),len(serie_log))\n",
        "coefs = np.polyfit(x,serie_log,1)\n",
        "\n",
        "# Calcul de la tendance non linéaire\n",
        "trend = coefs[0]*np.power(x,1) + coefs[1]\n",
        "\n",
        "# Calcul de la série sans tendance\n",
        "serie_log_detrend = serie_log - trend\n",
        "\n",
        "# Affiche les résultats\n",
        "ax1.plot(trend)\n",
        "ax1.plot(serie_log)\n",
        "ax1.set_title(\"Série originale et tendance non linéaire\")\n",
        "\n",
        "ax2.plot(serie_log_detrend)\n",
        "ax2.set_title(\"Série avec tendance non linéaire supprimée\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yNXs9Fm--Kcl"
      },
      "source": [
        "# ACF & PACF du bruit blanc\n",
        "\n",
        "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
        "\n",
        "f1, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
        "f1.subplots_adjust(hspace=0.3,wspace=0.2)\n",
        "\n",
        "plot_acf(serie_log_detrend, ax=ax1, lags = range(0,50))\n",
        "ax1.set_title(\"Autocorrélation du bruit blanc\")\n",
        "\n",
        "plot_pacf(serie_log_detrend, ax=ax2, lags = range(0, 50))\n",
        "ax2.set_title(\"Autocorrélation partielle du bruit blanc\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_r01cDgq0xaJ"
      },
      "source": [
        "import statsmodels.api as sm\n",
        "\n",
        "serie_test = serie_log_detrend\n",
        "\n",
        "adf, p, usedlag, nobs, cvs, aic = sm.tsa.stattools.adfuller(serie_test)\n",
        "\n",
        "adf_results_string = 'ADF: {}\\np-value: {},\\nN: {}, \\ncritical values: {}'\n",
        "print(adf_results_string.format(adf, p, nobs, cvs))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ychdf1RxMPDD"
      },
      "source": [
        "**5. Différentiation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-qaHkgtQMOqJ"
      },
      "source": [
        "# Différenciation d'odre 1 et saisonnale à l'odre 1 et de période 12\n",
        "\n",
        "from statsmodels.tsa.statespace.tools import diff\n",
        "\n",
        "serie_log_detrend_diff1 = diff(serie_log_detrend,1)       # diff=1 ; diff_saison=1 ; periode = 12\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(serie_log_detrend_diff1)\n",
        "plt.title(\"Signal différencié d'ordre 1 + saisonalité\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kFLlzv0JMks5"
      },
      "source": [
        "import statsmodels.api as sm\n",
        "\n",
        "serie_test = serie_log_detrend_diff1\n",
        "\n",
        "adf, p, usedlag, nobs, cvs, aic = sm.tsa.stattools.adfuller(serie_test)\n",
        "\n",
        "adf_results_string = 'ADF: {}\\np-value: {},\\nN: {}, \\ncritical values: {}'\n",
        "print(adf_results_string.format(adf, p, nobs, cvs))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q0Oqd_7XMqaZ"
      },
      "source": [
        "# ACF & PACF du bruit blanc\n",
        "\n",
        "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
        "\n",
        "f1, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
        "f1.subplots_adjust(hspace=0.3,wspace=0.2)\n",
        "\n",
        "plot_acf(serie_log_detrend_diff1, ax=ax1, lags = range(0,50))\n",
        "ax1.set_title(\"Autocorrélation du bruit blanc\")\n",
        "\n",
        "plot_pacf(serie_log_detrend_diff1, ax=ax2, lags = range(0, 50))\n",
        "ax2.set_title(\"Autocorrélation partielle du bruit blanc\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V5oIY2Yl5Tlt"
      },
      "source": [
        "**5. Enregistrement des données dans le dataframe**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WjFSWhdeM4KM"
      },
      "source": [
        "serie_log_detrend_diff1 = np.insert(serie_log_detrend_diff1,0,0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ele3kFOp5TTW"
      },
      "source": [
        "serie_etude['diff'] = serie_log_detrend_diff1\n",
        "serie_etude['diff'][0] = \"Nan\"\n",
        "serie_etude"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iG5Fyx5O5oe5"
      },
      "source": [
        "# Prépartion des datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P7cGUeWb5oe7"
      },
      "source": [
        "**1. Séparation des données en données pour l'entrainement et la validation**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ob-EAw_j5oe8"
      },
      "source": [
        "On réserve 20% des données pour l'entrainement et le reste pour la validation :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R5AWeK_Z5oe8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3e9b5dae-25b0-4cf0-c979-8e3070e9144e"
      },
      "source": [
        "# Sépare les données en entrainement et tests\n",
        "pourcentage = 0.5\n",
        "temps_separation = int(len(serie_etude['taux']) * pourcentage)\n",
        "date_separation = serie_etude.index[temps_separation]\n",
        "\n",
        "serie_entrainement = serie_etude['taux'].iloc[:temps_separation]\n",
        "serie_test = serie_etude['taux'].iloc[temps_separation:]\n",
        "\n",
        "print(\"Taille de l'entrainement : %d\" %len(serie_entrainement))\n",
        "print(\"Taille de la validation : %d\" %len(serie_test))"
      ],
      "execution_count": 160,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Taille de l'entrainement : 200\n",
            "Taille de la validation : 201\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vZUMMMro5oe9"
      },
      "source": [
        "On normalise les données :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xu_YxoSI5oe9"
      },
      "source": [
        "# Calcul de la moyenne et de l'écart type de la série\n",
        "mean = tf.math.reduce_mean(np.asarray(serie_entrainement))\n",
        "std = tf.math.reduce_std(np.asarray((serie_entrainement)))\n",
        "\n",
        "# Normalisation des données\n",
        "serie_entrainement = (serie_entrainement-mean)/std\n",
        "serie_test = (serie_test-mean)/std"
      ],
      "execution_count": 161,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v_4OZJ-p5oe9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 385
        },
        "outputId": "d0ec96ac-b127-4c00-8fb0-1a6629e2337c"
      },
      "source": [
        "# Affiche la série\n",
        "fig, ax = plt.subplots(constrained_layout=True, figsize=(15,5))\n",
        "ax.plot(serie_entrainement, label=\"Entrainement\")\n",
        "ax.plot(serie_test,label=\"Validation\")\n",
        "\n",
        "ax.set_title(\"Evolution du prix du BTC\")\n",
        "\n",
        "ax.legend()\n",
        "plt.show()"
      ],
      "execution_count": 162,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1080x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V-bANnT35oe-"
      },
      "source": [
        "**2. Création des datasets**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V_EweLDJ5oe-"
      },
      "source": [
        "# Fonction permettant de créer un dataset à partir des données de la série temporelle\n",
        "\n",
        "def prepare_dataset_XY(serie, taille_fenetre, horizon, batch_size):\n",
        "  dataset = tf.data.Dataset.from_tensor_slices(serie)\n",
        "  dataset = dataset.window(taille_fenetre+horizon, shift=1, drop_remainder=True)\n",
        "  dataset = dataset.flat_map(lambda x: x.batch(taille_fenetre + horizon))\n",
        "  dataset = dataset.map(lambda x: (tf.expand_dims(x[0:taille_fenetre],axis=1),x[-1:]))\n",
        "  dataset = dataset.batch(batch_size,drop_remainder=True).prefetch(1)\n",
        "  return dataset"
      ],
      "execution_count": 163,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Jh1RZYo5oe_"
      },
      "source": [
        "# Définition des caractéristiques du dataset que l'on souhaite créer\n",
        "taille_fenetre = 10\n",
        "horizon = 5\n",
        "batch_size = 1\n",
        "\n",
        "# Création du dataset\n",
        "dataset = prepare_dataset_XY(serie_entrainement,taille_fenetre,horizon,batch_size)\n",
        "dataset_val = prepare_dataset_XY(serie_test,taille_fenetre,horizon,batch_size)"
      ],
      "execution_count": 164,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dr2pbMox5oe_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f02b3218-12e8-479d-d0aa-fc66dac79a4a"
      },
      "source": [
        "print(len(list(dataset.as_numpy_iterator())))\n",
        "for element in dataset.take(1):\n",
        "  print(element[0].shape)\n",
        "  print(element[1].shape)"
      ],
      "execution_count": 165,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "186\n",
            "(1, 10, 1)\n",
            "(1, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "itll4lU9q67C",
        "outputId": "f9e69fa2-27db-4fd8-f300-926e0874f407"
      },
      "source": [
        "print(len(list(dataset_val.as_numpy_iterator())))\n",
        "for element in dataset_val.take(1):\n",
        "  print(element[0].shape)\n",
        "  print(element[1].shape)"
      ],
      "execution_count": 166,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "187\n",
            "(1, 10, 1)\n",
            "(1, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BHCcYn6i5oe_"
      },
      "source": [
        "On extrait maintenant les deux tenseurs (X,Y) pour l'entrainement :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z3ZhLIK15ofA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "964c2da4-03ec-4268-9d2c-2d2eee1796a9"
      },
      "source": [
        "# Extrait les X,Y du dataset\n",
        "#56x((1000,4,1),(1000,1)) => (56*1000,4,1) ; (56*1000,1)\n",
        "\n",
        "x,y = tuple(zip(*dataset))\n",
        "\n",
        "# Recombine les données\n",
        "# (56,1000,4,1) => (56*128,4,1)\n",
        "# (56,1000,1) => (56*128,1)\n",
        "x_train = np.asarray(tf.reshape(np.asarray(x,dtype=np.float32),shape=(np.asarray(x).shape[0]*np.asarray(x).shape[1],taille_fenetre,1)))\n",
        "y_train = np.asarray(tf.reshape(np.asarray(y,dtype=np.float32),shape=(np.asarray(y).shape[0]*np.asarray(y).shape[1])))\n",
        "\n",
        "# Affiche les formats\n",
        "print(x_train.shape)\n",
        "print(y_train.shape)"
      ],
      "execution_count": 167,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(186, 10, 1)\n",
            "(186,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "llnKyLvl5ofA"
      },
      "source": [
        "Puis la même chose pour les données de validation :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hadrKVrZ5ofB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4101254e-81d9-4a94-e9e8-bd8e3d35f2a3"
      },
      "source": [
        "# Extrait les X,Y du dataset_val\n",
        "\n",
        "x,y = tuple(zip(*dataset_val))\n",
        "\n",
        "# Recombine les données\n",
        "\n",
        "x_val = np.asarray(tf.reshape(np.asarray(x,dtype=np.float32),shape=(np.asarray(x).shape[0]*np.asarray(x).shape[1],taille_fenetre,1)))\n",
        "y_val = np.asarray(tf.reshape(np.asarray(y,dtype=np.float32),shape=(np.asarray(y).shape[0]*np.asarray(y).shape[1])))\n",
        "\n",
        "# Affiche les formats\n",
        "print(x_val.shape)\n",
        "print(y_val.shape)"
      ],
      "execution_count": 168,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(187, 10, 1)\n",
            "(187,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "083QISTMM3AM"
      },
      "source": [
        "# Optimisation des hyperparamètres"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2VzGM7ODMf8e"
      },
      "source": [
        "**1. Création de la série horaire pour l'optimisation des hyperparamètres**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zUpvJmTQiNk-"
      },
      "source": [
        "**3. Définition du modèle**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AuAyb8pciUle"
      },
      "source": [
        "Dans le modèle, les paramètres dim_LSTM, l1_reg, l2_reg seront optimisés :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WRY7JTnlrTMf"
      },
      "source": [
        "def ModelLSTM(dim_LSTM = 10, l1_reg=0, l2_reg=0):\n",
        "  # Définition de l'entrée du modèle\n",
        "  entrees = tf.keras.layers.Input(shape=(taille_fenetre,1))\n",
        "\n",
        "  # Encodeur\n",
        "  s_encodeur = tf.keras.layers.LSTM(dim_LSTM, kernel_regularizer=tf.keras.regularizers.l1_l2(l1=l1_reg,l2=l2_reg))(entrees)\n",
        "\n",
        "  # Décodeur\n",
        "  s_decodeur = tf.keras.layers.Dense(dim_LSTM,activation=\"tanh\",kernel_regularizer=tf.keras.regularizers.l1_l2(l1=l1_reg,l2=l2_reg))(s_encodeur)\n",
        "  s_decodeur = tf.keras.layers.Concatenate()([s_decodeur,s_encodeur])\n",
        "\n",
        "  # Générateur\n",
        "  sortie = tf.keras.layers.Dense(1,kernel_regularizer=tf.keras.regularizers.l1_l2(l1=l1_reg,l2=l2_reg))(s_decodeur)\n",
        "\n",
        "  # Construction du modèle\n",
        "  model = tf.keras.Model(entrees,sortie)\n",
        "  optimiseur=tf.keras.optimizers.Adam(learning_rate=1e-3)\n",
        "  model.compile(loss=\"mse\", optimizer=optimiseur,metrics=[\"mse\"])\n",
        "  return(model)"
      ],
      "execution_count": 169,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xYTuqrcYii9w"
      },
      "source": [
        "**4. Cross-validation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_g-t1CbmsOkn",
        "outputId": "4a06d263-9c0d-40aa-fe20-072280b9b588"
      },
      "source": [
        "batch_size"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 474
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CVCNBdgcihuv"
      },
      "source": [
        "from keras.callbacks import EarlyStopping\n",
        "from keras.wrappers.scikit_learn import KerasRegressor\n",
        "from sklearn.model_selection import KFold, TimeSeriesSplit, GridSearchCV\n",
        "\n",
        "# Définitions des paramètres\n",
        "dim_LSTM = [5,10,20,40,60]\n",
        "l1_reg = [0,0.001,0.01]\n",
        "l2_reg = [0,0.001,0.01]\n",
        "\n",
        "param_grid = {'dim_LSTM': dim_LSTM, 'l1_reg': l1_reg, 'l2_reg': l2_reg}\n",
        "\n",
        "max_periodes = 5\n",
        "\n",
        "# Surveillance de l'entrainement\n",
        "es = EarlyStopping(monitor='loss', mode='min', verbose=1, patience=50, min_delta=1e-7, restore_best_weights=True)\n",
        "\n",
        "\n",
        "tscv = TimeSeriesSplit(n_splits = 5)\n",
        "model = KerasRegressor(build_fn=ModelLSTM, epochs=max_periodes, verbose=3,batch_size=batch_size)\n",
        "grid = GridSearchCV(estimator=model, param_grid=param_grid, cv=tscv, n_jobs=1, verbose=3)\n",
        "\n",
        "grid_result = grid.fit(x_train, y_train,callbacks=[es])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kWTWBh8DjJpP"
      },
      "source": [
        "# Affiche les résultats\n",
        "print(\"Meilleur résultat : %f avec %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
        "means = grid_result.cv_results_['mean_test_score']\n",
        "stds = grid_result.cv_results_['std_test_score']\n",
        "params_ = grid_result.cv_results_['params']\n",
        "for mean, stdev, param_ in zip(means, stds, params_):\n",
        "  print(\"%f (%f) with %r\" % (mean, stdev, param_))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UHfiXLFZhrPs"
      },
      "source": [
        "# Création du modèle LSTM de type encodeur-décodeur"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nd9AzWFtjnjs"
      },
      "source": [
        "**1. Création du réseau**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x9OCzL7UjAhL"
      },
      "source": [
        "Par défaut, la dimension des vecteurs cachés est de 10 et aucune régularisation n'est utilisée."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SnFw_FPPhxiE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c3520a99-41a6-4c73-f132-cfc02569388e"
      },
      "source": [
        "dim_LSTM = 100\n",
        "l1_reg = 0.0\n",
        "l2_reg = 0.0\n",
        "\n",
        "# Définition de l'entrée du modèle\n",
        "entrees = tf.keras.layers.Input(shape=(taille_fenetre,1))\n",
        "\n",
        "# Encodeur\n",
        "s_encodeur = tf.keras.layers.GRU(dim_LSTM, kernel_regularizer=tf.keras.regularizers.l1_l2(l1=l1_reg,l2=l2_reg),)(entrees)\n",
        "\n",
        "# Décodeur\n",
        "s_decodeur = tf.keras.layers.Dense(dim_LSTM,activation=\"tanh\",kernel_regularizer=tf.keras.regularizers.l1_l2(l1=l1_reg,l2=l2_reg))(s_encodeur)\n",
        "s_decodeur = tf.keras.layers.Concatenate()([s_decodeur,s_encodeur])\n",
        "\n",
        "# Générateur\n",
        "sortie = tf.keras.layers.Dense(1,kernel_regularizer=tf.keras.regularizers.l1_l2(l1=l1_reg,l2=l2_reg))(s_decodeur)\n",
        "\n",
        "# Construction du modèle\n",
        "model = tf.keras.Model(entrees,sortie)\n",
        "model.summary()"
      ],
      "execution_count": 170,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_4\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_5 (InputLayer)            [(None, 10, 1)]      0                                            \n",
            "__________________________________________________________________________________________________\n",
            "gru_4 (GRU)                     (None, 100)          30900       input_5[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_8 (Dense)                 (None, 100)          10100       gru_4[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_4 (Concatenate)     (None, 200)          0           dense_8[0][0]                    \n",
            "                                                                 gru_4[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "dense_9 (Dense)                 (None, 1)            201         concatenate_4[0][0]              \n",
            "==================================================================================================\n",
            "Total params: 41,201\n",
            "Trainable params: 41,201\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_azfJaeUo2nU"
      },
      "source": [
        "**2. Optimisation de l'apprentissage**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pf3lwaQBnjxL"
      },
      "source": [
        "Pour accélérer le traitement des données, nous n'allons pas utiliser l'intégralité des données pendant la mise à jour du gradient, comme cela a été fait jusqu'à présent (en utilisant le dataset).  \n",
        "Cette fois-ci, nous allons forcer les mises à jour du gradient à se produire de manière moins fréquente en attribuant la valeur du batch_size à prendre en compte lors de la regression du modèle.  \n",
        "Pour cela, on utilise l'argument \"batch_size\" dans la méthode fit. En précisant un batch_size=1000, cela signifie que :\n",
        " - Sur notre total de 56000 échantillons, 56 seront utilisés pour les calculs du gradient\n",
        " - Il y aura également 56 itérations à chaque période.\n",
        "  \n",
        "    \n",
        "    \n",
        "Si nous avions pris le dataset comme entrée, nous aurions eu :\n",
        "- Un total de 56000 échantillons également\n",
        "- Chaque période aurait également pris 56 itérations pour se compléter\n",
        "- Mais 1000 échantillons auraient été utilisés pour le calcul du gradient, au lieu de 56 avec la méthode utilisée."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K6Z35rNWj5SA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "149c89b9-9a24-4aa1-f3e1-f809874196c6"
      },
      "source": [
        "# Définition de la fonction de régulation du taux d'apprentissage\n",
        "def RegulationTauxApprentissage(periode, taux):\n",
        "  return 1e-8*10**(periode/10)\n",
        "\n",
        "# Définition de l'optimiseur à utiliser\n",
        "optimiseur=tf.keras.optimizers.SGD()\n",
        "\n",
        "# Compile le modèle\n",
        "model.compile(loss=\"mse\", optimizer=optimiseur, metrics=\"mse\")\n",
        "\n",
        "# Utilisation de la méthode ModelCheckPoint\n",
        "CheckPoint = tf.keras.callbacks.ModelCheckpoint(\"poids.hdf5\", monitor='loss', verbose=1, save_best_only=True, save_weights_only = True, mode='auto', save_freq='epoch')\n",
        "\n",
        "# Entraine le modèle en utilisant notre fonction personnelle de régulation du taux d'apprentissage\n",
        "historique = model.fit(dataset,epochs=100,verbose=1, callbacks=[tf.keras.callbacks.LearningRateScheduler(RegulationTauxApprentissage), CheckPoint],batch_size=batch_size)"
      ],
      "execution_count": 171,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "186/186 [==============================] - 2s 3ms/step - loss: 0.8948 - mse: 0.8948\n",
            "\n",
            "Epoch 00001: loss improved from inf to 0.70735, saving model to poids.hdf5\n",
            "Epoch 2/100\n",
            "186/186 [==============================] - 1s 3ms/step - loss: 0.8948 - mse: 0.8948\n",
            "\n",
            "Epoch 00002: loss improved from 0.70735 to 0.70734, saving model to poids.hdf5\n",
            "Epoch 3/100\n",
            "186/186 [==============================] - 1s 3ms/step - loss: 0.8948 - mse: 0.8948\n",
            "\n",
            "Epoch 00003: loss improved from 0.70734 to 0.70733, saving model to poids.hdf5\n",
            "Epoch 4/100\n",
            "186/186 [==============================] - 1s 3ms/step - loss: 0.8948 - mse: 0.8948\n",
            "\n",
            "Epoch 00004: loss improved from 0.70733 to 0.70731, saving model to poids.hdf5\n",
            "Epoch 5/100\n",
            "186/186 [==============================] - 1s 3ms/step - loss: 0.8947 - mse: 0.8947\n",
            "\n",
            "Epoch 00005: loss improved from 0.70731 to 0.70728, saving model to poids.hdf5\n",
            "Epoch 6/100\n",
            "186/186 [==============================] - 1s 3ms/step - loss: 0.8947 - mse: 0.8947\n",
            "\n",
            "Epoch 00006: loss improved from 0.70728 to 0.70725, saving model to poids.hdf5\n",
            "Epoch 7/100\n",
            "186/186 [==============================] - 1s 3ms/step - loss: 0.8946 - mse: 0.8946\n",
            "\n",
            "Epoch 00007: loss improved from 0.70725 to 0.70721, saving model to poids.hdf5\n",
            "Epoch 8/100\n",
            "186/186 [==============================] - 1s 3ms/step - loss: 0.8946 - mse: 0.8946\n",
            "\n",
            "Epoch 00008: loss improved from 0.70721 to 0.70716, saving model to poids.hdf5\n",
            "Epoch 9/100\n",
            "186/186 [==============================] - 1s 3ms/step - loss: 0.8945 - mse: 0.8945\n",
            "\n",
            "Epoch 00009: loss improved from 0.70716 to 0.70709, saving model to poids.hdf5\n",
            "Epoch 10/100\n",
            "186/186 [==============================] - 1s 3ms/step - loss: 0.8944 - mse: 0.8944\n",
            "\n",
            "Epoch 00010: loss improved from 0.70709 to 0.70701, saving model to poids.hdf5\n",
            "Epoch 11/100\n",
            "186/186 [==============================] - 1s 3ms/step - loss: 0.8943 - mse: 0.8943\n",
            "\n",
            "Epoch 00011: loss improved from 0.70701 to 0.70690, saving model to poids.hdf5\n",
            "Epoch 12/100\n",
            "186/186 [==============================] - 1s 3ms/step - loss: 0.8941 - mse: 0.8941\n",
            "\n",
            "Epoch 00012: loss improved from 0.70690 to 0.70676, saving model to poids.hdf5\n",
            "Epoch 13/100\n",
            "186/186 [==============================] - 1s 3ms/step - loss: 0.8939 - mse: 0.8939\n",
            "\n",
            "Epoch 00013: loss improved from 0.70676 to 0.70658, saving model to poids.hdf5\n",
            "Epoch 14/100\n",
            "186/186 [==============================] - 1s 3ms/step - loss: 0.8936 - mse: 0.8936\n",
            "\n",
            "Epoch 00014: loss improved from 0.70658 to 0.70635, saving model to poids.hdf5\n",
            "Epoch 15/100\n",
            "186/186 [==============================] - 1s 3ms/step - loss: 0.8932 - mse: 0.8932\n",
            "\n",
            "Epoch 00015: loss improved from 0.70635 to 0.70607, saving model to poids.hdf5\n",
            "Epoch 16/100\n",
            "186/186 [==============================] - 1s 3ms/step - loss: 0.8928 - mse: 0.8928\n",
            "\n",
            "Epoch 00016: loss improved from 0.70607 to 0.70571, saving model to poids.hdf5\n",
            "Epoch 17/100\n",
            "186/186 [==============================] - 1s 3ms/step - loss: 0.8922 - mse: 0.8922\n",
            "\n",
            "Epoch 00017: loss improved from 0.70571 to 0.70526, saving model to poids.hdf5\n",
            "Epoch 18/100\n",
            "186/186 [==============================] - 1s 3ms/step - loss: 0.8915 - mse: 0.8915\n",
            "\n",
            "Epoch 00018: loss improved from 0.70526 to 0.70468, saving model to poids.hdf5\n",
            "Epoch 19/100\n",
            "186/186 [==============================] - 1s 3ms/step - loss: 0.8906 - mse: 0.8906\n",
            "\n",
            "Epoch 00019: loss improved from 0.70468 to 0.70396, saving model to poids.hdf5\n",
            "Epoch 20/100\n",
            "186/186 [==============================] - 1s 3ms/step - loss: 0.8895 - mse: 0.8895\n",
            "\n",
            "Epoch 00020: loss improved from 0.70396 to 0.70305, saving model to poids.hdf5\n",
            "Epoch 21/100\n",
            "186/186 [==============================] - 1s 3ms/step - loss: 0.8880 - mse: 0.8880\n",
            "\n",
            "Epoch 00021: loss improved from 0.70305 to 0.70190, saving model to poids.hdf5\n",
            "Epoch 22/100\n",
            "186/186 [==============================] - 1s 3ms/step - loss: 0.8862 - mse: 0.8862\n",
            "\n",
            "Epoch 00022: loss improved from 0.70190 to 0.70046, saving model to poids.hdf5\n",
            "Epoch 23/100\n",
            "186/186 [==============================] - 1s 3ms/step - loss: 0.8840 - mse: 0.8840\n",
            "\n",
            "Epoch 00023: loss improved from 0.70046 to 0.69864, saving model to poids.hdf5\n",
            "Epoch 24/100\n",
            "186/186 [==============================] - 1s 3ms/step - loss: 0.8812 - mse: 0.8812\n",
            "\n",
            "Epoch 00024: loss improved from 0.69864 to 0.69637, saving model to poids.hdf5\n",
            "Epoch 25/100\n",
            "186/186 [==============================] - 1s 3ms/step - loss: 0.8776 - mse: 0.8776\n",
            "\n",
            "Epoch 00025: loss improved from 0.69637 to 0.69352, saving model to poids.hdf5\n",
            "Epoch 26/100\n",
            "186/186 [==============================] - 1s 3ms/step - loss: 0.8732 - mse: 0.8732\n",
            "\n",
            "Epoch 00026: loss improved from 0.69352 to 0.68996, saving model to poids.hdf5\n",
            "Epoch 27/100\n",
            "186/186 [==============================] - 1s 3ms/step - loss: 0.8676 - mse: 0.8676\n",
            "\n",
            "Epoch 00027: loss improved from 0.68996 to 0.68551, saving model to poids.hdf5\n",
            "Epoch 28/100\n",
            "186/186 [==============================] - 1s 3ms/step - loss: 0.8607 - mse: 0.8607\n",
            "\n",
            "Epoch 00028: loss improved from 0.68551 to 0.67997, saving model to poids.hdf5\n",
            "Epoch 29/100\n",
            "186/186 [==============================] - 1s 3ms/step - loss: 0.8522 - mse: 0.8522\n",
            "\n",
            "Epoch 00029: loss improved from 0.67997 to 0.67309, saving model to poids.hdf5\n",
            "Epoch 30/100\n",
            "186/186 [==============================] - 1s 3ms/step - loss: 0.8415 - mse: 0.8415\n",
            "\n",
            "Epoch 00030: loss improved from 0.67309 to 0.66458, saving model to poids.hdf5\n",
            "Epoch 31/100\n",
            "186/186 [==============================] - 1s 3ms/step - loss: 0.8284 - mse: 0.8284\n",
            "\n",
            "Epoch 00031: loss improved from 0.66458 to 0.65410, saving model to poids.hdf5\n",
            "Epoch 32/100\n",
            "186/186 [==============================] - 1s 3ms/step - loss: 0.8124 - mse: 0.8124\n",
            "\n",
            "Epoch 00032: loss improved from 0.65410 to 0.64127, saving model to poids.hdf5\n",
            "Epoch 33/100\n",
            "186/186 [==============================] - 1s 3ms/step - loss: 0.7928 - mse: 0.7928\n",
            "\n",
            "Epoch 00033: loss improved from 0.64127 to 0.62568, saving model to poids.hdf5\n",
            "Epoch 34/100\n",
            "186/186 [==============================] - 1s 3ms/step - loss: 0.7692 - mse: 0.7692\n",
            "\n",
            "Epoch 00034: loss improved from 0.62568 to 0.60690, saving model to poids.hdf5\n",
            "Epoch 35/100\n",
            "186/186 [==============================] - 1s 3ms/step - loss: 0.7410 - mse: 0.7410\n",
            "\n",
            "Epoch 00035: loss improved from 0.60690 to 0.58455, saving model to poids.hdf5\n",
            "Epoch 36/100\n",
            "186/186 [==============================] - 1s 3ms/step - loss: 0.7079 - mse: 0.7079\n",
            "\n",
            "Epoch 00036: loss improved from 0.58455 to 0.55833, saving model to poids.hdf5\n",
            "Epoch 37/100\n",
            "186/186 [==============================] - 1s 3ms/step - loss: 0.6695 - mse: 0.6695\n",
            "\n",
            "Epoch 00037: loss improved from 0.55833 to 0.52815, saving model to poids.hdf5\n",
            "Epoch 38/100\n",
            "186/186 [==============================] - 1s 3ms/step - loss: 0.6260 - mse: 0.6260\n",
            "\n",
            "Epoch 00038: loss improved from 0.52815 to 0.49423, saving model to poids.hdf5\n",
            "Epoch 39/100\n",
            "186/186 [==============================] - 1s 3ms/step - loss: 0.5783 - mse: 0.5783\n",
            "\n",
            "Epoch 00039: loss improved from 0.49423 to 0.45727, saving model to poids.hdf5\n",
            "Epoch 40/100\n",
            "186/186 [==============================] - 1s 3ms/step - loss: 0.5277 - mse: 0.5277\n",
            "\n",
            "Epoch 00040: loss improved from 0.45727 to 0.41856, saving model to poids.hdf5\n",
            "Epoch 41/100\n",
            "186/186 [==============================] - 1s 3ms/step - loss: 0.4765 - mse: 0.4765\n",
            "\n",
            "Epoch 00041: loss improved from 0.41856 to 0.38006, saving model to poids.hdf5\n",
            "Epoch 42/100\n",
            "186/186 [==============================] - 1s 3ms/step - loss: 0.4278 - mse: 0.4278\n",
            "\n",
            "Epoch 00042: loss improved from 0.38006 to 0.34424, saving model to poids.hdf5\n",
            "Epoch 43/100\n",
            "186/186 [==============================] - 1s 3ms/step - loss: 0.3848 - mse: 0.3848\n",
            "\n",
            "Epoch 00043: loss improved from 0.34424 to 0.31359, saving model to poids.hdf5\n",
            "Epoch 44/100\n",
            "186/186 [==============================] - 1s 3ms/step - loss: 0.3503 - mse: 0.3503\n",
            "\n",
            "Epoch 00044: loss improved from 0.31359 to 0.28993, saving model to poids.hdf5\n",
            "Epoch 45/100\n",
            "186/186 [==============================] - 1s 3ms/step - loss: 0.3251 - mse: 0.3251\n",
            "\n",
            "Epoch 00045: loss improved from 0.28993 to 0.27353, saving model to poids.hdf5\n",
            "Epoch 46/100\n",
            "186/186 [==============================] - 1s 3ms/step - loss: 0.3083 - mse: 0.3083\n",
            "\n",
            "Epoch 00046: loss improved from 0.27353 to 0.26303, saving model to poids.hdf5\n",
            "Epoch 47/100\n",
            "186/186 [==============================] - 1s 3ms/step - loss: 0.2976 - mse: 0.2976\n",
            "\n",
            "Epoch 00047: loss improved from 0.26303 to 0.25614, saving model to poids.hdf5\n",
            "Epoch 48/100\n",
            "186/186 [==============================] - 1s 3ms/step - loss: 0.2905 - mse: 0.2905\n",
            "\n",
            "Epoch 00048: loss improved from 0.25614 to 0.25090, saving model to poids.hdf5\n",
            "Epoch 49/100\n",
            "186/186 [==============================] - 1s 3ms/step - loss: 0.2854 - mse: 0.2854\n",
            "\n",
            "Epoch 00049: loss improved from 0.25090 to 0.24617, saving model to poids.hdf5\n",
            "Epoch 50/100\n",
            "186/186 [==============================] - 1s 3ms/step - loss: 0.2812 - mse: 0.2812\n",
            "\n",
            "Epoch 00050: loss improved from 0.24617 to 0.24136, saving model to poids.hdf5\n",
            "Epoch 51/100\n",
            "186/186 [==============================] - 1s 3ms/step - loss: 0.2770 - mse: 0.2770\n",
            "\n",
            "Epoch 00051: loss improved from 0.24136 to 0.23596, saving model to poids.hdf5\n",
            "Epoch 52/100\n",
            "186/186 [==============================] - 1s 3ms/step - loss: 0.2717 - mse: 0.2717\n",
            "\n",
            "Epoch 00052: loss improved from 0.23596 to 0.22942, saving model to poids.hdf5\n",
            "Epoch 53/100\n",
            "186/186 [==============================] - 1s 3ms/step - loss: 0.2647 - mse: 0.2647\n",
            "\n",
            "Epoch 00053: loss improved from 0.22942 to 0.22129, saving model to poids.hdf5\n",
            "Epoch 54/100\n",
            "186/186 [==============================] - 1s 3ms/step - loss: 0.2554 - mse: 0.2554\n",
            "\n",
            "Epoch 00054: loss improved from 0.22129 to 0.21123, saving model to poids.hdf5\n",
            "Epoch 55/100\n",
            "186/186 [==============================] - 1s 3ms/step - loss: 0.2430 - mse: 0.2430\n",
            "\n",
            "Epoch 00055: loss improved from 0.21123 to 0.19902, saving model to poids.hdf5\n",
            "Epoch 56/100\n",
            "186/186 [==============================] - 1s 3ms/step - loss: 0.2273 - mse: 0.2273\n",
            "\n",
            "Epoch 00056: loss improved from 0.19902 to 0.18453, saving model to poids.hdf5\n",
            "Epoch 57/100\n",
            "186/186 [==============================] - 1s 3ms/step - loss: 0.2078 - mse: 0.2078\n",
            "\n",
            "Epoch 00057: loss improved from 0.18453 to 0.16779, saving model to poids.hdf5\n",
            "Epoch 58/100\n",
            "186/186 [==============================] - 1s 3ms/step - loss: 0.1849 - mse: 0.1849\n",
            "\n",
            "Epoch 00058: loss improved from 0.16779 to 0.14896, saving model to poids.hdf5\n",
            "Epoch 59/100\n",
            "186/186 [==============================] - 1s 3ms/step - loss: 0.1594 - mse: 0.1594\n",
            "\n",
            "Epoch 00059: loss improved from 0.14896 to 0.12829, saving model to poids.hdf5\n",
            "Epoch 60/100\n",
            "186/186 [==============================] - 1s 3ms/step - loss: 0.1324 - mse: 0.1324\n",
            "\n",
            "Epoch 00060: loss improved from 0.12829 to 0.10600, saving model to poids.hdf5\n",
            "Epoch 61/100\n",
            "186/186 [==============================] - 1s 3ms/step - loss: 0.1047 - mse: 0.1047\n",
            "\n",
            "Epoch 00061: loss improved from 0.10600 to 0.08230, saving model to poids.hdf5\n",
            "Epoch 62/100\n",
            "186/186 [==============================] - 1s 3ms/step - loss: 0.0837 - mse: 0.0837\n",
            "\n",
            "Epoch 00062: loss improved from 0.08230 to 0.06443, saving model to poids.hdf5\n",
            "Epoch 63/100\n",
            "186/186 [==============================] - 1s 3ms/step - loss: 0.3268 - mse: 0.3268\n",
            "\n",
            "Epoch 00063: loss did not improve from 0.06443\n",
            "Epoch 64/100\n",
            "186/186 [==============================] - 1s 3ms/step - loss: 0.0843 - mse: 0.0843\n",
            "\n",
            "Epoch 00064: loss did not improve from 0.06443\n",
            "Epoch 65/100\n",
            "186/186 [==============================] - 1s 3ms/step - loss: 0.1868 - mse: 0.1868\n",
            "\n",
            "Epoch 00065: loss did not improve from 0.06443\n",
            "Epoch 66/100\n",
            "186/186 [==============================] - 1s 3ms/step - loss: 0.1302 - mse: 0.1302\n",
            "\n",
            "Epoch 00066: loss did not improve from 0.06443\n",
            "Epoch 67/100\n",
            "186/186 [==============================] - 1s 3ms/step - loss: 0.0864 - mse: 0.0864\n",
            "\n",
            "Epoch 00067: loss did not improve from 0.06443\n",
            "Epoch 68/100\n",
            "186/186 [==============================] - 1s 3ms/step - loss: 0.0489 - mse: 0.0489\n",
            "\n",
            "Epoch 00068: loss improved from 0.06443 to 0.04101, saving model to poids.hdf5\n",
            "Epoch 69/100\n",
            "186/186 [==============================] - 1s 3ms/step - loss: 0.0796 - mse: 0.0796\n",
            "\n",
            "Epoch 00069: loss improved from 0.04101 to 0.03597, saving model to poids.hdf5\n",
            "Epoch 70/100\n",
            "186/186 [==============================] - 1s 3ms/step - loss: nan - mse: nan\n",
            "\n",
            "Epoch 00070: loss did not improve from 0.03597\n",
            "Epoch 71/100\n",
            "186/186 [==============================] - 1s 3ms/step - loss: nan - mse: nan\n",
            "\n",
            "Epoch 00071: loss did not improve from 0.03597\n",
            "Epoch 72/100\n",
            "186/186 [==============================] - 1s 3ms/step - loss: nan - mse: nan\n",
            "\n",
            "Epoch 00072: loss did not improve from 0.03597\n",
            "Epoch 73/100\n",
            "186/186 [==============================] - 1s 3ms/step - loss: nan - mse: nan\n",
            "\n",
            "Epoch 00073: loss did not improve from 0.03597\n",
            "Epoch 74/100\n",
            "186/186 [==============================] - 1s 3ms/step - loss: nan - mse: nan\n",
            "\n",
            "Epoch 00074: loss did not improve from 0.03597\n",
            "Epoch 75/100\n",
            "186/186 [==============================] - 1s 3ms/step - loss: nan - mse: nan\n",
            "\n",
            "Epoch 00075: loss did not improve from 0.03597\n",
            "Epoch 76/100\n",
            "186/186 [==============================] - 1s 3ms/step - loss: nan - mse: nan\n",
            "\n",
            "Epoch 00076: loss did not improve from 0.03597\n",
            "Epoch 77/100\n",
            "186/186 [==============================] - 1s 3ms/step - loss: nan - mse: nan\n",
            "\n",
            "Epoch 00077: loss did not improve from 0.03597\n",
            "Epoch 78/100\n",
            "186/186 [==============================] - 1s 3ms/step - loss: nan - mse: nan\n",
            "\n",
            "Epoch 00078: loss did not improve from 0.03597\n",
            "Epoch 79/100\n",
            "186/186 [==============================] - 1s 3ms/step - loss: nan - mse: nan\n",
            "\n",
            "Epoch 00079: loss did not improve from 0.03597\n",
            "Epoch 80/100\n",
            "186/186 [==============================] - 1s 3ms/step - loss: nan - mse: nan\n",
            "\n",
            "Epoch 00080: loss did not improve from 0.03597\n",
            "Epoch 81/100\n",
            "186/186 [==============================] - 1s 3ms/step - loss: nan - mse: nan\n",
            "\n",
            "Epoch 00081: loss did not improve from 0.03597\n",
            "Epoch 82/100\n",
            "186/186 [==============================] - 1s 3ms/step - loss: nan - mse: nan\n",
            "\n",
            "Epoch 00082: loss did not improve from 0.03597\n",
            "Epoch 83/100\n",
            "186/186 [==============================] - 1s 3ms/step - loss: nan - mse: nan\n",
            "\n",
            "Epoch 00083: loss did not improve from 0.03597\n",
            "Epoch 84/100\n",
            "186/186 [==============================] - 1s 3ms/step - loss: nan - mse: nan\n",
            "\n",
            "Epoch 00084: loss did not improve from 0.03597\n",
            "Epoch 85/100\n",
            "186/186 [==============================] - 1s 3ms/step - loss: nan - mse: nan\n",
            "\n",
            "Epoch 00085: loss did not improve from 0.03597\n",
            "Epoch 86/100\n",
            "186/186 [==============================] - 1s 3ms/step - loss: nan - mse: nan\n",
            "\n",
            "Epoch 00086: loss did not improve from 0.03597\n",
            "Epoch 87/100\n",
            "186/186 [==============================] - 1s 3ms/step - loss: nan - mse: nan\n",
            "\n",
            "Epoch 00087: loss did not improve from 0.03597\n",
            "Epoch 88/100\n",
            "186/186 [==============================] - 1s 3ms/step - loss: nan - mse: nan\n",
            "\n",
            "Epoch 00088: loss did not improve from 0.03597\n",
            "Epoch 89/100\n",
            "186/186 [==============================] - 1s 3ms/step - loss: nan - mse: nan\n",
            "\n",
            "Epoch 00089: loss did not improve from 0.03597\n",
            "Epoch 90/100\n",
            "186/186 [==============================] - 1s 3ms/step - loss: nan - mse: nan\n",
            "\n",
            "Epoch 00090: loss did not improve from 0.03597\n",
            "Epoch 91/100\n",
            "186/186 [==============================] - 1s 3ms/step - loss: nan - mse: nan\n",
            "\n",
            "Epoch 00091: loss did not improve from 0.03597\n",
            "Epoch 92/100\n",
            "186/186 [==============================] - 1s 3ms/step - loss: nan - mse: nan\n",
            "\n",
            "Epoch 00092: loss did not improve from 0.03597\n",
            "Epoch 93/100\n",
            "186/186 [==============================] - 1s 3ms/step - loss: nan - mse: nan\n",
            "\n",
            "Epoch 00093: loss did not improve from 0.03597\n",
            "Epoch 94/100\n",
            "186/186 [==============================] - 1s 3ms/step - loss: nan - mse: nan\n",
            "\n",
            "Epoch 00094: loss did not improve from 0.03597\n",
            "Epoch 95/100\n",
            "186/186 [==============================] - 1s 3ms/step - loss: nan - mse: nan\n",
            "\n",
            "Epoch 00095: loss did not improve from 0.03597\n",
            "Epoch 96/100\n",
            "186/186 [==============================] - 1s 3ms/step - loss: nan - mse: nan\n",
            "\n",
            "Epoch 00096: loss did not improve from 0.03597\n",
            "Epoch 97/100\n",
            "186/186 [==============================] - 1s 3ms/step - loss: nan - mse: nan\n",
            "\n",
            "Epoch 00097: loss did not improve from 0.03597\n",
            "Epoch 98/100\n",
            "186/186 [==============================] - 1s 3ms/step - loss: nan - mse: nan\n",
            "\n",
            "Epoch 00098: loss did not improve from 0.03597\n",
            "Epoch 99/100\n",
            "186/186 [==============================] - 1s 3ms/step - loss: nan - mse: nan\n",
            "\n",
            "Epoch 00099: loss did not improve from 0.03597\n",
            "Epoch 100/100\n",
            "186/186 [==============================] - 1s 3ms/step - loss: nan - mse: nan\n",
            "\n",
            "Epoch 00100: loss did not improve from 0.03597\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u2aP9J3TkNGG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 411
        },
        "outputId": "b333f6fc-5d19-4297-9543-c6afe647660b"
      },
      "source": [
        "# Construit un vecteur avec les valeurs du taux d'apprentissage à chaque période \n",
        "taux = 1e-8*(10**(np.arange(100)/10))\n",
        "\n",
        "# Affiche l'erreur en fonction du taux d'apprentissage\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.semilogx(taux,historique.history[\"loss\"])\n",
        "plt.axis([ taux[0], taux[99], 0, 1])\n",
        "plt.title(\"Evolution de l'erreur en fonction du taux d'apprentissage\")"
      ],
      "execution_count": 172,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, \"Evolution de l'erreur en fonction du taux d'apprentissage\")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 172
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cZxCgpuYkQ2Q"
      },
      "source": [
        "# Chargement des poids sauvegardés\n",
        "model.load_weights(\"poids.hdf5\")"
      ],
      "execution_count": 173,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zmdbo23qkTKE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "267302b9-e221-42ab-956c-c16cc444d161"
      },
      "source": [
        "max_periodes = 500\n",
        "\n",
        "# Classe permettant d'arrêter l'entrainement si la variation\n",
        "# devient plus petite qu'une valeur à choisir sur un nombre\n",
        "# de périodes à choisir\n",
        "class StopTrain(keras.callbacks.Callback):\n",
        "    def __init__(self, delta=0.01,periodes=100, term=\"loss\", logs={}):\n",
        "      self.n_periodes = 0\n",
        "      self.periodes = periodes\n",
        "      self.loss_1 = 100\n",
        "      self.delta = delta\n",
        "      self.term = term\n",
        "    def on_epoch_end(self, epoch, logs={}):\n",
        "      diff_loss = abs(self.loss_1 - logs[self.term])\n",
        "      self.loss_1 = logs[self.term]\n",
        "      if (diff_loss < self.delta):\n",
        "        self.n_periodes = self.n_periodes + 1\n",
        "      else:\n",
        "        self.n_periodes = 0\n",
        "      if (self.n_periodes == self.periodes):\n",
        "        print(\"Arrêt de l'entrainement...\")\n",
        "        self.model.stop_training = True\n",
        "\n",
        "# Définition des paramètres liés à l'évolution du taux d'apprentissage\n",
        "lr_schedule = tf.keras.optimizers.schedules.InverseTimeDecay(\n",
        "    initial_learning_rate=0.01,\n",
        "    decay_steps=10,\n",
        "    decay_rate=0.01)\n",
        "\n",
        "# Définition de l'optimiseur à utiliser\n",
        "optimiseur=tf.keras.optimizers.SGD(learning_rate=lr_schedule,momentum=0.9)\n",
        "\n",
        "# Utilisation de la méthode ModelCheckPoint\n",
        "CheckPoint = tf.keras.callbacks.ModelCheckpoint(\"poids_train.hdf5\", monitor='loss', verbose=1, save_best_only=True, save_weights_only = True, mode='auto', save_freq='epoch')\n",
        "\n",
        "# Compile le modèle\n",
        "model.compile(loss=\"mse\", optimizer=optimiseur, metrics=[\"mse\"])\n",
        "\n",
        "# Entraine le modèle, avec une réduction des calculs du gradient\n",
        "#historique = model.fit(x=x_train,y=y_train,validation_data=(x_val,y_val), epochs=max_periodes,verbose=1, callbacks=[CheckPoint,StopTrain(delta=1e-7,periodes = 10, term=\"My_MSE\")],batch_size=batch_size)\n",
        "\n",
        "# Entraine le modèle sans réduction de calculs\n",
        "historique = model.fit(dataset,validation_data=dataset_val, epochs=max_periodes,verbose=1, callbacks=[CheckPoint,StopTrain(delta=1e-5,periodes = 10, term=\"loss\")])\n",
        "#historique = model.fit(dataset, epochs=max_periodes)\n"
      ],
      "execution_count": 180,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/500\n",
            "186/186 [==============================] - 3s 9ms/step - loss: 0.0339 - mse: 0.0339 - val_loss: 0.0641 - val_mse: 0.0641\n",
            "\n",
            "Epoch 00001: loss improved from inf to 0.05686, saving model to poids_train.hdf5\n",
            "Epoch 2/500\n",
            "186/186 [==============================] - 1s 5ms/step - loss: 0.0658 - mse: 0.0658 - val_loss: 0.5189 - val_mse: 0.5189\n",
            "\n",
            "Epoch 00002: loss did not improve from 0.05686\n",
            "Epoch 3/500\n",
            "186/186 [==============================] - 1s 5ms/step - loss: 0.2691 - mse: 0.2691 - val_loss: 2.5925 - val_mse: 2.5925\n",
            "\n",
            "Epoch 00003: loss did not improve from 0.05686\n",
            "Epoch 4/500\n",
            "186/186 [==============================] - 1s 5ms/step - loss: 0.2705 - mse: 0.2705 - val_loss: 0.9596 - val_mse: 0.9596\n",
            "\n",
            "Epoch 00004: loss did not improve from 0.05686\n",
            "Epoch 5/500\n",
            "186/186 [==============================] - 1s 5ms/step - loss: 0.2240 - mse: 0.2240 - val_loss: 0.3026 - val_mse: 0.3026\n",
            "\n",
            "Epoch 00005: loss did not improve from 0.05686\n",
            "Epoch 6/500\n",
            "186/186 [==============================] - 1s 5ms/step - loss: 0.3675 - mse: 0.3675 - val_loss: 0.2941 - val_mse: 0.2941\n",
            "\n",
            "Epoch 00006: loss did not improve from 0.05686\n",
            "Epoch 7/500\n",
            "186/186 [==============================] - 1s 5ms/step - loss: 0.2614 - mse: 0.2614 - val_loss: 0.2675 - val_mse: 0.2675\n",
            "\n",
            "Epoch 00007: loss did not improve from 0.05686\n",
            "Epoch 8/500\n",
            "186/186 [==============================] - 1s 5ms/step - loss: 0.2304 - mse: 0.2304 - val_loss: 1.2528 - val_mse: 1.2528\n",
            "\n",
            "Epoch 00008: loss did not improve from 0.05686\n",
            "Epoch 9/500\n",
            "186/186 [==============================] - 1s 5ms/step - loss: 0.2982 - mse: 0.2982 - val_loss: 3.7286 - val_mse: 3.7286\n",
            "\n",
            "Epoch 00009: loss did not improve from 0.05686\n",
            "Epoch 10/500\n",
            "186/186 [==============================] - 1s 5ms/step - loss: 0.6169 - mse: 0.6169 - val_loss: 1.8341 - val_mse: 1.8341\n",
            "\n",
            "Epoch 00010: loss did not improve from 0.05686\n",
            "Epoch 11/500\n",
            "186/186 [==============================] - 1s 5ms/step - loss: 0.4688 - mse: 0.4688 - val_loss: 1.7289 - val_mse: 1.7289\n",
            "\n",
            "Epoch 00011: loss did not improve from 0.05686\n",
            "Epoch 12/500\n",
            "186/186 [==============================] - 1s 5ms/step - loss: 0.4103 - mse: 0.4103 - val_loss: 1.7252 - val_mse: 1.7252\n",
            "\n",
            "Epoch 00012: loss did not improve from 0.05686\n",
            "Epoch 13/500\n",
            "186/186 [==============================] - 1s 5ms/step - loss: 0.3876 - mse: 0.3876 - val_loss: 0.7593 - val_mse: 0.7593\n",
            "\n",
            "Epoch 00013: loss did not improve from 0.05686\n",
            "Epoch 14/500\n",
            "186/186 [==============================] - 1s 5ms/step - loss: 0.3390 - mse: 0.3390 - val_loss: 0.8809 - val_mse: 0.8809\n",
            "\n",
            "Epoch 00014: loss did not improve from 0.05686\n",
            "Epoch 15/500\n",
            "186/186 [==============================] - 1s 5ms/step - loss: 0.4623 - mse: 0.4623 - val_loss: 2.6011 - val_mse: 2.6011\n",
            "\n",
            "Epoch 00015: loss did not improve from 0.05686\n",
            "Epoch 16/500\n",
            "186/186 [==============================] - 1s 5ms/step - loss: 0.5929 - mse: 0.5929 - val_loss: 2.3211 - val_mse: 2.3211\n",
            "\n",
            "Epoch 00016: loss did not improve from 0.05686\n",
            "Epoch 17/500\n",
            "186/186 [==============================] - 1s 5ms/step - loss: 0.6137 - mse: 0.6137 - val_loss: 2.5795 - val_mse: 2.5795\n",
            "\n",
            "Epoch 00017: loss did not improve from 0.05686\n",
            "Epoch 18/500\n",
            "186/186 [==============================] - 1s 5ms/step - loss: 0.3061 - mse: 0.3061 - val_loss: 0.4075 - val_mse: 0.4075\n",
            "\n",
            "Epoch 00018: loss did not improve from 0.05686\n",
            "Epoch 19/500\n",
            "186/186 [==============================] - 1s 5ms/step - loss: 0.5004 - mse: 0.5004 - val_loss: 1.9866 - val_mse: 1.9866\n",
            "\n",
            "Epoch 00019: loss did not improve from 0.05686\n",
            "Epoch 20/500\n",
            "186/186 [==============================] - 1s 5ms/step - loss: 0.4341 - mse: 0.4341 - val_loss: 1.5265 - val_mse: 1.5265\n",
            "\n",
            "Epoch 00020: loss did not improve from 0.05686\n",
            "Epoch 21/500\n",
            "186/186 [==============================] - 1s 5ms/step - loss: 0.4185 - mse: 0.4185 - val_loss: 0.6389 - val_mse: 0.6389\n",
            "\n",
            "Epoch 00021: loss did not improve from 0.05686\n",
            "Epoch 22/500\n",
            "186/186 [==============================] - 1s 5ms/step - loss: 0.6975 - mse: 0.6975 - val_loss: 8.9754 - val_mse: 8.9754\n",
            "\n",
            "Epoch 00022: loss did not improve from 0.05686\n",
            "Epoch 23/500\n",
            "186/186 [==============================] - 1s 5ms/step - loss: 0.9006 - mse: 0.9006 - val_loss: 0.8204 - val_mse: 0.8204\n",
            "\n",
            "Epoch 00023: loss did not improve from 0.05686\n",
            "Epoch 24/500\n",
            "186/186 [==============================] - 1s 5ms/step - loss: 0.5169 - mse: 0.5169 - val_loss: 0.7282 - val_mse: 0.7282\n",
            "\n",
            "Epoch 00024: loss did not improve from 0.05686\n",
            "Epoch 25/500\n",
            "186/186 [==============================] - 1s 5ms/step - loss: 0.5331 - mse: 0.5331 - val_loss: 2.3046 - val_mse: 2.3046\n",
            "\n",
            "Epoch 00025: loss did not improve from 0.05686\n",
            "Epoch 26/500\n",
            "186/186 [==============================] - 1s 5ms/step - loss: 0.5151 - mse: 0.5151 - val_loss: 0.0628 - val_mse: 0.0628\n",
            "\n",
            "Epoch 00026: loss did not improve from 0.05686\n",
            "Epoch 27/500\n",
            "186/186 [==============================] - 1s 5ms/step - loss: 0.3827 - mse: 0.3827 - val_loss: 0.1503 - val_mse: 0.1503\n",
            "\n",
            "Epoch 00027: loss did not improve from 0.05686\n",
            "Epoch 28/500\n",
            "186/186 [==============================] - 1s 5ms/step - loss: 0.2120 - mse: 0.2120 - val_loss: 0.4247 - val_mse: 0.4247\n",
            "\n",
            "Epoch 00028: loss did not improve from 0.05686\n",
            "Epoch 29/500\n",
            "186/186 [==============================] - 1s 5ms/step - loss: 0.2336 - mse: 0.2336 - val_loss: 0.5348 - val_mse: 0.5348\n",
            "\n",
            "Epoch 00029: loss did not improve from 0.05686\n",
            "Epoch 30/500\n",
            "186/186 [==============================] - 1s 5ms/step - loss: 0.3805 - mse: 0.3805 - val_loss: 0.0584 - val_mse: 0.0584\n",
            "\n",
            "Epoch 00030: loss did not improve from 0.05686\n",
            "Epoch 31/500\n",
            "186/186 [==============================] - 1s 5ms/step - loss: 0.1189 - mse: 0.1189 - val_loss: 0.6256 - val_mse: 0.6256\n",
            "\n",
            "Epoch 00031: loss did not improve from 0.05686\n",
            "Epoch 32/500\n",
            "186/186 [==============================] - 1s 5ms/step - loss: 0.3426 - mse: 0.3426 - val_loss: 0.1150 - val_mse: 0.1150\n",
            "\n",
            "Epoch 00032: loss did not improve from 0.05686\n",
            "Epoch 33/500\n",
            "186/186 [==============================] - 1s 5ms/step - loss: 0.1428 - mse: 0.1428 - val_loss: 0.5304 - val_mse: 0.5304\n",
            "\n",
            "Epoch 00033: loss did not improve from 0.05686\n",
            "Epoch 34/500\n",
            "186/186 [==============================] - 1s 5ms/step - loss: 0.1864 - mse: 0.1864 - val_loss: 0.1234 - val_mse: 0.1234\n",
            "\n",
            "Epoch 00034: loss did not improve from 0.05686\n",
            "Epoch 35/500\n",
            "186/186 [==============================] - 1s 5ms/step - loss: 0.0740 - mse: 0.0740 - val_loss: 0.1183 - val_mse: 0.1183\n",
            "\n",
            "Epoch 00035: loss did not improve from 0.05686\n",
            "Epoch 36/500\n",
            "186/186 [==============================] - 1s 5ms/step - loss: 0.1843 - mse: 0.1843 - val_loss: 0.0726 - val_mse: 0.0726\n",
            "\n",
            "Epoch 00036: loss did not improve from 0.05686\n",
            "Epoch 37/500\n",
            "186/186 [==============================] - 1s 5ms/step - loss: 0.0788 - mse: 0.0788 - val_loss: 0.2553 - val_mse: 0.2553\n",
            "\n",
            "Epoch 00037: loss did not improve from 0.05686\n",
            "Epoch 38/500\n",
            "186/186 [==============================] - 1s 5ms/step - loss: 0.0767 - mse: 0.0767 - val_loss: 0.0995 - val_mse: 0.0995\n",
            "\n",
            "Epoch 00038: loss did not improve from 0.05686\n",
            "Epoch 39/500\n",
            "186/186 [==============================] - 1s 5ms/step - loss: 0.0479 - mse: 0.0479 - val_loss: 0.0446 - val_mse: 0.0446\n",
            "\n",
            "Epoch 00039: loss did not improve from 0.05686\n",
            "Epoch 40/500\n",
            "186/186 [==============================] - 1s 5ms/step - loss: 0.0654 - mse: 0.0654 - val_loss: 0.0762 - val_mse: 0.0762\n",
            "\n",
            "Epoch 00040: loss did not improve from 0.05686\n",
            "Epoch 41/500\n",
            "186/186 [==============================] - 1s 5ms/step - loss: 0.0489 - mse: 0.0489 - val_loss: 0.1036 - val_mse: 0.1036\n",
            "\n",
            "Epoch 00041: loss did not improve from 0.05686\n",
            "Epoch 42/500\n",
            "186/186 [==============================] - 1s 5ms/step - loss: 0.0437 - mse: 0.0437 - val_loss: 0.0761 - val_mse: 0.0761\n",
            "\n",
            "Epoch 00042: loss improved from 0.05686 to 0.05489, saving model to poids_train.hdf5\n",
            "Epoch 43/500\n",
            "186/186 [==============================] - 1s 5ms/step - loss: 0.0430 - mse: 0.0430 - val_loss: 0.0644 - val_mse: 0.0644\n",
            "\n",
            "Epoch 00043: loss improved from 0.05489 to 0.05329, saving model to poids_train.hdf5\n",
            "Epoch 44/500\n",
            "186/186 [==============================] - 1s 5ms/step - loss: 0.0444 - mse: 0.0444 - val_loss: 0.0679 - val_mse: 0.0679\n",
            "\n",
            "Epoch 00044: loss did not improve from 0.05329\n",
            "Epoch 45/500\n",
            "186/186 [==============================] - 1s 5ms/step - loss: 0.0425 - mse: 0.0425 - val_loss: 0.0666 - val_mse: 0.0666\n",
            "\n",
            "Epoch 00045: loss improved from 0.05329 to 0.05284, saving model to poids_train.hdf5\n",
            "Epoch 46/500\n",
            "186/186 [==============================] - 1s 5ms/step - loss: 0.0415 - mse: 0.0415 - val_loss: 0.0611 - val_mse: 0.0611\n",
            "\n",
            "Epoch 00046: loss improved from 0.05284 to 0.05151, saving model to poids_train.hdf5\n",
            "Epoch 47/500\n",
            "186/186 [==============================] - 1s 5ms/step - loss: 0.0419 - mse: 0.0419 - val_loss: 0.0590 - val_mse: 0.0590\n",
            "\n",
            "Epoch 00047: loss improved from 0.05151 to 0.05141, saving model to poids_train.hdf5\n",
            "Epoch 48/500\n",
            "186/186 [==============================] - 1s 5ms/step - loss: 0.0425 - mse: 0.0425 - val_loss: 0.0631 - val_mse: 0.0631\n",
            "\n",
            "Epoch 00048: loss improved from 0.05141 to 0.05141, saving model to poids_train.hdf5\n",
            "Epoch 49/500\n",
            "186/186 [==============================] - 1s 5ms/step - loss: 0.0433 - mse: 0.0433 - val_loss: 0.0748 - val_mse: 0.0748\n",
            "\n",
            "Epoch 00049: loss improved from 0.05141 to 0.05098, saving model to poids_train.hdf5\n",
            "Epoch 50/500\n",
            "186/186 [==============================] - 1s 5ms/step - loss: 0.0445 - mse: 0.0445 - val_loss: 0.0871 - val_mse: 0.0871\n",
            "\n",
            "Epoch 00050: loss improved from 0.05098 to 0.05029, saving model to poids_train.hdf5\n",
            "Epoch 51/500\n",
            "186/186 [==============================] - 1s 5ms/step - loss: 0.0451 - mse: 0.0451 - val_loss: 0.0935 - val_mse: 0.0935\n",
            "\n",
            "Epoch 00051: loss improved from 0.05029 to 0.04933, saving model to poids_train.hdf5\n",
            "Epoch 52/500\n",
            "186/186 [==============================] - 1s 5ms/step - loss: 0.0454 - mse: 0.0454 - val_loss: 0.0976 - val_mse: 0.0976\n",
            "\n",
            "Epoch 00052: loss improved from 0.04933 to 0.04828, saving model to poids_train.hdf5\n",
            "Epoch 53/500\n",
            "186/186 [==============================] - 1s 5ms/step - loss: 0.0457 - mse: 0.0457 - val_loss: 0.1009 - val_mse: 0.1009\n",
            "\n",
            "Epoch 00053: loss improved from 0.04828 to 0.04726, saving model to poids_train.hdf5\n",
            "Epoch 54/500\n",
            "186/186 [==============================] - 1s 5ms/step - loss: 0.0461 - mse: 0.0461 - val_loss: 0.1032 - val_mse: 0.1032\n",
            "\n",
            "Epoch 00054: loss improved from 0.04726 to 0.04630, saving model to poids_train.hdf5\n",
            "Epoch 55/500\n",
            "186/186 [==============================] - 1s 5ms/step - loss: 0.0466 - mse: 0.0466 - val_loss: 0.1047 - val_mse: 0.1047\n",
            "\n",
            "Epoch 00055: loss improved from 0.04630 to 0.04538, saving model to poids_train.hdf5\n",
            "Epoch 56/500\n",
            "186/186 [==============================] - 1s 5ms/step - loss: 0.0470 - mse: 0.0470 - val_loss: 0.1052 - val_mse: 0.1052\n",
            "\n",
            "Epoch 00056: loss improved from 0.04538 to 0.04450, saving model to poids_train.hdf5\n",
            "Epoch 57/500\n",
            "186/186 [==============================] - 1s 5ms/step - loss: 0.0473 - mse: 0.0473 - val_loss: 0.1049 - val_mse: 0.1049\n",
            "\n",
            "Epoch 00057: loss improved from 0.04450 to 0.04366, saving model to poids_train.hdf5\n",
            "Epoch 58/500\n",
            "186/186 [==============================] - 1s 5ms/step - loss: 0.0474 - mse: 0.0474 - val_loss: 0.1041 - val_mse: 0.1041\n",
            "\n",
            "Epoch 00058: loss improved from 0.04366 to 0.04285, saving model to poids_train.hdf5\n",
            "Epoch 59/500\n",
            "186/186 [==============================] - 1s 5ms/step - loss: 0.0474 - mse: 0.0474 - val_loss: 0.1028 - val_mse: 0.1028\n",
            "\n",
            "Epoch 00059: loss improved from 0.04285 to 0.04207, saving model to poids_train.hdf5\n",
            "Epoch 60/500\n",
            "186/186 [==============================] - 1s 6ms/step - loss: 0.0471 - mse: 0.0471 - val_loss: 0.1013 - val_mse: 0.1013\n",
            "\n",
            "Epoch 00060: loss improved from 0.04207 to 0.04130, saving model to poids_train.hdf5\n",
            "Epoch 61/500\n",
            "186/186 [==============================] - 1s 5ms/step - loss: 0.0466 - mse: 0.0466 - val_loss: 0.0998 - val_mse: 0.0998\n",
            "\n",
            "Epoch 00061: loss improved from 0.04130 to 0.04053, saving model to poids_train.hdf5\n",
            "Epoch 62/500\n",
            "186/186 [==============================] - 1s 5ms/step - loss: 0.0460 - mse: 0.0460 - val_loss: 0.0985 - val_mse: 0.0985\n",
            "\n",
            "Epoch 00062: loss improved from 0.04053 to 0.03977, saving model to poids_train.hdf5\n",
            "Epoch 63/500\n",
            "186/186 [==============================] - 1s 5ms/step - loss: 0.0452 - mse: 0.0452 - val_loss: 0.0974 - val_mse: 0.0974\n",
            "\n",
            "Epoch 00063: loss improved from 0.03977 to 0.03903, saving model to poids_train.hdf5\n",
            "Epoch 64/500\n",
            "186/186 [==============================] - 1s 5ms/step - loss: 0.0442 - mse: 0.0442 - val_loss: 0.0967 - val_mse: 0.0967\n",
            "\n",
            "Epoch 00064: loss improved from 0.03903 to 0.03829, saving model to poids_train.hdf5\n",
            "Epoch 65/500\n",
            "186/186 [==============================] - 1s 5ms/step - loss: 0.0433 - mse: 0.0433 - val_loss: 0.0963 - val_mse: 0.0963\n",
            "\n",
            "Epoch 00065: loss improved from 0.03829 to 0.03759, saving model to poids_train.hdf5\n",
            "Epoch 66/500\n",
            "186/186 [==============================] - 1s 5ms/step - loss: 0.0423 - mse: 0.0423 - val_loss: 0.0962 - val_mse: 0.0962\n",
            "\n",
            "Epoch 00066: loss improved from 0.03759 to 0.03691, saving model to poids_train.hdf5\n",
            "Epoch 67/500\n",
            "186/186 [==============================] - 1s 5ms/step - loss: 0.0414 - mse: 0.0414 - val_loss: 0.0965 - val_mse: 0.0965\n",
            "\n",
            "Epoch 00067: loss improved from 0.03691 to 0.03627, saving model to poids_train.hdf5\n",
            "Epoch 68/500\n",
            "186/186 [==============================] - 1s 5ms/step - loss: 0.0404 - mse: 0.0404 - val_loss: 0.0970 - val_mse: 0.0970\n",
            "\n",
            "Epoch 00068: loss improved from 0.03627 to 0.03566, saving model to poids_train.hdf5\n",
            "Epoch 69/500\n",
            "186/186 [==============================] - 1s 5ms/step - loss: 0.0396 - mse: 0.0396 - val_loss: 0.0978 - val_mse: 0.0978\n",
            "\n",
            "Epoch 00069: loss improved from 0.03566 to 0.03509, saving model to poids_train.hdf5\n",
            "Epoch 70/500\n",
            "186/186 [==============================] - 1s 5ms/step - loss: 0.0387 - mse: 0.0387 - val_loss: 0.0988 - val_mse: 0.0988\n",
            "\n",
            "Epoch 00070: loss improved from 0.03509 to 0.03455, saving model to poids_train.hdf5\n",
            "Epoch 71/500\n",
            "186/186 [==============================] - 1s 5ms/step - loss: 0.0379 - mse: 0.0379 - val_loss: 0.0999 - val_mse: 0.0999\n",
            "\n",
            "Epoch 00071: loss improved from 0.03455 to 0.03404, saving model to poids_train.hdf5\n",
            "Epoch 72/500\n",
            "186/186 [==============================] - 1s 5ms/step - loss: 0.0372 - mse: 0.0372 - val_loss: 0.1012 - val_mse: 0.1012\n",
            "\n",
            "Epoch 00072: loss improved from 0.03404 to 0.03357, saving model to poids_train.hdf5\n",
            "Epoch 73/500\n",
            "186/186 [==============================] - 1s 5ms/step - loss: 0.0365 - mse: 0.0365 - val_loss: 0.1026 - val_mse: 0.1026\n",
            "\n",
            "Epoch 00073: loss improved from 0.03357 to 0.03312, saving model to poids_train.hdf5\n",
            "Epoch 74/500\n",
            "186/186 [==============================] - 1s 5ms/step - loss: 0.0359 - mse: 0.0359 - val_loss: 0.1041 - val_mse: 0.1041\n",
            "\n",
            "Epoch 00074: loss improved from 0.03312 to 0.03271, saving model to poids_train.hdf5\n",
            "Epoch 75/500\n",
            "186/186 [==============================] - 1s 5ms/step - loss: 0.0353 - mse: 0.0353 - val_loss: 0.1056 - val_mse: 0.1056\n",
            "\n",
            "Epoch 00075: loss improved from 0.03271 to 0.03231, saving model to poids_train.hdf5\n",
            "Epoch 76/500\n",
            "186/186 [==============================] - 1s 5ms/step - loss: 0.0348 - mse: 0.0348 - val_loss: 0.1073 - val_mse: 0.1073\n",
            "\n",
            "Epoch 00076: loss improved from 0.03231 to 0.03194, saving model to poids_train.hdf5\n",
            "Epoch 77/500\n",
            "186/186 [==============================] - 1s 5ms/step - loss: 0.0342 - mse: 0.0342 - val_loss: 0.1090 - val_mse: 0.1090\n",
            "\n",
            "Epoch 00077: loss improved from 0.03194 to 0.03159, saving model to poids_train.hdf5\n",
            "Epoch 78/500\n",
            "186/186 [==============================] - 1s 5ms/step - loss: 0.0338 - mse: 0.0338 - val_loss: 0.1107 - val_mse: 0.1107\n",
            "\n",
            "Epoch 00078: loss improved from 0.03159 to 0.03126, saving model to poids_train.hdf5\n",
            "Epoch 79/500\n",
            "186/186 [==============================] - 1s 5ms/step - loss: 0.0333 - mse: 0.0333 - val_loss: 0.1124 - val_mse: 0.1124\n",
            "\n",
            "Epoch 00079: loss improved from 0.03126 to 0.03094, saving model to poids_train.hdf5\n",
            "Epoch 80/500\n",
            "186/186 [==============================] - 1s 5ms/step - loss: 0.0329 - mse: 0.0329 - val_loss: 0.1142 - val_mse: 0.1142\n",
            "\n",
            "Epoch 00080: loss improved from 0.03094 to 0.03064, saving model to poids_train.hdf5\n",
            "Epoch 81/500\n",
            "186/186 [==============================] - 1s 5ms/step - loss: 0.0325 - mse: 0.0325 - val_loss: 0.1160 - val_mse: 0.1160\n",
            "\n",
            "Epoch 00081: loss improved from 0.03064 to 0.03036, saving model to poids_train.hdf5\n",
            "Epoch 82/500\n",
            "186/186 [==============================] - 1s 5ms/step - loss: 0.0321 - mse: 0.0321 - val_loss: 0.1179 - val_mse: 0.1179\n",
            "\n",
            "Epoch 00082: loss improved from 0.03036 to 0.03009, saving model to poids_train.hdf5\n",
            "Epoch 83/500\n",
            "186/186 [==============================] - 1s 5ms/step - loss: 0.0317 - mse: 0.0317 - val_loss: 0.1197 - val_mse: 0.1197\n",
            "\n",
            "Epoch 00083: loss improved from 0.03009 to 0.02983, saving model to poids_train.hdf5\n",
            "Epoch 84/500\n",
            "186/186 [==============================] - 1s 5ms/step - loss: 0.0313 - mse: 0.0313 - val_loss: 0.1215 - val_mse: 0.1215\n",
            "\n",
            "Epoch 00084: loss improved from 0.02983 to 0.02958, saving model to poids_train.hdf5\n",
            "Epoch 85/500\n",
            "186/186 [==============================] - 1s 5ms/step - loss: 0.0310 - mse: 0.0310 - val_loss: 0.1234 - val_mse: 0.1234\n",
            "\n",
            "Epoch 00085: loss improved from 0.02958 to 0.02934, saving model to poids_train.hdf5\n",
            "Epoch 86/500\n",
            "186/186 [==============================] - 1s 5ms/step - loss: 0.0307 - mse: 0.0307 - val_loss: 0.1252 - val_mse: 0.1252\n",
            "\n",
            "Epoch 00086: loss improved from 0.02934 to 0.02912, saving model to poids_train.hdf5\n",
            "Epoch 87/500\n",
            "186/186 [==============================] - 1s 5ms/step - loss: 0.0304 - mse: 0.0304 - val_loss: 0.1271 - val_mse: 0.1271\n",
            "\n",
            "Epoch 00087: loss improved from 0.02912 to 0.02890, saving model to poids_train.hdf5\n",
            "Epoch 88/500\n",
            "186/186 [==============================] - 1s 5ms/step - loss: 0.0301 - mse: 0.0301 - val_loss: 0.1289 - val_mse: 0.1289\n",
            "\n",
            "Epoch 00088: loss improved from 0.02890 to 0.02869, saving model to poids_train.hdf5\n",
            "Epoch 89/500\n",
            "186/186 [==============================] - 1s 5ms/step - loss: 0.0298 - mse: 0.0298 - val_loss: 0.1308 - val_mse: 0.1308\n",
            "\n",
            "Epoch 00089: loss improved from 0.02869 to 0.02849, saving model to poids_train.hdf5\n",
            "Epoch 90/500\n",
            "186/186 [==============================] - 1s 5ms/step - loss: 0.0295 - mse: 0.0295 - val_loss: 0.1326 - val_mse: 0.1326\n",
            "\n",
            "Epoch 00090: loss improved from 0.02849 to 0.02829, saving model to poids_train.hdf5\n",
            "Epoch 91/500\n",
            "186/186 [==============================] - 1s 5ms/step - loss: 0.0293 - mse: 0.0293 - val_loss: 0.1345 - val_mse: 0.1345\n",
            "\n",
            "Epoch 00091: loss improved from 0.02829 to 0.02811, saving model to poids_train.hdf5\n",
            "Epoch 92/500\n",
            "186/186 [==============================] - 1s 5ms/step - loss: 0.0290 - mse: 0.0290 - val_loss: 0.1363 - val_mse: 0.1363\n",
            "\n",
            "Epoch 00092: loss improved from 0.02811 to 0.02793, saving model to poids_train.hdf5\n",
            "Epoch 93/500\n",
            "186/186 [==============================] - 1s 5ms/step - loss: 0.0288 - mse: 0.0288 - val_loss: 0.1381 - val_mse: 0.1381\n",
            "\n",
            "Epoch 00093: loss improved from 0.02793 to 0.02775, saving model to poids_train.hdf5\n",
            "Epoch 94/500\n",
            "186/186 [==============================] - 1s 5ms/step - loss: 0.0286 - mse: 0.0286 - val_loss: 0.1399 - val_mse: 0.1399\n",
            "\n",
            "Epoch 00094: loss improved from 0.02775 to 0.02759, saving model to poids_train.hdf5\n",
            "Epoch 95/500\n",
            "186/186 [==============================] - 1s 5ms/step - loss: 0.0283 - mse: 0.0283 - val_loss: 0.1417 - val_mse: 0.1417\n",
            "\n",
            "Epoch 00095: loss improved from 0.02759 to 0.02742, saving model to poids_train.hdf5\n",
            "Epoch 96/500\n",
            "186/186 [==============================] - 1s 5ms/step - loss: 0.0281 - mse: 0.0281 - val_loss: 0.1435 - val_mse: 0.1435\n",
            "\n",
            "Epoch 00096: loss improved from 0.02742 to 0.02727, saving model to poids_train.hdf5\n",
            "Epoch 97/500\n",
            "186/186 [==============================] - 1s 5ms/step - loss: 0.0279 - mse: 0.0279 - val_loss: 0.1453 - val_mse: 0.1453\n",
            "\n",
            "Epoch 00097: loss improved from 0.02727 to 0.02712, saving model to poids_train.hdf5\n",
            "Epoch 98/500\n",
            "186/186 [==============================] - 1s 5ms/step - loss: 0.0277 - mse: 0.0277 - val_loss: 0.1470 - val_mse: 0.1470\n",
            "\n",
            "Epoch 00098: loss improved from 0.02712 to 0.02697, saving model to poids_train.hdf5\n",
            "Epoch 99/500\n",
            "186/186 [==============================] - 1s 5ms/step - loss: 0.0275 - mse: 0.0275 - val_loss: 0.1488 - val_mse: 0.1488\n",
            "\n",
            "Epoch 00099: loss improved from 0.02697 to 0.02683, saving model to poids_train.hdf5\n",
            "Epoch 100/500\n",
            "186/186 [==============================] - 1s 5ms/step - loss: 0.0273 - mse: 0.0273 - val_loss: 0.1505 - val_mse: 0.1505\n",
            "\n",
            "Epoch 00100: loss improved from 0.02683 to 0.02669, saving model to poids_train.hdf5\n",
            "Epoch 101/500\n",
            "186/186 [==============================] - 1s 5ms/step - loss: 0.0271 - mse: 0.0271 - val_loss: 0.1522 - val_mse: 0.1522\n",
            "\n",
            "Epoch 00101: loss improved from 0.02669 to 0.02655, saving model to poids_train.hdf5\n",
            "Epoch 102/500\n",
            "186/186 [==============================] - 1s 5ms/step - loss: 0.0269 - mse: 0.0269 - val_loss: 0.1539 - val_mse: 0.1539\n",
            "\n",
            "Epoch 00102: loss improved from 0.02655 to 0.02642, saving model to poids_train.hdf5\n",
            "Epoch 103/500\n",
            "186/186 [==============================] - 1s 5ms/step - loss: 0.0268 - mse: 0.0268 - val_loss: 0.1556 - val_mse: 0.1556\n",
            "\n",
            "Epoch 00103: loss improved from 0.02642 to 0.02630, saving model to poids_train.hdf5\n",
            "Epoch 104/500\n",
            "186/186 [==============================] - 1s 5ms/step - loss: 0.0266 - mse: 0.0266 - val_loss: 0.1573 - val_mse: 0.1573\n",
            "\n",
            "Epoch 00104: loss improved from 0.02630 to 0.02617, saving model to poids_train.hdf5\n",
            "Epoch 105/500\n",
            "186/186 [==============================] - 1s 5ms/step - loss: 0.0264 - mse: 0.0264 - val_loss: 0.1589 - val_mse: 0.1589\n",
            "\n",
            "Epoch 00105: loss improved from 0.02617 to 0.02606, saving model to poids_train.hdf5\n",
            "Epoch 106/500\n",
            "186/186 [==============================] - 1s 5ms/step - loss: 0.0263 - mse: 0.0263 - val_loss: 0.1605 - val_mse: 0.1605\n",
            "\n",
            "Epoch 00106: loss improved from 0.02606 to 0.02594, saving model to poids_train.hdf5\n",
            "Epoch 107/500\n",
            "186/186 [==============================] - 1s 5ms/step - loss: 0.0261 - mse: 0.0261 - val_loss: 0.1622 - val_mse: 0.1622\n",
            "\n",
            "Epoch 00107: loss improved from 0.02594 to 0.02583, saving model to poids_train.hdf5\n",
            "Epoch 108/500\n",
            "186/186 [==============================] - 1s 5ms/step - loss: 0.0260 - mse: 0.0260 - val_loss: 0.1638 - val_mse: 0.1638\n",
            "\n",
            "Epoch 00108: loss improved from 0.02583 to 0.02572, saving model to poids_train.hdf5\n",
            "Epoch 109/500\n",
            "186/186 [==============================] - 1s 5ms/step - loss: 0.0258 - mse: 0.0258 - val_loss: 0.1654 - val_mse: 0.1654\n",
            "\n",
            "Epoch 00109: loss improved from 0.02572 to 0.02561, saving model to poids_train.hdf5\n",
            "Epoch 110/500\n",
            "186/186 [==============================] - 1s 5ms/step - loss: 0.0257 - mse: 0.0257 - val_loss: 0.1669 - val_mse: 0.1669\n",
            "\n",
            "Epoch 00110: loss improved from 0.02561 to 0.02550, saving model to poids_train.hdf5\n",
            "Epoch 111/500\n",
            "186/186 [==============================] - 1s 5ms/step - loss: 0.0255 - mse: 0.0255 - val_loss: 0.1685 - val_mse: 0.1685\n",
            "\n",
            "Epoch 00111: loss improved from 0.02550 to 0.02540, saving model to poids_train.hdf5\n",
            "Epoch 112/500\n",
            "186/186 [==============================] - 1s 5ms/step - loss: 0.0254 - mse: 0.0254 - val_loss: 0.1700 - val_mse: 0.1700\n",
            "\n",
            "Epoch 00112: loss improved from 0.02540 to 0.02530, saving model to poids_train.hdf5\n",
            "Epoch 113/500\n",
            "186/186 [==============================] - 1s 5ms/step - loss: 0.0253 - mse: 0.0253 - val_loss: 0.1716 - val_mse: 0.1716\n",
            "\n",
            "Epoch 00113: loss improved from 0.02530 to 0.02520, saving model to poids_train.hdf5\n",
            "Epoch 114/500\n",
            "186/186 [==============================] - 1s 5ms/step - loss: 0.0251 - mse: 0.0251 - val_loss: 0.1731 - val_mse: 0.1731\n",
            "\n",
            "Epoch 00114: loss improved from 0.02520 to 0.02511, saving model to poids_train.hdf5\n",
            "Epoch 115/500\n",
            "186/186 [==============================] - 1s 5ms/step - loss: 0.0250 - mse: 0.0250 - val_loss: 0.1746 - val_mse: 0.1746\n",
            "\n",
            "Epoch 00115: loss improved from 0.02511 to 0.02501, saving model to poids_train.hdf5\n",
            "Epoch 116/500\n",
            "186/186 [==============================] - 1s 5ms/step - loss: 0.0249 - mse: 0.0249 - val_loss: 0.1761 - val_mse: 0.1761\n",
            "\n",
            "Epoch 00116: loss improved from 0.02501 to 0.02492, saving model to poids_train.hdf5\n",
            "Epoch 117/500\n",
            "186/186 [==============================] - 1s 5ms/step - loss: 0.0248 - mse: 0.0248 - val_loss: 0.1775 - val_mse: 0.1775\n",
            "\n",
            "Epoch 00117: loss improved from 0.02492 to 0.02484, saving model to poids_train.hdf5\n",
            "Epoch 118/500\n",
            "186/186 [==============================] - 1s 5ms/step - loss: 0.0246 - mse: 0.0246 - val_loss: 0.1790 - val_mse: 0.1790\n",
            "\n",
            "Epoch 00118: loss improved from 0.02484 to 0.02475, saving model to poids_train.hdf5\n",
            "Epoch 119/500\n",
            "186/186 [==============================] - 1s 5ms/step - loss: 0.0245 - mse: 0.0245 - val_loss: 0.1804 - val_mse: 0.1804\n",
            "\n",
            "Epoch 00119: loss improved from 0.02475 to 0.02466, saving model to poids_train.hdf5\n",
            "Epoch 120/500\n",
            "186/186 [==============================] - 1s 5ms/step - loss: 0.0244 - mse: 0.0244 - val_loss: 0.1818 - val_mse: 0.1818\n",
            "\n",
            "Epoch 00120: loss improved from 0.02466 to 0.02458, saving model to poids_train.hdf5\n",
            "Epoch 121/500\n",
            "186/186 [==============================] - 1s 5ms/step - loss: 0.0243 - mse: 0.0243 - val_loss: 0.1833 - val_mse: 0.1833\n",
            "\n",
            "Epoch 00121: loss improved from 0.02458 to 0.02450, saving model to poids_train.hdf5\n",
            "Epoch 122/500\n",
            "186/186 [==============================] - 1s 5ms/step - loss: 0.0242 - mse: 0.0242 - val_loss: 0.1847 - val_mse: 0.1847\n",
            "\n",
            "Epoch 00122: loss improved from 0.02450 to 0.02442, saving model to poids_train.hdf5\n",
            "Epoch 123/500\n",
            "186/186 [==============================] - 1s 5ms/step - loss: 0.0241 - mse: 0.0241 - val_loss: 0.1860 - val_mse: 0.1860\n",
            "\n",
            "Epoch 00123: loss improved from 0.02442 to 0.02434, saving model to poids_train.hdf5\n",
            "Epoch 124/500\n",
            "186/186 [==============================] - 1s 6ms/step - loss: 0.0240 - mse: 0.0240 - val_loss: 0.1874 - val_mse: 0.1874\n",
            "\n",
            "Epoch 00124: loss improved from 0.02434 to 0.02426, saving model to poids_train.hdf5\n",
            "Epoch 125/500\n",
            "186/186 [==============================] - 1s 5ms/step - loss: 0.0239 - mse: 0.0239 - val_loss: 0.1888 - val_mse: 0.1888\n",
            "\n",
            "Epoch 00125: loss improved from 0.02426 to 0.02419, saving model to poids_train.hdf5\n",
            "Epoch 126/500\n",
            "186/186 [==============================] - 1s 5ms/step - loss: 0.0238 - mse: 0.0238 - val_loss: 0.1901 - val_mse: 0.1901\n",
            "\n",
            "Epoch 00126: loss improved from 0.02419 to 0.02412, saving model to poids_train.hdf5\n",
            "Epoch 127/500\n",
            "186/186 [==============================] - 1s 5ms/step - loss: 0.0237 - mse: 0.0237 - val_loss: 0.1914 - val_mse: 0.1914\n",
            "\n",
            "Epoch 00127: loss improved from 0.02412 to 0.02404, saving model to poids_train.hdf5\n",
            "Epoch 128/500\n",
            "186/186 [==============================] - 1s 5ms/step - loss: 0.0236 - mse: 0.0236 - val_loss: 0.1927 - val_mse: 0.1927\n",
            "\n",
            "Epoch 00128: loss improved from 0.02404 to 0.02397, saving model to poids_train.hdf5\n",
            "Epoch 129/500\n",
            "186/186 [==============================] - 1s 5ms/step - loss: 0.0235 - mse: 0.0235 - val_loss: 0.1940 - val_mse: 0.1940\n",
            "\n",
            "Epoch 00129: loss improved from 0.02397 to 0.02390, saving model to poids_train.hdf5\n",
            "Epoch 130/500\n",
            "186/186 [==============================] - 1s 5ms/step - loss: 0.0234 - mse: 0.0234 - val_loss: 0.1953 - val_mse: 0.1953\n",
            "\n",
            "Epoch 00130: loss improved from 0.02390 to 0.02384, saving model to poids_train.hdf5\n",
            "Epoch 131/500\n",
            "186/186 [==============================] - 1s 5ms/step - loss: 0.0233 - mse: 0.0233 - val_loss: 0.1966 - val_mse: 0.1966\n",
            "\n",
            "Epoch 00131: loss improved from 0.02384 to 0.02377, saving model to poids_train.hdf5\n",
            "Epoch 132/500\n",
            "186/186 [==============================] - 1s 5ms/step - loss: 0.0232 - mse: 0.0232 - val_loss: 0.1978 - val_mse: 0.1978\n",
            "\n",
            "Epoch 00132: loss improved from 0.02377 to 0.02370, saving model to poids_train.hdf5\n",
            "Epoch 133/500\n",
            "186/186 [==============================] - 1s 5ms/step - loss: 0.0231 - mse: 0.0231 - val_loss: 0.1991 - val_mse: 0.1991\n",
            "\n",
            "Epoch 00133: loss improved from 0.02370 to 0.02364, saving model to poids_train.hdf5\n",
            "Epoch 134/500\n",
            "186/186 [==============================] - 1s 6ms/step - loss: 0.0231 - mse: 0.0231 - val_loss: 0.2003 - val_mse: 0.2003\n",
            "\n",
            "Epoch 00134: loss improved from 0.02364 to 0.02357, saving model to poids_train.hdf5\n",
            "Epoch 135/500\n",
            "186/186 [==============================] - 1s 5ms/step - loss: 0.0230 - mse: 0.0230 - val_loss: 0.2016 - val_mse: 0.2016\n",
            "\n",
            "Epoch 00135: loss improved from 0.02357 to 0.02351, saving model to poids_train.hdf5\n",
            "Epoch 136/500\n",
            "186/186 [==============================] - 1s 5ms/step - loss: 0.0229 - mse: 0.0229 - val_loss: 0.2028 - val_mse: 0.2028\n",
            "\n",
            "Epoch 00136: loss improved from 0.02351 to 0.02345, saving model to poids_train.hdf5\n",
            "Epoch 137/500\n",
            "186/186 [==============================] - 1s 5ms/step - loss: 0.0228 - mse: 0.0228 - val_loss: 0.2040 - val_mse: 0.2040\n",
            "\n",
            "Epoch 00137: loss improved from 0.02345 to 0.02339, saving model to poids_train.hdf5\n",
            "Epoch 138/500\n",
            "186/186 [==============================] - 1s 5ms/step - loss: 0.0227 - mse: 0.0227 - val_loss: 0.2052 - val_mse: 0.2052\n",
            "\n",
            "Epoch 00138: loss improved from 0.02339 to 0.02333, saving model to poids_train.hdf5\n",
            "Epoch 139/500\n",
            "186/186 [==============================] - 1s 5ms/step - loss: 0.0227 - mse: 0.0227 - val_loss: 0.2064 - val_mse: 0.2064\n",
            "\n",
            "Epoch 00139: loss improved from 0.02333 to 0.02327, saving model to poids_train.hdf5\n",
            "Epoch 140/500\n",
            "186/186 [==============================] - 1s 5ms/step - loss: 0.0226 - mse: 0.0226 - val_loss: 0.2075 - val_mse: 0.2075\n",
            "\n",
            "Epoch 00140: loss improved from 0.02327 to 0.02322, saving model to poids_train.hdf5\n",
            "Epoch 141/500\n",
            "186/186 [==============================] - 1s 5ms/step - loss: 0.0225 - mse: 0.0225 - val_loss: 0.2087 - val_mse: 0.2087\n",
            "\n",
            "Epoch 00141: loss improved from 0.02322 to 0.02316, saving model to poids_train.hdf5\n",
            "Epoch 142/500\n",
            "186/186 [==============================] - 1s 5ms/step - loss: 0.0224 - mse: 0.0224 - val_loss: 0.2098 - val_mse: 0.2098\n",
            "\n",
            "Epoch 00142: loss improved from 0.02316 to 0.02311, saving model to poids_train.hdf5\n",
            "Epoch 143/500\n",
            "186/186 [==============================] - 1s 5ms/step - loss: 0.0224 - mse: 0.0224 - val_loss: 0.2110 - val_mse: 0.2110\n",
            "\n",
            "Epoch 00143: loss improved from 0.02311 to 0.02305, saving model to poids_train.hdf5\n",
            "Epoch 144/500\n",
            "186/186 [==============================] - 1s 5ms/step - loss: 0.0223 - mse: 0.0223 - val_loss: 0.2121 - val_mse: 0.2121\n",
            "\n",
            "Epoch 00144: loss improved from 0.02305 to 0.02300, saving model to poids_train.hdf5\n",
            "Epoch 145/500\n",
            "186/186 [==============================] - 1s 5ms/step - loss: 0.0222 - mse: 0.0222 - val_loss: 0.2132 - val_mse: 0.2132\n",
            "\n",
            "Epoch 00145: loss improved from 0.02300 to 0.02294, saving model to poids_train.hdf5\n",
            "Epoch 146/500\n",
            "186/186 [==============================] - 1s 5ms/step - loss: 0.0222 - mse: 0.0222 - val_loss: 0.2143 - val_mse: 0.2143\n",
            "\n",
            "Epoch 00146: loss improved from 0.02294 to 0.02289, saving model to poids_train.hdf5\n",
            "Epoch 147/500\n",
            "186/186 [==============================] - 1s 5ms/step - loss: 0.0221 - mse: 0.0221 - val_loss: 0.2154 - val_mse: 0.2154\n",
            "\n",
            "Epoch 00147: loss improved from 0.02289 to 0.02284, saving model to poids_train.hdf5\n",
            "Epoch 148/500\n",
            "186/186 [==============================] - 1s 5ms/step - loss: 0.0220 - mse: 0.0220 - val_loss: 0.2165 - val_mse: 0.2165\n",
            "\n",
            "Epoch 00148: loss improved from 0.02284 to 0.02279, saving model to poids_train.hdf5\n",
            "Epoch 149/500\n",
            "186/186 [==============================] - 1s 5ms/step - loss: 0.0220 - mse: 0.0220 - val_loss: 0.2176 - val_mse: 0.2176\n",
            "\n",
            "Epoch 00149: loss improved from 0.02279 to 0.02274, saving model to poids_train.hdf5\n",
            "Epoch 150/500\n",
            "186/186 [==============================] - 1s 5ms/step - loss: 0.0219 - mse: 0.0219 - val_loss: 0.2186 - val_mse: 0.2186\n",
            "\n",
            "Epoch 00150: loss improved from 0.02274 to 0.02269, saving model to poids_train.hdf5\n",
            "Epoch 151/500\n",
            "186/186 [==============================] - 1s 5ms/step - loss: 0.0218 - mse: 0.0218 - val_loss: 0.2197 - val_mse: 0.2197\n",
            "\n",
            "Epoch 00151: loss improved from 0.02269 to 0.02264, saving model to poids_train.hdf5\n",
            "Epoch 152/500\n",
            "186/186 [==============================] - 1s 5ms/step - loss: 0.0218 - mse: 0.0218 - val_loss: 0.2208 - val_mse: 0.2208\n",
            "\n",
            "Epoch 00152: loss improved from 0.02264 to 0.02260, saving model to poids_train.hdf5\n",
            "Epoch 153/500\n",
            "186/186 [==============================] - 1s 5ms/step - loss: 0.0217 - mse: 0.0217 - val_loss: 0.2218 - val_mse: 0.2218\n",
            "\n",
            "Epoch 00153: loss improved from 0.02260 to 0.02255, saving model to poids_train.hdf5\n",
            "Epoch 154/500\n",
            "186/186 [==============================] - 1s 5ms/step - loss: 0.0217 - mse: 0.0217 - val_loss: 0.2228 - val_mse: 0.2228\n",
            "\n",
            "Epoch 00154: loss improved from 0.02255 to 0.02250, saving model to poids_train.hdf5\n",
            "Epoch 155/500\n",
            "186/186 [==============================] - 1s 5ms/step - loss: 0.0216 - mse: 0.0216 - val_loss: 0.2239 - val_mse: 0.2239\n",
            "\n",
            "Epoch 00155: loss improved from 0.02250 to 0.02246, saving model to poids_train.hdf5\n",
            "Epoch 156/500\n",
            "186/186 [==============================] - 1s 5ms/step - loss: 0.0215 - mse: 0.0215 - val_loss: 0.2249 - val_mse: 0.2249\n",
            "\n",
            "Epoch 00156: loss improved from 0.02246 to 0.02241, saving model to poids_train.hdf5\n",
            "Epoch 157/500\n",
            "186/186 [==============================] - 1s 5ms/step - loss: 0.0215 - mse: 0.0215 - val_loss: 0.2259 - val_mse: 0.2259\n",
            "\n",
            "Epoch 00157: loss improved from 0.02241 to 0.02237, saving model to poids_train.hdf5\n",
            "Epoch 158/500\n",
            "186/186 [==============================] - 1s 5ms/step - loss: 0.0214 - mse: 0.0214 - val_loss: 0.2269 - val_mse: 0.2269\n",
            "\n",
            "Epoch 00158: loss improved from 0.02237 to 0.02232, saving model to poids_train.hdf5\n",
            "Epoch 159/500\n",
            "186/186 [==============================] - 1s 5ms/step - loss: 0.0214 - mse: 0.0214 - val_loss: 0.2279 - val_mse: 0.2279\n",
            "\n",
            "Epoch 00159: loss improved from 0.02232 to 0.02228, saving model to poids_train.hdf5\n",
            "Epoch 160/500\n",
            "186/186 [==============================] - 1s 5ms/step - loss: 0.0213 - mse: 0.0213 - val_loss: 0.2289 - val_mse: 0.2289\n",
            "\n",
            "Epoch 00160: loss improved from 0.02228 to 0.02224, saving model to poids_train.hdf5\n",
            "Epoch 161/500\n",
            "186/186 [==============================] - 1s 5ms/step - loss: 0.0213 - mse: 0.0213 - val_loss: 0.2298 - val_mse: 0.2298\n",
            "\n",
            "Epoch 00161: loss improved from 0.02224 to 0.02220, saving model to poids_train.hdf5\n",
            "Epoch 162/500\n",
            "186/186 [==============================] - 1s 6ms/step - loss: 0.0212 - mse: 0.0212 - val_loss: 0.2308 - val_mse: 0.2308\n",
            "\n",
            "Epoch 00162: loss improved from 0.02220 to 0.02216, saving model to poids_train.hdf5\n",
            "Epoch 163/500\n",
            "186/186 [==============================] - 1s 6ms/step - loss: 0.0212 - mse: 0.0212 - val_loss: 0.2317 - val_mse: 0.2317\n",
            "\n",
            "Epoch 00163: loss improved from 0.02216 to 0.02211, saving model to poids_train.hdf5\n",
            "Epoch 164/500\n",
            "186/186 [==============================] - 1s 5ms/step - loss: 0.0211 - mse: 0.0211 - val_loss: 0.2327 - val_mse: 0.2327\n",
            "\n",
            "Epoch 00164: loss improved from 0.02211 to 0.02207, saving model to poids_train.hdf5\n",
            "Epoch 165/500\n",
            "186/186 [==============================] - 1s 5ms/step - loss: 0.0211 - mse: 0.0211 - val_loss: 0.2336 - val_mse: 0.2336\n",
            "\n",
            "Epoch 00165: loss improved from 0.02207 to 0.02203, saving model to poids_train.hdf5\n",
            "Epoch 166/500\n",
            "186/186 [==============================] - 1s 5ms/step - loss: 0.0210 - mse: 0.0210 - val_loss: 0.2346 - val_mse: 0.2346\n",
            "\n",
            "Epoch 00166: loss improved from 0.02203 to 0.02200, saving model to poids_train.hdf5\n",
            "Epoch 167/500\n",
            "186/186 [==============================] - 1s 5ms/step - loss: 0.0210 - mse: 0.0210 - val_loss: 0.2355 - val_mse: 0.2355\n",
            "\n",
            "Epoch 00167: loss improved from 0.02200 to 0.02196, saving model to poids_train.hdf5\n",
            "Epoch 168/500\n",
            "186/186 [==============================] - 1s 5ms/step - loss: 0.0209 - mse: 0.0209 - val_loss: 0.2364 - val_mse: 0.2364\n",
            "\n",
            "Epoch 00168: loss improved from 0.02196 to 0.02192, saving model to poids_train.hdf5\n",
            "Epoch 169/500\n",
            "186/186 [==============================] - 1s 6ms/step - loss: 0.0209 - mse: 0.0209 - val_loss: 0.2374 - val_mse: 0.2374\n",
            "\n",
            "Epoch 00169: loss improved from 0.02192 to 0.02188, saving model to poids_train.hdf5\n",
            "Epoch 170/500\n",
            "186/186 [==============================] - 1s 5ms/step - loss: 0.0208 - mse: 0.0208 - val_loss: 0.2383 - val_mse: 0.2383\n",
            "\n",
            "Epoch 00170: loss improved from 0.02188 to 0.02184, saving model to poids_train.hdf5\n",
            "Epoch 171/500\n",
            "186/186 [==============================] - 1s 5ms/step - loss: 0.0208 - mse: 0.0208 - val_loss: 0.2392 - val_mse: 0.2392\n",
            "\n",
            "Epoch 00171: loss improved from 0.02184 to 0.02181, saving model to poids_train.hdf5\n",
            "Epoch 172/500\n",
            "186/186 [==============================] - 1s 5ms/step - loss: 0.0207 - mse: 0.0207 - val_loss: 0.2401 - val_mse: 0.2401\n",
            "\n",
            "Epoch 00172: loss improved from 0.02181 to 0.02177, saving model to poids_train.hdf5\n",
            "Epoch 173/500\n",
            "186/186 [==============================] - 1s 5ms/step - loss: 0.0207 - mse: 0.0207 - val_loss: 0.2409 - val_mse: 0.2409\n",
            "\n",
            "Epoch 00173: loss improved from 0.02177 to 0.02173, saving model to poids_train.hdf5\n",
            "Epoch 174/500\n",
            "186/186 [==============================] - 1s 5ms/step - loss: 0.0206 - mse: 0.0206 - val_loss: 0.2418 - val_mse: 0.2418\n",
            "\n",
            "Epoch 00174: loss improved from 0.02173 to 0.02170, saving model to poids_train.hdf5\n",
            "Epoch 175/500\n",
            "186/186 [==============================] - 1s 5ms/step - loss: 0.0206 - mse: 0.0206 - val_loss: 0.2427 - val_mse: 0.2427\n",
            "\n",
            "Epoch 00175: loss improved from 0.02170 to 0.02166, saving model to poids_train.hdf5\n",
            "Epoch 176/500\n",
            "186/186 [==============================] - 1s 5ms/step - loss: 0.0206 - mse: 0.0206 - val_loss: 0.2436 - val_mse: 0.2436\n",
            "\n",
            "Epoch 00176: loss improved from 0.02166 to 0.02163, saving model to poids_train.hdf5\n",
            "Epoch 177/500\n",
            "186/186 [==============================] - 1s 6ms/step - loss: 0.0205 - mse: 0.0205 - val_loss: 0.2444 - val_mse: 0.2444\n",
            "\n",
            "Epoch 00177: loss improved from 0.02163 to 0.02159, saving model to poids_train.hdf5\n",
            "Epoch 178/500\n",
            "186/186 [==============================] - 1s 6ms/step - loss: 0.0205 - mse: 0.0205 - val_loss: 0.2453 - val_mse: 0.2453\n",
            "\n",
            "Epoch 00178: loss improved from 0.02159 to 0.02156, saving model to poids_train.hdf5\n",
            "Epoch 179/500\n",
            "186/186 [==============================] - 1s 6ms/step - loss: 0.0204 - mse: 0.0204 - val_loss: 0.2461 - val_mse: 0.2461\n",
            "\n",
            "Epoch 00179: loss improved from 0.02156 to 0.02152, saving model to poids_train.hdf5\n",
            "Epoch 180/500\n",
            "186/186 [==============================] - 1s 5ms/step - loss: 0.0204 - mse: 0.0204 - val_loss: 0.2470 - val_mse: 0.2470\n",
            "\n",
            "Epoch 00180: loss improved from 0.02152 to 0.02149, saving model to poids_train.hdf5\n",
            "Epoch 181/500\n",
            "186/186 [==============================] - 1s 5ms/step - loss: 0.0204 - mse: 0.0204 - val_loss: 0.2478 - val_mse: 0.2478\n",
            "\n",
            "Epoch 00181: loss improved from 0.02149 to 0.02146, saving model to poids_train.hdf5\n",
            "Epoch 182/500\n",
            "186/186 [==============================] - 1s 5ms/step - loss: 0.0203 - mse: 0.0203 - val_loss: 0.2486 - val_mse: 0.2486\n",
            "\n",
            "Epoch 00182: loss improved from 0.02146 to 0.02143, saving model to poids_train.hdf5\n",
            "Epoch 183/500\n",
            "186/186 [==============================] - 1s 6ms/step - loss: 0.0203 - mse: 0.0203 - val_loss: 0.2495 - val_mse: 0.2495\n",
            "\n",
            "Epoch 00183: loss improved from 0.02143 to 0.02139, saving model to poids_train.hdf5\n",
            "Epoch 184/500\n",
            "186/186 [==============================] - 1s 5ms/step - loss: 0.0202 - mse: 0.0202 - val_loss: 0.2503 - val_mse: 0.2503\n",
            "\n",
            "Epoch 00184: loss improved from 0.02139 to 0.02136, saving model to poids_train.hdf5\n",
            "Epoch 185/500\n",
            "186/186 [==============================] - 1s 5ms/step - loss: 0.0202 - mse: 0.0202 - val_loss: 0.2511 - val_mse: 0.2511\n",
            "\n",
            "Epoch 00185: loss improved from 0.02136 to 0.02133, saving model to poids_train.hdf5\n",
            "Epoch 186/500\n",
            "186/186 [==============================] - 1s 5ms/step - loss: 0.0202 - mse: 0.0202 - val_loss: 0.2519 - val_mse: 0.2519\n",
            "\n",
            "Epoch 00186: loss improved from 0.02133 to 0.02130, saving model to poids_train.hdf5\n",
            "Epoch 187/500\n",
            "186/186 [==============================] - 1s 5ms/step - loss: 0.0201 - mse: 0.0201 - val_loss: 0.2527 - val_mse: 0.2527\n",
            "\n",
            "Epoch 00187: loss improved from 0.02130 to 0.02127, saving model to poids_train.hdf5\n",
            "Epoch 188/500\n",
            "186/186 [==============================] - 1s 5ms/step - loss: 0.0201 - mse: 0.0201 - val_loss: 0.2535 - val_mse: 0.2535\n",
            "\n",
            "Epoch 00188: loss improved from 0.02127 to 0.02124, saving model to poids_train.hdf5\n",
            "Epoch 189/500\n",
            "186/186 [==============================] - 1s 5ms/step - loss: 0.0200 - mse: 0.0200 - val_loss: 0.2543 - val_mse: 0.2543\n",
            "\n",
            "Epoch 00189: loss improved from 0.02124 to 0.02121, saving model to poids_train.hdf5\n",
            "Epoch 190/500\n",
            "186/186 [==============================] - 1s 5ms/step - loss: 0.0200 - mse: 0.0200 - val_loss: 0.2551 - val_mse: 0.2551\n",
            "\n",
            "Epoch 00190: loss improved from 0.02121 to 0.02118, saving model to poids_train.hdf5\n",
            "Epoch 191/500\n",
            "186/186 [==============================] - 1s 5ms/step - loss: 0.0200 - mse: 0.0200 - val_loss: 0.2559 - val_mse: 0.2559\n",
            "\n",
            "Epoch 00191: loss improved from 0.02118 to 0.02115, saving model to poids_train.hdf5\n",
            "Epoch 192/500\n",
            "186/186 [==============================] - 1s 5ms/step - loss: 0.0199 - mse: 0.0199 - val_loss: 0.2566 - val_mse: 0.2566\n",
            "\n",
            "Epoch 00192: loss improved from 0.02115 to 0.02112, saving model to poids_train.hdf5\n",
            "Epoch 193/500\n",
            "186/186 [==============================] - 1s 6ms/step - loss: 0.0199 - mse: 0.0199 - val_loss: 0.2574 - val_mse: 0.2574\n",
            "\n",
            "Epoch 00193: loss improved from 0.02112 to 0.02109, saving model to poids_train.hdf5\n",
            "Epoch 194/500\n",
            "186/186 [==============================] - 1s 6ms/step - loss: 0.0199 - mse: 0.0199 - val_loss: 0.2582 - val_mse: 0.2582\n",
            "\n",
            "Epoch 00194: loss improved from 0.02109 to 0.02106, saving model to poids_train.hdf5\n",
            "Epoch 195/500\n",
            "186/186 [==============================] - 1s 5ms/step - loss: 0.0198 - mse: 0.0198 - val_loss: 0.2589 - val_mse: 0.2589\n",
            "\n",
            "Epoch 00195: loss improved from 0.02106 to 0.02103, saving model to poids_train.hdf5\n",
            "Epoch 196/500\n",
            "186/186 [==============================] - 1s 5ms/step - loss: 0.0198 - mse: 0.0198 - val_loss: 0.2597 - val_mse: 0.2597\n",
            "\n",
            "Epoch 00196: loss improved from 0.02103 to 0.02100, saving model to poids_train.hdf5\n",
            "Epoch 197/500\n",
            "186/186 [==============================] - 1s 5ms/step - loss: 0.0198 - mse: 0.0198 - val_loss: 0.2605 - val_mse: 0.2605\n",
            "\n",
            "Epoch 00197: loss improved from 0.02100 to 0.02098, saving model to poids_train.hdf5\n",
            "Epoch 198/500\n",
            "186/186 [==============================] - 1s 5ms/step - loss: 0.0197 - mse: 0.0197 - val_loss: 0.2612 - val_mse: 0.2612\n",
            "\n",
            "Epoch 00198: loss improved from 0.02098 to 0.02095, saving model to poids_train.hdf5\n",
            "Epoch 199/500\n",
            "186/186 [==============================] - 1s 6ms/step - loss: 0.0197 - mse: 0.0197 - val_loss: 0.2619 - val_mse: 0.2619\n",
            "\n",
            "Epoch 00199: loss improved from 0.02095 to 0.02092, saving model to poids_train.hdf5\n",
            "Epoch 200/500\n",
            "186/186 [==============================] - 1s 5ms/step - loss: 0.0197 - mse: 0.0197 - val_loss: 0.2627 - val_mse: 0.2627\n",
            "\n",
            "Epoch 00200: loss improved from 0.02092 to 0.02089, saving model to poids_train.hdf5\n",
            "Epoch 201/500\n",
            "186/186 [==============================] - 1s 5ms/step - loss: 0.0196 - mse: 0.0196 - val_loss: 0.2634 - val_mse: 0.2634\n",
            "\n",
            "Epoch 00201: loss improved from 0.02089 to 0.02087, saving model to poids_train.hdf5\n",
            "Epoch 202/500\n",
            "186/186 [==============================] - 1s 5ms/step - loss: 0.0196 - mse: 0.0196 - val_loss: 0.2641 - val_mse: 0.2641\n",
            "\n",
            "Epoch 00202: loss improved from 0.02087 to 0.02084, saving model to poids_train.hdf5\n",
            "Epoch 203/500\n",
            "186/186 [==============================] - 1s 6ms/step - loss: 0.0196 - mse: 0.0196 - val_loss: 0.2649 - val_mse: 0.2649\n",
            "\n",
            "Epoch 00203: loss improved from 0.02084 to 0.02081, saving model to poids_train.hdf5\n",
            "Epoch 204/500\n",
            "186/186 [==============================] - 1s 6ms/step - loss: 0.0195 - mse: 0.0195 - val_loss: 0.2656 - val_mse: 0.2656\n",
            "\n",
            "Epoch 00204: loss improved from 0.02081 to 0.02079, saving model to poids_train.hdf5\n",
            "Epoch 205/500\n",
            "186/186 [==============================] - 1s 5ms/step - loss: 0.0195 - mse: 0.0195 - val_loss: 0.2663 - val_mse: 0.2663\n",
            "\n",
            "Epoch 00205: loss improved from 0.02079 to 0.02076, saving model to poids_train.hdf5\n",
            "Epoch 206/500\n",
            "186/186 [==============================] - 1s 5ms/step - loss: 0.0195 - mse: 0.0195 - val_loss: 0.2670 - val_mse: 0.2670\n",
            "\n",
            "Epoch 00206: loss improved from 0.02076 to 0.02074, saving model to poids_train.hdf5\n",
            "Epoch 207/500\n",
            "186/186 [==============================] - 1s 5ms/step - loss: 0.0194 - mse: 0.0194 - val_loss: 0.2677 - val_mse: 0.2677\n",
            "\n",
            "Epoch 00207: loss improved from 0.02074 to 0.02071, saving model to poids_train.hdf5\n",
            "Epoch 208/500\n",
            "186/186 [==============================] - 1s 5ms/step - loss: 0.0194 - mse: 0.0194 - val_loss: 0.2684 - val_mse: 0.2684\n",
            "\n",
            "Epoch 00208: loss improved from 0.02071 to 0.02069, saving model to poids_train.hdf5\n",
            "Epoch 209/500\n",
            "186/186 [==============================] - 1s 6ms/step - loss: 0.0194 - mse: 0.0194 - val_loss: 0.2691 - val_mse: 0.2691\n",
            "\n",
            "Epoch 00209: loss improved from 0.02069 to 0.02066, saving model to poids_train.hdf5\n",
            "Epoch 210/500\n",
            "186/186 [==============================] - 1s 5ms/step - loss: 0.0194 - mse: 0.0194 - val_loss: 0.2698 - val_mse: 0.2698\n",
            "\n",
            "Epoch 00210: loss improved from 0.02066 to 0.02064, saving model to poids_train.hdf5\n",
            "Epoch 211/500\n",
            "186/186 [==============================] - 1s 6ms/step - loss: 0.0193 - mse: 0.0193 - val_loss: 0.2705 - val_mse: 0.2705\n",
            "\n",
            "Epoch 00211: loss improved from 0.02064 to 0.02061, saving model to poids_train.hdf5\n",
            "Epoch 212/500\n",
            "186/186 [==============================] - 1s 6ms/step - loss: 0.0193 - mse: 0.0193 - val_loss: 0.2712 - val_mse: 0.2712\n",
            "\n",
            "Epoch 00212: loss improved from 0.02061 to 0.02059, saving model to poids_train.hdf5\n",
            "Epoch 213/500\n",
            "186/186 [==============================] - 1s 5ms/step - loss: 0.0193 - mse: 0.0193 - val_loss: 0.2718 - val_mse: 0.2718\n",
            "\n",
            "Epoch 00213: loss improved from 0.02059 to 0.02056, saving model to poids_train.hdf5\n",
            "Epoch 214/500\n",
            "186/186 [==============================] - 1s 6ms/step - loss: 0.0192 - mse: 0.0192 - val_loss: 0.2725 - val_mse: 0.2725\n",
            "\n",
            "Epoch 00214: loss improved from 0.02056 to 0.02054, saving model to poids_train.hdf5\n",
            "Epoch 215/500\n",
            "186/186 [==============================] - 1s 5ms/step - loss: 0.0192 - mse: 0.0192 - val_loss: 0.2732 - val_mse: 0.2732\n",
            "\n",
            "Epoch 00215: loss improved from 0.02054 to 0.02052, saving model to poids_train.hdf5\n",
            "Epoch 216/500\n",
            "186/186 [==============================] - 1s 5ms/step - loss: 0.0192 - mse: 0.0192 - val_loss: 0.2739 - val_mse: 0.2739\n",
            "\n",
            "Epoch 00216: loss improved from 0.02052 to 0.02049, saving model to poids_train.hdf5\n",
            "Epoch 217/500\n",
            "186/186 [==============================] - 1s 5ms/step - loss: 0.0192 - mse: 0.0192 - val_loss: 0.2745 - val_mse: 0.2745\n",
            "\n",
            "Epoch 00217: loss improved from 0.02049 to 0.02047, saving model to poids_train.hdf5\n",
            "Epoch 218/500\n",
            "186/186 [==============================] - 1s 6ms/step - loss: 0.0191 - mse: 0.0191 - val_loss: 0.2752 - val_mse: 0.2752\n",
            "\n",
            "Epoch 00218: loss improved from 0.02047 to 0.02045, saving model to poids_train.hdf5\n",
            "Epoch 219/500\n",
            "186/186 [==============================] - 1s 6ms/step - loss: 0.0191 - mse: 0.0191 - val_loss: 0.2758 - val_mse: 0.2758\n",
            "\n",
            "Epoch 00219: loss improved from 0.02045 to 0.02043, saving model to poids_train.hdf5\n",
            "Epoch 220/500\n",
            "186/186 [==============================] - 1s 6ms/step - loss: 0.0191 - mse: 0.0191 - val_loss: 0.2765 - val_mse: 0.2765\n",
            "\n",
            "Epoch 00220: loss improved from 0.02043 to 0.02040, saving model to poids_train.hdf5\n",
            "Epoch 221/500\n",
            "186/186 [==============================] - 1s 5ms/step - loss: 0.0191 - mse: 0.0191 - val_loss: 0.2771 - val_mse: 0.2771\n",
            "\n",
            "Epoch 00221: loss improved from 0.02040 to 0.02038, saving model to poids_train.hdf5\n",
            "Epoch 222/500\n",
            "186/186 [==============================] - 1s 6ms/step - loss: 0.0190 - mse: 0.0190 - val_loss: 0.2778 - val_mse: 0.2778\n",
            "\n",
            "Epoch 00222: loss improved from 0.02038 to 0.02036, saving model to poids_train.hdf5\n",
            "Epoch 223/500\n",
            "186/186 [==============================] - 1s 5ms/step - loss: 0.0190 - mse: 0.0190 - val_loss: 0.2784 - val_mse: 0.2784\n",
            "\n",
            "Epoch 00223: loss improved from 0.02036 to 0.02034, saving model to poids_train.hdf5\n",
            "Epoch 224/500\n",
            "186/186 [==============================] - 1s 5ms/step - loss: 0.0190 - mse: 0.0190 - val_loss: 0.2790 - val_mse: 0.2790\n",
            "\n",
            "Epoch 00224: loss improved from 0.02034 to 0.02031, saving model to poids_train.hdf5\n",
            "Epoch 225/500\n",
            "186/186 [==============================] - 1s 5ms/step - loss: 0.0189 - mse: 0.0189 - val_loss: 0.2797 - val_mse: 0.2797\n",
            "\n",
            "Epoch 00225: loss improved from 0.02031 to 0.02029, saving model to poids_train.hdf5\n",
            "Epoch 226/500\n",
            "186/186 [==============================] - 1s 6ms/step - loss: 0.0189 - mse: 0.0189 - val_loss: 0.2803 - val_mse: 0.2803\n",
            "\n",
            "Epoch 00226: loss improved from 0.02029 to 0.02027, saving model to poids_train.hdf5\n",
            "Epoch 227/500\n",
            "186/186 [==============================] - 1s 5ms/step - loss: 0.0189 - mse: 0.0189 - val_loss: 0.2809 - val_mse: 0.2809\n",
            "\n",
            "Epoch 00227: loss improved from 0.02027 to 0.02025, saving model to poids_train.hdf5\n",
            "Epoch 228/500\n",
            "186/186 [==============================] - 1s 6ms/step - loss: 0.0189 - mse: 0.0189 - val_loss: 0.2816 - val_mse: 0.2816\n",
            "\n",
            "Epoch 00228: loss improved from 0.02025 to 0.02023, saving model to poids_train.hdf5\n",
            "Epoch 229/500\n",
            "186/186 [==============================] - 1s 5ms/step - loss: 0.0189 - mse: 0.0189 - val_loss: 0.2822 - val_mse: 0.2822\n",
            "\n",
            "Epoch 00229: loss improved from 0.02023 to 0.02021, saving model to poids_train.hdf5\n",
            "Epoch 230/500\n",
            "186/186 [==============================] - 1s 5ms/step - loss: 0.0188 - mse: 0.0188 - val_loss: 0.2828 - val_mse: 0.2828\n",
            "\n",
            "Epoch 00230: loss improved from 0.02021 to 0.02019, saving model to poids_train.hdf5\n",
            "Epoch 231/500\n",
            "186/186 [==============================] - 1s 5ms/step - loss: 0.0188 - mse: 0.0188 - val_loss: 0.2834 - val_mse: 0.2834\n",
            "\n",
            "Epoch 00231: loss improved from 0.02019 to 0.02017, saving model to poids_train.hdf5\n",
            "Epoch 232/500\n",
            "186/186 [==============================] - 1s 6ms/step - loss: 0.0188 - mse: 0.0188 - val_loss: 0.2840 - val_mse: 0.2840\n",
            "\n",
            "Epoch 00232: loss improved from 0.02017 to 0.02015, saving model to poids_train.hdf5\n",
            "Epoch 233/500\n",
            "186/186 [==============================] - 1s 6ms/step - loss: 0.0188 - mse: 0.0188 - val_loss: 0.2846 - val_mse: 0.2846\n",
            "\n",
            "Epoch 00233: loss improved from 0.02015 to 0.02013, saving model to poids_train.hdf5\n",
            "Epoch 234/500\n",
            "186/186 [==============================] - 1s 5ms/step - loss: 0.0187 - mse: 0.0187 - val_loss: 0.2852 - val_mse: 0.2852\n",
            "\n",
            "Epoch 00234: loss improved from 0.02013 to 0.02011, saving model to poids_train.hdf5\n",
            "Epoch 235/500\n",
            "186/186 [==============================] - 1s 6ms/step - loss: 0.0187 - mse: 0.0187 - val_loss: 0.2858 - val_mse: 0.2858\n",
            "\n",
            "Epoch 00235: loss improved from 0.02011 to 0.02009, saving model to poids_train.hdf5\n",
            "Epoch 236/500\n",
            "186/186 [==============================] - 1s 6ms/step - loss: 0.0187 - mse: 0.0187 - val_loss: 0.2864 - val_mse: 0.2864\n",
            "\n",
            "Epoch 00236: loss improved from 0.02009 to 0.02007, saving model to poids_train.hdf5\n",
            "Epoch 237/500\n",
            "186/186 [==============================] - 1s 6ms/step - loss: 0.0187 - mse: 0.0187 - val_loss: 0.2870 - val_mse: 0.2870\n",
            "\n",
            "Epoch 00237: loss improved from 0.02007 to 0.02005, saving model to poids_train.hdf5\n",
            "Epoch 238/500\n",
            "186/186 [==============================] - 1s 6ms/step - loss: 0.0186 - mse: 0.0186 - val_loss: 0.2876 - val_mse: 0.2876\n",
            "\n",
            "Epoch 00238: loss improved from 0.02005 to 0.02003, saving model to poids_train.hdf5\n",
            "Epoch 239/500\n",
            "186/186 [==============================] - 1s 6ms/step - loss: 0.0186 - mse: 0.0186 - val_loss: 0.2882 - val_mse: 0.2882\n",
            "\n",
            "Epoch 00239: loss improved from 0.02003 to 0.02001, saving model to poids_train.hdf5\n",
            "Epoch 240/500\n",
            "186/186 [==============================] - 1s 5ms/step - loss: 0.0186 - mse: 0.0186 - val_loss: 0.2888 - val_mse: 0.2888\n",
            "\n",
            "Epoch 00240: loss improved from 0.02001 to 0.01999, saving model to poids_train.hdf5\n",
            "Epoch 241/500\n",
            "186/186 [==============================] - 1s 6ms/step - loss: 0.0186 - mse: 0.0186 - val_loss: 0.2893 - val_mse: 0.2893\n",
            "\n",
            "Epoch 00241: loss improved from 0.01999 to 0.01997, saving model to poids_train.hdf5\n",
            "Epoch 242/500\n",
            "186/186 [==============================] - 1s 6ms/step - loss: 0.0186 - mse: 0.0186 - val_loss: 0.2899 - val_mse: 0.2899\n",
            "\n",
            "Epoch 00242: loss improved from 0.01997 to 0.01995, saving model to poids_train.hdf5\n",
            "Epoch 243/500\n",
            "186/186 [==============================] - 1s 6ms/step - loss: 0.0185 - mse: 0.0185 - val_loss: 0.2905 - val_mse: 0.2905\n",
            "\n",
            "Epoch 00243: loss improved from 0.01995 to 0.01993, saving model to poids_train.hdf5\n",
            "Epoch 244/500\n",
            "186/186 [==============================] - 1s 6ms/step - loss: 0.0185 - mse: 0.0185 - val_loss: 0.2911 - val_mse: 0.2911\n",
            "\n",
            "Epoch 00244: loss improved from 0.01993 to 0.01991, saving model to poids_train.hdf5\n",
            "Epoch 245/500\n",
            "186/186 [==============================] - 1s 6ms/step - loss: 0.0185 - mse: 0.0185 - val_loss: 0.2916 - val_mse: 0.2916\n",
            "\n",
            "Epoch 00245: loss improved from 0.01991 to 0.01990, saving model to poids_train.hdf5\n",
            "Epoch 246/500\n",
            "186/186 [==============================] - 1s 6ms/step - loss: 0.0185 - mse: 0.0185 - val_loss: 0.2922 - val_mse: 0.2922\n",
            "\n",
            "Epoch 00246: loss improved from 0.01990 to 0.01988, saving model to poids_train.hdf5\n",
            "Epoch 247/500\n",
            "186/186 [==============================] - 1s 6ms/step - loss: 0.0184 - mse: 0.0184 - val_loss: 0.2928 - val_mse: 0.2928\n",
            "\n",
            "Epoch 00247: loss improved from 0.01988 to 0.01986, saving model to poids_train.hdf5\n",
            "Epoch 248/500\n",
            "186/186 [==============================] - 1s 5ms/step - loss: 0.0184 - mse: 0.0184 - val_loss: 0.2933 - val_mse: 0.2933\n",
            "\n",
            "Epoch 00248: loss improved from 0.01986 to 0.01984, saving model to poids_train.hdf5\n",
            "Epoch 249/500\n",
            "186/186 [==============================] - 1s 6ms/step - loss: 0.0184 - mse: 0.0184 - val_loss: 0.2939 - val_mse: 0.2939\n",
            "\n",
            "Epoch 00249: loss improved from 0.01984 to 0.01982, saving model to poids_train.hdf5\n",
            "Epoch 250/500\n",
            "186/186 [==============================] - 1s 6ms/step - loss: 0.0184 - mse: 0.0184 - val_loss: 0.2944 - val_mse: 0.2944\n",
            "\n",
            "Epoch 00250: loss improved from 0.01982 to 0.01981, saving model to poids_train.hdf5\n",
            "Epoch 251/500\n",
            "186/186 [==============================] - 1s 6ms/step - loss: 0.0184 - mse: 0.0184 - val_loss: 0.2950 - val_mse: 0.2950\n",
            "\n",
            "Epoch 00251: loss improved from 0.01981 to 0.01979, saving model to poids_train.hdf5\n",
            "Epoch 252/500\n",
            "186/186 [==============================] - 1s 6ms/step - loss: 0.0183 - mse: 0.0183 - val_loss: 0.2955 - val_mse: 0.2955\n",
            "\n",
            "Epoch 00252: loss improved from 0.01979 to 0.01977, saving model to poids_train.hdf5\n",
            "Epoch 253/500\n",
            "186/186 [==============================] - 1s 5ms/step - loss: 0.0183 - mse: 0.0183 - val_loss: 0.2961 - val_mse: 0.2961\n",
            "\n",
            "Epoch 00253: loss improved from 0.01977 to 0.01975, saving model to poids_train.hdf5\n",
            "Epoch 254/500\n",
            "186/186 [==============================] - 1s 6ms/step - loss: 0.0183 - mse: 0.0183 - val_loss: 0.2966 - val_mse: 0.2966\n",
            "\n",
            "Epoch 00254: loss improved from 0.01975 to 0.01974, saving model to poids_train.hdf5\n",
            "Epoch 255/500\n",
            "186/186 [==============================] - 1s 5ms/step - loss: 0.0183 - mse: 0.0183 - val_loss: 0.2971 - val_mse: 0.2971\n",
            "\n",
            "Epoch 00255: loss improved from 0.01974 to 0.01972, saving model to poids_train.hdf5\n",
            "Epoch 256/500\n",
            "186/186 [==============================] - 1s 5ms/step - loss: 0.0183 - mse: 0.0183 - val_loss: 0.2977 - val_mse: 0.2977\n",
            "\n",
            "Epoch 00256: loss improved from 0.01972 to 0.01970, saving model to poids_train.hdf5\n",
            "Epoch 257/500\n",
            "186/186 [==============================] - 1s 6ms/step - loss: 0.0182 - mse: 0.0182 - val_loss: 0.2982 - val_mse: 0.2982\n",
            "\n",
            "Epoch 00257: loss improved from 0.01970 to 0.01969, saving model to poids_train.hdf5\n",
            "Epoch 258/500\n",
            "186/186 [==============================] - 1s 5ms/step - loss: 0.0182 - mse: 0.0182 - val_loss: 0.2987 - val_mse: 0.2987\n",
            "\n",
            "Epoch 00258: loss improved from 0.01969 to 0.01967, saving model to poids_train.hdf5\n",
            "Epoch 259/500\n",
            "186/186 [==============================] - 1s 6ms/step - loss: 0.0182 - mse: 0.0182 - val_loss: 0.2993 - val_mse: 0.2993\n",
            "\n",
            "Epoch 00259: loss improved from 0.01967 to 0.01965, saving model to poids_train.hdf5\n",
            "Epoch 260/500\n",
            "186/186 [==============================] - 1s 6ms/step - loss: 0.0182 - mse: 0.0182 - val_loss: 0.2998 - val_mse: 0.2998\n",
            "\n",
            "Epoch 00260: loss improved from 0.01965 to 0.01964, saving model to poids_train.hdf5\n",
            "Epoch 261/500\n",
            "186/186 [==============================] - 1s 6ms/step - loss: 0.0182 - mse: 0.0182 - val_loss: 0.3003 - val_mse: 0.3003\n",
            "\n",
            "Epoch 00261: loss improved from 0.01964 to 0.01962, saving model to poids_train.hdf5\n",
            "Epoch 262/500\n",
            "186/186 [==============================] - 1s 6ms/step - loss: 0.0182 - mse: 0.0182 - val_loss: 0.3008 - val_mse: 0.3008\n",
            "\n",
            "Epoch 00262: loss improved from 0.01962 to 0.01960, saving model to poids_train.hdf5\n",
            "Epoch 263/500\n",
            "186/186 [==============================] - 1s 6ms/step - loss: 0.0181 - mse: 0.0181 - val_loss: 0.3013 - val_mse: 0.3013\n",
            "\n",
            "Epoch 00263: loss improved from 0.01960 to 0.01959, saving model to poids_train.hdf5\n",
            "Epoch 264/500\n",
            "186/186 [==============================] - 1s 6ms/step - loss: 0.0181 - mse: 0.0181 - val_loss: 0.3019 - val_mse: 0.3019\n",
            "\n",
            "Epoch 00264: loss improved from 0.01959 to 0.01957, saving model to poids_train.hdf5\n",
            "Epoch 265/500\n",
            "186/186 [==============================] - 1s 6ms/step - loss: 0.0181 - mse: 0.0181 - val_loss: 0.3024 - val_mse: 0.3024\n",
            "\n",
            "Epoch 00265: loss improved from 0.01957 to 0.01955, saving model to poids_train.hdf5\n",
            "Epoch 266/500\n",
            "186/186 [==============================] - 1s 5ms/step - loss: 0.0181 - mse: 0.0181 - val_loss: 0.3029 - val_mse: 0.3029\n",
            "\n",
            "Epoch 00266: loss improved from 0.01955 to 0.01954, saving model to poids_train.hdf5\n",
            "Epoch 267/500\n",
            "186/186 [==============================] - 1s 6ms/step - loss: 0.0181 - mse: 0.0181 - val_loss: 0.3034 - val_mse: 0.3034\n",
            "\n",
            "Epoch 00267: loss improved from 0.01954 to 0.01952, saving model to poids_train.hdf5\n",
            "Epoch 268/500\n",
            "186/186 [==============================] - 1s 6ms/step - loss: 0.0180 - mse: 0.0180 - val_loss: 0.3039 - val_mse: 0.3039\n",
            "\n",
            "Epoch 00268: loss improved from 0.01952 to 0.01951, saving model to poids_train.hdf5\n",
            "Epoch 269/500\n",
            "186/186 [==============================] - 1s 6ms/step - loss: 0.0180 - mse: 0.0180 - val_loss: 0.3044 - val_mse: 0.3044\n",
            "\n",
            "Epoch 00269: loss improved from 0.01951 to 0.01949, saving model to poids_train.hdf5\n",
            "Epoch 270/500\n",
            "186/186 [==============================] - 1s 6ms/step - loss: 0.0180 - mse: 0.0180 - val_loss: 0.3049 - val_mse: 0.3049\n",
            "\n",
            "Epoch 00270: loss improved from 0.01949 to 0.01948, saving model to poids_train.hdf5\n",
            "Epoch 271/500\n",
            "186/186 [==============================] - 1s 6ms/step - loss: 0.0180 - mse: 0.0180 - val_loss: 0.3054 - val_mse: 0.3054\n",
            "\n",
            "Epoch 00271: loss improved from 0.01948 to 0.01946, saving model to poids_train.hdf5\n",
            "Epoch 272/500\n",
            "186/186 [==============================] - 1s 5ms/step - loss: 0.0180 - mse: 0.0180 - val_loss: 0.3059 - val_mse: 0.3059\n",
            "\n",
            "Epoch 00272: loss improved from 0.01946 to 0.01945, saving model to poids_train.hdf5\n",
            "Epoch 273/500\n",
            "186/186 [==============================] - 1s 6ms/step - loss: 0.0180 - mse: 0.0180 - val_loss: 0.3064 - val_mse: 0.3064\n",
            "\n",
            "Epoch 00273: loss improved from 0.01945 to 0.01943, saving model to poids_train.hdf5\n",
            "Epoch 274/500\n",
            "186/186 [==============================] - 1s 5ms/step - loss: 0.0179 - mse: 0.0179 - val_loss: 0.3069 - val_mse: 0.3069\n",
            "\n",
            "Epoch 00274: loss improved from 0.01943 to 0.01942, saving model to poids_train.hdf5\n",
            "Epoch 275/500\n",
            "186/186 [==============================] - 1s 6ms/step - loss: 0.0179 - mse: 0.0179 - val_loss: 0.3073 - val_mse: 0.3073\n",
            "\n",
            "Epoch 00275: loss improved from 0.01942 to 0.01940, saving model to poids_train.hdf5\n",
            "Epoch 276/500\n",
            "186/186 [==============================] - 1s 5ms/step - loss: 0.0179 - mse: 0.0179 - val_loss: 0.3078 - val_mse: 0.3078\n",
            "\n",
            "Epoch 00276: loss improved from 0.01940 to 0.01939, saving model to poids_train.hdf5\n",
            "Epoch 277/500\n",
            "186/186 [==============================] - 1s 5ms/step - loss: 0.0179 - mse: 0.0179 - val_loss: 0.3083 - val_mse: 0.3083\n",
            "\n",
            "Epoch 00277: loss improved from 0.01939 to 0.01937, saving model to poids_train.hdf5\n",
            "Epoch 278/500\n",
            "186/186 [==============================] - 1s 5ms/step - loss: 0.0179 - mse: 0.0179 - val_loss: 0.3088 - val_mse: 0.3088\n",
            "\n",
            "Epoch 00278: loss improved from 0.01937 to 0.01936, saving model to poids_train.hdf5\n",
            "Epoch 279/500\n",
            "186/186 [==============================] - 1s 6ms/step - loss: 0.0179 - mse: 0.0179 - val_loss: 0.3093 - val_mse: 0.3093\n",
            "\n",
            "Epoch 00279: loss improved from 0.01936 to 0.01934, saving model to poids_train.hdf5\n",
            "Epoch 280/500\n",
            "186/186 [==============================] - 1s 6ms/step - loss: 0.0178 - mse: 0.0178 - val_loss: 0.3097 - val_mse: 0.3097\n",
            "\n",
            "Epoch 00280: loss improved from 0.01934 to 0.01933, saving model to poids_train.hdf5\n",
            "Epoch 281/500\n",
            "186/186 [==============================] - 1s 6ms/step - loss: 0.0178 - mse: 0.0178 - val_loss: 0.3102 - val_mse: 0.3102\n",
            "\n",
            "Epoch 00281: loss improved from 0.01933 to 0.01931, saving model to poids_train.hdf5\n",
            "Epoch 282/500\n",
            "186/186 [==============================] - 1s 6ms/step - loss: 0.0178 - mse: 0.0178 - val_loss: 0.3107 - val_mse: 0.3107\n",
            "\n",
            "Epoch 00282: loss improved from 0.01931 to 0.01930, saving model to poids_train.hdf5\n",
            "Epoch 283/500\n",
            "186/186 [==============================] - 1s 6ms/step - loss: 0.0178 - mse: 0.0178 - val_loss: 0.3111 - val_mse: 0.3111\n",
            "\n",
            "Epoch 00283: loss improved from 0.01930 to 0.01929, saving model to poids_train.hdf5\n",
            "Epoch 284/500\n",
            "186/186 [==============================] - 1s 6ms/step - loss: 0.0178 - mse: 0.0178 - val_loss: 0.3116 - val_mse: 0.3116\n",
            "\n",
            "Epoch 00284: loss improved from 0.01929 to 0.01927, saving model to poids_train.hdf5\n",
            "Epoch 285/500\n",
            "186/186 [==============================] - 1s 6ms/step - loss: 0.0178 - mse: 0.0178 - val_loss: 0.3121 - val_mse: 0.3121\n",
            "\n",
            "Epoch 00285: loss improved from 0.01927 to 0.01926, saving model to poids_train.hdf5\n",
            "Epoch 286/500\n",
            "186/186 [==============================] - 1s 6ms/step - loss: 0.0178 - mse: 0.0178 - val_loss: 0.3125 - val_mse: 0.3125\n",
            "\n",
            "Epoch 00286: loss improved from 0.01926 to 0.01924, saving model to poids_train.hdf5\n",
            "Epoch 287/500\n",
            "186/186 [==============================] - 1s 6ms/step - loss: 0.0177 - mse: 0.0177 - val_loss: 0.3130 - val_mse: 0.3130\n",
            "\n",
            "Epoch 00287: loss improved from 0.01924 to 0.01923, saving model to poids_train.hdf5\n",
            "Epoch 288/500\n",
            "186/186 [==============================] - 1s 6ms/step - loss: 0.0177 - mse: 0.0177 - val_loss: 0.3135 - val_mse: 0.3135\n",
            "\n",
            "Epoch 00288: loss improved from 0.01923 to 0.01922, saving model to poids_train.hdf5\n",
            "Epoch 289/500\n",
            "186/186 [==============================] - 1s 6ms/step - loss: 0.0177 - mse: 0.0177 - val_loss: 0.3139 - val_mse: 0.3139\n",
            "\n",
            "Epoch 00289: loss improved from 0.01922 to 0.01920, saving model to poids_train.hdf5\n",
            "Epoch 290/500\n",
            "186/186 [==============================] - 1s 6ms/step - loss: 0.0177 - mse: 0.0177 - val_loss: 0.3144 - val_mse: 0.3144\n",
            "\n",
            "Epoch 00290: loss improved from 0.01920 to 0.01919, saving model to poids_train.hdf5\n",
            "Epoch 291/500\n",
            "186/186 [==============================] - 1s 6ms/step - loss: 0.0177 - mse: 0.0177 - val_loss: 0.3148 - val_mse: 0.3148\n",
            "\n",
            "Epoch 00291: loss improved from 0.01919 to 0.01918, saving model to poids_train.hdf5\n",
            "Epoch 292/500\n",
            "186/186 [==============================] - 1s 6ms/step - loss: 0.0177 - mse: 0.0177 - val_loss: 0.3153 - val_mse: 0.3153\n",
            "\n",
            "Epoch 00292: loss improved from 0.01918 to 0.01916, saving model to poids_train.hdf5\n",
            "Epoch 293/500\n",
            "186/186 [==============================] - 1s 6ms/step - loss: 0.0176 - mse: 0.0176 - val_loss: 0.3157 - val_mse: 0.3157\n",
            "\n",
            "Epoch 00293: loss improved from 0.01916 to 0.01915, saving model to poids_train.hdf5\n",
            "Epoch 294/500\n",
            "186/186 [==============================] - 1s 6ms/step - loss: 0.0176 - mse: 0.0176 - val_loss: 0.3162 - val_mse: 0.3162\n",
            "\n",
            "Epoch 00294: loss improved from 0.01915 to 0.01914, saving model to poids_train.hdf5\n",
            "Epoch 295/500\n",
            "186/186 [==============================] - 1s 6ms/step - loss: 0.0176 - mse: 0.0176 - val_loss: 0.3166 - val_mse: 0.3166\n",
            "\n",
            "Epoch 00295: loss improved from 0.01914 to 0.01912, saving model to poids_train.hdf5\n",
            "Epoch 296/500\n",
            "186/186 [==============================] - 1s 6ms/step - loss: 0.0176 - mse: 0.0176 - val_loss: 0.3170 - val_mse: 0.3170\n",
            "\n",
            "Epoch 00296: loss improved from 0.01912 to 0.01911, saving model to poids_train.hdf5\n",
            "Epoch 297/500\n",
            "186/186 [==============================] - 1s 6ms/step - loss: 0.0176 - mse: 0.0176 - val_loss: 0.3175 - val_mse: 0.3175\n",
            "\n",
            "Epoch 00297: loss improved from 0.01911 to 0.01910, saving model to poids_train.hdf5\n",
            "Epoch 298/500\n",
            "186/186 [==============================] - 1s 6ms/step - loss: 0.0176 - mse: 0.0176 - val_loss: 0.3179 - val_mse: 0.3179\n",
            "\n",
            "Epoch 00298: loss improved from 0.01910 to 0.01908, saving model to poids_train.hdf5\n",
            "Epoch 299/500\n",
            "186/186 [==============================] - 1s 6ms/step - loss: 0.0176 - mse: 0.0176 - val_loss: 0.3183 - val_mse: 0.3183\n",
            "\n",
            "Epoch 00299: loss improved from 0.01908 to 0.01907, saving model to poids_train.hdf5\n",
            "Epoch 300/500\n",
            "186/186 [==============================] - 1s 6ms/step - loss: 0.0175 - mse: 0.0175 - val_loss: 0.3188 - val_mse: 0.3188\n",
            "\n",
            "Epoch 00300: loss improved from 0.01907 to 0.01906, saving model to poids_train.hdf5\n",
            "Epoch 301/500\n",
            "186/186 [==============================] - 1s 6ms/step - loss: 0.0175 - mse: 0.0175 - val_loss: 0.3192 - val_mse: 0.3192\n",
            "\n",
            "Epoch 00301: loss improved from 0.01906 to 0.01905, saving model to poids_train.hdf5\n",
            "Epoch 302/500\n",
            "186/186 [==============================] - 1s 6ms/step - loss: 0.0175 - mse: 0.0175 - val_loss: 0.3196 - val_mse: 0.3196\n",
            "\n",
            "Epoch 00302: loss improved from 0.01905 to 0.01903, saving model to poids_train.hdf5\n",
            "Epoch 303/500\n",
            "186/186 [==============================] - 1s 6ms/step - loss: 0.0175 - mse: 0.0175 - val_loss: 0.3201 - val_mse: 0.3201\n",
            "\n",
            "Epoch 00303: loss improved from 0.01903 to 0.01902, saving model to poids_train.hdf5\n",
            "Epoch 304/500\n",
            "186/186 [==============================] - 1s 6ms/step - loss: 0.0175 - mse: 0.0175 - val_loss: 0.3205 - val_mse: 0.3205\n",
            "\n",
            "Epoch 00304: loss improved from 0.01902 to 0.01901, saving model to poids_train.hdf5\n",
            "Epoch 305/500\n",
            "186/186 [==============================] - 1s 5ms/step - loss: 0.0175 - mse: 0.0175 - val_loss: 0.3209 - val_mse: 0.3209\n",
            "\n",
            "Epoch 00305: loss improved from 0.01901 to 0.01900, saving model to poids_train.hdf5\n",
            "Epoch 306/500\n",
            "186/186 [==============================] - 1s 6ms/step - loss: 0.0175 - mse: 0.0175 - val_loss: 0.3213 - val_mse: 0.3213\n",
            "\n",
            "Epoch 00306: loss improved from 0.01900 to 0.01898, saving model to poids_train.hdf5\n",
            "Epoch 307/500\n",
            "186/186 [==============================] - 1s 6ms/step - loss: 0.0174 - mse: 0.0174 - val_loss: 0.3218 - val_mse: 0.3218\n",
            "\n",
            "Epoch 00307: loss improved from 0.01898 to 0.01897, saving model to poids_train.hdf5\n",
            "Epoch 308/500\n",
            "186/186 [==============================] - 1s 6ms/step - loss: 0.0174 - mse: 0.0174 - val_loss: 0.3222 - val_mse: 0.3222\n",
            "\n",
            "Epoch 00308: loss improved from 0.01897 to 0.01896, saving model to poids_train.hdf5\n",
            "Epoch 309/500\n",
            "186/186 [==============================] - 1s 6ms/step - loss: 0.0174 - mse: 0.0174 - val_loss: 0.3226 - val_mse: 0.3226\n",
            "\n",
            "Epoch 00309: loss improved from 0.01896 to 0.01895, saving model to poids_train.hdf5\n",
            "Epoch 310/500\n",
            "186/186 [==============================] - 1s 5ms/step - loss: 0.0174 - mse: 0.0174 - val_loss: 0.3230 - val_mse: 0.3230\n",
            "\n",
            "Epoch 00310: loss improved from 0.01895 to 0.01894, saving model to poids_train.hdf5\n",
            "Epoch 311/500\n",
            "186/186 [==============================] - 1s 6ms/step - loss: 0.0174 - mse: 0.0174 - val_loss: 0.3234 - val_mse: 0.3234\n",
            "\n",
            "Epoch 00311: loss improved from 0.01894 to 0.01892, saving model to poids_train.hdf5\n",
            "Epoch 312/500\n",
            "186/186 [==============================] - 1s 6ms/step - loss: 0.0174 - mse: 0.0174 - val_loss: 0.3238 - val_mse: 0.3238\n",
            "\n",
            "Epoch 00312: loss improved from 0.01892 to 0.01891, saving model to poids_train.hdf5\n",
            "Epoch 313/500\n",
            "186/186 [==============================] - 1s 6ms/step - loss: 0.0174 - mse: 0.0174 - val_loss: 0.3242 - val_mse: 0.3242\n",
            "\n",
            "Epoch 00313: loss improved from 0.01891 to 0.01890, saving model to poids_train.hdf5\n",
            "Epoch 314/500\n",
            "186/186 [==============================] - 1s 5ms/step - loss: 0.0174 - mse: 0.0174 - val_loss: 0.3246 - val_mse: 0.3246\n",
            "\n",
            "Epoch 00314: loss improved from 0.01890 to 0.01889, saving model to poids_train.hdf5\n",
            "Epoch 315/500\n",
            "186/186 [==============================] - 1s 6ms/step - loss: 0.0173 - mse: 0.0173 - val_loss: 0.3250 - val_mse: 0.3250\n",
            "\n",
            "Epoch 00315: loss improved from 0.01889 to 0.01888, saving model to poids_train.hdf5\n",
            "Epoch 316/500\n",
            "186/186 [==============================] - 1s 6ms/step - loss: 0.0173 - mse: 0.0173 - val_loss: 0.3254 - val_mse: 0.3254\n",
            "\n",
            "Epoch 00316: loss improved from 0.01888 to 0.01887, saving model to poids_train.hdf5\n",
            "Epoch 317/500\n",
            "186/186 [==============================] - 1s 6ms/step - loss: 0.0173 - mse: 0.0173 - val_loss: 0.3258 - val_mse: 0.3258\n",
            "\n",
            "Epoch 00317: loss improved from 0.01887 to 0.01885, saving model to poids_train.hdf5\n",
            "Epoch 318/500\n",
            "186/186 [==============================] - 1s 6ms/step - loss: 0.0173 - mse: 0.0173 - val_loss: 0.3262 - val_mse: 0.3262\n",
            "\n",
            "Epoch 00318: loss improved from 0.01885 to 0.01884, saving model to poids_train.hdf5\n",
            "Epoch 319/500\n",
            "186/186 [==============================] - 1s 6ms/step - loss: 0.0173 - mse: 0.0173 - val_loss: 0.3266 - val_mse: 0.3266\n",
            "\n",
            "Epoch 00319: loss improved from 0.01884 to 0.01883, saving model to poids_train.hdf5\n",
            "Epoch 320/500\n",
            "186/186 [==============================] - 1s 6ms/step - loss: 0.0173 - mse: 0.0173 - val_loss: 0.3270 - val_mse: 0.3270\n",
            "\n",
            "Epoch 00320: loss improved from 0.01883 to 0.01882, saving model to poids_train.hdf5\n",
            "Epoch 321/500\n",
            "186/186 [==============================] - 1s 6ms/step - loss: 0.0173 - mse: 0.0173 - val_loss: 0.3274 - val_mse: 0.3274\n",
            "\n",
            "Epoch 00321: loss improved from 0.01882 to 0.01881, saving model to poids_train.hdf5\n",
            "Epoch 322/500\n",
            "186/186 [==============================] - 1s 6ms/step - loss: 0.0173 - mse: 0.0173 - val_loss: 0.3278 - val_mse: 0.3278\n",
            "\n",
            "Epoch 00322: loss improved from 0.01881 to 0.01880, saving model to poids_train.hdf5\n",
            "Epoch 323/500\n",
            "186/186 [==============================] - 1s 6ms/step - loss: 0.0172 - mse: 0.0172 - val_loss: 0.3282 - val_mse: 0.3282\n",
            "\n",
            "Epoch 00323: loss improved from 0.01880 to 0.01879, saving model to poids_train.hdf5\n",
            "Epoch 324/500\n",
            "186/186 [==============================] - 1s 6ms/step - loss: 0.0172 - mse: 0.0172 - val_loss: 0.3286 - val_mse: 0.3286\n",
            "\n",
            "Epoch 00324: loss improved from 0.01879 to 0.01877, saving model to poids_train.hdf5\n",
            "Epoch 325/500\n",
            "186/186 [==============================] - 1s 6ms/step - loss: 0.0172 - mse: 0.0172 - val_loss: 0.3290 - val_mse: 0.3290\n",
            "\n",
            "Epoch 00325: loss improved from 0.01877 to 0.01876, saving model to poids_train.hdf5\n",
            "Epoch 326/500\n",
            "186/186 [==============================] - 1s 6ms/step - loss: 0.0172 - mse: 0.0172 - val_loss: 0.3294 - val_mse: 0.3294\n",
            "\n",
            "Epoch 00326: loss improved from 0.01876 to 0.01875, saving model to poids_train.hdf5\n",
            "Epoch 327/500\n",
            "186/186 [==============================] - 1s 6ms/step - loss: 0.0172 - mse: 0.0172 - val_loss: 0.3297 - val_mse: 0.3297\n",
            "\n",
            "Epoch 00327: loss improved from 0.01875 to 0.01874, saving model to poids_train.hdf5\n",
            "Epoch 328/500\n",
            "186/186 [==============================] - 1s 6ms/step - loss: 0.0172 - mse: 0.0172 - val_loss: 0.3301 - val_mse: 0.3301\n",
            "\n",
            "Epoch 00328: loss improved from 0.01874 to 0.01873, saving model to poids_train.hdf5\n",
            "Epoch 329/500\n",
            "186/186 [==============================] - 1s 6ms/step - loss: 0.0172 - mse: 0.0172 - val_loss: 0.3305 - val_mse: 0.3305\n",
            "\n",
            "Epoch 00329: loss improved from 0.01873 to 0.01872, saving model to poids_train.hdf5\n",
            "Epoch 330/500\n",
            "186/186 [==============================] - 1s 6ms/step - loss: 0.0172 - mse: 0.0172 - val_loss: 0.3309 - val_mse: 0.3309\n",
            "\n",
            "Epoch 00330: loss improved from 0.01872 to 0.01871, saving model to poids_train.hdf5\n",
            "Epoch 331/500\n",
            "186/186 [==============================] - 1s 6ms/step - loss: 0.0172 - mse: 0.0172 - val_loss: 0.3313 - val_mse: 0.3313\n",
            "\n",
            "Epoch 00331: loss improved from 0.01871 to 0.01870, saving model to poids_train.hdf5\n",
            "Epoch 332/500\n",
            "186/186 [==============================] - 1s 5ms/step - loss: 0.0171 - mse: 0.0171 - val_loss: 0.3316 - val_mse: 0.3316\n",
            "\n",
            "Epoch 00332: loss improved from 0.01870 to 0.01869, saving model to poids_train.hdf5\n",
            "Epoch 333/500\n",
            "186/186 [==============================] - 1s 5ms/step - loss: 0.0171 - mse: 0.0171 - val_loss: 0.3320 - val_mse: 0.3320\n",
            "\n",
            "Epoch 00333: loss improved from 0.01869 to 0.01868, saving model to poids_train.hdf5\n",
            "Epoch 334/500\n",
            "186/186 [==============================] - 1s 6ms/step - loss: 0.0171 - mse: 0.0171 - val_loss: 0.3324 - val_mse: 0.3324\n",
            "\n",
            "Epoch 00334: loss improved from 0.01868 to 0.01867, saving model to poids_train.hdf5\n",
            "Epoch 335/500\n",
            "186/186 [==============================] - 1s 6ms/step - loss: 0.0171 - mse: 0.0171 - val_loss: 0.3328 - val_mse: 0.3328\n",
            "\n",
            "Epoch 00335: loss improved from 0.01867 to 0.01866, saving model to poids_train.hdf5\n",
            "Epoch 336/500\n",
            "186/186 [==============================] - 1s 6ms/step - loss: 0.0171 - mse: 0.0171 - val_loss: 0.3331 - val_mse: 0.3331\n",
            "\n",
            "Epoch 00336: loss improved from 0.01866 to 0.01865, saving model to poids_train.hdf5\n",
            "Epoch 337/500\n",
            "186/186 [==============================] - 1s 6ms/step - loss: 0.0171 - mse: 0.0171 - val_loss: 0.3335 - val_mse: 0.3335\n",
            "\n",
            "Epoch 00337: loss improved from 0.01865 to 0.01864, saving model to poids_train.hdf5\n",
            "Epoch 338/500\n",
            "186/186 [==============================] - 1s 6ms/step - loss: 0.0171 - mse: 0.0171 - val_loss: 0.3339 - val_mse: 0.3339\n",
            "\n",
            "Epoch 00338: loss improved from 0.01864 to 0.01863, saving model to poids_train.hdf5\n",
            "Epoch 339/500\n",
            "186/186 [==============================] - 1s 6ms/step - loss: 0.0171 - mse: 0.0171 - val_loss: 0.3342 - val_mse: 0.3342\n",
            "\n",
            "Epoch 00339: loss improved from 0.01863 to 0.01862, saving model to poids_train.hdf5\n",
            "Epoch 340/500\n",
            "186/186 [==============================] - 1s 6ms/step - loss: 0.0171 - mse: 0.0171 - val_loss: 0.3346 - val_mse: 0.3346\n",
            "\n",
            "Epoch 00340: loss improved from 0.01862 to 0.01861, saving model to poids_train.hdf5\n",
            "Epoch 341/500\n",
            "186/186 [==============================] - 1s 6ms/step - loss: 0.0170 - mse: 0.0170 - val_loss: 0.3349 - val_mse: 0.3349\n",
            "\n",
            "Epoch 00341: loss improved from 0.01861 to 0.01860, saving model to poids_train.hdf5\n",
            "Epoch 342/500\n",
            "186/186 [==============================] - 1s 6ms/step - loss: 0.0170 - mse: 0.0170 - val_loss: 0.3353 - val_mse: 0.3353\n",
            "\n",
            "Epoch 00342: loss improved from 0.01860 to 0.01859, saving model to poids_train.hdf5\n",
            "Epoch 343/500\n",
            "186/186 [==============================] - 1s 6ms/step - loss: 0.0170 - mse: 0.0170 - val_loss: 0.3357 - val_mse: 0.3357\n",
            "\n",
            "Epoch 00343: loss improved from 0.01859 to 0.01858, saving model to poids_train.hdf5\n",
            "Epoch 344/500\n",
            "186/186 [==============================] - 1s 6ms/step - loss: 0.0170 - mse: 0.0170 - val_loss: 0.3360 - val_mse: 0.3360\n",
            "\n",
            "Epoch 00344: loss improved from 0.01858 to 0.01857, saving model to poids_train.hdf5\n",
            "Epoch 345/500\n",
            "186/186 [==============================] - 1s 6ms/step - loss: 0.0170 - mse: 0.0170 - val_loss: 0.3364 - val_mse: 0.3364\n",
            "\n",
            "Epoch 00345: loss improved from 0.01857 to 0.01856, saving model to poids_train.hdf5\n",
            "Epoch 346/500\n",
            "186/186 [==============================] - 1s 6ms/step - loss: 0.0170 - mse: 0.0170 - val_loss: 0.3367 - val_mse: 0.3367\n",
            "\n",
            "Epoch 00346: loss improved from 0.01856 to 0.01855, saving model to poids_train.hdf5\n",
            "Epoch 347/500\n",
            "186/186 [==============================] - 1s 6ms/step - loss: 0.0170 - mse: 0.0170 - val_loss: 0.3371 - val_mse: 0.3371\n",
            "\n",
            "Epoch 00347: loss improved from 0.01855 to 0.01854, saving model to poids_train.hdf5\n",
            "Epoch 348/500\n",
            "186/186 [==============================] - 1s 6ms/step - loss: 0.0170 - mse: 0.0170 - val_loss: 0.3374 - val_mse: 0.3374\n",
            "\n",
            "Epoch 00348: loss improved from 0.01854 to 0.01853, saving model to poids_train.hdf5\n",
            "Epoch 349/500\n",
            "186/186 [==============================] - 1s 6ms/step - loss: 0.0170 - mse: 0.0170 - val_loss: 0.3378 - val_mse: 0.3378\n",
            "\n",
            "Epoch 00349: loss improved from 0.01853 to 0.01852, saving model to poids_train.hdf5\n",
            "Epoch 350/500\n",
            "186/186 [==============================] - 1s 6ms/step - loss: 0.0169 - mse: 0.0169 - val_loss: 0.3381 - val_mse: 0.3381\n",
            "\n",
            "Epoch 00350: loss improved from 0.01852 to 0.01851, saving model to poids_train.hdf5\n",
            "Epoch 351/500\n",
            "186/186 [==============================] - 1s 6ms/step - loss: 0.0169 - mse: 0.0169 - val_loss: 0.3385 - val_mse: 0.3385\n",
            "\n",
            "Epoch 00351: loss improved from 0.01851 to 0.01850, saving model to poids_train.hdf5\n",
            "Epoch 352/500\n",
            "186/186 [==============================] - 1s 6ms/step - loss: 0.0169 - mse: 0.0169 - val_loss: 0.3388 - val_mse: 0.3388\n",
            "\n",
            "Epoch 00352: loss improved from 0.01850 to 0.01849, saving model to poids_train.hdf5\n",
            "Epoch 353/500\n",
            "186/186 [==============================] - 1s 6ms/step - loss: 0.0169 - mse: 0.0169 - val_loss: 0.3392 - val_mse: 0.3392\n",
            "\n",
            "Epoch 00353: loss improved from 0.01849 to 0.01848, saving model to poids_train.hdf5\n",
            "Arrêt de l'entrainement...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CfbomV0LS9LD"
      },
      "source": [
        "model.load_weights(\"poids_train.hdf5\")"
      ],
      "execution_count": 181,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8MDY8O1-l6kN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        },
        "outputId": "96ec1285-a8a2-4e4a-ea50-8d4df17cddf7"
      },
      "source": [
        "erreur_entrainement = historique.history[\"loss\"]\n",
        "#erreur_validation = historique.history[\"val_loss\"]\n",
        "\n",
        "# Affiche l'erreur en fonction de la période\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(np.arange(0,len(erreur_entrainement)),erreur_entrainement, label=\"Erreurs sur les entrainements\")\n",
        "#plt.plot(np.arange(0,len(erreur_entrainement)),erreur_validation, label =\"Erreurs sur les validations\")\n",
        "plt.legend()\n",
        "\n",
        "plt.title(\"Evolution de l'erreur en fonction de la période\")"
      ],
      "execution_count": 182,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, \"Evolution de l'erreur en fonction de la période\")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 182
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uEuSDQ6vZnBm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8dbe0134-e629-44ae-888a-da1a149de590"
      },
      "source": [
        "# Evaluation du modèle\n",
        "\n",
        "model.evaluate(dataset)\n",
        "model.evaluate(dataset_val)\n"
      ],
      "execution_count": 183,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "186/186 [==============================] - 0s 2ms/step - loss: 0.0176 - mse: 0.0176\n",
            "187/187 [==============================] - 0s 2ms/step - loss: 0.3392 - mse: 0.3392\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.3391560912132263, 0.3391560912132263]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 183
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lbzro22hgt4b"
      },
      "source": [
        "**3. Prédictions**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wMmVn1e5zEAm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7cf8ca79-504c-48e9-9ec9-5eb7a75b86a8"
      },
      "source": [
        "# Création des instants d'entrainement et de validation\n",
        "y_train_timing = serie_entrainement.index[taille_fenetre + horizon-1:]\n",
        "y_val_timing = serie_test.index[taille_fenetre + horizon-1:]\n",
        "\n",
        "# Calcul des prédictions\n",
        "pred_ent = model.predict(x_train, verbose=1)\n",
        "pred_val = model.predict(x_val, verbose=1)"
      ],
      "execution_count": 184,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "6/6 [==============================] - 0s 2ms/step\n",
            "6/6 [==============================] - 0s 2ms/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ZklNPJ5NAQv",
        "outputId": "e600407d-843f-4821-8aec-50c153001b20",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        }
      },
      "source": [
        "import plotly.graph_objects as go\n",
        "\n",
        "fig = go.Figure()\n",
        "\n",
        "tmax = len(np.asarray(predictions)[:,0])\n",
        "\n",
        "\n",
        "fig.add_trace(go.Scatter(x=serie_entrainement.index,y=serie_entrainement,line=dict(color='blue', width=1),name=\"true\"))\n",
        "fig.add_trace(go.Scatter(x=serie_test.index,y=serie_test,line=dict(color='green', width=1),name=\"true\"))\n",
        "\n",
        "# Courbes des prédictions d'entrainement\n",
        "fig.add_trace(go.Scatter(x=y_train_timing,y=pred_ent[:,0],line=dict(color='red', width=1),name=\"Prédiction\"))\n",
        "fig.add_trace(go.Scatter(x=y_val_timing,y=pred_val[:,0],line=dict(color='red', width=1)))\n",
        "\n",
        "fig.update_xaxes(rangeslider_visible=True)\n",
        "yaxis=dict(autorange = True,fixedrange= False)\n",
        "fig.update_yaxes(yaxis)\n",
        "fig.show()"
      ],
      "execution_count": 185,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>\n",
              "            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>\n",
              "                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-latest.min.js\"></script>    \n",
              "            <div id=\"146cfa8b-2ad2-4d3f-84e0-544203206cf6\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>\n",
              "            <script type=\"text/javascript\">\n",
              "                \n",
              "                    window.PLOTLYENV=window.PLOTLYENV || {};\n",
              "                    \n",
              "                if (document.getElementById(\"146cfa8b-2ad2-4d3f-84e0-544203206cf6\")) {\n",
              "                    Plotly.newPlot(\n",
              "                        '146cfa8b-2ad2-4d3f-84e0-544203206cf6',\n",
              "                        [{\"line\": {\"color\": \"blue\", \"width\": 1}, \"name\": \"true\", \"type\": \"scatter\", \"x\": [\"2020-03-18T00:00:00\", \"2020-03-19T00:00:00\", \"2020-03-20T00:00:00\", \"2020-03-21T00:00:00\", \"2020-03-22T00:00:00\", \"2020-03-23T00:00:00\", \"2020-03-24T00:00:00\", \"2020-03-25T00:00:00\", \"2020-03-26T00:00:00\", \"2020-03-27T00:00:00\", \"2020-03-28T00:00:00\", \"2020-03-29T00:00:00\", \"2020-03-30T00:00:00\", \"2020-03-31T00:00:00\", \"2020-04-01T00:00:00\", \"2020-04-02T00:00:00\", \"2020-04-03T00:00:00\", \"2020-04-04T00:00:00\", \"2020-04-05T00:00:00\", \"2020-04-06T00:00:00\", \"2020-04-07T00:00:00\", \"2020-04-08T00:00:00\", \"2020-04-09T00:00:00\", \"2020-04-10T00:00:00\", \"2020-04-11T00:00:00\", \"2020-04-12T00:00:00\", \"2020-04-13T00:00:00\", \"2020-04-14T00:00:00\", \"2020-04-15T00:00:00\", \"2020-04-16T00:00:00\", \"2020-04-17T00:00:00\", \"2020-04-18T00:00:00\", \"2020-04-19T00:00:00\", \"2020-04-20T00:00:00\", \"2020-04-21T00:00:00\", \"2020-04-22T00:00:00\", \"2020-04-23T00:00:00\", \"2020-04-24T00:00:00\", \"2020-04-25T00:00:00\", \"2020-04-26T00:00:00\", \"2020-04-27T00:00:00\", \"2020-04-28T00:00:00\", \"2020-04-29T00:00:00\", \"2020-04-30T00:00:00\", \"2020-05-01T00:00:00\", \"2020-05-02T00:00:00\", \"2020-05-03T00:00:00\", \"2020-05-04T00:00:00\", \"2020-05-05T00:00:00\", \"2020-05-06T00:00:00\", \"2020-05-07T00:00:00\", \"2020-05-08T00:00:00\", \"2020-05-09T00:00:00\", \"2020-05-10T00:00:00\", \"2020-05-11T00:00:00\", \"2020-05-12T00:00:00\", \"2020-05-13T00:00:00\", \"2020-05-14T00:00:00\", \"2020-05-15T00:00:00\", \"2020-05-16T00:00:00\", \"2020-05-17T00:00:00\", \"2020-05-18T00:00:00\", \"2020-05-19T00:00:00\", \"2020-05-20T00:00:00\", \"2020-05-21T00:00:00\", \"2020-05-22T00:00:00\", \"2020-05-23T00:00:00\", \"2020-05-24T00:00:00\", \"2020-05-25T00:00:00\", \"2020-05-26T00:00:00\", \"2020-05-27T00:00:00\", \"2020-05-28T00:00:00\", \"2020-05-29T00:00:00\", \"2020-05-30T00:00:00\", \"2020-05-31T00:00:00\", \"2020-06-01T00:00:00\", \"2020-06-02T00:00:00\", \"2020-06-03T00:00:00\", \"2020-06-04T00:00:00\", \"2020-06-05T00:00:00\", \"2020-06-06T00:00:00\", \"2020-06-07T00:00:00\", \"2020-06-08T00:00:00\", \"2020-06-09T00:00:00\", \"2020-06-10T00:00:00\", \"2020-06-11T00:00:00\", \"2020-06-12T00:00:00\", \"2020-06-13T00:00:00\", \"2020-06-14T00:00:00\", \"2020-06-15T00:00:00\", \"2020-06-16T00:00:00\", \"2020-06-17T00:00:00\", \"2020-06-18T00:00:00\", \"2020-06-19T00:00:00\", \"2020-06-20T00:00:00\", \"2020-06-21T00:00:00\", \"2020-06-22T00:00:00\", \"2020-06-23T00:00:00\", \"2020-06-24T00:00:00\", \"2020-06-25T00:00:00\", \"2020-06-26T00:00:00\", \"2020-06-27T00:00:00\", \"2020-06-28T00:00:00\", \"2020-06-29T00:00:00\", \"2020-06-30T00:00:00\", \"2020-07-01T00:00:00\", \"2020-07-02T00:00:00\", \"2020-07-03T00:00:00\", \"2020-07-04T00:00:00\", \"2020-07-05T00:00:00\", \"2020-07-06T00:00:00\", \"2020-07-07T00:00:00\", \"2020-07-08T00:00:00\", \"2020-07-09T00:00:00\", \"2020-07-10T00:00:00\", \"2020-07-11T00:00:00\", \"2020-07-12T00:00:00\", \"2020-07-13T00:00:00\", \"2020-07-14T00:00:00\", \"2020-07-15T00:00:00\", \"2020-07-16T00:00:00\", \"2020-07-17T00:00:00\", \"2020-07-18T00:00:00\", \"2020-07-19T00:00:00\", \"2020-07-20T00:00:00\", \"2020-07-21T00:00:00\", \"2020-07-22T00:00:00\", \"2020-07-23T00:00:00\", \"2020-07-24T00:00:00\", \"2020-07-25T00:00:00\", \"2020-07-26T00:00:00\", \"2020-07-27T00:00:00\", \"2020-07-28T00:00:00\", \"2020-07-29T00:00:00\", \"2020-07-30T00:00:00\", \"2020-07-31T00:00:00\", \"2020-08-01T00:00:00\", \"2020-08-02T00:00:00\", \"2020-08-03T00:00:00\", \"2020-08-04T00:00:00\", \"2020-08-05T00:00:00\", \"2020-08-06T00:00:00\", \"2020-08-07T00:00:00\", \"2020-08-08T00:00:00\", \"2020-08-09T00:00:00\", \"2020-08-10T00:00:00\", \"2020-08-11T00:00:00\", \"2020-08-12T00:00:00\", \"2020-08-13T00:00:00\", \"2020-08-14T00:00:00\", \"2020-08-15T00:00:00\", \"2020-08-16T00:00:00\", \"2020-08-17T00:00:00\", \"2020-08-18T00:00:00\", \"2020-08-19T00:00:00\", \"2020-08-20T00:00:00\", \"2020-08-21T00:00:00\", \"2020-08-22T00:00:00\", \"2020-08-23T00:00:00\", \"2020-08-24T00:00:00\", \"2020-08-25T00:00:00\", \"2020-08-26T00:00:00\", \"2020-08-27T00:00:00\", \"2020-08-28T00:00:00\", \"2020-08-29T00:00:00\", \"2020-08-30T00:00:00\", \"2020-08-31T00:00:00\", \"2020-09-01T00:00:00\", \"2020-09-02T00:00:00\", \"2020-09-03T00:00:00\", \"2020-09-04T00:00:00\", \"2020-09-05T00:00:00\", \"2020-09-06T00:00:00\", \"2020-09-07T00:00:00\", \"2020-09-08T00:00:00\", \"2020-09-09T00:00:00\", \"2020-09-10T00:00:00\", \"2020-09-11T00:00:00\", \"2020-09-12T00:00:00\", \"2020-09-13T00:00:00\", \"2020-09-14T00:00:00\", \"2020-09-15T00:00:00\", \"2020-09-16T00:00:00\", \"2020-09-17T00:00:00\", \"2020-09-18T00:00:00\", \"2020-09-19T00:00:00\", \"2020-09-20T00:00:00\", \"2020-09-21T00:00:00\", \"2020-09-22T00:00:00\", \"2020-09-23T00:00:00\", \"2020-09-24T00:00:00\", \"2020-09-25T00:00:00\", \"2020-09-26T00:00:00\", \"2020-09-27T00:00:00\", \"2020-09-28T00:00:00\", \"2020-09-29T00:00:00\", \"2020-09-30T00:00:00\", \"2020-10-01T00:00:00\", \"2020-10-02T00:00:00\", \"2020-10-03T00:00:00\"], \"y\": [-0.7101431396027159, -0.7101431396027159, -0.7101431396027159, -0.7101431396027159, -0.7101431396027159, -0.7101431396027159, -0.7101431396027159, -0.7101431396027159, -0.7101431396027159, -0.7101431396027159, -0.7101431396027159, -0.7101431396027159, -0.7101431396027159, -0.7101431396027159, -0.7101431396027159, -0.7101431396027159, -0.7101431396027159, -0.7101431396027159, -0.7101431396027159, -0.7101431396027159, -0.7101431396027159, -0.7101431396027159, -0.7101431396027159, -0.7101431396027159, -0.7101431396027159, -0.7101431396027159, -0.7101431396027159, -0.7101431396027159, -0.7101431396027159, -0.7101431396027159, -0.7101431396027159, -0.7101431396027159, -0.7101431396027159, -0.7101431396027159, -0.7101431396027159, -0.7101431396027159, -0.7101431396027159, -0.7101431396027159, -0.7101431396027159, -0.7101431396027159, -0.7101431396027159, -0.7101431396027159, -0.7101431396027159, -0.7101431396027159, -0.7101431396027159, -0.6496301051838075, -0.5549791147171378, -0.4453167764541238, -0.32929449021508855, -0.2994120875924591, -0.2972609287182167, -0.10650925376093122, 0.01807090365172089, 0.14120136704042696, 0.3405109131713292, 0.5106395215298984, 0.5825630508469627, 0.5925238517211724, 0.7875778444269429, 1.0929488759226706, 1.3733945230711975, 1.6275118561719297, 1.9699202317633109, 2.0830898942778076, 2.1165731497986253, 2.427649428743431, 2.701688363592583, 2.940841113220325, 3.1138223453034333, 3.1466041359739547, 3.173633914872045, 3.1771880034468802, 3.2796954002368706, 3.329499404607919, 3.1935555166204646, 3.0675724295072193, 2.8952926622744077, 2.8020446015083307, 2.776417752310833, 2.446869565641554, 2.0304332661822198, 1.396168748544156, 1.1427528802937197, 0.9292269798634756, 0.8573034505464114, 0.8494938085464443, 0.6402234615413323, 0.4173914607638217, 0.5910741576972264, 0.3654362975185302, 0.1846454234354548, 0.12057830044171103, 0.11061749956750125, -0.06591782109044254, -0.1833898013534239, -0.26667706124529067, -0.29585799901762366, -0.3464102325623223, -0.3342982728138699, -0.33715089653840896, -0.4090276615321201, -0.441061223028992, -0.4339530458793211, -0.5037254163221428, -0.5243484829208589, -0.5393130663938501, -0.5393130663938501, -0.5165388409208915, -0.48450527942401966, -0.5008727925976039, -0.486609673974909, -0.4830555854000736, -0.47454447854980986, -0.47309478452586384, -0.4773503379509957, -0.46313398365165404, -0.46028135992711505, -0.43325158102902456, -0.3620295165622569, -0.2873001278440069, -0.20901665055092136, -0.21967891627542763, -0.18479273105401672, -0.17342900047921397, -0.22608562857480202, -0.4076247318315271, -0.4702421608013248, -0.5428671549686854, -0.5257514126214518, -0.5528279558428953, -0.5214958591963199, -0.48590820912461263, -0.49091199172339406, -0.48165265569948074, -0.4759474082504027, -0.41898846240632986, -0.38410227718491896, -0.40046979035850316, -0.37128885258617017, -0.19405206707793016, -0.21041958025151433, -0.19760615565276554, -0.2360464294490118, -0.27163407952071905, -0.251011012922003, -0.25386363664654205, -0.26667706124529067, -0.2567162603710809, -0.28159488039492897, -0.24105021204779323, -0.21542336285029576, -0.21327220397605323, -0.19550176110187606, -0.19690469080246906, -0.17268077130556442, -0.16271997043135464, -0.1328375678087253, -0.10010254146155695, -0.10010254146155695, -0.10295516518609583, -0.0730259982401133, -0.06947190966527793, -0.07377422741376286, -0.06591782109044254, -0.08658765201251165, -0.04884884306656187, -0.030330171018735162, -0.04955030791685836, -0.07873124568919121, -0.08303356343767627, -0.1698749119043786, -0.1698749119043786, -0.20901665055092136, -0.251011012922003, -0.2823431095685785, -0.2830445744188749, -0.2823431095685785, -0.27238230869436875, -0.3115240473409114, -0.33785236138870545, -0.32288777791571416, -0.32503893678995666, -0.32003515419117523, -0.31362844189180084, -0.28159488039492897, -0.2709326146704227, -0.2360464294490118, -0.25386363664654205, -0.2396005180238472, -0.24105021204779323, -0.251011012922003, -0.30081501729305204, -0.33359680796357344, -0.3805481886100836, -0.4054735729572846, -0.42539517470570426, -0.42684486872965016, -0.4246937098554078, -0.41968992725662635, -0.38485050635856854]}, {\"line\": {\"color\": \"green\", \"width\": 1}, \"name\": \"true\", \"type\": \"scatter\", \"x\": [\"2020-10-04T00:00:00\", \"2020-10-05T00:00:00\", \"2020-10-06T00:00:00\", \"2020-10-07T00:00:00\", \"2020-10-08T00:00:00\", \"2020-10-09T00:00:00\", \"2020-10-10T00:00:00\", \"2020-10-11T00:00:00\", \"2020-10-12T00:00:00\", \"2020-10-13T00:00:00\", \"2020-10-14T00:00:00\", \"2020-10-15T00:00:00\", \"2020-10-16T00:00:00\", \"2020-10-17T00:00:00\", \"2020-10-18T00:00:00\", \"2020-10-19T00:00:00\", \"2020-10-20T00:00:00\", \"2020-10-21T00:00:00\", \"2020-10-22T00:00:00\", \"2020-10-23T00:00:00\", \"2020-10-24T00:00:00\", \"2020-10-25T00:00:00\", \"2020-10-26T00:00:00\", \"2020-10-27T00:00:00\", \"2020-10-28T00:00:00\", \"2020-10-29T00:00:00\", \"2020-10-30T00:00:00\", \"2020-10-31T00:00:00\", \"2020-11-01T00:00:00\", \"2020-11-02T00:00:00\", \"2020-11-03T00:00:00\", \"2020-11-04T00:00:00\", \"2020-11-05T00:00:00\", \"2020-11-06T00:00:00\", \"2020-11-07T00:00:00\", \"2020-11-08T00:00:00\", \"2020-11-09T00:00:00\", \"2020-11-10T00:00:00\", \"2020-11-11T00:00:00\", \"2020-11-12T00:00:00\", \"2020-11-13T00:00:00\", \"2020-11-14T00:00:00\", \"2020-11-15T00:00:00\", \"2020-11-16T00:00:00\", \"2020-11-17T00:00:00\", \"2020-11-18T00:00:00\", \"2020-11-19T00:00:00\", \"2020-11-20T00:00:00\", \"2020-11-21T00:00:00\", \"2020-11-22T00:00:00\", \"2020-11-23T00:00:00\", \"2020-11-24T00:00:00\", \"2020-11-25T00:00:00\", \"2020-11-26T00:00:00\", \"2020-11-27T00:00:00\", \"2020-11-28T00:00:00\", \"2020-11-29T00:00:00\", \"2020-11-30T00:00:00\", \"2020-12-01T00:00:00\", \"2020-12-02T00:00:00\", \"2020-12-03T00:00:00\", \"2020-12-04T00:00:00\", \"2020-12-05T00:00:00\", \"2020-12-06T00:00:00\", \"2020-12-07T00:00:00\", \"2020-12-08T00:00:00\", \"2020-12-09T00:00:00\", \"2020-12-10T00:00:00\", \"2020-12-11T00:00:00\", \"2020-12-12T00:00:00\", \"2020-12-13T00:00:00\", \"2020-12-14T00:00:00\", \"2020-12-15T00:00:00\", \"2020-12-16T00:00:00\", \"2020-12-17T00:00:00\", \"2020-12-18T00:00:00\", \"2020-12-19T00:00:00\", \"2020-12-20T00:00:00\", \"2020-12-21T00:00:00\", \"2020-12-22T00:00:00\", \"2020-12-23T00:00:00\", \"2020-12-24T00:00:00\", \"2020-12-25T00:00:00\", \"2020-12-26T00:00:00\", \"2020-12-27T00:00:00\", \"2020-12-28T00:00:00\", \"2020-12-29T00:00:00\", \"2020-12-30T00:00:00\", \"2020-12-31T00:00:00\", \"2021-01-01T00:00:00\", \"2021-01-02T00:00:00\", \"2021-01-03T00:00:00\", \"2021-01-04T00:00:00\", \"2021-01-05T00:00:00\", \"2021-01-06T00:00:00\", \"2021-01-07T00:00:00\", \"2021-01-08T00:00:00\", \"2021-01-09T00:00:00\", \"2021-01-10T00:00:00\", \"2021-01-11T00:00:00\", \"2021-01-12T00:00:00\", \"2021-01-13T00:00:00\", \"2021-01-14T00:00:00\", \"2021-01-15T00:00:00\", \"2021-01-16T00:00:00\", \"2021-01-17T00:00:00\", \"2021-01-18T00:00:00\", \"2021-01-19T00:00:00\", \"2021-01-20T00:00:00\", \"2021-01-21T00:00:00\", \"2021-01-22T00:00:00\", \"2021-01-23T00:00:00\", \"2021-01-24T00:00:00\", \"2021-01-25T00:00:00\", \"2021-01-26T00:00:00\", \"2021-01-27T00:00:00\", \"2021-01-28T00:00:00\", \"2021-01-29T00:00:00\", \"2021-01-30T00:00:00\", \"2021-01-31T00:00:00\", \"2021-02-01T00:00:00\", \"2021-02-02T00:00:00\", \"2021-02-03T00:00:00\", \"2021-02-04T00:00:00\", \"2021-02-05T00:00:00\", \"2021-02-06T00:00:00\", \"2021-02-07T00:00:00\", \"2021-02-08T00:00:00\", \"2021-02-09T00:00:00\", \"2021-02-10T00:00:00\", \"2021-02-11T00:00:00\", \"2021-02-12T00:00:00\", \"2021-02-13T00:00:00\", \"2021-02-14T00:00:00\", \"2021-02-15T00:00:00\", \"2021-02-16T00:00:00\", \"2021-02-17T00:00:00\", \"2021-02-18T00:00:00\", \"2021-02-19T00:00:00\", \"2021-02-20T00:00:00\", \"2021-02-21T00:00:00\", \"2021-02-22T00:00:00\", \"2021-02-23T00:00:00\", \"2021-02-24T00:00:00\", \"2021-02-25T00:00:00\", \"2021-02-26T00:00:00\", \"2021-02-27T00:00:00\", \"2021-02-28T00:00:00\", \"2021-03-01T00:00:00\", \"2021-03-02T00:00:00\", \"2021-03-03T00:00:00\", \"2021-03-04T00:00:00\", \"2021-03-05T00:00:00\", \"2021-03-06T00:00:00\", \"2021-03-07T00:00:00\", \"2021-03-08T00:00:00\", \"2021-03-09T00:00:00\", \"2021-03-10T00:00:00\", \"2021-03-11T00:00:00\", \"2021-03-12T00:00:00\", \"2021-03-13T00:00:00\", \"2021-03-14T00:00:00\", \"2021-03-15T00:00:00\", \"2021-03-16T00:00:00\", \"2021-03-17T00:00:00\", \"2021-03-18T00:00:00\", \"2021-03-19T00:00:00\", \"2021-03-20T00:00:00\", \"2021-03-21T00:00:00\", \"2021-03-22T00:00:00\", \"2021-03-23T00:00:00\", \"2021-03-24T00:00:00\", \"2021-03-25T00:00:00\", \"2021-03-26T00:00:00\", \"2021-03-27T00:00:00\", \"2021-03-28T00:00:00\", \"2021-03-29T00:00:00\", \"2021-03-30T00:00:00\", \"2021-03-31T00:00:00\", \"2021-04-01T00:00:00\", \"2021-04-02T00:00:00\", \"2021-04-03T00:00:00\", \"2021-04-04T00:00:00\", \"2021-04-05T00:00:00\", \"2021-04-06T00:00:00\", \"2021-04-07T00:00:00\", \"2021-04-08T00:00:00\", \"2021-04-09T00:00:00\", \"2021-04-10T00:00:00\", \"2021-04-11T00:00:00\", \"2021-04-12T00:00:00\", \"2021-04-13T00:00:00\", \"2021-04-14T00:00:00\", \"2021-04-15T00:00:00\", \"2021-04-16T00:00:00\", \"2021-04-17T00:00:00\", \"2021-04-18T00:00:00\", \"2021-04-19T00:00:00\", \"2021-04-20T00:00:00\", \"2021-04-21T00:00:00\", \"2021-04-22T00:00:00\"], \"y\": [-0.37769556488554457, -0.34000352026294783, -0.2951565341673272, -0.27804079182009345, -0.2702311498201262, -0.2175277574011851, -0.14920508098230947, -0.10936187748547023, -0.061662267665310674, -0.028927241318142314, -0.002552162946995296, 0.00025369645419066964, 0.05580971259767067, 0.06787490802276978, 0.1554644856631218, 0.22238423238140456, 0.31348113427323887, 0.35047171404553895, 0.351921408069485, 0.43876275653618735, 0.5184959278532189, 0.564044378799136, 0.6451804798167606, 0.6615479929903448, 0.6715555581879076, 0.676512576463336, 0.3248916291713947, 0.42094554933865713, 0.39962101788964455, 0.3006677096744901, 0.25441779387827657, 0.24726285240525248, 0.24871254642919852, 0.5562347367991687, 0.3732927038418506, 0.3462161606204072, 0.33340273602165843, 0.2707853070518607, 0.2515651701537375, 0.24300729898012075, 0.20882257860900633, -0.1155932235722704, -0.44000902575354717, -0.7644248279348239, -1.0888406301161007, -1.0710234229185704, -1.0603611571940643, -1.0397380905953482, -1.0005495876254522, -0.9927399456254851, -0.9877361630267035, -1.0049310449980733, -1.0221259269694432, -1.0393208089408128, -1.0565156909121827, -1.0737105728835523, -1.0909054548549222, -1.1081003368262918, -1.1252952187976615, -1.1424901007690313, -1.159684982740401, -1.1768798647117709, -1.1940747466831407, -1.2112696286545104, -1.2048629163551359, -1.2013088277803006, -1.2013088277803006, -1.2013088277803006, -1.1934524214569802, -1.1870457091576057, -1.1856427794570128, -1.1913480269060908, -1.1898983328821449, -1.1884954031815518, -1.1884954031815518, -1.1942006506306297, -1.1991576689060581, -1.2041614515048396, -1.2041614515048396, -1.2048629163551359, -1.2048629163551359, -1.2041614515048396, -1.203459986654543, -1.2027117574808937, -1.2041614515048396, -1.2048629163551359, -1.2055643812054326, -1.2048629163551359, -1.2048629163551359, -1.207715540079675, -1.209118469780268, -1.2098666989539173, -1.2041614515048396, -1.2048629163551359, -1.2070140752293785, -1.2070140752293785, -1.2070140752293785, -1.2055643812054326, -1.2027117574808937, -1.2055643812054326, -1.206265846055729, -1.203459986654543, -1.2041614515048396, -1.2006073629300043, -1.1956035803312226, -1.1977547392054653, -1.1970532743551687, -1.1934524214569802, -1.1920494917563873, -1.1920494917563873, -1.1913480269060908, -1.1927509566066836, -1.1920494917563873, -1.1956035803312226, -1.1991576689060581, -1.2027117574808937, -1.2027117574808937, -1.2055643812054326, -1.207715540079675, -1.207715540079675, -1.2055643812054326, -1.2055643812054326, -1.206265846055729, -1.2055643812054326, -1.2070140752293785, -1.210568163804214, -1.210568163804214, -1.2126725583551032, -1.210568163804214, -1.207715540079675, -1.2084170049299714, -1.206265846055729, -1.1991576689060581, -1.1977547392054653, -1.1934524214569802, -1.1827901557324738, -1.18423984975642, -1.1827901557324738, -1.1756819785828032, -1.1756819785828032, -1.174232284558857, -1.1664226425588897, -1.1692752662834287, -1.1671241074091863, -1.1671241074091863, -1.1699767311337252, -1.1671241074091863, -1.1650197128582969, -1.1664226425588897, -1.1721278900079677, -1.1699767311337252, -1.1706781959840216, -1.1614188599601083, -1.1635700188343507, -1.1600159302595152, -1.159314465409219, -1.1479039705110632, -1.1529077531098446, -1.153609217960141, -1.1486054353613595, -1.1400943285110958, -1.1315364573374789, -1.1194244975890266, -1.1016540547148495, -1.0902435598166937, -0.8211616432429696, -0.7955815583688254, -0.7898763109197473, -0.8809732128115816, -0.8816746776618781, -0.8809732128115816, -0.8653071644882939, -0.9877361630267035, -0.9557026015298317, -0.9308239815059837, -0.9222661103323667, -0.912305309458157, -0.9001933497097048, -0.8888296191349021, -0.8880813899612524, -0.8944881022606268, -0.7400255422253453, -0.7756131922970526, -0.8126505363927059, -0.8226113372669156, -0.8632027699374044, -0.8617530759134584, -0.8418314741650389, -0.7976859529197147, -0.7364714536505098, -0.7393240773750487, -0.7371729185008064, -0.747133719375016, -0.7478819485486657, -0.8375759207399069, -0.8403817801410928, -0.8425329390153353, -0.8660086293385905, -0.8646056996379974, -0.8688612530631293, -0.8539434339134911]}, {\"line\": {\"color\": \"red\", \"width\": 1}, \"name\": \"Pr\\u00e9diction\", \"type\": \"scatter\", \"x\": [\"2020-04-01T00:00:00\", \"2020-04-02T00:00:00\", \"2020-04-03T00:00:00\", \"2020-04-04T00:00:00\", \"2020-04-05T00:00:00\", \"2020-04-06T00:00:00\", \"2020-04-07T00:00:00\", \"2020-04-08T00:00:00\", \"2020-04-09T00:00:00\", \"2020-04-10T00:00:00\", \"2020-04-11T00:00:00\", \"2020-04-12T00:00:00\", \"2020-04-13T00:00:00\", \"2020-04-14T00:00:00\", \"2020-04-15T00:00:00\", \"2020-04-16T00:00:00\", \"2020-04-17T00:00:00\", \"2020-04-18T00:00:00\", \"2020-04-19T00:00:00\", \"2020-04-20T00:00:00\", \"2020-04-21T00:00:00\", \"2020-04-22T00:00:00\", \"2020-04-23T00:00:00\", \"2020-04-24T00:00:00\", \"2020-04-25T00:00:00\", \"2020-04-26T00:00:00\", \"2020-04-27T00:00:00\", \"2020-04-28T00:00:00\", \"2020-04-29T00:00:00\", \"2020-04-30T00:00:00\", \"2020-05-01T00:00:00\", \"2020-05-02T00:00:00\", \"2020-05-03T00:00:00\", \"2020-05-04T00:00:00\", \"2020-05-05T00:00:00\", \"2020-05-06T00:00:00\", \"2020-05-07T00:00:00\", \"2020-05-08T00:00:00\", \"2020-05-09T00:00:00\", \"2020-05-10T00:00:00\", \"2020-05-11T00:00:00\", \"2020-05-12T00:00:00\", \"2020-05-13T00:00:00\", \"2020-05-14T00:00:00\", \"2020-05-15T00:00:00\", \"2020-05-16T00:00:00\", \"2020-05-17T00:00:00\", \"2020-05-18T00:00:00\", \"2020-05-19T00:00:00\", \"2020-05-20T00:00:00\", \"2020-05-21T00:00:00\", \"2020-05-22T00:00:00\", \"2020-05-23T00:00:00\", \"2020-05-24T00:00:00\", \"2020-05-25T00:00:00\", \"2020-05-26T00:00:00\", \"2020-05-27T00:00:00\", \"2020-05-28T00:00:00\", \"2020-05-29T00:00:00\", \"2020-05-30T00:00:00\", \"2020-05-31T00:00:00\", \"2020-06-01T00:00:00\", \"2020-06-02T00:00:00\", \"2020-06-03T00:00:00\", \"2020-06-04T00:00:00\", \"2020-06-05T00:00:00\", \"2020-06-06T00:00:00\", \"2020-06-07T00:00:00\", \"2020-06-08T00:00:00\", \"2020-06-09T00:00:00\", \"2020-06-10T00:00:00\", \"2020-06-11T00:00:00\", \"2020-06-12T00:00:00\", \"2020-06-13T00:00:00\", \"2020-06-14T00:00:00\", \"2020-06-15T00:00:00\", \"2020-06-16T00:00:00\", \"2020-06-17T00:00:00\", \"2020-06-18T00:00:00\", \"2020-06-19T00:00:00\", \"2020-06-20T00:00:00\", \"2020-06-21T00:00:00\", \"2020-06-22T00:00:00\", \"2020-06-23T00:00:00\", \"2020-06-24T00:00:00\", \"2020-06-25T00:00:00\", \"2020-06-26T00:00:00\", \"2020-06-27T00:00:00\", \"2020-06-28T00:00:00\", \"2020-06-29T00:00:00\", \"2020-06-30T00:00:00\", \"2020-07-01T00:00:00\", \"2020-07-02T00:00:00\", \"2020-07-03T00:00:00\", \"2020-07-04T00:00:00\", \"2020-07-05T00:00:00\", \"2020-07-06T00:00:00\", \"2020-07-07T00:00:00\", \"2020-07-08T00:00:00\", \"2020-07-09T00:00:00\", \"2020-07-10T00:00:00\", \"2020-07-11T00:00:00\", \"2020-07-12T00:00:00\", \"2020-07-13T00:00:00\", \"2020-07-14T00:00:00\", \"2020-07-15T00:00:00\", \"2020-07-16T00:00:00\", \"2020-07-17T00:00:00\", \"2020-07-18T00:00:00\", \"2020-07-19T00:00:00\", \"2020-07-20T00:00:00\", \"2020-07-21T00:00:00\", \"2020-07-22T00:00:00\", \"2020-07-23T00:00:00\", \"2020-07-24T00:00:00\", \"2020-07-25T00:00:00\", \"2020-07-26T00:00:00\", \"2020-07-27T00:00:00\", \"2020-07-28T00:00:00\", \"2020-07-29T00:00:00\", \"2020-07-30T00:00:00\", \"2020-07-31T00:00:00\", \"2020-08-01T00:00:00\", \"2020-08-02T00:00:00\", \"2020-08-03T00:00:00\", \"2020-08-04T00:00:00\", \"2020-08-05T00:00:00\", \"2020-08-06T00:00:00\", \"2020-08-07T00:00:00\", \"2020-08-08T00:00:00\", \"2020-08-09T00:00:00\", \"2020-08-10T00:00:00\", \"2020-08-11T00:00:00\", \"2020-08-12T00:00:00\", \"2020-08-13T00:00:00\", \"2020-08-14T00:00:00\", \"2020-08-15T00:00:00\", \"2020-08-16T00:00:00\", \"2020-08-17T00:00:00\", \"2020-08-18T00:00:00\", \"2020-08-19T00:00:00\", \"2020-08-20T00:00:00\", \"2020-08-21T00:00:00\", \"2020-08-22T00:00:00\", \"2020-08-23T00:00:00\", \"2020-08-24T00:00:00\", \"2020-08-25T00:00:00\", \"2020-08-26T00:00:00\", \"2020-08-27T00:00:00\", \"2020-08-28T00:00:00\", \"2020-08-29T00:00:00\", \"2020-08-30T00:00:00\", \"2020-08-31T00:00:00\", \"2020-09-01T00:00:00\", \"2020-09-02T00:00:00\", \"2020-09-03T00:00:00\", \"2020-09-04T00:00:00\", \"2020-09-05T00:00:00\", \"2020-09-06T00:00:00\", \"2020-09-07T00:00:00\", \"2020-09-08T00:00:00\", \"2020-09-09T00:00:00\", \"2020-09-10T00:00:00\", \"2020-09-11T00:00:00\", \"2020-09-12T00:00:00\", \"2020-09-13T00:00:00\", \"2020-09-14T00:00:00\", \"2020-09-15T00:00:00\", \"2020-09-16T00:00:00\", \"2020-09-17T00:00:00\", \"2020-09-18T00:00:00\", \"2020-09-19T00:00:00\", \"2020-09-20T00:00:00\", \"2020-09-21T00:00:00\", \"2020-09-22T00:00:00\", \"2020-09-23T00:00:00\", \"2020-09-24T00:00:00\", \"2020-09-25T00:00:00\", \"2020-09-26T00:00:00\", \"2020-09-27T00:00:00\", \"2020-09-28T00:00:00\", \"2020-09-29T00:00:00\", \"2020-09-30T00:00:00\", \"2020-10-01T00:00:00\", \"2020-10-02T00:00:00\", \"2020-10-03T00:00:00\"], \"y\": [-0.6263971328735352, -0.6263971328735352, -0.6263971328735352, -0.6263971328735352, -0.6263971328735352, -0.6263971328735352, -0.6263971328735352, -0.6263971328735352, -0.6263971328735352, -0.6263971328735352, -0.6263971328735352, -0.6263971328735352, -0.6263971328735352, -0.6263971328735352, -0.6263971328735352, -0.6263971328735352, -0.6263971328735352, -0.6263971328735352, -0.6263971328735352, -0.6263971328735352, -0.6263971328735352, -0.6263971328735352, -0.6263971328735352, -0.6263971328735352, -0.6263971328735352, -0.6263971328735352, -0.6263971328735352, -0.6263971328735352, -0.6263971328735352, -0.6263971328735352, -0.6263971328735352, -0.6263971328735352, -0.6263971328735352, -0.6263971328735352, -0.6263971328735352, -0.6263971328735352, -0.4567832946777344, -0.2709977626800537, -0.041220903396606445, 0.16329050064086914, 0.16641974449157715, 0.22657132148742676, 0.6018719673156738, 0.5775220394134521, 0.9302289485931396, 0.8968048095703125, 1.2496228218078613, 1.5800285339355469, 1.7357778549194336, 2.037642478942871, 2.35054874420166, 2.591010570526123, 2.793829917907715, 2.9828176498413086, 2.947227954864502, 2.875443458557129, 3.0165019035339355, 3.2450742721557617, 3.3590545654296875, 3.3812499046325684, 3.2952280044555664, 3.1227049827575684, 2.7828874588012695, 2.6456966400146484, 2.549581527709961, 2.143249034881592, 1.7857356071472168, 1.4834342002868652, 1.3024864196777344, 1.2646656036376953, 1.1221694946289062, 0.9271094799041748, 0.5742177963256836, 0.4185142517089844, 0.35155344009399414, 0.336122989654541, 0.37856388092041016, 0.2088642120361328, -0.11724424362182617, -0.015180110931396484, -0.17101073265075684, -0.32703638076782227, -0.2846226692199707, -0.15315985679626465, -0.3972477912902832, -0.3858628273010254, -0.5027425289154053, -0.29577064514160156, -0.6905040740966797, -0.6337172985076904, -0.4971904754638672, -0.6433649063110352, -0.4947512149810791, -0.4030153751373291, -0.5873687267303467, -0.5011422634124756, -0.5216469764709473, -0.4654371738433838, -0.4062168598175049, -0.3397679328918457, -0.43175554275512695, -0.37567710876464844, -0.4242122173309326, -0.36586761474609375, -0.42847204208374023, -0.4013381004333496, -0.3999290466308594, -0.4240846633911133, -0.3526453971862793, -0.23775053024291992, -0.16196560859680176, -0.08538269996643066, -0.270949125289917, -0.1692655086517334, -0.25766611099243164, -0.38020992279052734, -0.7773528099060059, -0.6661829948425293, -0.6563353538513184, -0.45536041259765625, -0.4972076416015625, -0.33516359329223633, -0.28607845306396484, -0.3432009220123291, -0.28009748458862305, -0.39348435401916504, -0.23744678497314453, -0.27516913414001465, -0.33197855949401855, -0.2918527126312256, 0.07369685173034668, -0.3016164302825928, -0.09782028198242188, -0.4028961658477783, -0.3903374671936035, -0.3031649589538574, -0.34697794914245605, -0.31607580184936523, -0.33025312423706055, -0.35054707527160645, -0.21280431747436523, -0.20790982246398926, -0.22841358184814453, -0.19838380813598633, -0.2372744083404541, -0.15697073936462402, -0.17834830284118652, -0.09781408309936523, -0.05140876770019531, -0.0776216983795166, -0.06403946876525879, -0.0018491744995117188, -0.005049705505371094, -0.016284704208374023, 0.006411552429199219, -0.05328369140625, 0.04607796669006348, 0.05730581283569336, 0.017276525497436523, -0.038194894790649414, -0.05020594596862793, -0.25641536712646484, -0.20546364784240723, -0.304105281829834, -0.38666248321533203, -0.39612460136413574, -0.36934900283813477, -0.3158249855041504, -0.3055241107940674, -0.38774871826171875, -0.41288208961486816, -0.3238186836242676, -0.35880565643310547, -0.3286876678466797, -0.3420984745025635, -0.2611217498779297, -0.2983577251434326, -0.21981143951416016, -0.32871031761169434, -0.28098368644714355, -0.30130887031555176, -0.33074307441711426, -0.42807984352111816, -0.4564049243927002, -0.4974040985107422, -0.4875648021697998]}, {\"line\": {\"color\": \"red\", \"width\": 1}, \"type\": \"scatter\", \"x\": [\"2020-10-18T00:00:00\", \"2020-10-19T00:00:00\", \"2020-10-20T00:00:00\", \"2020-10-21T00:00:00\", \"2020-10-22T00:00:00\", \"2020-10-23T00:00:00\", \"2020-10-24T00:00:00\", \"2020-10-25T00:00:00\", \"2020-10-26T00:00:00\", \"2020-10-27T00:00:00\", \"2020-10-28T00:00:00\", \"2020-10-29T00:00:00\", \"2020-10-30T00:00:00\", \"2020-10-31T00:00:00\", \"2020-11-01T00:00:00\", \"2020-11-02T00:00:00\", \"2020-11-03T00:00:00\", \"2020-11-04T00:00:00\", \"2020-11-05T00:00:00\", \"2020-11-06T00:00:00\", \"2020-11-07T00:00:00\", \"2020-11-08T00:00:00\", \"2020-11-09T00:00:00\", \"2020-11-10T00:00:00\", \"2020-11-11T00:00:00\", \"2020-11-12T00:00:00\", \"2020-11-13T00:00:00\", \"2020-11-14T00:00:00\", \"2020-11-15T00:00:00\", \"2020-11-16T00:00:00\", \"2020-11-17T00:00:00\", \"2020-11-18T00:00:00\", \"2020-11-19T00:00:00\", \"2020-11-20T00:00:00\", \"2020-11-21T00:00:00\", \"2020-11-22T00:00:00\", \"2020-11-23T00:00:00\", \"2020-11-24T00:00:00\", \"2020-11-25T00:00:00\", \"2020-11-26T00:00:00\", \"2020-11-27T00:00:00\", \"2020-11-28T00:00:00\", \"2020-11-29T00:00:00\", \"2020-11-30T00:00:00\", \"2020-12-01T00:00:00\", \"2020-12-02T00:00:00\", \"2020-12-03T00:00:00\", \"2020-12-04T00:00:00\", \"2020-12-05T00:00:00\", \"2020-12-06T00:00:00\", \"2020-12-07T00:00:00\", \"2020-12-08T00:00:00\", \"2020-12-09T00:00:00\", \"2020-12-10T00:00:00\", \"2020-12-11T00:00:00\", \"2020-12-12T00:00:00\", \"2020-12-13T00:00:00\", \"2020-12-14T00:00:00\", \"2020-12-15T00:00:00\", \"2020-12-16T00:00:00\", \"2020-12-17T00:00:00\", \"2020-12-18T00:00:00\", \"2020-12-19T00:00:00\", \"2020-12-20T00:00:00\", \"2020-12-21T00:00:00\", \"2020-12-22T00:00:00\", \"2020-12-23T00:00:00\", \"2020-12-24T00:00:00\", \"2020-12-25T00:00:00\", \"2020-12-26T00:00:00\", \"2020-12-27T00:00:00\", \"2020-12-28T00:00:00\", \"2020-12-29T00:00:00\", \"2020-12-30T00:00:00\", \"2020-12-31T00:00:00\", \"2021-01-01T00:00:00\", \"2021-01-02T00:00:00\", \"2021-01-03T00:00:00\", \"2021-01-04T00:00:00\", \"2021-01-05T00:00:00\", \"2021-01-06T00:00:00\", \"2021-01-07T00:00:00\", \"2021-01-08T00:00:00\", \"2021-01-09T00:00:00\", \"2021-01-10T00:00:00\", \"2021-01-11T00:00:00\", \"2021-01-12T00:00:00\", \"2021-01-13T00:00:00\", \"2021-01-14T00:00:00\", \"2021-01-15T00:00:00\", \"2021-01-16T00:00:00\", \"2021-01-17T00:00:00\", \"2021-01-18T00:00:00\", \"2021-01-19T00:00:00\", \"2021-01-20T00:00:00\", \"2021-01-21T00:00:00\", \"2021-01-22T00:00:00\", \"2021-01-23T00:00:00\", \"2021-01-24T00:00:00\", \"2021-01-25T00:00:00\", \"2021-01-26T00:00:00\", \"2021-01-27T00:00:00\", \"2021-01-28T00:00:00\", \"2021-01-29T00:00:00\", \"2021-01-30T00:00:00\", \"2021-01-31T00:00:00\", \"2021-02-01T00:00:00\", \"2021-02-02T00:00:00\", \"2021-02-03T00:00:00\", \"2021-02-04T00:00:00\", \"2021-02-05T00:00:00\", \"2021-02-06T00:00:00\", \"2021-02-07T00:00:00\", \"2021-02-08T00:00:00\", \"2021-02-09T00:00:00\", \"2021-02-10T00:00:00\", \"2021-02-11T00:00:00\", \"2021-02-12T00:00:00\", \"2021-02-13T00:00:00\", \"2021-02-14T00:00:00\", \"2021-02-15T00:00:00\", \"2021-02-16T00:00:00\", \"2021-02-17T00:00:00\", \"2021-02-18T00:00:00\", \"2021-02-19T00:00:00\", \"2021-02-20T00:00:00\", \"2021-02-21T00:00:00\", \"2021-02-22T00:00:00\", \"2021-02-23T00:00:00\", \"2021-02-24T00:00:00\", \"2021-02-25T00:00:00\", \"2021-02-26T00:00:00\", \"2021-02-27T00:00:00\", \"2021-02-28T00:00:00\", \"2021-03-01T00:00:00\", \"2021-03-02T00:00:00\", \"2021-03-03T00:00:00\", \"2021-03-04T00:00:00\", \"2021-03-05T00:00:00\", \"2021-03-06T00:00:00\", \"2021-03-07T00:00:00\", \"2021-03-08T00:00:00\", \"2021-03-09T00:00:00\", \"2021-03-10T00:00:00\", \"2021-03-11T00:00:00\", \"2021-03-12T00:00:00\", \"2021-03-13T00:00:00\", \"2021-03-14T00:00:00\", \"2021-03-15T00:00:00\", \"2021-03-16T00:00:00\", \"2021-03-17T00:00:00\", \"2021-03-18T00:00:00\", \"2021-03-19T00:00:00\", \"2021-03-20T00:00:00\", \"2021-03-21T00:00:00\", \"2021-03-22T00:00:00\", \"2021-03-23T00:00:00\", \"2021-03-24T00:00:00\", \"2021-03-25T00:00:00\", \"2021-03-26T00:00:00\", \"2021-03-27T00:00:00\", \"2021-03-28T00:00:00\", \"2021-03-29T00:00:00\", \"2021-03-30T00:00:00\", \"2021-03-31T00:00:00\", \"2021-04-01T00:00:00\", \"2021-04-02T00:00:00\", \"2021-04-03T00:00:00\", \"2021-04-04T00:00:00\", \"2021-04-05T00:00:00\", \"2021-04-06T00:00:00\", \"2021-04-07T00:00:00\", \"2021-04-08T00:00:00\", \"2021-04-09T00:00:00\", \"2021-04-10T00:00:00\", \"2021-04-11T00:00:00\", \"2021-04-12T00:00:00\", \"2021-04-13T00:00:00\", \"2021-04-14T00:00:00\", \"2021-04-15T00:00:00\", \"2021-04-16T00:00:00\", \"2021-04-17T00:00:00\", \"2021-04-18T00:00:00\", \"2021-04-19T00:00:00\", \"2021-04-20T00:00:00\", \"2021-04-21T00:00:00\", \"2021-04-22T00:00:00\"], \"y\": [0.03927946090698242, 0.1065835952758789, 0.12593936920166016, 0.27321720123291016, 0.2913820743560791, 0.5053205490112305, 0.6491560935974121, 0.8903665542602539, 1.020479679107666, 1.0785090923309326, 1.2395806312561035, 1.3205957412719727, 1.3428306579589844, 1.4137396812438965, 1.36555814743042, 1.31016206741333, 1.2235708236694336, 0.7292938232421875, 0.695253849029541, 0.571406364440918, 0.3525712490081787, 0.22620773315429688, 0.15377521514892578, 0.15292143821716309, 0.5522308349609375, 0.42220377922058105, 0.6121652126312256, 0.5023114681243896, 0.45126843452453613, 0.5192363262176514, 0.5453579425811768, 0.4623687267303467, -0.13690948486328125, -0.49648237228393555, -1.0220239162445068, -1.3305777311325073, -1.3378260135650635, -1.3732527494430542, -1.2937567234039307, -1.214590072631836, -1.226821780204773, -1.2271227836608887, -1.2994484901428223, -1.3543756008148193, -1.3927487134933472, -1.4380285739898682, -1.4847642183303833, -1.532956600189209, -1.5823051929473877, -1.631207823753357, -1.6803932189941406, -1.7296617031097412, -1.779479742050171, -1.8297860622406006, -1.8805230855941772, -1.857873797416687, -1.8546247482299805, -1.8575315475463867, -1.8587324619293213, -1.835213541984558, -1.8195122480392456, -1.817266583442688, -1.8347235918045044, -1.8270000219345093, -1.8236424922943115, -1.8237861394882202, -1.8412466049194336, -1.8539700508117676, -1.8681198358535767, -1.8667267560958862, -1.8700385093688965, -1.8701756000518799, -1.8684595823287964, -1.8668888807296753, -1.8650156259536743, -1.8699833154678345, -1.8714905977249146, -1.873611569404602, -1.871195912361145, -1.871659755706787, -1.8805201053619385, -1.8836452960968018, -1.8858222961425781, -1.867905616760254, -1.8729956150054932, -1.8786225318908691, -1.8777393102645874, -1.8779892921447754, -1.8734514713287354, -1.865220308303833, -1.875230073928833, -1.8756235837936401, -1.8668296337127686, -1.8703947067260742, -1.8585283756256104, -1.84456205368042, -1.8529584407806396, -1.8488349914550781, -1.8379777669906616, -1.8349494934082031, -1.8348547220230103, -1.8322033882141113, -1.8366676568984985, -1.8334944248199463, -1.8449851274490356, -1.8542990684509277, -1.8643091917037964, -1.8632936477661133, -1.8729788064956665, -1.8787124156951904, -1.8784701824188232, -1.8723615407943726, -1.8736475706100464, -1.8757764101028442, -1.8734016418457031, -1.8784282207489014, -1.888816237449646, -1.8874690532684326, -1.894653081893921, -1.887206792831421, -1.879684567451477, -1.8830097913742065, -1.8755977153778076, -1.854394555091858, -1.852914810180664, -1.8388689756393433, -1.8069958686828613, -1.815486192703247, -1.8080872297286987, -1.786185622215271, -1.7887054681777954, -1.7825243473052979, -1.7583057880401611, -1.7701715230941772, -1.7604156732559204, -1.7614152431488037, -1.7695776224136353, -1.7590824365615845, -1.7540977001190186, -1.758907675743103, -1.775565505027771, -1.7662956714630127, -1.77037513256073, -1.7409406900405884, -1.7522984743118286, -1.7387280464172363, -1.738442301750183, -1.7024757862091064, -1.723247766494751, -1.7208317518234253, -1.7053245306015015, -1.680995225906372, -1.6575368642807007, -1.6225663423538208, -1.5717792510986328, -1.542999029159546, -0.7160129547119141, -0.8915810585021973, -0.7369940280914307, -1.0513955354690552, -0.9424108266830444, -0.9730191230773926, -0.9099299907684326, -1.2862675189971924, -1.1143416166305542, -1.119431495666504, -1.100784420967102, -1.0754817724227905, -1.0366764068603516, -1.009639024734497, -1.0119134187698364, -1.026956558227539, -0.557551383972168, -0.8324148654937744, -0.7911474704742432, -0.8544259071350098, -0.9470354318618774, -0.9234369993209839, -0.8800837993621826, -0.7664470672607422, -0.6276340484619141, -0.7068543434143066, -0.6567707061767578, -0.6982111930847168, -0.6708791255950928, -0.9329345226287842, -0.8552830219268799]}],\n",
              "                        {\"template\": {\"data\": {\"bar\": [{\"error_x\": {\"color\": \"#2a3f5f\"}, \"error_y\": {\"color\": \"#2a3f5f\"}, \"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"bar\"}], \"barpolar\": [{\"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"barpolar\"}], \"carpet\": [{\"aaxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"baxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"type\": \"carpet\"}], \"choropleth\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"choropleth\"}], \"contour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"contour\"}], \"contourcarpet\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"contourcarpet\"}], \"heatmap\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmap\"}], \"heatmapgl\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmapgl\"}], \"histogram\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"histogram\"}], \"histogram2d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2d\"}], \"histogram2dcontour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2dcontour\"}], \"mesh3d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"mesh3d\"}], \"parcoords\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"parcoords\"}], \"pie\": [{\"automargin\": true, \"type\": \"pie\"}], \"scatter\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter\"}], \"scatter3d\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter3d\"}], \"scattercarpet\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattercarpet\"}], \"scattergeo\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergeo\"}], \"scattergl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergl\"}], \"scattermapbox\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattermapbox\"}], \"scatterpolar\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolar\"}], \"scatterpolargl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolargl\"}], \"scatterternary\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterternary\"}], \"surface\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"surface\"}], \"table\": [{\"cells\": {\"fill\": {\"color\": \"#EBF0F8\"}, \"line\": {\"color\": \"white\"}}, \"header\": {\"fill\": {\"color\": \"#C8D4E3\"}, \"line\": {\"color\": \"white\"}}, \"type\": \"table\"}]}, \"layout\": {\"annotationdefaults\": {\"arrowcolor\": \"#2a3f5f\", \"arrowhead\": 0, \"arrowwidth\": 1}, \"coloraxis\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"colorscale\": {\"diverging\": [[0, \"#8e0152\"], [0.1, \"#c51b7d\"], [0.2, \"#de77ae\"], [0.3, \"#f1b6da\"], [0.4, \"#fde0ef\"], [0.5, \"#f7f7f7\"], [0.6, \"#e6f5d0\"], [0.7, \"#b8e186\"], [0.8, \"#7fbc41\"], [0.9, \"#4d9221\"], [1, \"#276419\"]], \"sequential\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"sequentialminus\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}, \"colorway\": [\"#636efa\", \"#EF553B\", \"#00cc96\", \"#ab63fa\", \"#FFA15A\", \"#19d3f3\", \"#FF6692\", \"#B6E880\", \"#FF97FF\", \"#FECB52\"], \"font\": {\"color\": \"#2a3f5f\"}, \"geo\": {\"bgcolor\": \"white\", \"lakecolor\": \"white\", \"landcolor\": \"#E5ECF6\", \"showlakes\": true, \"showland\": true, \"subunitcolor\": \"white\"}, \"hoverlabel\": {\"align\": \"left\"}, \"hovermode\": \"closest\", \"mapbox\": {\"style\": \"light\"}, \"paper_bgcolor\": \"white\", \"plot_bgcolor\": \"#E5ECF6\", \"polar\": {\"angularaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"radialaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"scene\": {\"xaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"yaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"zaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}}, \"shapedefaults\": {\"line\": {\"color\": \"#2a3f5f\"}}, \"ternary\": {\"aaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"baxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"caxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"title\": {\"x\": 0.05}, \"xaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}, \"yaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}}}, \"xaxis\": {\"rangeslider\": {\"visible\": true}}, \"yaxis\": {\"autorange\": true, \"fixedrange\": false}},\n",
              "                        {\"responsive\": true}\n",
              "                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('146cfa8b-2ad2-4d3f-84e0-544203206cf6');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })\n",
              "                };\n",
              "                \n",
              "            </script>\n",
              "        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}