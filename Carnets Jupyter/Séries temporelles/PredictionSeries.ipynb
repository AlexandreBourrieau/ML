{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PredictionsSeries.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AlexandreBourrieau/ML/blob/main/Carnets%20Jupyter/S%C3%A9ries%20temporelles/PredictionSeries.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TVuCzMYKDp3z"
      },
      "source": [
        "# Chargement des données"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i3nLyKtnliCW"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import plotly.express as px\n",
        "import pandas as pd"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fln1XUm2bxPx",
        "outputId": "73c8d9fc-a55f-4e4f-f0bd-0cf9b43e7e49"
      },
      "source": [
        "!wget --no-check-certificate --content-disposition \"https://raw.githubusercontent.com/AlexandreBourrieau/ML/main/Carnets%20Jupyter/S%C3%A9ries%20temporelles/data/table-indicateurs-open-data-dep-serie.csv\""
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-04-23 15:52:58--  https://raw.githubusercontent.com/AlexandreBourrieau/ML/main/Carnets%20Jupyter/S%C3%A9ries%20temporelles/data/table-indicateurs-open-data-dep-serie.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4340764 (4.1M) [text/plain]\n",
            "Saving to: ‘table-indicateurs-open-data-dep-serie.csv’\n",
            "\n",
            "table-indicateurs-o 100%[===================>]   4.14M  23.5MB/s    in 0.2s    \n",
            "\n",
            "2021-04-23 15:52:58 (23.5 MB/s) - ‘table-indicateurs-open-data-dep-serie.csv’ saved [4340764/4340764]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MPJ6nnrRsUBm"
      },
      "source": [
        "Charge la série sous Pandas et affiche les informations du fichier :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VEB_JjihEYTP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 695
        },
        "outputId": "b83877bb-a068-42ae-865a-583038537dc0"
      },
      "source": [
        "# Création de la série sous Pandas\n",
        "serie = pd.read_csv(\"table-indicateurs-open-data-dep-serie.csv\")\n",
        "serie"
      ],
      "execution_count": 197,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>extract_date</th>\n",
              "      <th>departement</th>\n",
              "      <th>region</th>\n",
              "      <th>libelle_reg</th>\n",
              "      <th>libelle_dep</th>\n",
              "      <th>tx_incid</th>\n",
              "      <th>R</th>\n",
              "      <th>taux_occupation_sae</th>\n",
              "      <th>tx_pos</th>\n",
              "      <th>tx_incid_couleur</th>\n",
              "      <th>R_couleur</th>\n",
              "      <th>taux_occupation_sae_couleur</th>\n",
              "      <th>tx_pos_couleur</th>\n",
              "      <th>nb_orange</th>\n",
              "      <th>nb_rouge</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2020-03-20</td>\n",
              "      <td>01</td>\n",
              "      <td>84</td>\n",
              "      <td>Auvergne Rhône Alpes</td>\n",
              "      <td>Ain</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>15.6</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>vert</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2020-03-21</td>\n",
              "      <td>01</td>\n",
              "      <td>84</td>\n",
              "      <td>Auvergne Rhône Alpes</td>\n",
              "      <td>Ain</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>15.7</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>vert</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2020-03-19</td>\n",
              "      <td>01</td>\n",
              "      <td>84</td>\n",
              "      <td>Auvergne Rhône Alpes</td>\n",
              "      <td>Ain</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>14.1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>vert</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2020-03-18</td>\n",
              "      <td>01</td>\n",
              "      <td>84</td>\n",
              "      <td>Auvergne Rhône Alpes</td>\n",
              "      <td>Ain</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>6.3</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>vert</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2020-04-28</td>\n",
              "      <td>01</td>\n",
              "      <td>84</td>\n",
              "      <td>Auvergne Rhône Alpes</td>\n",
              "      <td>Ain</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>72.6</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>rouge</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40496</th>\n",
              "      <td>2021-04-15</td>\n",
              "      <td>84</td>\n",
              "      <td>93</td>\n",
              "      <td>Provence Alpes Côte d'Azur</td>\n",
              "      <td>Vaucluse</td>\n",
              "      <td>403.39</td>\n",
              "      <td>0.92</td>\n",
              "      <td>124.6</td>\n",
              "      <td>12.075129</td>\n",
              "      <td>rouge</td>\n",
              "      <td>vert</td>\n",
              "      <td>rouge</td>\n",
              "      <td>rouge</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40497</th>\n",
              "      <td>2021-04-16</td>\n",
              "      <td>84</td>\n",
              "      <td>93</td>\n",
              "      <td>Provence Alpes Côte d'Azur</td>\n",
              "      <td>Vaucluse</td>\n",
              "      <td>408.38</td>\n",
              "      <td>NaN</td>\n",
              "      <td>127.4</td>\n",
              "      <td>12.472100</td>\n",
              "      <td>rouge</td>\n",
              "      <td>NaN</td>\n",
              "      <td>rouge</td>\n",
              "      <td>rouge</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40498</th>\n",
              "      <td>2021-04-13</td>\n",
              "      <td>84</td>\n",
              "      <td>93</td>\n",
              "      <td>Provence Alpes Côte d'Azur</td>\n",
              "      <td>Vaucluse</td>\n",
              "      <td>434.58</td>\n",
              "      <td>NaN</td>\n",
              "      <td>124.3</td>\n",
              "      <td>12.066320</td>\n",
              "      <td>rouge</td>\n",
              "      <td>NaN</td>\n",
              "      <td>rouge</td>\n",
              "      <td>rouge</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40499</th>\n",
              "      <td>2021-04-18</td>\n",
              "      <td>84</td>\n",
              "      <td>93</td>\n",
              "      <td>Provence Alpes Côte d'Azur</td>\n",
              "      <td>Vaucluse</td>\n",
              "      <td>396.26</td>\n",
              "      <td>NaN</td>\n",
              "      <td>124.3</td>\n",
              "      <td>12.487361</td>\n",
              "      <td>rouge</td>\n",
              "      <td>NaN</td>\n",
              "      <td>rouge</td>\n",
              "      <td>rouge</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40500</th>\n",
              "      <td>2021-04-17</td>\n",
              "      <td>84</td>\n",
              "      <td>93</td>\n",
              "      <td>Provence Alpes Côte d'Azur</td>\n",
              "      <td>Vaucluse</td>\n",
              "      <td>403.75</td>\n",
              "      <td>NaN</td>\n",
              "      <td>124.3</td>\n",
              "      <td>12.593128</td>\n",
              "      <td>rouge</td>\n",
              "      <td>NaN</td>\n",
              "      <td>rouge</td>\n",
              "      <td>rouge</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>40501 rows × 15 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      extract_date departement  region  ... tx_pos_couleur nb_orange  nb_rouge\n",
              "0       2020-03-20          01      84  ...            NaN         0         0\n",
              "1       2020-03-21          01      84  ...            NaN         0         0\n",
              "2       2020-03-19          01      84  ...            NaN         0         0\n",
              "3       2020-03-18          01      84  ...            NaN         0         0\n",
              "4       2020-04-28          01      84  ...            NaN         0         1\n",
              "...            ...         ...     ...  ...            ...       ...       ...\n",
              "40496   2021-04-15          84      93  ...          rouge         0         3\n",
              "40497   2021-04-16          84      93  ...          rouge         0         3\n",
              "40498   2021-04-13          84      93  ...          rouge         0         3\n",
              "40499   2021-04-18          84      93  ...          rouge         0         3\n",
              "40500   2021-04-17          84      93  ...          rouge         0         3\n",
              "\n",
              "[40501 rows x 15 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 197
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 662
        },
        "id": "cbYvPt63d-GS",
        "outputId": "4a3d17ee-e2e0-4508-bb65-c9a58207d6f8"
      },
      "source": [
        "serie.groupby(by=\"region\").agg(['count'])"
      ],
      "execution_count": 207,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead tr th {\n",
              "        text-align: left;\n",
              "    }\n",
              "\n",
              "    .dataframe thead tr:last-of-type th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th>extract_date</th>\n",
              "      <th>departement</th>\n",
              "      <th>libelle_reg</th>\n",
              "      <th>libelle_dep</th>\n",
              "      <th>tx_incid</th>\n",
              "      <th>R</th>\n",
              "      <th>taux_occupation_sae</th>\n",
              "      <th>tx_pos</th>\n",
              "      <th>tx_incid_couleur</th>\n",
              "      <th>R_couleur</th>\n",
              "      <th>taux_occupation_sae_couleur</th>\n",
              "      <th>tx_pos_couleur</th>\n",
              "      <th>nb_orange</th>\n",
              "      <th>nb_rouge</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "      <th>count</th>\n",
              "      <th>count</th>\n",
              "      <th>count</th>\n",
              "      <th>count</th>\n",
              "      <th>count</th>\n",
              "      <th>count</th>\n",
              "      <th>count</th>\n",
              "      <th>count</th>\n",
              "      <th>count</th>\n",
              "      <th>count</th>\n",
              "      <th>count</th>\n",
              "      <th>count</th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>region</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>401</td>\n",
              "      <td>401</td>\n",
              "      <td>401</td>\n",
              "      <td>401</td>\n",
              "      <td>342</td>\n",
              "      <td>54</td>\n",
              "      <td>401</td>\n",
              "      <td>336</td>\n",
              "      <td>342</td>\n",
              "      <td>54</td>\n",
              "      <td>401</td>\n",
              "      <td>336</td>\n",
              "      <td>401</td>\n",
              "      <td>401</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>401</td>\n",
              "      <td>401</td>\n",
              "      <td>401</td>\n",
              "      <td>401</td>\n",
              "      <td>342</td>\n",
              "      <td>56</td>\n",
              "      <td>401</td>\n",
              "      <td>336</td>\n",
              "      <td>342</td>\n",
              "      <td>56</td>\n",
              "      <td>401</td>\n",
              "      <td>336</td>\n",
              "      <td>401</td>\n",
              "      <td>401</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>401</td>\n",
              "      <td>401</td>\n",
              "      <td>401</td>\n",
              "      <td>401</td>\n",
              "      <td>342</td>\n",
              "      <td>68</td>\n",
              "      <td>401</td>\n",
              "      <td>336</td>\n",
              "      <td>342</td>\n",
              "      <td>68</td>\n",
              "      <td>401</td>\n",
              "      <td>336</td>\n",
              "      <td>401</td>\n",
              "      <td>401</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>401</td>\n",
              "      <td>401</td>\n",
              "      <td>401</td>\n",
              "      <td>401</td>\n",
              "      <td>342</td>\n",
              "      <td>55</td>\n",
              "      <td>401</td>\n",
              "      <td>336</td>\n",
              "      <td>342</td>\n",
              "      <td>55</td>\n",
              "      <td>401</td>\n",
              "      <td>336</td>\n",
              "      <td>401</td>\n",
              "      <td>401</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>401</td>\n",
              "      <td>401</td>\n",
              "      <td>401</td>\n",
              "      <td>401</td>\n",
              "      <td>342</td>\n",
              "      <td>35</td>\n",
              "      <td>401</td>\n",
              "      <td>336</td>\n",
              "      <td>342</td>\n",
              "      <td>35</td>\n",
              "      <td>401</td>\n",
              "      <td>336</td>\n",
              "      <td>401</td>\n",
              "      <td>401</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>3208</td>\n",
              "      <td>3208</td>\n",
              "      <td>3208</td>\n",
              "      <td>3208</td>\n",
              "      <td>2736</td>\n",
              "      <td>544</td>\n",
              "      <td>3208</td>\n",
              "      <td>2688</td>\n",
              "      <td>2736</td>\n",
              "      <td>544</td>\n",
              "      <td>3208</td>\n",
              "      <td>2688</td>\n",
              "      <td>3208</td>\n",
              "      <td>3208</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>2406</td>\n",
              "      <td>2406</td>\n",
              "      <td>2406</td>\n",
              "      <td>2406</td>\n",
              "      <td>2052</td>\n",
              "      <td>408</td>\n",
              "      <td>2406</td>\n",
              "      <td>2016</td>\n",
              "      <td>2052</td>\n",
              "      <td>408</td>\n",
              "      <td>2406</td>\n",
              "      <td>2016</td>\n",
              "      <td>2406</td>\n",
              "      <td>2406</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>3208</td>\n",
              "      <td>3208</td>\n",
              "      <td>3208</td>\n",
              "      <td>3208</td>\n",
              "      <td>2736</td>\n",
              "      <td>544</td>\n",
              "      <td>3208</td>\n",
              "      <td>2688</td>\n",
              "      <td>2736</td>\n",
              "      <td>544</td>\n",
              "      <td>3208</td>\n",
              "      <td>2688</td>\n",
              "      <td>3208</td>\n",
              "      <td>3208</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>2005</td>\n",
              "      <td>2005</td>\n",
              "      <td>2005</td>\n",
              "      <td>2005</td>\n",
              "      <td>1710</td>\n",
              "      <td>340</td>\n",
              "      <td>2005</td>\n",
              "      <td>1680</td>\n",
              "      <td>1710</td>\n",
              "      <td>340</td>\n",
              "      <td>2005</td>\n",
              "      <td>1680</td>\n",
              "      <td>2005</td>\n",
              "      <td>2005</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>2005</td>\n",
              "      <td>2005</td>\n",
              "      <td>2005</td>\n",
              "      <td>2005</td>\n",
              "      <td>1710</td>\n",
              "      <td>340</td>\n",
              "      <td>2005</td>\n",
              "      <td>1680</td>\n",
              "      <td>1710</td>\n",
              "      <td>340</td>\n",
              "      <td>2005</td>\n",
              "      <td>1680</td>\n",
              "      <td>2005</td>\n",
              "      <td>2005</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44</th>\n",
              "      <td>4010</td>\n",
              "      <td>4010</td>\n",
              "      <td>4010</td>\n",
              "      <td>4010</td>\n",
              "      <td>3420</td>\n",
              "      <td>680</td>\n",
              "      <td>4010</td>\n",
              "      <td>3360</td>\n",
              "      <td>3420</td>\n",
              "      <td>680</td>\n",
              "      <td>4010</td>\n",
              "      <td>3360</td>\n",
              "      <td>4010</td>\n",
              "      <td>4010</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>52</th>\n",
              "      <td>2005</td>\n",
              "      <td>2005</td>\n",
              "      <td>2005</td>\n",
              "      <td>2005</td>\n",
              "      <td>1710</td>\n",
              "      <td>340</td>\n",
              "      <td>2005</td>\n",
              "      <td>1680</td>\n",
              "      <td>1710</td>\n",
              "      <td>340</td>\n",
              "      <td>2005</td>\n",
              "      <td>1680</td>\n",
              "      <td>2005</td>\n",
              "      <td>2005</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>53</th>\n",
              "      <td>1604</td>\n",
              "      <td>1604</td>\n",
              "      <td>1604</td>\n",
              "      <td>1604</td>\n",
              "      <td>1368</td>\n",
              "      <td>272</td>\n",
              "      <td>1604</td>\n",
              "      <td>1344</td>\n",
              "      <td>1368</td>\n",
              "      <td>272</td>\n",
              "      <td>1604</td>\n",
              "      <td>1344</td>\n",
              "      <td>1604</td>\n",
              "      <td>1604</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75</th>\n",
              "      <td>4812</td>\n",
              "      <td>4812</td>\n",
              "      <td>4812</td>\n",
              "      <td>4812</td>\n",
              "      <td>4104</td>\n",
              "      <td>816</td>\n",
              "      <td>4812</td>\n",
              "      <td>4032</td>\n",
              "      <td>4104</td>\n",
              "      <td>816</td>\n",
              "      <td>4812</td>\n",
              "      <td>4032</td>\n",
              "      <td>4812</td>\n",
              "      <td>4812</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>76</th>\n",
              "      <td>5213</td>\n",
              "      <td>5213</td>\n",
              "      <td>5213</td>\n",
              "      <td>5213</td>\n",
              "      <td>4446</td>\n",
              "      <td>884</td>\n",
              "      <td>5213</td>\n",
              "      <td>4368</td>\n",
              "      <td>4446</td>\n",
              "      <td>884</td>\n",
              "      <td>5213</td>\n",
              "      <td>4368</td>\n",
              "      <td>5213</td>\n",
              "      <td>5213</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>84</th>\n",
              "      <td>4812</td>\n",
              "      <td>4812</td>\n",
              "      <td>4812</td>\n",
              "      <td>4812</td>\n",
              "      <td>4104</td>\n",
              "      <td>816</td>\n",
              "      <td>4812</td>\n",
              "      <td>4032</td>\n",
              "      <td>4104</td>\n",
              "      <td>816</td>\n",
              "      <td>4812</td>\n",
              "      <td>4032</td>\n",
              "      <td>4812</td>\n",
              "      <td>4812</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>93</th>\n",
              "      <td>2406</td>\n",
              "      <td>2406</td>\n",
              "      <td>2406</td>\n",
              "      <td>2406</td>\n",
              "      <td>2052</td>\n",
              "      <td>408</td>\n",
              "      <td>2406</td>\n",
              "      <td>2016</td>\n",
              "      <td>2052</td>\n",
              "      <td>408</td>\n",
              "      <td>2406</td>\n",
              "      <td>2016</td>\n",
              "      <td>2406</td>\n",
              "      <td>2406</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>94</th>\n",
              "      <td>802</td>\n",
              "      <td>802</td>\n",
              "      <td>802</td>\n",
              "      <td>802</td>\n",
              "      <td>684</td>\n",
              "      <td>104</td>\n",
              "      <td>802</td>\n",
              "      <td>672</td>\n",
              "      <td>684</td>\n",
              "      <td>104</td>\n",
              "      <td>802</td>\n",
              "      <td>672</td>\n",
              "      <td>802</td>\n",
              "      <td>802</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       extract_date departement libelle_reg  ... tx_pos_couleur nb_orange nb_rouge\n",
              "              count       count       count  ...          count     count    count\n",
              "region                                       ...                                  \n",
              "1               401         401         401  ...            336       401      401\n",
              "2               401         401         401  ...            336       401      401\n",
              "3               401         401         401  ...            336       401      401\n",
              "4               401         401         401  ...            336       401      401\n",
              "6               401         401         401  ...            336       401      401\n",
              "11             3208        3208        3208  ...           2688      3208     3208\n",
              "24             2406        2406        2406  ...           2016      2406     2406\n",
              "27             3208        3208        3208  ...           2688      3208     3208\n",
              "28             2005        2005        2005  ...           1680      2005     2005\n",
              "32             2005        2005        2005  ...           1680      2005     2005\n",
              "44             4010        4010        4010  ...           3360      4010     4010\n",
              "52             2005        2005        2005  ...           1680      2005     2005\n",
              "53             1604        1604        1604  ...           1344      1604     1604\n",
              "75             4812        4812        4812  ...           4032      4812     4812\n",
              "76             5213        5213        5213  ...           4368      5213     5213\n",
              "84             4812        4812        4812  ...           4032      4812     4812\n",
              "93             2406        2406        2406  ...           2016      2406     2406\n",
              "94              802         802         802  ...            672       802      802\n",
              "\n",
              "[18 rows x 14 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 207
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EJLcuFiNevyy"
      },
      "source": [
        "Regardons l'évolution du taux d'incidence sur paris :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 415
        },
        "id": "Q17wIXPLe2i_",
        "outputId": "5d288d63-125d-4822-b665-cb4e4de26c38"
      },
      "source": [
        "serie_paris = serie.loc[serie['region']==84]\n",
        "serie_paris = serie_paris[['extract_date','tx_incid']]\n",
        "\n",
        "serie_paris"
      ],
      "execution_count": 208,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>extract_date</th>\n",
              "      <th>tx_incid</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2020-03-20</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2020-03-21</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2020-03-19</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2020-03-18</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2020-04-28</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4807</th>\n",
              "      <td>2021-04-16</td>\n",
              "      <td>291.40</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4808</th>\n",
              "      <td>2021-04-13</td>\n",
              "      <td>330.15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4809</th>\n",
              "      <td>2021-04-18</td>\n",
              "      <td>281.02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4810</th>\n",
              "      <td>2021-04-19</td>\n",
              "      <td>264.48</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4811</th>\n",
              "      <td>2021-04-17</td>\n",
              "      <td>280.78</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4812 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     extract_date  tx_incid\n",
              "0      2020-03-20       NaN\n",
              "1      2020-03-21       NaN\n",
              "2      2020-03-19       NaN\n",
              "3      2020-03-18       NaN\n",
              "4      2020-04-28       NaN\n",
              "...           ...       ...\n",
              "4807   2021-04-16    291.40\n",
              "4808   2021-04-13    330.15\n",
              "4809   2021-04-18    281.02\n",
              "4810   2021-04-19    264.48\n",
              "4811   2021-04-17    280.78\n",
              "\n",
              "[4812 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 208
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cTSg8XwLknp9",
        "outputId": "80329476-f829-4e0e-c148-9441cb252f48",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 446
        }
      },
      "source": [
        "df_paris = pd.DataFrame(data={'taux' : serie_paris['tx_incid'].values},index=serie_paris['extract_date'])\n",
        "df_paris.index = pd.to_datetime(df_paris.index)\n",
        "df_paris = df_paris[~df_paris.index.duplicated(keep='first')]\n",
        "df_paris"
      ],
      "execution_count": 209,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>taux</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>extract_date</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2020-03-20</th>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2020-03-21</th>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2020-03-19</th>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2020-03-18</th>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2020-04-28</th>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2020-09-27</th>\n",
              "      <td>80.22</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2020-09-28</th>\n",
              "      <td>75.20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2020-09-29</th>\n",
              "      <td>75.50</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2020-09-30</th>\n",
              "      <td>74.59</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2020-10-01</th>\n",
              "      <td>77.78</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>401 rows × 1 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "               taux\n",
              "extract_date       \n",
              "2020-03-20      NaN\n",
              "2020-03-21      NaN\n",
              "2020-03-19      NaN\n",
              "2020-03-18      NaN\n",
              "2020-04-28      NaN\n",
              "...             ...\n",
              "2020-09-27    80.22\n",
              "2020-09-28    75.20\n",
              "2020-09-29    75.50\n",
              "2020-09-30    74.59\n",
              "2020-10-01    77.78\n",
              "\n",
              "[401 rows x 1 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 209
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m23cEXjcny_q",
        "outputId": "c5f8199d-5528-41e2-a578-25be959accfd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 446
        }
      },
      "source": [
        "df_paris.index = df_paris.index.sort_values()\n",
        "df_paris"
      ],
      "execution_count": 210,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>taux</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>extract_date</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2020-03-18</th>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2020-03-19</th>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2020-03-20</th>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2020-03-21</th>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2020-03-22</th>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2021-04-18</th>\n",
              "      <td>80.22</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2021-04-19</th>\n",
              "      <td>75.20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2021-04-20</th>\n",
              "      <td>75.50</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2021-04-21</th>\n",
              "      <td>74.59</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2021-04-22</th>\n",
              "      <td>77.78</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>401 rows × 1 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "               taux\n",
              "extract_date       \n",
              "2020-03-18      NaN\n",
              "2020-03-19      NaN\n",
              "2020-03-20      NaN\n",
              "2020-03-21      NaN\n",
              "2020-03-22      NaN\n",
              "...             ...\n",
              "2021-04-18    80.22\n",
              "2021-04-19    75.20\n",
              "2021-04-20    75.50\n",
              "2021-04-21    74.59\n",
              "2021-04-22    77.78\n",
              "\n",
              "[401 rows x 1 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 210
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qYpzzcbGi5FE",
        "outputId": "feec558c-a501-4984-eb36-5cf1ed0eeb00",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        }
      },
      "source": [
        "plt.plot(df_paris)"
      ],
      "execution_count": 211,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f78f8035490>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 211
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WF62FumBty9H"
      },
      "source": [
        "# Pré-traitement des données"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NUzjd-qN2s-T",
        "outputId": "ef25d71f-3bae-4289-d916-f49cc2bd3840",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Affichage du nombre total de données manquantes\n",
        "\n",
        "data_manquantes = sum(np.isnan(df_paris['taux']))\n",
        "print (\"Nombre de données manquantes : %s\" %data_manquantes)"
      ],
      "execution_count": 212,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Nombre de données manquantes : 59\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tkbi7uuBnUD3"
      },
      "source": [
        "**3. Correction des données**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8IQuSqAknduG"
      },
      "source": [
        "Pour corriger les données, on va tout simplement utiliser la fonction [fillna](https://pandas.pydata.org/docs/reference/api/pandas.Series.fillna.html) de Pandas avec la fonctionnalité de type `backfill` :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p2Oav6gin5aP",
        "outputId": "908d0e15-a3bf-418f-82ca-05d88df0aac2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Applique la fonction de remplissage automatique des données non numérique avec l'option backfill\n",
        "df_paris = df_paris.interpolate(method=\"slinear\")\n",
        "data_manquantes = sum(np.isnan(df_paris['taux']))\n",
        "print (\"Nombre de données manquantes : %s\" %data_manquantes)"
      ],
      "execution_count": 213,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Nombre de données manquantes : 44\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n84L5raJo72w",
        "outputId": "07129a7b-bd71-4826-d9c2-77c0039578bd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "df_paris = df_paris.fillna(method=\"backfill\")\n",
        "data_manquantes = sum(np.isnan(df_paris['taux']))\n",
        "print (\"Nombre de données manquantes : %s\" %data_manquantes)"
      ],
      "execution_count": 214,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Nombre de données manquantes : 0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v05rWWccJI26"
      },
      "source": [
        "**4. Affichage des données**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T1QKMBThNQni",
        "outputId": "1e903dbb-d5e5-4e6c-f582-bf7c768a23fc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        }
      },
      "source": [
        "# Affiche la série\n",
        "plt.figure(figsize=(15,5))\n",
        "plt.plot(df_paris)\n",
        "plt.title(\"Evolution du prix du BTC\")"
      ],
      "execution_count": 215,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'Evolution du prix du BTC')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 215
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1080x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zU7u1mA1E6jk"
      },
      "source": [
        "# Préparation des données"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fwOeFLtLSPnv"
      },
      "source": [
        "**2. Détection des anomalies dans la série \"horaire\"**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y1joYv2Kd7Js"
      },
      "source": [
        "Les anomalies sont fréquentes dans les séries temporelles, et la performance des prédictions est souvent améliorée lorsque ces anomalies sont traitées.  \n",
        "Pour avoir un apperçu de ces éventuelles anomalies, nous allons utiliser la méthode [\"Isolation Forest\"](https://scikit-learn.org/stable/modules/outlier_detection.html#isolation-forest) disponnible dans Scikit-learn.  \n",
        "\n",
        "Les paramètres utilisés sont les suivants :\n",
        " - **n_estimators** : C'est le nombre de sous-groupes d'échantillons à utiliser. Une valeur de 128 ou 256 est préconnisée dans le document de recherche.\n",
        " - **max_samples** : C'est le nombre d'échantillons maximum à utiliser. Nous utiliserons l'ensemble des échantillons.\n",
        " - **max_features** :  C'est le nombre de motifs aléatoirement choisis sur chaque noeud de l'arbre. Nous choisirons un seul motif.\n",
        " - **contamination** : C'est le pourcentage estimé d'anomalies dans les données. Ce paramètre permet de régler la sensibilité de l'algorithme. On va commencer avec 5% et affiner si nécessaire par la suite."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yHag65S4dH7x",
        "outputId": "d692ae8a-1629-4ef5-a8df-7724f30963d7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Initialise le modèle\n",
        "from sklearn.ensemble import IsolationForest\n",
        "\n",
        "clf = IsolationForest(n_estimators=256,max_samples=df_paris['taux'].size, contamination=0.01,max_features=1, verbose=1)\n",
        "clf.fit(df_paris['taux'].values.reshape(-1,1))"
      ],
      "execution_count": 221,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.3s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "IsolationForest(behaviour='deprecated', bootstrap=False, contamination=0.01,\n",
              "                max_features=1, max_samples=401, n_estimators=256, n_jobs=None,\n",
              "                random_state=None, verbose=1, warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 221
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HAPFfAaffb4h",
        "outputId": "f58e3100-2138-4c20-d770-6f295f3b6037",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Réalise les prédictions\n",
        "pred = clf.predict(df_paris['taux'].values.reshape(-1,1))\n",
        "pred"
      ],
      "execution_count": 222,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
              "        1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
              "        1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
              "        1,  1,  1,  1,  1,  1,  1,  1,  1,  1, -1,  1,  1,  1,  1, -1,  1,\n",
              "        1,  1,  1,  1, -1, -1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
              "        1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
              "        1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
              "        1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
              "        1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
              "        1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
              "        1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
              "        1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
              "        1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
              "        1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
              "        1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
              "        1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
              "        1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
              "        1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
              "        1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
              "        1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
              "        1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
              "        1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
              "        1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
              "        1,  1,  1,  1,  1,  1,  1,  1,  1,  1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 222
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OU0TN1UEBqR2"
      },
      "source": [
        "On ajoute maintenant ces informations dans la série journalière et on affiche les informations :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IWg0uUb9G5Ws",
        "outputId": "d153748e-0a25-4baf-bb60-3c38c01bd28c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 446
        }
      },
      "source": [
        "# Ajoute une colonne \"Anomalie\" dans la série\n",
        "df_paris['Anomalies']=pred\n",
        "df_paris['Anomalies'] = df_paris['Anomalies'].apply(lambda x: 1 if (x==-1) else 0)\n",
        "df_paris"
      ],
      "execution_count": 223,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>taux</th>\n",
              "      <th>Anomalies</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>extract_date</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2020-03-18</th>\n",
              "      <td>108.53</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2020-03-19</th>\n",
              "      <td>108.53</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2020-03-20</th>\n",
              "      <td>108.53</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2020-03-21</th>\n",
              "      <td>108.53</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2020-03-22</th>\n",
              "      <td>108.53</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2021-04-18</th>\n",
              "      <td>80.22</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2021-04-19</th>\n",
              "      <td>75.20</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2021-04-20</th>\n",
              "      <td>75.50</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2021-04-21</th>\n",
              "      <td>74.59</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2021-04-22</th>\n",
              "      <td>77.78</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>401 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                taux  Anomalies\n",
              "extract_date                   \n",
              "2020-03-18    108.53          0\n",
              "2020-03-19    108.53          0\n",
              "2020-03-20    108.53          0\n",
              "2020-03-21    108.53          0\n",
              "2020-03-22    108.53          0\n",
              "...              ...        ...\n",
              "2021-04-18     80.22          0\n",
              "2021-04-19     75.20          0\n",
              "2021-04-20     75.50          0\n",
              "2021-04-21     74.59          0\n",
              "2021-04-22     77.78          0\n",
              "\n",
              "[401 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 223
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "105qNoy1EwWd",
        "outputId": "601ff73b-c009-4c42-bc82-13b085516c0e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Affiche les informations sur les anomalies\n",
        "print(df_paris['Anomalies'].value_counts())"
      ],
      "execution_count": 224,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0    397\n",
            "1      4\n",
            "Name: Anomalies, dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HaV_MfJyFXkF"
      },
      "source": [
        "**3. Affichage des anomalies sur le graphique**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2idYKYImFh8v",
        "outputId": "08e15cca-91bf-4f40-cabb-19d12301e390",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        }
      },
      "source": [
        "# Affiche la série\n",
        "\n",
        "fig = px.line(x=df_paris.index,y=df_paris['taux'],title=\"Evolution du prix du BTC\")\n",
        "fig.add_trace(px.scatter(x=df_paris.index,y=df_paris['Anomalies']*df_paris['taux'],color=df_paris['Anomalies'].astype(np.bool)).data[0])\n",
        "\n",
        "fig.update_xaxes(rangeslider_visible=True)\n",
        "yaxis=dict(autorange = True,fixedrange= False)\n",
        "fig.update_yaxes(yaxis)\n",
        "fig.show()"
      ],
      "execution_count": 225,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>\n",
              "            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>\n",
              "                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-latest.min.js\"></script>    \n",
              "            <div id=\"d761acf0-dc52-4b7e-9227-37df53b1147a\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>\n",
              "            <script type=\"text/javascript\">\n",
              "                \n",
              "                    window.PLOTLYENV=window.PLOTLYENV || {};\n",
              "                    \n",
              "                if (document.getElementById(\"d761acf0-dc52-4b7e-9227-37df53b1147a\")) {\n",
              "                    Plotly.newPlot(\n",
              "                        'd761acf0-dc52-4b7e-9227-37df53b1147a',\n",
              "                        [{\"hoverlabel\": {\"namelength\": 0}, \"hovertemplate\": \"x=%{x}<br>y=%{y}\", \"legendgroup\": \"\", \"line\": {\"color\": \"#636efa\", \"dash\": \"solid\"}, \"mode\": \"lines\", \"name\": \"\", \"showlegend\": false, \"type\": \"scatter\", \"x\": [\"2020-03-18T00:00:00\", \"2020-03-19T00:00:00\", \"2020-03-20T00:00:00\", \"2020-03-21T00:00:00\", \"2020-03-22T00:00:00\", \"2020-03-23T00:00:00\", \"2020-03-24T00:00:00\", \"2020-03-25T00:00:00\", \"2020-03-26T00:00:00\", \"2020-03-27T00:00:00\", \"2020-03-28T00:00:00\", \"2020-03-29T00:00:00\", \"2020-03-30T00:00:00\", \"2020-03-31T00:00:00\", \"2020-04-01T00:00:00\", \"2020-04-02T00:00:00\", \"2020-04-03T00:00:00\", \"2020-04-04T00:00:00\", \"2020-04-05T00:00:00\", \"2020-04-06T00:00:00\", \"2020-04-07T00:00:00\", \"2020-04-08T00:00:00\", \"2020-04-09T00:00:00\", \"2020-04-10T00:00:00\", \"2020-04-11T00:00:00\", \"2020-04-12T00:00:00\", \"2020-04-13T00:00:00\", \"2020-04-14T00:00:00\", \"2020-04-15T00:00:00\", \"2020-04-16T00:00:00\", \"2020-04-17T00:00:00\", \"2020-04-18T00:00:00\", \"2020-04-19T00:00:00\", \"2020-04-20T00:00:00\", \"2020-04-21T00:00:00\", \"2020-04-22T00:00:00\", \"2020-04-23T00:00:00\", \"2020-04-24T00:00:00\", \"2020-04-25T00:00:00\", \"2020-04-26T00:00:00\", \"2020-04-27T00:00:00\", \"2020-04-28T00:00:00\", \"2020-04-29T00:00:00\", \"2020-04-30T00:00:00\", \"2020-05-01T00:00:00\", \"2020-05-02T00:00:00\", \"2020-05-03T00:00:00\", \"2020-05-04T00:00:00\", \"2020-05-05T00:00:00\", \"2020-05-06T00:00:00\", \"2020-05-07T00:00:00\", \"2020-05-08T00:00:00\", \"2020-05-09T00:00:00\", \"2020-05-10T00:00:00\", \"2020-05-11T00:00:00\", \"2020-05-12T00:00:00\", \"2020-05-13T00:00:00\", \"2020-05-14T00:00:00\", \"2020-05-15T00:00:00\", \"2020-05-16T00:00:00\", \"2020-05-17T00:00:00\", \"2020-05-18T00:00:00\", \"2020-05-19T00:00:00\", \"2020-05-20T00:00:00\", \"2020-05-21T00:00:00\", \"2020-05-22T00:00:00\", \"2020-05-23T00:00:00\", \"2020-05-24T00:00:00\", \"2020-05-25T00:00:00\", \"2020-05-26T00:00:00\", \"2020-05-27T00:00:00\", \"2020-05-28T00:00:00\", \"2020-05-29T00:00:00\", \"2020-05-30T00:00:00\", \"2020-05-31T00:00:00\", \"2020-06-01T00:00:00\", \"2020-06-02T00:00:00\", \"2020-06-03T00:00:00\", \"2020-06-04T00:00:00\", \"2020-06-05T00:00:00\", \"2020-06-06T00:00:00\", \"2020-06-07T00:00:00\", \"2020-06-08T00:00:00\", \"2020-06-09T00:00:00\", \"2020-06-10T00:00:00\", \"2020-06-11T00:00:00\", \"2020-06-12T00:00:00\", \"2020-06-13T00:00:00\", \"2020-06-14T00:00:00\", \"2020-06-15T00:00:00\", \"2020-06-16T00:00:00\", \"2020-06-17T00:00:00\", \"2020-06-18T00:00:00\", \"2020-06-19T00:00:00\", \"2020-06-20T00:00:00\", \"2020-06-21T00:00:00\", \"2020-06-22T00:00:00\", \"2020-06-23T00:00:00\", \"2020-06-24T00:00:00\", \"2020-06-25T00:00:00\", \"2020-06-26T00:00:00\", \"2020-06-27T00:00:00\", \"2020-06-28T00:00:00\", \"2020-06-29T00:00:00\", \"2020-06-30T00:00:00\", \"2020-07-01T00:00:00\", \"2020-07-02T00:00:00\", \"2020-07-03T00:00:00\", \"2020-07-04T00:00:00\", \"2020-07-05T00:00:00\", \"2020-07-06T00:00:00\", \"2020-07-07T00:00:00\", \"2020-07-08T00:00:00\", \"2020-07-09T00:00:00\", \"2020-07-10T00:00:00\", \"2020-07-11T00:00:00\", \"2020-07-12T00:00:00\", \"2020-07-13T00:00:00\", \"2020-07-14T00:00:00\", \"2020-07-15T00:00:00\", \"2020-07-16T00:00:00\", \"2020-07-17T00:00:00\", \"2020-07-18T00:00:00\", \"2020-07-19T00:00:00\", \"2020-07-20T00:00:00\", \"2020-07-21T00:00:00\", \"2020-07-22T00:00:00\", \"2020-07-23T00:00:00\", \"2020-07-24T00:00:00\", \"2020-07-25T00:00:00\", \"2020-07-26T00:00:00\", \"2020-07-27T00:00:00\", \"2020-07-28T00:00:00\", \"2020-07-29T00:00:00\", \"2020-07-30T00:00:00\", \"2020-07-31T00:00:00\", \"2020-08-01T00:00:00\", \"2020-08-02T00:00:00\", \"2020-08-03T00:00:00\", \"2020-08-04T00:00:00\", \"2020-08-05T00:00:00\", \"2020-08-06T00:00:00\", \"2020-08-07T00:00:00\", \"2020-08-08T00:00:00\", \"2020-08-09T00:00:00\", \"2020-08-10T00:00:00\", \"2020-08-11T00:00:00\", \"2020-08-12T00:00:00\", \"2020-08-13T00:00:00\", \"2020-08-14T00:00:00\", \"2020-08-15T00:00:00\", \"2020-08-16T00:00:00\", \"2020-08-17T00:00:00\", \"2020-08-18T00:00:00\", \"2020-08-19T00:00:00\", \"2020-08-20T00:00:00\", \"2020-08-21T00:00:00\", \"2020-08-22T00:00:00\", \"2020-08-23T00:00:00\", \"2020-08-24T00:00:00\", \"2020-08-25T00:00:00\", \"2020-08-26T00:00:00\", \"2020-08-27T00:00:00\", \"2020-08-28T00:00:00\", \"2020-08-29T00:00:00\", \"2020-08-30T00:00:00\", \"2020-08-31T00:00:00\", \"2020-09-01T00:00:00\", \"2020-09-02T00:00:00\", \"2020-09-03T00:00:00\", \"2020-09-04T00:00:00\", \"2020-09-05T00:00:00\", \"2020-09-06T00:00:00\", \"2020-09-07T00:00:00\", \"2020-09-08T00:00:00\", \"2020-09-09T00:00:00\", \"2020-09-10T00:00:00\", \"2020-09-11T00:00:00\", \"2020-09-12T00:00:00\", \"2020-09-13T00:00:00\", \"2020-09-14T00:00:00\", \"2020-09-15T00:00:00\", \"2020-09-16T00:00:00\", \"2020-09-17T00:00:00\", \"2020-09-18T00:00:00\", \"2020-09-19T00:00:00\", \"2020-09-20T00:00:00\", \"2020-09-21T00:00:00\", \"2020-09-22T00:00:00\", \"2020-09-23T00:00:00\", \"2020-09-24T00:00:00\", \"2020-09-25T00:00:00\", \"2020-09-26T00:00:00\", \"2020-09-27T00:00:00\", \"2020-09-28T00:00:00\", \"2020-09-29T00:00:00\", \"2020-09-30T00:00:00\", \"2020-10-01T00:00:00\", \"2020-10-02T00:00:00\", \"2020-10-03T00:00:00\", \"2020-10-04T00:00:00\", \"2020-10-05T00:00:00\", \"2020-10-06T00:00:00\", \"2020-10-07T00:00:00\", \"2020-10-08T00:00:00\", \"2020-10-09T00:00:00\", \"2020-10-10T00:00:00\", \"2020-10-11T00:00:00\", \"2020-10-12T00:00:00\", \"2020-10-13T00:00:00\", \"2020-10-14T00:00:00\", \"2020-10-15T00:00:00\", \"2020-10-16T00:00:00\", \"2020-10-17T00:00:00\", \"2020-10-18T00:00:00\", \"2020-10-19T00:00:00\", \"2020-10-20T00:00:00\", \"2020-10-21T00:00:00\", \"2020-10-22T00:00:00\", \"2020-10-23T00:00:00\", \"2020-10-24T00:00:00\", \"2020-10-25T00:00:00\", \"2020-10-26T00:00:00\", \"2020-10-27T00:00:00\", \"2020-10-28T00:00:00\", \"2020-10-29T00:00:00\", \"2020-10-30T00:00:00\", \"2020-10-31T00:00:00\", \"2020-11-01T00:00:00\", \"2020-11-02T00:00:00\", \"2020-11-03T00:00:00\", \"2020-11-04T00:00:00\", \"2020-11-05T00:00:00\", \"2020-11-06T00:00:00\", \"2020-11-07T00:00:00\", \"2020-11-08T00:00:00\", \"2020-11-09T00:00:00\", \"2020-11-10T00:00:00\", \"2020-11-11T00:00:00\", \"2020-11-12T00:00:00\", \"2020-11-13T00:00:00\", \"2020-11-14T00:00:00\", \"2020-11-15T00:00:00\", \"2020-11-16T00:00:00\", \"2020-11-17T00:00:00\", \"2020-11-18T00:00:00\", \"2020-11-19T00:00:00\", \"2020-11-20T00:00:00\", \"2020-11-21T00:00:00\", \"2020-11-22T00:00:00\", \"2020-11-23T00:00:00\", \"2020-11-24T00:00:00\", \"2020-11-25T00:00:00\", \"2020-11-26T00:00:00\", \"2020-11-27T00:00:00\", \"2020-11-28T00:00:00\", \"2020-11-29T00:00:00\", \"2020-11-30T00:00:00\", \"2020-12-01T00:00:00\", \"2020-12-02T00:00:00\", \"2020-12-03T00:00:00\", \"2020-12-04T00:00:00\", \"2020-12-05T00:00:00\", \"2020-12-06T00:00:00\", \"2020-12-07T00:00:00\", \"2020-12-08T00:00:00\", \"2020-12-09T00:00:00\", \"2020-12-10T00:00:00\", \"2020-12-11T00:00:00\", \"2020-12-12T00:00:00\", \"2020-12-13T00:00:00\", \"2020-12-14T00:00:00\", \"2020-12-15T00:00:00\", \"2020-12-16T00:00:00\", \"2020-12-17T00:00:00\", \"2020-12-18T00:00:00\", \"2020-12-19T00:00:00\", \"2020-12-20T00:00:00\", \"2020-12-21T00:00:00\", \"2020-12-22T00:00:00\", \"2020-12-23T00:00:00\", \"2020-12-24T00:00:00\", \"2020-12-25T00:00:00\", \"2020-12-26T00:00:00\", \"2020-12-27T00:00:00\", \"2020-12-28T00:00:00\", \"2020-12-29T00:00:00\", \"2020-12-30T00:00:00\", \"2020-12-31T00:00:00\", \"2021-01-01T00:00:00\", \"2021-01-02T00:00:00\", \"2021-01-03T00:00:00\", \"2021-01-04T00:00:00\", \"2021-01-05T00:00:00\", \"2021-01-06T00:00:00\", \"2021-01-07T00:00:00\", \"2021-01-08T00:00:00\", \"2021-01-09T00:00:00\", \"2021-01-10T00:00:00\", \"2021-01-11T00:00:00\", \"2021-01-12T00:00:00\", \"2021-01-13T00:00:00\", \"2021-01-14T00:00:00\", \"2021-01-15T00:00:00\", \"2021-01-16T00:00:00\", \"2021-01-17T00:00:00\", \"2021-01-18T00:00:00\", \"2021-01-19T00:00:00\", \"2021-01-20T00:00:00\", \"2021-01-21T00:00:00\", \"2021-01-22T00:00:00\", \"2021-01-23T00:00:00\", \"2021-01-24T00:00:00\", \"2021-01-25T00:00:00\", \"2021-01-26T00:00:00\", \"2021-01-27T00:00:00\", \"2021-01-28T00:00:00\", \"2021-01-29T00:00:00\", \"2021-01-30T00:00:00\", \"2021-01-31T00:00:00\", \"2021-02-01T00:00:00\", \"2021-02-02T00:00:00\", \"2021-02-03T00:00:00\", \"2021-02-04T00:00:00\", \"2021-02-05T00:00:00\", \"2021-02-06T00:00:00\", \"2021-02-07T00:00:00\", \"2021-02-08T00:00:00\", \"2021-02-09T00:00:00\", \"2021-02-10T00:00:00\", \"2021-02-11T00:00:00\", \"2021-02-12T00:00:00\", \"2021-02-13T00:00:00\", \"2021-02-14T00:00:00\", \"2021-02-15T00:00:00\", \"2021-02-16T00:00:00\", \"2021-02-17T00:00:00\", \"2021-02-18T00:00:00\", \"2021-02-19T00:00:00\", \"2021-02-20T00:00:00\", \"2021-02-21T00:00:00\", \"2021-02-22T00:00:00\", \"2021-02-23T00:00:00\", \"2021-02-24T00:00:00\", \"2021-02-25T00:00:00\", \"2021-02-26T00:00:00\", \"2021-02-27T00:00:00\", \"2021-02-28T00:00:00\", \"2021-03-01T00:00:00\", \"2021-03-02T00:00:00\", \"2021-03-03T00:00:00\", \"2021-03-04T00:00:00\", \"2021-03-05T00:00:00\", \"2021-03-06T00:00:00\", \"2021-03-07T00:00:00\", \"2021-03-08T00:00:00\", \"2021-03-09T00:00:00\", \"2021-03-10T00:00:00\", \"2021-03-11T00:00:00\", \"2021-03-12T00:00:00\", \"2021-03-13T00:00:00\", \"2021-03-14T00:00:00\", \"2021-03-15T00:00:00\", \"2021-03-16T00:00:00\", \"2021-03-17T00:00:00\", \"2021-03-18T00:00:00\", \"2021-03-19T00:00:00\", \"2021-03-20T00:00:00\", \"2021-03-21T00:00:00\", \"2021-03-22T00:00:00\", \"2021-03-23T00:00:00\", \"2021-03-24T00:00:00\", \"2021-03-25T00:00:00\", \"2021-03-26T00:00:00\", \"2021-03-27T00:00:00\", \"2021-03-28T00:00:00\", \"2021-03-29T00:00:00\", \"2021-03-30T00:00:00\", \"2021-03-31T00:00:00\", \"2021-04-01T00:00:00\", \"2021-04-02T00:00:00\", \"2021-04-03T00:00:00\", \"2021-04-04T00:00:00\", \"2021-04-05T00:00:00\", \"2021-04-06T00:00:00\", \"2021-04-07T00:00:00\", \"2021-04-08T00:00:00\", \"2021-04-09T00:00:00\", \"2021-04-10T00:00:00\", \"2021-04-11T00:00:00\", \"2021-04-12T00:00:00\", \"2021-04-13T00:00:00\", \"2021-04-14T00:00:00\", \"2021-04-15T00:00:00\", \"2021-04-16T00:00:00\", \"2021-04-17T00:00:00\", \"2021-04-18T00:00:00\", \"2021-04-19T00:00:00\", \"2021-04-20T00:00:00\", \"2021-04-21T00:00:00\", \"2021-04-22T00:00:00\"], \"xaxis\": \"x\", \"y\": [108.53, 108.53, 108.53, 108.53, 108.53, 108.53, 108.53, 108.53, 108.53, 108.53, 108.53, 108.53, 108.53, 108.53, 108.53, 108.53, 108.53, 108.53, 108.53, 108.53, 108.53, 108.53, 108.53, 108.53, 108.53, 108.53, 108.53, 108.53, 108.53, 108.53, 108.53, 108.53, 108.53, 108.53, 108.53, 108.53, 108.53, 108.53, 108.53, 108.53, 108.53, 108.53, 108.53, 108.53, 108.53, 121.47, 141.71, 165.16, 189.97, 196.36, 196.82, 237.61, 264.25, 290.58, 333.2, 369.58, 384.96, 387.09, 428.8, 494.1, 554.07, 608.41, 681.63, 705.83, 712.99, 779.51, 838.11, 889.25, 926.24, 933.25, 939.03, 939.79, 961.71, 972.36, 943.29, 916.35, 879.51, 859.57, 854.09, 783.62, 694.57, 558.94, 504.75, 459.09, 443.71, 442.04, 397.29, 349.64, 386.78, 338.53, 299.87, 286.17, 284.04, 246.29, 221.17, 203.36, 197.12, 186.31, 188.9, 188.29, 172.92, 166.07, 167.59, 152.67, 148.26, 145.06, 145.06, 149.93, 156.78, 153.28, 156.33, 157.09, 158.91, 159.22, 158.31, 161.35, 161.96, 167.74, 182.97, 198.95, 215.69, 213.41, 220.87, 223.3, 212.04, 173.22, 159.83, 144.3, 147.96, 142.17, 148.87, 156.48, 155.41, 157.39, 158.61, 170.79, 178.25, 174.75, 180.99, 218.89, 215.39, 218.13, 209.91, 202.3, 206.71, 206.1, 203.36, 205.49, 200.17, 208.84, 214.32, 214.78, 218.58, 218.28, 223.46, 225.59, 231.98, 238.98, 238.98, 238.37, 244.77, 245.53, 244.61, 246.29, 241.87, 249.94, 253.9, 249.79, 243.55, 242.63, 224.06, 224.06, 215.69, 206.71, 200.01, 199.86, 200.01, 202.14, 193.77, 188.14, 191.34, 190.88, 191.95, 193.32, 200.17, 202.45, 209.91, 206.1, 209.15, 208.84, 206.71, 196.06, 189.05, 179.01, 173.68, 169.42, 169.11, 169.57, 170.64, 178.09, 179.62, 187.68, 197.27, 200.93, 202.6, 213.87, 228.48, 237.0, 247.2, 254.2, 259.84, 260.44, 272.32, 274.9, 293.63, 307.94, 327.42, 335.33, 335.64, 354.21, 371.26, 381.0, 398.35, 401.85, 403.99, 405.05, 329.86, 350.4, 345.84, 324.68, 314.79, 313.26, 313.57, 379.33, 340.21, 334.42, 331.68, 318.29, 314.18, 312.35, 305.04, 235.66750000000002, 166.29500000000002, 96.92250000000001, 27.55, 31.36, 33.64, 38.05, 46.43, 48.1, 49.17, 45.49307692307692, 41.81615384615384, 38.139230769230764, 34.46230769230769, 30.78538461538461, 27.108461538461537, 23.43153846153846, 19.75461538461538, 16.077692307692306, 12.40076923076923, 8.723846153846154, 5.046923076923076, 1.37, 2.74, 3.5, 3.5, 3.5, 5.18, 6.55, 6.85, 5.63, 5.94, 6.24, 6.24, 5.02, 3.96, 2.89, 2.89, 2.74, 2.74, 2.89, 3.04, 3.2, 2.89, 2.74, 2.59, 2.74, 2.74, 2.13, 1.83, 1.67, 2.89, 2.74, 2.28, 2.28, 2.28, 2.59, 3.2, 2.59, 2.44, 3.04, 2.89, 3.65, 4.72, 4.26, 4.41, 5.18, 5.48, 5.48, 5.63, 5.33, 5.48, 4.72, 3.96, 3.2, 3.2, 2.59, 2.13, 2.13, 2.59, 2.59, 2.44, 2.59, 2.28, 1.52, 1.52, 1.07, 1.52, 2.13, 1.98, 2.44, 3.96, 4.26, 5.18, 7.46, 7.15, 7.46, 8.98, 8.98, 9.29, 10.96, 10.35, 10.81, 10.81, 10.2, 10.81, 11.26, 10.96, 9.74, 10.2, 10.05, 12.03, 11.57, 12.33, 12.48, 14.92, 13.85, 13.7, 14.77, 16.59, 18.42, 21.01, 24.81, 27.25, 84.79, 90.26, 91.48, 72.0, 71.85, 72.0, 75.35, 49.17, 56.02, 61.34, 63.17, 65.3, 67.89, 70.32, 70.48, 69.11, 102.14, 94.53, 86.61, 84.48, 75.8, 76.11, 80.37, 89.81, 102.9, 102.29, 102.75, 100.62, 100.46, 81.28, 80.68, 80.22, 75.2, 75.5, 74.59, 77.78], \"yaxis\": \"y\"}, {\"hoverlabel\": {\"namelength\": 0}, \"hovertemplate\": \"x=%{x}<br>y=%{y}<br>color=%{marker.color}\", \"legendgroup\": \"\", \"marker\": {\"color\": [false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, true, false, false, false, false, true, false, false, false, false, false, true, true, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false, false], \"coloraxis\": \"coloraxis\", \"symbol\": \"circle\"}, \"mode\": \"markers\", \"name\": \"\", \"showlegend\": false, \"type\": \"scatter\", \"x\": [\"2020-03-18T00:00:00\", \"2020-03-19T00:00:00\", \"2020-03-20T00:00:00\", \"2020-03-21T00:00:00\", \"2020-03-22T00:00:00\", \"2020-03-23T00:00:00\", \"2020-03-24T00:00:00\", \"2020-03-25T00:00:00\", \"2020-03-26T00:00:00\", \"2020-03-27T00:00:00\", \"2020-03-28T00:00:00\", \"2020-03-29T00:00:00\", \"2020-03-30T00:00:00\", \"2020-03-31T00:00:00\", \"2020-04-01T00:00:00\", \"2020-04-02T00:00:00\", \"2020-04-03T00:00:00\", \"2020-04-04T00:00:00\", \"2020-04-05T00:00:00\", \"2020-04-06T00:00:00\", \"2020-04-07T00:00:00\", \"2020-04-08T00:00:00\", \"2020-04-09T00:00:00\", \"2020-04-10T00:00:00\", \"2020-04-11T00:00:00\", \"2020-04-12T00:00:00\", \"2020-04-13T00:00:00\", \"2020-04-14T00:00:00\", \"2020-04-15T00:00:00\", \"2020-04-16T00:00:00\", \"2020-04-17T00:00:00\", \"2020-04-18T00:00:00\", \"2020-04-19T00:00:00\", \"2020-04-20T00:00:00\", \"2020-04-21T00:00:00\", \"2020-04-22T00:00:00\", \"2020-04-23T00:00:00\", \"2020-04-24T00:00:00\", \"2020-04-25T00:00:00\", \"2020-04-26T00:00:00\", \"2020-04-27T00:00:00\", \"2020-04-28T00:00:00\", \"2020-04-29T00:00:00\", \"2020-04-30T00:00:00\", \"2020-05-01T00:00:00\", \"2020-05-02T00:00:00\", \"2020-05-03T00:00:00\", \"2020-05-04T00:00:00\", \"2020-05-05T00:00:00\", \"2020-05-06T00:00:00\", \"2020-05-07T00:00:00\", \"2020-05-08T00:00:00\", \"2020-05-09T00:00:00\", \"2020-05-10T00:00:00\", \"2020-05-11T00:00:00\", \"2020-05-12T00:00:00\", \"2020-05-13T00:00:00\", \"2020-05-14T00:00:00\", \"2020-05-15T00:00:00\", \"2020-05-16T00:00:00\", \"2020-05-17T00:00:00\", \"2020-05-18T00:00:00\", \"2020-05-19T00:00:00\", \"2020-05-20T00:00:00\", \"2020-05-21T00:00:00\", \"2020-05-22T00:00:00\", \"2020-05-23T00:00:00\", \"2020-05-24T00:00:00\", \"2020-05-25T00:00:00\", \"2020-05-26T00:00:00\", \"2020-05-27T00:00:00\", \"2020-05-28T00:00:00\", \"2020-05-29T00:00:00\", \"2020-05-30T00:00:00\", \"2020-05-31T00:00:00\", \"2020-06-01T00:00:00\", \"2020-06-02T00:00:00\", \"2020-06-03T00:00:00\", \"2020-06-04T00:00:00\", \"2020-06-05T00:00:00\", \"2020-06-06T00:00:00\", \"2020-06-07T00:00:00\", \"2020-06-08T00:00:00\", \"2020-06-09T00:00:00\", \"2020-06-10T00:00:00\", \"2020-06-11T00:00:00\", \"2020-06-12T00:00:00\", \"2020-06-13T00:00:00\", \"2020-06-14T00:00:00\", \"2020-06-15T00:00:00\", \"2020-06-16T00:00:00\", \"2020-06-17T00:00:00\", \"2020-06-18T00:00:00\", \"2020-06-19T00:00:00\", \"2020-06-20T00:00:00\", \"2020-06-21T00:00:00\", \"2020-06-22T00:00:00\", \"2020-06-23T00:00:00\", \"2020-06-24T00:00:00\", \"2020-06-25T00:00:00\", \"2020-06-26T00:00:00\", \"2020-06-27T00:00:00\", \"2020-06-28T00:00:00\", \"2020-06-29T00:00:00\", \"2020-06-30T00:00:00\", \"2020-07-01T00:00:00\", \"2020-07-02T00:00:00\", \"2020-07-03T00:00:00\", \"2020-07-04T00:00:00\", \"2020-07-05T00:00:00\", \"2020-07-06T00:00:00\", \"2020-07-07T00:00:00\", \"2020-07-08T00:00:00\", \"2020-07-09T00:00:00\", \"2020-07-10T00:00:00\", \"2020-07-11T00:00:00\", \"2020-07-12T00:00:00\", \"2020-07-13T00:00:00\", \"2020-07-14T00:00:00\", \"2020-07-15T00:00:00\", \"2020-07-16T00:00:00\", \"2020-07-17T00:00:00\", \"2020-07-18T00:00:00\", \"2020-07-19T00:00:00\", \"2020-07-20T00:00:00\", \"2020-07-21T00:00:00\", \"2020-07-22T00:00:00\", \"2020-07-23T00:00:00\", \"2020-07-24T00:00:00\", \"2020-07-25T00:00:00\", \"2020-07-26T00:00:00\", \"2020-07-27T00:00:00\", \"2020-07-28T00:00:00\", \"2020-07-29T00:00:00\", \"2020-07-30T00:00:00\", \"2020-07-31T00:00:00\", \"2020-08-01T00:00:00\", \"2020-08-02T00:00:00\", \"2020-08-03T00:00:00\", \"2020-08-04T00:00:00\", \"2020-08-05T00:00:00\", \"2020-08-06T00:00:00\", \"2020-08-07T00:00:00\", \"2020-08-08T00:00:00\", \"2020-08-09T00:00:00\", \"2020-08-10T00:00:00\", \"2020-08-11T00:00:00\", \"2020-08-12T00:00:00\", \"2020-08-13T00:00:00\", \"2020-08-14T00:00:00\", \"2020-08-15T00:00:00\", \"2020-08-16T00:00:00\", \"2020-08-17T00:00:00\", \"2020-08-18T00:00:00\", \"2020-08-19T00:00:00\", \"2020-08-20T00:00:00\", \"2020-08-21T00:00:00\", \"2020-08-22T00:00:00\", \"2020-08-23T00:00:00\", \"2020-08-24T00:00:00\", \"2020-08-25T00:00:00\", \"2020-08-26T00:00:00\", \"2020-08-27T00:00:00\", \"2020-08-28T00:00:00\", \"2020-08-29T00:00:00\", \"2020-08-30T00:00:00\", \"2020-08-31T00:00:00\", \"2020-09-01T00:00:00\", \"2020-09-02T00:00:00\", \"2020-09-03T00:00:00\", \"2020-09-04T00:00:00\", \"2020-09-05T00:00:00\", \"2020-09-06T00:00:00\", \"2020-09-07T00:00:00\", \"2020-09-08T00:00:00\", \"2020-09-09T00:00:00\", \"2020-09-10T00:00:00\", \"2020-09-11T00:00:00\", \"2020-09-12T00:00:00\", \"2020-09-13T00:00:00\", \"2020-09-14T00:00:00\", \"2020-09-15T00:00:00\", \"2020-09-16T00:00:00\", \"2020-09-17T00:00:00\", \"2020-09-18T00:00:00\", \"2020-09-19T00:00:00\", \"2020-09-20T00:00:00\", \"2020-09-21T00:00:00\", \"2020-09-22T00:00:00\", \"2020-09-23T00:00:00\", \"2020-09-24T00:00:00\", \"2020-09-25T00:00:00\", \"2020-09-26T00:00:00\", \"2020-09-27T00:00:00\", \"2020-09-28T00:00:00\", \"2020-09-29T00:00:00\", \"2020-09-30T00:00:00\", \"2020-10-01T00:00:00\", \"2020-10-02T00:00:00\", \"2020-10-03T00:00:00\", \"2020-10-04T00:00:00\", \"2020-10-05T00:00:00\", \"2020-10-06T00:00:00\", \"2020-10-07T00:00:00\", \"2020-10-08T00:00:00\", \"2020-10-09T00:00:00\", \"2020-10-10T00:00:00\", \"2020-10-11T00:00:00\", \"2020-10-12T00:00:00\", \"2020-10-13T00:00:00\", \"2020-10-14T00:00:00\", \"2020-10-15T00:00:00\", \"2020-10-16T00:00:00\", \"2020-10-17T00:00:00\", \"2020-10-18T00:00:00\", \"2020-10-19T00:00:00\", \"2020-10-20T00:00:00\", \"2020-10-21T00:00:00\", \"2020-10-22T00:00:00\", \"2020-10-23T00:00:00\", \"2020-10-24T00:00:00\", \"2020-10-25T00:00:00\", \"2020-10-26T00:00:00\", \"2020-10-27T00:00:00\", \"2020-10-28T00:00:00\", \"2020-10-29T00:00:00\", \"2020-10-30T00:00:00\", \"2020-10-31T00:00:00\", \"2020-11-01T00:00:00\", \"2020-11-02T00:00:00\", \"2020-11-03T00:00:00\", \"2020-11-04T00:00:00\", \"2020-11-05T00:00:00\", \"2020-11-06T00:00:00\", \"2020-11-07T00:00:00\", \"2020-11-08T00:00:00\", \"2020-11-09T00:00:00\", \"2020-11-10T00:00:00\", \"2020-11-11T00:00:00\", \"2020-11-12T00:00:00\", \"2020-11-13T00:00:00\", \"2020-11-14T00:00:00\", \"2020-11-15T00:00:00\", \"2020-11-16T00:00:00\", \"2020-11-17T00:00:00\", \"2020-11-18T00:00:00\", \"2020-11-19T00:00:00\", \"2020-11-20T00:00:00\", \"2020-11-21T00:00:00\", \"2020-11-22T00:00:00\", \"2020-11-23T00:00:00\", \"2020-11-24T00:00:00\", \"2020-11-25T00:00:00\", \"2020-11-26T00:00:00\", \"2020-11-27T00:00:00\", \"2020-11-28T00:00:00\", \"2020-11-29T00:00:00\", \"2020-11-30T00:00:00\", \"2020-12-01T00:00:00\", \"2020-12-02T00:00:00\", \"2020-12-03T00:00:00\", \"2020-12-04T00:00:00\", \"2020-12-05T00:00:00\", \"2020-12-06T00:00:00\", \"2020-12-07T00:00:00\", \"2020-12-08T00:00:00\", \"2020-12-09T00:00:00\", \"2020-12-10T00:00:00\", \"2020-12-11T00:00:00\", \"2020-12-12T00:00:00\", \"2020-12-13T00:00:00\", \"2020-12-14T00:00:00\", \"2020-12-15T00:00:00\", \"2020-12-16T00:00:00\", \"2020-12-17T00:00:00\", \"2020-12-18T00:00:00\", \"2020-12-19T00:00:00\", \"2020-12-20T00:00:00\", \"2020-12-21T00:00:00\", \"2020-12-22T00:00:00\", \"2020-12-23T00:00:00\", \"2020-12-24T00:00:00\", \"2020-12-25T00:00:00\", \"2020-12-26T00:00:00\", \"2020-12-27T00:00:00\", \"2020-12-28T00:00:00\", \"2020-12-29T00:00:00\", \"2020-12-30T00:00:00\", \"2020-12-31T00:00:00\", \"2021-01-01T00:00:00\", \"2021-01-02T00:00:00\", \"2021-01-03T00:00:00\", \"2021-01-04T00:00:00\", \"2021-01-05T00:00:00\", \"2021-01-06T00:00:00\", \"2021-01-07T00:00:00\", \"2021-01-08T00:00:00\", \"2021-01-09T00:00:00\", \"2021-01-10T00:00:00\", \"2021-01-11T00:00:00\", \"2021-01-12T00:00:00\", \"2021-01-13T00:00:00\", \"2021-01-14T00:00:00\", \"2021-01-15T00:00:00\", \"2021-01-16T00:00:00\", \"2021-01-17T00:00:00\", \"2021-01-18T00:00:00\", \"2021-01-19T00:00:00\", \"2021-01-20T00:00:00\", \"2021-01-21T00:00:00\", \"2021-01-22T00:00:00\", \"2021-01-23T00:00:00\", \"2021-01-24T00:00:00\", \"2021-01-25T00:00:00\", \"2021-01-26T00:00:00\", \"2021-01-27T00:00:00\", \"2021-01-28T00:00:00\", \"2021-01-29T00:00:00\", \"2021-01-30T00:00:00\", \"2021-01-31T00:00:00\", \"2021-02-01T00:00:00\", \"2021-02-02T00:00:00\", \"2021-02-03T00:00:00\", \"2021-02-04T00:00:00\", \"2021-02-05T00:00:00\", \"2021-02-06T00:00:00\", \"2021-02-07T00:00:00\", \"2021-02-08T00:00:00\", \"2021-02-09T00:00:00\", \"2021-02-10T00:00:00\", \"2021-02-11T00:00:00\", \"2021-02-12T00:00:00\", \"2021-02-13T00:00:00\", \"2021-02-14T00:00:00\", \"2021-02-15T00:00:00\", \"2021-02-16T00:00:00\", \"2021-02-17T00:00:00\", \"2021-02-18T00:00:00\", \"2021-02-19T00:00:00\", \"2021-02-20T00:00:00\", \"2021-02-21T00:00:00\", \"2021-02-22T00:00:00\", \"2021-02-23T00:00:00\", \"2021-02-24T00:00:00\", \"2021-02-25T00:00:00\", \"2021-02-26T00:00:00\", \"2021-02-27T00:00:00\", \"2021-02-28T00:00:00\", \"2021-03-01T00:00:00\", \"2021-03-02T00:00:00\", \"2021-03-03T00:00:00\", \"2021-03-04T00:00:00\", \"2021-03-05T00:00:00\", \"2021-03-06T00:00:00\", \"2021-03-07T00:00:00\", \"2021-03-08T00:00:00\", \"2021-03-09T00:00:00\", \"2021-03-10T00:00:00\", \"2021-03-11T00:00:00\", \"2021-03-12T00:00:00\", \"2021-03-13T00:00:00\", \"2021-03-14T00:00:00\", \"2021-03-15T00:00:00\", \"2021-03-16T00:00:00\", \"2021-03-17T00:00:00\", \"2021-03-18T00:00:00\", \"2021-03-19T00:00:00\", \"2021-03-20T00:00:00\", \"2021-03-21T00:00:00\", \"2021-03-22T00:00:00\", \"2021-03-23T00:00:00\", \"2021-03-24T00:00:00\", \"2021-03-25T00:00:00\", \"2021-03-26T00:00:00\", \"2021-03-27T00:00:00\", \"2021-03-28T00:00:00\", \"2021-03-29T00:00:00\", \"2021-03-30T00:00:00\", \"2021-03-31T00:00:00\", \"2021-04-01T00:00:00\", \"2021-04-02T00:00:00\", \"2021-04-03T00:00:00\", \"2021-04-04T00:00:00\", \"2021-04-05T00:00:00\", \"2021-04-06T00:00:00\", \"2021-04-07T00:00:00\", \"2021-04-08T00:00:00\", \"2021-04-09T00:00:00\", \"2021-04-10T00:00:00\", \"2021-04-11T00:00:00\", \"2021-04-12T00:00:00\", \"2021-04-13T00:00:00\", \"2021-04-14T00:00:00\", \"2021-04-15T00:00:00\", \"2021-04-16T00:00:00\", \"2021-04-17T00:00:00\", \"2021-04-18T00:00:00\", \"2021-04-19T00:00:00\", \"2021-04-20T00:00:00\", \"2021-04-21T00:00:00\", \"2021-04-22T00:00:00\"], \"xaxis\": \"x\", \"y\": [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 608.41, 0.0, 0.0, 0.0, 0.0, 838.11, 0.0, 0.0, 0.0, 0.0, 0.0, 961.71, 972.36, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], \"yaxis\": \"y\"}],\n",
              "                        {\"legend\": {\"tracegroupgap\": 0}, \"template\": {\"data\": {\"bar\": [{\"error_x\": {\"color\": \"#2a3f5f\"}, \"error_y\": {\"color\": \"#2a3f5f\"}, \"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"bar\"}], \"barpolar\": [{\"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"barpolar\"}], \"carpet\": [{\"aaxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"baxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"type\": \"carpet\"}], \"choropleth\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"choropleth\"}], \"contour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"contour\"}], \"contourcarpet\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"contourcarpet\"}], \"heatmap\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmap\"}], \"heatmapgl\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmapgl\"}], \"histogram\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"histogram\"}], \"histogram2d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2d\"}], \"histogram2dcontour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2dcontour\"}], \"mesh3d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"mesh3d\"}], \"parcoords\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"parcoords\"}], \"pie\": [{\"automargin\": true, \"type\": \"pie\"}], \"scatter\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter\"}], \"scatter3d\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter3d\"}], \"scattercarpet\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattercarpet\"}], \"scattergeo\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergeo\"}], \"scattergl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergl\"}], \"scattermapbox\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattermapbox\"}], \"scatterpolar\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolar\"}], \"scatterpolargl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolargl\"}], \"scatterternary\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterternary\"}], \"surface\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"surface\"}], \"table\": [{\"cells\": {\"fill\": {\"color\": \"#EBF0F8\"}, \"line\": {\"color\": \"white\"}}, \"header\": {\"fill\": {\"color\": \"#C8D4E3\"}, \"line\": {\"color\": \"white\"}}, \"type\": \"table\"}]}, \"layout\": {\"annotationdefaults\": {\"arrowcolor\": \"#2a3f5f\", \"arrowhead\": 0, \"arrowwidth\": 1}, \"coloraxis\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"colorscale\": {\"diverging\": [[0, \"#8e0152\"], [0.1, \"#c51b7d\"], [0.2, \"#de77ae\"], [0.3, \"#f1b6da\"], [0.4, \"#fde0ef\"], [0.5, \"#f7f7f7\"], [0.6, \"#e6f5d0\"], [0.7, \"#b8e186\"], [0.8, \"#7fbc41\"], [0.9, \"#4d9221\"], [1, \"#276419\"]], \"sequential\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"sequentialminus\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}, \"colorway\": [\"#636efa\", \"#EF553B\", \"#00cc96\", \"#ab63fa\", \"#FFA15A\", \"#19d3f3\", \"#FF6692\", \"#B6E880\", \"#FF97FF\", \"#FECB52\"], \"font\": {\"color\": \"#2a3f5f\"}, \"geo\": {\"bgcolor\": \"white\", \"lakecolor\": \"white\", \"landcolor\": \"#E5ECF6\", \"showlakes\": true, \"showland\": true, \"subunitcolor\": \"white\"}, \"hoverlabel\": {\"align\": \"left\"}, \"hovermode\": \"closest\", \"mapbox\": {\"style\": \"light\"}, \"paper_bgcolor\": \"white\", \"plot_bgcolor\": \"#E5ECF6\", \"polar\": {\"angularaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"radialaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"scene\": {\"xaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"yaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"zaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}}, \"shapedefaults\": {\"line\": {\"color\": \"#2a3f5f\"}}, \"ternary\": {\"aaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"baxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"caxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"title\": {\"x\": 0.05}, \"xaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}, \"yaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}}}, \"title\": {\"text\": \"Evolution du prix du BTC\"}, \"xaxis\": {\"anchor\": \"y\", \"domain\": [0.0, 1.0], \"rangeslider\": {\"visible\": true}, \"title\": {\"text\": \"x\"}}, \"yaxis\": {\"anchor\": \"x\", \"autorange\": true, \"domain\": [0.0, 1.0], \"fixedrange\": false, \"title\": {\"text\": \"y\"}}},\n",
              "                        {\"responsive\": true}\n",
              "                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('d761acf0-dc52-4b7e-9227-37df53b1147a');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })\n",
              "                };\n",
              "                \n",
              "            </script>\n",
              "        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zVAWVQioe-kS"
      },
      "source": [
        "Comme les anomalies détectées ne sembles pas cohérentes, nous n'allons pas les traiter..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7vDYEK-cxE0C"
      },
      "source": [
        "# Analyse de la série"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mGY4fCB3xdUx",
        "outputId": "89d1ab50-bfa2-402c-be37-c9da63377843",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 446
        }
      },
      "source": [
        "df_paris"
      ],
      "execution_count": 226,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>taux</th>\n",
              "      <th>Anomalies</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>extract_date</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2020-03-18</th>\n",
              "      <td>108.53</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2020-03-19</th>\n",
              "      <td>108.53</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2020-03-20</th>\n",
              "      <td>108.53</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2020-03-21</th>\n",
              "      <td>108.53</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2020-03-22</th>\n",
              "      <td>108.53</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2021-04-18</th>\n",
              "      <td>80.22</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2021-04-19</th>\n",
              "      <td>75.20</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2021-04-20</th>\n",
              "      <td>75.50</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2021-04-21</th>\n",
              "      <td>74.59</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2021-04-22</th>\n",
              "      <td>77.78</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>401 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                taux  Anomalies\n",
              "extract_date                   \n",
              "2020-03-18    108.53          0\n",
              "2020-03-19    108.53          0\n",
              "2020-03-20    108.53          0\n",
              "2020-03-21    108.53          0\n",
              "2020-03-22    108.53          0\n",
              "...              ...        ...\n",
              "2021-04-18     80.22          0\n",
              "2021-04-19     75.20          0\n",
              "2021-04-20     75.50          0\n",
              "2021-04-21     74.59          0\n",
              "2021-04-22     77.78          0\n",
              "\n",
              "[401 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 226
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kBCbjPSNxWXy"
      },
      "source": [
        "**1. ACF & PACF**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CleN4htOxYqZ",
        "outputId": "0bcb7814-e833-47c2-c168-bc756d5f2120",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        }
      },
      "source": [
        "# ACF & PACF du bruit blanc\n",
        "\n",
        "serie = df_paris['taux']\n",
        "\n",
        "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
        "\n",
        "f1, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
        "f1.subplots_adjust(hspace=0.3,wspace=0.2)\n",
        "\n",
        "plot_acf(serie, ax=ax1, lags = range(0,100))\n",
        "ax1.set_title(\"Autocorrélation du bruit blanc\")\n",
        "\n",
        "plot_pacf(serie, ax=ax2, lags = range(0, 100))\n",
        "ax2.set_title(\"Autocorrélation partielle du bruit blanc\")"
      ],
      "execution_count": 235,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/statsmodels/regression/linear_model.py:1358: RuntimeWarning:\n",
            "\n",
            "invalid value encountered in sqrt\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'Autocorrélation partielle du bruit blanc')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 235
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1080x360 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o66MqHZTyHX5"
      },
      "source": [
        "**2. Test de Dickey-Fuller**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fm5VXMhkyLSN",
        "outputId": "d66f1f85-9ef4-498a-dd7c-eedaffaf1458",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import statsmodels.api as sm\n",
        "\n",
        "serie_test = serie\n",
        "\n",
        "adf, p, usedlag, nobs, cvs, aic = sm.tsa.stattools.adfuller(serie_test)\n",
        "\n",
        "adf_results_string = 'ADF: {}\\np-value: {},\\nN: {}, \\ncritical values: {}'\n",
        "print(adf_results_string.format(adf, p, nobs, cvs))"
      ],
      "execution_count": 228,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ADF: -3.2152287548025362\n",
            "p-value: 0.019119929430470778,\n",
            "N: 390, \n",
            "critical values: {'1%': -3.4472291365835566, '5%': -2.8689795375849223, '10%': -2.5707330834976987}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "moHyQgGfyTi4"
      },
      "source": [
        "**3. Suppression de la tendance non linéaire et test de sationnarité**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "43AcGds6y0pI"
      },
      "source": [
        "from scipy.stats import boxcox\n",
        "\n",
        "serie_log, lam = boxcox(serie)\n",
        "\n",
        "f1, (ax1,ax2) = plt.subplots(2, 1, figsize=(15, 5))\n",
        "ax1.plot(serie_etude.index,serie_log)\n",
        "ax2.plot(serie_etude.index,serie)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1fRPXCkO0DUh"
      },
      "source": [
        "import statsmodels.api as sm\n",
        "\n",
        "serie_test = serie_log\n",
        "\n",
        "adf, p, usedlag, nobs, cvs, aic = sm.tsa.stattools.adfuller(serie_test)\n",
        "\n",
        "adf_results_string = 'ADF: {}\\np-value: {},\\nN: {}, \\ncritical values: {}'\n",
        "print(adf_results_string.format(adf, p, nobs, cvs))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wI8sp_Rlz6GT"
      },
      "source": [
        "***4. Suppression de la tendance linéaire et test de stationnarité***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1iHrAWJH0TdT"
      },
      "source": [
        "f1, (ax1, ax2) = plt.subplots(2, 1, figsize=(15, 5))\n",
        "\n",
        "# Calcul des coefficients\n",
        "x = np.linspace(0,len(serie_log),len(serie_log))\n",
        "coefs = np.polyfit(x,serie_log,1)\n",
        "\n",
        "# Calcul de la tendance non linéaire\n",
        "trend = coefs[0]*np.power(x,1) + coefs[1]\n",
        "\n",
        "# Calcul de la série sans tendance\n",
        "serie_log_detrend = serie_log - trend\n",
        "\n",
        "# Affiche les résultats\n",
        "ax1.plot(trend)\n",
        "ax1.plot(serie_log)\n",
        "ax1.set_title(\"Série originale et tendance non linéaire\")\n",
        "\n",
        "ax2.plot(serie_log_detrend)\n",
        "ax2.set_title(\"Série avec tendance non linéaire supprimée\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yNXs9Fm--Kcl"
      },
      "source": [
        "# ACF & PACF du bruit blanc\n",
        "\n",
        "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
        "\n",
        "f1, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
        "f1.subplots_adjust(hspace=0.3,wspace=0.2)\n",
        "\n",
        "plot_acf(serie_log_detrend, ax=ax1, lags = range(0,50))\n",
        "ax1.set_title(\"Autocorrélation du bruit blanc\")\n",
        "\n",
        "plot_pacf(serie_log_detrend, ax=ax2, lags = range(0, 50))\n",
        "ax2.set_title(\"Autocorrélation partielle du bruit blanc\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_r01cDgq0xaJ"
      },
      "source": [
        "import statsmodels.api as sm\n",
        "\n",
        "serie_test = serie_log_detrend\n",
        "\n",
        "adf, p, usedlag, nobs, cvs, aic = sm.tsa.stattools.adfuller(serie_test)\n",
        "\n",
        "adf_results_string = 'ADF: {}\\np-value: {},\\nN: {}, \\ncritical values: {}'\n",
        "print(adf_results_string.format(adf, p, nobs, cvs))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ychdf1RxMPDD"
      },
      "source": [
        "**5. Différentiation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-qaHkgtQMOqJ"
      },
      "source": [
        "# Différenciation d'odre 1 et saisonnale à l'odre 1 et de période 12\n",
        "\n",
        "from statsmodels.tsa.statespace.tools import diff\n",
        "\n",
        "serie_log_detrend_diff1 = diff(serie_log_detrend,1)       # diff=1 ; diff_saison=1 ; periode = 12\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(serie_log_detrend_diff1)\n",
        "plt.title(\"Signal différencié d'ordre 1 + saisonalité\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kFLlzv0JMks5"
      },
      "source": [
        "import statsmodels.api as sm\n",
        "\n",
        "serie_test = serie_log_detrend_diff1\n",
        "\n",
        "adf, p, usedlag, nobs, cvs, aic = sm.tsa.stattools.adfuller(serie_test)\n",
        "\n",
        "adf_results_string = 'ADF: {}\\np-value: {},\\nN: {}, \\ncritical values: {}'\n",
        "print(adf_results_string.format(adf, p, nobs, cvs))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q0Oqd_7XMqaZ"
      },
      "source": [
        "# ACF & PACF du bruit blanc\n",
        "\n",
        "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
        "\n",
        "f1, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
        "f1.subplots_adjust(hspace=0.3,wspace=0.2)\n",
        "\n",
        "plot_acf(serie_log_detrend_diff1, ax=ax1, lags = range(0,50))\n",
        "ax1.set_title(\"Autocorrélation du bruit blanc\")\n",
        "\n",
        "plot_pacf(serie_log_detrend_diff1, ax=ax2, lags = range(0, 50))\n",
        "ax2.set_title(\"Autocorrélation partielle du bruit blanc\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V5oIY2Yl5Tlt"
      },
      "source": [
        "**5. Enregistrement des données dans le dataframe**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WjFSWhdeM4KM"
      },
      "source": [
        "serie_log_detrend_diff1 = np.insert(serie_log_detrend_diff1,0,0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ele3kFOp5TTW"
      },
      "source": [
        "serie_etude['diff'] = serie_log_detrend_diff1\n",
        "serie_etude['diff'][0] = \"Nan\"\n",
        "serie_etude"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iG5Fyx5O5oe5"
      },
      "source": [
        "# Prépartion des datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P7cGUeWb5oe7"
      },
      "source": [
        "**1. Séparation des données en données pour l'entrainement et la validation**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ob-EAw_j5oe8"
      },
      "source": [
        "On réserve 20% des données pour l'entrainement et le reste pour la validation :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R5AWeK_Z5oe8",
        "outputId": "3c7dc285-4549-40dc-8fa5-384ab5e991a1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Sépare les données en entrainement et tests\n",
        "pourcentage = 0.9\n",
        "temps_separation = int(len(df_paris['taux']) * pourcentage)\n",
        "date_separation = df_paris.index[temps_separation]\n",
        "\n",
        "serie_entrainement = df_paris['taux'].iloc[:temps_separation]\n",
        "serie_test = df_paris['taux'].iloc[temps_separation:]\n",
        "\n",
        "print(\"Taille de l'entrainement : %d\" %len(serie_entrainement))\n",
        "print(\"Taille de la validation : %d\" %len(serie_test))"
      ],
      "execution_count": 381,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Taille de l'entrainement : 360\n",
            "Taille de la validation : 41\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vZUMMMro5oe9"
      },
      "source": [
        "On normalise les données :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xu_YxoSI5oe9"
      },
      "source": [
        "# Calcul de la moyenne et de l'écart type de la série\n",
        "mean = tf.math.reduce_mean(np.asarray(serie_entrainement))\n",
        "std = tf.math.reduce_std(np.asarray((serie_entrainement)))\n",
        "\n",
        "# Normalisation des données\n",
        "serie_entrainement = (serie_entrainement-mean)/std\n",
        "serie_test = (serie_test-mean)/std"
      ],
      "execution_count": 382,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v_4OZJ-p5oe9",
        "outputId": "3c34ae3f-8654-4a31-bc0f-58e2cc11d4b5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 385
        }
      },
      "source": [
        "# Affiche la série\n",
        "fig, ax = plt.subplots(constrained_layout=True, figsize=(15,5))\n",
        "ax.plot(serie_entrainement, label=\"Entrainement\")\n",
        "ax.plot(serie_test,label=\"Validation\")\n",
        "\n",
        "ax.set_title(\"Evolution du prix du BTC\")\n",
        "\n",
        "ax.legend()\n",
        "plt.show()"
      ],
      "execution_count": 383,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAABEAAAAFwCAYAAAC4vQ5FAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOzdeXjcZbn/8c8zk2Wyp82+tHRvaem+AQVsy64sgiwWECoCgh5xOcJPPCocxeUIKgc3FDigghQOAirLESiUVVq6031N0+xLsyeTZGae3x+TxLR0SZtJvjOT9+u6cl3JzHyf752kheaT+7kfY60VAAAAAABANHM5XQAAAAAAAMBAIwABAAAAAABRjwAEAAAAAABEPQIQAAAAAAAQ9QhAAAAAAABA1CMAAQAAAAAAUY8ABACAKGSMscaYcSd47ZnGmO2hrukI9yoyxpwzSPe61hjzaojWWmGMuSkUawEAgMFBAAIAgIO6AoA2Y0xzr7dfDXINB4Ul1tp3rLUTB7OGwWCtfdJae57TdRzyPa8zxrxkjBnR9dwrvf4cdBpjOnp9/JAJut0Ys8kY02KMKTHG/K8xZqrTnxcAAOGOAAQAAOddbK1N7vX2b04XFG2MMTFO13CIi621yZLyJFVK+qUkWWsv7P5zIOlJST/t9efiVkn/Lemrkm6XNFzSBEkvSPqUE58EAACRhAAEAIAwZIyJN8bUG2NO6fVYVlfnQHbXxzcbY3YZYw4YY/5mjMk/wloHbdcwxiw1xrzb9f7bXQ9v6OoyuNoYs9AYU9Lr9Sd3rVFvjNlsjLmk13OPG2N+3dXF0GSMWWmMGXuUz+tzxph9xphaY8x/HPLc48aYe3t9fFAdh1nLdnVD7DHG1Bhj7jPGuHp9ju8ZY35hjKmVdM8hn/fpXdd0d15M7+rGmHSEe51rjNlmjGno6tAxvZ67xxjzRK+PR3XVdszQxVrrlfSspMnHeq0xZrykL0taYq19w1rbbq1t7eps+cmxrgcAYKgjAAEAIAxZa9slPSdpSa+Hr5L0lrW2yhizWNKPux7Lk7RP0rITuM9ZXe9O7+oyeLr388aYWEl/l/SqpGxJX5H0pDGm9xaZz0r6T0nDJO2S9MPD3csYM1nSbyV9TlK+pAxJhcdb8yEukzRH0ixJl0q6sddz8yXtkZRzaE3W2vcl/U7SH4wxCZKekPRda+22w9SdqeD34juSMiXtlrSgn3V3r50o6WpJH/Th5WdLKrHWrgrFvQEAGGoIQAAAcN4LXd0V3W83dz3+ZwXDhW7XdD0mSddK+h9r7dqusOQuSacZY0aFuLZTJSVL+om1tsNa+4akF3VwMPO8tXaVtdan4LaNGUdY6wpJL1pr3+6q+buSAv2s77+stQestcWSHjikrjJr7S+ttT5rbdthrr1HUpqkVZJKJf36CPf4pKTN1tpnrbWdXfep6GfdLxhj6iU1SDpX0n19uCZDUnk/7wsAwJBFAAIAgPM+ba1N7/X2cNfjb0pKNMbM7wo2Zkh6vuu5fAW7PiRJ1tpmSbWSCkJcW76k/dba3kHFvkPu0zsMaFUwMDniWt0fWGtbFKy5P/b3en9f1z0O99zHdIUZj0s6RdLPrLX2CC89tG57rLX74NPW2nRJHkn/JuktY0zuMa6pVbDbBwAAnAACEAAAwpS11i/pGQW7GpYo2D3R1PV0maSTul9rjElSsEOg9DBLtUhK7PXxsX7Q7q1M0oju2RpdRh7hPsdSLmlE9wdd2z8y+lnniF7vj1Sw3m5HCjS6718g6W5Jj0n6mTEm/ggvPbRuc8h9T/jra631W2ufk+SXdMYxXr5cUqExZk5f1wcAAP9CAAIAQHj7s4IzIq7Vv7a/SNJTkj5vjJnR9YP7jySttNYWHWaN9ZIuN8Ykdh13+4VDnq+UNOYI91+pYFfHncaYWGPMQkkX6wTmjSg47PMiY8wZxpg4Sd/Xwf8WWS/pk8aY4V3dEF/rw5p3GGOGdQ0z/aqkp491gdQTYjwu6VEFvx7lkn5whJe/JGmKMebyrsGmt+vgkGO9pLOMMSONMWkKbkfqk65jbS9VcH7K1qO91lq7U9JvJD3VNSA2zhjjMcZ81hjzrb7eEwCAoYoABAAA5/296wSW7rfubS6y1q5UsMMgX9IrvR5/XcEZGn9R8If3sTp4Xkhvv5DUoWDQ8QcF53T0do+Cw0DrjTFX9X7CWtuhYOBxoaQaBX8Av/5ww0KPxVq7WcFTTP7cVXOdpN6nvPxJ0gZJRQoOXe1LmPFXSWsUDCFeUjDQ6IvbFRzq+t2uLS2fVzBQOvMwdddIulLSTxTchjJe0nu9nn+tq9aNXbW82If7/90Y0yypUcEBrTd0fX36UvevFJxXUq/gQNbLFBxUCwAAjsIcebsrAABA+DLGWEnjrbW7nK4FAACEPzpAAAAAAABA1CMAAQAAAAAAUY8tMAAAAAAAIOrRAQIAAAAAAKIeAQgAAAAAAIh6MU7cNDMz044aNcqJWwMAAAAAgCi1Zs2aGmtt1uGecyQAGTVqlFavXu3ErQEAAAAAQJQyxuw70nNsgQEAAAAAAFGPAAQAAAAAAEQ9AhAAAAAAABD1HJkBAgAAAABAuOvs7FRJSYm8Xq/TpeAQHo9HhYWFio2N7fM1IQtAjDFuSasllVprLwrVugAAAAAAOKGkpEQpKSkaNWqUjDFOl4Mu1lrV1taqpKREo0eP7vN1odwC81VJW0O4HgAAAAAAjvF6vcrIyCD8CDPGGGVkZBx3Z05IAhBjTKGkT0l6JBTrAQAAAAAQDgg/wtOJfF9C1QHygKQ7JQWO9AJjzC3GmNXGmNXV1dUhui0AAAAAANHL7XZrxowZPW8/+clPjvr6FStW6P333z/u+6xevVq33377iZY5YB544AG1traGZK1+zwAxxlwkqcpau8YYs/BIr7PW/l7S7yVpzpw5tr/3BQAAAAAg2iUkJGj9+vV9fv2KFSuUnJys008//WPP+Xw+xcQcPgaYM2eO5syZc8J1DpQHHnhA1113nRITE/u9Vig6QBZIusQYUyRpmaTFxpgnQrAuAAAAAAA4jFGjRunuu+/WrFmzNHXqVG3btk1FRUV66KGH9Itf/EIzZszQO++8o6VLl+rWW2/V/Pnzdeedd2rVqlU67bTTNHPmTJ1++unavn27pGBwctFFwfNM7rnnHt14441auHChxowZowcffLDnvk888YTmzZunGTNm6Itf/KL8fr8kKTk5WXfccYemTJmic845R6tWreq5/m9/+5skye/364477tDcuXM1bdo0/e53v+u598KFC3XFFVdo0qRJuvbaa2Wt1YMPPqiysjItWrRIixYt6vfXrN8dINbauyTdJUldHSDftNZe1991AQAAAAAIF//5983aUtYY0jUn56fq7ounHPU1bW1tmjFjRs/Hd911l66++mpJUmZmptauXavf/OY3uv/++/XII4/o1ltvVXJysr75zW9Kkh599FGVlJTo/fffl9vtVmNjo9555x3FxMTo9ddf17e//W395S9/+dh9t23bpjfffFNNTU2aOHGibrvtNu3atUtPP/203nvvPcXGxupLX/qSnnzySV1//fVqaWnR4sWLdd999+myyy7Td77zHb322mvasmWLbrjhBl1yySV69NFHlZaWpg8//FDt7e1asGCBzjvvPEnSunXrtHnzZuXn52vBggV67733dPvtt+vnP/+53nzzTWVmZvb76x2yY3ABhC9vp1/r99fr1DEZTpcCAAAA4DgcbQvM5ZdfLkmaPXu2nnvuuSOuceWVV8rtdkuSGhoadMMNN2jnzp0yxqizs/Ow13zqU59SfHy84uPjlZ2drcrKSi1fvlxr1qzR3LlzJQXDmezsbElSXFycLrjgAknS1KlTFR8fr9jYWE2dOlVFRUWSpFdffVUbN27Us88+21PLzp07FRcXp3nz5qmwsFCSNGPGDBUVFemMM844ni/VMYU0ALHWrpC0IpRrAugfa63+/ZkNeumjcr3+jbM0LjvF6ZIAAACAiHOsTg0nxMfHSwoOSvX5fEd8XVJSUs/73/3ud7Vo0SI9//zzKioq0sKFC4+6du/1rbW64YYb9OMf//hjr4+Nje05mcXlcvVc73K5emqz1uqXv/ylzj///IOuXbFixWHvF2qhOgUGQJh6YmWxXvqoXJL01o4ah6sBAAAAMJBSUlLU1NR0xOcbGhpUUFAgSXr88cePa+2zzz5bzz77rKqqqiRJBw4c0L59+/p8/fnnn6/f/va3PV0nO3bsUEtLy1GvOdbnczwIQIAotqm0QT/4+xZ9YkKWxmQm6Z2dHEENAAAARJLuGSDdb9/61reO+vqLL75Yzz//fM8Q1EPdeeeduuuuuzRz5szj7rKYPHmy7r33Xp133nmaNm2azj33XJWXl/f5+ptuukmTJ0/WrFmzdMopp+iLX/ziMWu45ZZbdMEFF4RkCKqxdvBPpJ0zZ45dvXr1oN8XGGou/dW7qmj06uXbz9Qv39ilZR8Wa8Pd5yk+xu10aQAAAEDY27p1q04++WSny8ARHO77Y4xZY6097Hm+dIAAUWpnZZM2lDToi2eNVUZyvM4cnylvZ0BriuqcLg0AAAAABh0BCBClnltXKrfL6JIZ+ZKkU8dkKNZt9PZO5oAAAAAAGHoIQIAoFAhY/XVdqc4an6nM5OA05aT4GM0aOYw5IAAAAACGJAIQIAp9sLdWZQ1eXTar8KDHz5qQpc1ljappbneoMgAAAABwBgEIEIWeX1uq5PgYnTc556DHzxyfKUl6l20wAAAAAIaYGKcLABAaVU1erdhereqmdr2yqUIXnpIrT+zBp72ckp+m4UlxemtHtT49s8ChSgEAAABg8NEBAkSBVzdX6LxfvK07n92o+/6xXXExLl136kkfe53LZbRwYpbe3F4lf2Dwj8AGAAAA0HeLFi3SP/7xj4Mee+CBB3Tbbbcd9vULFy7U6tWrJUmf/OQnVV9f/7HX3HPPPbr//vuPet8XXnhBW7Zs6fn4e9/7nl5//fXjLT/s0AECRDCfP6B7X9qqx98v0pT8VD3xhfkal538sc6P3hZPytZza0u1rrhOc0YNH8RqAQAAAByPJUuWaNmyZTr//PN7Hlu2bJl++tOfHvPal19++YTv+8ILL+iiiy7S5MmTJUnf//73T3itcEIHCBChWtp9uumPq/X4+0W6ccFoPfel03VKQdpRww9JOnN8lmJcRm9sqxqkSgEAAACciCuuuEIvvfSSOjo6JElFRUUqKyvTU089pTlz5mjKlCm6++67D3vtqFGjVFMTnP33wx/+UBMmTNAZZ5yh7du397zm4Ycf1ty5czV9+nR95jOfUWtrq95//3397W9/0x133KEZM2Zo9+7dWrp0qZ599llJ0vLlyzVz5kxNnTpVN954o9rb23vud/fdd2vWrFmaOnWqtm3bNpBfmhNCBwgQgRpaO3Xtox9oS1mjfnTZVF0zf2Sfr01LiNXcUcP1xrYq3XnBpAGsEgAAAIgir3xLqvgotGvmTpUu/MkRnx4+fLjmzZunV155RZdeeqmWLVumq666St/+9rc1fPhw+f1+nX322dq4caOmTZt22DXWrFmjZcuWaf369fL5fJo1a5Zmz54tSbr88st18803S5K+853v6NFHH9VXvvIVXXLJJbrooot0xRVXHLSW1+vV0qVLtXz5ck2YMEHXX3+9fvvb3+prX/uaJCkzM1Nr167Vb37zG91///165JFHQvFVChk6QIAI9ML6Um0qbdRD180+rvCj2+JJ2dpW0aTS+rYBqA4AAABAqHRvg5GC21+WLFmiZ555RrNmzdLMmTO1efPmg+Z1HOqdd97RZZddpsTERKWmpuqSSy7peW7Tpk0688wzNXXqVD355JPavHnzUWvZvn27Ro8erQkTJkiSbrjhBr399ts9z19++eWSpNmzZ6uoqOhEP+UBQwcIEIHWFdcpOyVe5x5yzG1fLT45Wz98eave2Falzx1mWCoAAACAQxylU2MgXXrppfr617+utWvXqrW1VcOHD9f999+vDz/8UMOGDdPSpUvl9XpPaO2lS5fqhRde0PTp0/X4449rxYoV/ao1Pj5ekuR2u+Xz+fq11kCgAwSIQOv312vGiHQZY07o+jGZSRqVkag3tlaGuDIAAAAAoZScnKxFixbpxhtv1JIlS9TY2KikpCSlpaWpsrJSr7zyylGvP+uss/TCCy+ora1NTU1N+vvf/97zXFNTk/Ly8tTZ2aknn3yy5/GUlBQ1NTV9bK2JEyeqqKhIu3btkiT96U9/0ic+8YkQfaYDjwAEiDB1LR0qqm3VjJHpJ7yGMUafmJClD/YckM8fCGF1AAAAAEJtyZIl2rBhg5YsWaLp06dr5syZmjRpkq655hotWLDgqNfOmjVLV199taZPn64LL7xQc+fO7XnuBz/4gebPn68FCxZo0qR/zQf87Gc/q/vuu08zZ87U7t27ex73eDx67LHHdOWVV2rq1KlyuVy69dZbQ/8JDxBjrR30m86ZM8d2n00M4Pi8ub1Kn3/sQ/355vk6fWzmCa/z1/Wl+uqy9Xr59jM1OT81hBUCAAAA0WHr1q06+eSTnS4DR3C4748xZo21ds7hXk8HCBBh1hfXy2WkaYUn3gEiSTNGBK9fv78+FGUBAAAAQFgjAAEizPr99ZqQk6Lk+P7NMB45PFHDk+K0fn9diCoDAAAAgPBFAAJEEGttzwDU/jLGaHphmtYV0wECAAAAIPoRgAARZG9NixraOkMSgEjSzJHDtKu6WU3ezpCsBwAAAEQbJ+Zm4thO5PtCAAJEkO55Hf05Aaa3GSPSZa20saQhJOsBAAAA0cTj8ai2tpYQJMxYa1VbWyuPx3Nc1/VviACAQbV+f72S4twan50SkvWmd3WSrCuu04JxJ36iDAAAABCNCgsLVVJSourqaqdLwSE8Ho8KCwuP6xoCECCCbCpt0JSCNLldJiTrpSXEakxWEifBAAAAAIcRGxur0aNHO10GQoQtMECEsNZqd3WLxmcnh3TdmSOGaf3+etr6AAAAAEQ1AhAgQtS2dKihrVNjs0IbgMwYma6a5g6V1LWFdF0AAAAACCcEIECE2F3VLEkaG+IOkHmjhkuSlm+tDOm6AAAAABBOCECACLG7ukWSNDYrKaTrTsxN0bTCNC37cD/bYAAAAABELQIQIELsrm6WJ9al/LSEkK+9ZN5Ibato0jqGoQIAAACIUgQgQITYXd2sMZnJcoXoBJjeLp6er6Q4t/68sjjkawMAAABAOCAAASLEnuoWjQnx9pduyfExumRGgV7cWKaGts4BuQcAAAAAOIkABIgA3k6/9te1hvwEmN6unT9S3s6A/nf1/gG7BwAAAAA4hQAEiABFtS2yNvQnwPR2SkGa5o0erh++vFU/fGmLvJ3+AbsXAAAAAAw2AhAgAuyuGpgTYA71+Ofn6tr5I/XwO3t15UP/lM8fGND7AQAAAMBgIQABIsDu6mZJ0pjMgesAkaTEuBjd++mpuuvCSfqotEFl9d4BvR8AAAAADBYCECAC7KluVkF6ghLi3INyvyn5aZKksoa2QbkfAAAAAAw0AhAgAuwewBNgDicv3SNJKicAAQAAABAlCECAMGet1e7q5gE9AeZQ+WkJksQWGAAAAABRgwAECHMVjV61dvgHfABqbwlxbqUnxtIBAgAAACBqEIAAYa6oplWSNCpz8AIQScpLS1A5HSAAAAAAogQBCBDm9h8IBiAnDR/cACQ/zaOyBgIQAAAAANGBAAQIc/sOtCjGZZTfNZh0sOSle9gCAwAAACBqEIAAYW5fbasKhiUoxj24f13z0hJU39qptg7/oN4XAAAAAAYCAQgQ5ooPtGrk8MRBv293x0kZXSAAAAAAogABCBDm9tU6E4DkdR2FW8EcEAAAAABRgAAECGMNrZ1qaOvUSRlOBCBdHSD1dIAAAAAAiHwEIEAYK+46AWbkIJ8AI0m5XQFIOR0gAAAAAKIAAQgQxvYdaJEkRzpA4mPcykyO4yQYAAAAAFGBAAQIY/tqgx0gIxyYASIF54CU1dMBAgAAACDyEYAAYWz/gVZlJscpOT7GkfvnpXnoAAEAAAAQFfodgBhjPMaYVcaYDcaYzcaY/wxFYQCcOwGmW356gsrpAAEAAAAQBULRAdIuabG1drqkGZIuMMacGoJ1gSGv+ECrTsoY/AGo3fLSPGpq96nJ2+lYDQAAAAAQCv0OQGxQc9eHsV1vtr/rAkNdu8+vsoY2RztA8tITJHESDAAAAIDIF5IZIMYYtzFmvaQqSa9Za1eGYl1gKCupa5O1cnYLTNdRuGX1zAEBAAAAENlCEoBYa/3W2hmSCiXNM8accuhrjDG3GGNWG2NWV1dXh+K2QFQrPhA8AcaJI3C70QECAAAAIFqE9BQYa229pDclXXCY535vrZ1jrZ2TlZUVytsCUam46wjckQ4GINkp8ZKkykYCEAAAAACRLRSnwGQZY9K73k+QdK6kbf1dFxjqig+0yhPrUlZyvGM1xLpdSk+MVU1zu2M1AAAAAEAoxIRgjTxJfzDGuBUMVJ6x1r4YgnWBIa2svk0F6QkyxjhaR2ZyvGqaOhytAQAAAAD6q98BiLV2o6SZIagFQC+l9W0qGObc9pdumclxqm2hAwQAAABAZAvpDBAAoVNa16aCdI/TZQQ7QJrpAAEAAAAQ2QhAgDDk7fSrtqVDBV2nsDgpuAWGDhAAAAAAkY0ABAhDpfVtkqSCYc4HIFkp8Wpq98nb6Xe6FAAAAAA4YQQgQBgqrQsGIPlpzgcgmclxksRJMAAAAAAiGgEIEIbKwqgDJCMpeAwvc0AAAAAARDICECAMlda3yWWknNQwGIKa0hWAMAcEAAAAQAQjAAHCUGldm3JTPYp1O/9XtHsLDEfhAgAAAIhkzv90BeBjSuvbwmL7ixQ8BUZiCwwAAACAyEYAAoSh0vo25YfBEbiS5Il1KyU+RtVsgQEAAAAQwQhAgDDjD1hVNHhVECYBiBScA8IpMAAAAAAiGQEIEGaqmrzyBWzYbIGRgnNACEAAAAAARDICECDMlNYFj8ANly0wUvAoXGaAAAAAAIhkBCBAmCmtDwYghWEUgGSm0AECAAAAILIRgABhpjsACacOkMzkeNW3dqrTH3C6FAAAAAA4IQQgQJgprWtTemKskuJjnC6lR/dRuAda2AYDAAAAIDIRgABhpqy+LaxOgJH+FYBwFC4AAACASEUAAoSZ0vq2sNr+IklZKXGSxBwQAAAAABGLAAQIE9ZaPfD6Du2obNYp+WlOl3OQ7g4QToIBAAAAEKnCZ8gAMIT5A1bfeWGTnlpVrM/MKtSXFo11uqSDZPQEIHSAAAAAAIhMBCBAGHhxY5meWlWsWz8xVv/vgokyxjhd0kGS4tzyxLpUwwwQAAAAABGKLTBAGHhxY7lyUz268/zwCz8kyRijzOR41XIKDAAAAIAIRQACOKy53ae3dlTrwqm5crnCL/zolpkczxYYAAAAABGLAARw2PKtlerwBfTJqXlOl3JUmcnxHIMLAAAAIGIRgAAOe+WjCmWnxGv2yGFOl3JU6YmxamjrdLoMAAAAADghBCCAg1rafXpze5UuOCW8t79IUoonRk1en9NlAAAAAMAJIQABHLRie7XaI2D7iySleGLV3O6TP2CdLgUAAAAAjhsBCOCg17ZUKDM5TnNHDXe6lGNK9QRPzW5upwsEAAAAQOQhAAEctLemRSfnpcod5ttfpOAWGElq8jIHBAAAAEDkIQABHFTe4FVemsfpMvokxRMrScwBAQAAABCRCEAAh3T6A6publduWoLTpfTJvzpACEAAAAAARB4CEMAh1U3tslYR2AHCFhgAAAAAkYcABHBIeYNXkpQbMQEIHSAAAAAAIhcBCOCQiu4AJDXSAhA6QAAAAABEHgIQwCHlDW2SImcLTGrXFphGOkAAAAAARCACEMAhFQ1eeWJdSkuIdbqUPomPcSnWbdgCAwAAACAiEYAADilv9CovLUHGGKdL6RNjjFI8sWyBAQAAABCRCEAAh1Q0eCNm/ke3FE8MHSAAAAAAIhIBCOCQigZvxMz/6BYMQOgAAQAAABB5CEAABwQCVpWN3og5ArdbSnwsHSAAAAAAIhIBCOCAmpZ2+QI24gKQ1AS2wAAAAACITAQggAMqGrySFIEzQBiCCgAAACAyEYAADijvCkDy0hIcruT4MAQVAAAAQKQiAAEc0NMBEmFbYFI8sWru8CkQsE6XAgAAAADHhQAEcEBFo1exbqOMpDinSzkuqZ4YWSs1d9AFAgAAACCyEIAADqho8Con1SOXyzhdynFJ8cRIEttgAAAAAEQcAhDAAeUNbcqLsO0vUnALjCQGoQIAAACIOAQggAO6O0AiDR0gAAAAACIVAQgwyKy1Km/w0gECAAAAAIOIAAQYZHWtnWr3BZQbYUfgSnSAAAAAAIhcBCDAINtX2yJJGjk80eFKjl93ANJIAAIAAAAgwhCAAIOsqCsAGZ2Z5HAlxy+VLTAAAAAAIhQBCDDI9la3yGUiswMkPsalWLdhCwwAAACAiNPvAMQYM8IY86YxZosxZrMx5quhKAyIVntrW1U4LFFxMZGXPxpjlOKJpQMEAAAAQMSJCcEaPkn/bq1da4xJkbTGGPOatXZLCNYGos7emmaNisDtL91SPDF0gAAAAACIOP3+FbS1ttxau7br/SZJWyUV9HddIBpZa1VU06oxBCAAAAAAMKhC2oNvjBklaaaklYd57hZjzGpjzOrq6upQ3haIGNXN7Wpu92lURuTN/+iWEs8WGAAAAACRJ2QBiDEmWdJfJH3NWtt46PPW2t9ba+dYa+dkZWWF6rZARCmqaZUktsAAAAAAwCALSQBijIlVMPx40lr7XCjWBKLR3ppmSdKYzGSHKzlxwSGoBCAAAAAAIksoToExkh6VtNVa+/P+lwREr701rYp1G+Wne5wu5YSleGLUyBYYAAAAABEmFB0gCyR9TtJiY8z6rrdPhmBdIOrsrWnWyOGJinFH3hG43VI9MWpu9ykQsE6XAgAAAAB91u9jcK2170oyIagFiHpFNa0aHcHzP6TgFhhrpeYOn1I9sU6XAwAAAAB9Erm/hgYiTCBgVVTbEgUBSIKPGfIAACAASURBVDA3ZQ4IAAAAgEhCAAIMkvJGr9p9gYg+AUYKdoBI4ihcAAAAABGFAAQYJHurWyQp4jtA0hKCAUhDKwEIAAAAgMhBAAIMkr210RGAFA5LkCQVH2h1uBIAAAAA6DsCEGCQ7KtpUXyMSzkpkXsErhQMQGJcRntrWpwuBQAAAAD6jAAEGCTFB1o1cniiXK7IPjQpxu3SyIxEAhAAAAAAEYUABBgk3QFINBidkUQAAgAAACCiEIAAg8Baq/0HWjUiWgKQzCQV1bYoELBOlwIAAAAAfUIAAgyCAy0daunwR00HyKjMJHk7A6po9DpdCgAAAAD0CQEIMAi6T0yJlgBkTNdJNkVsgwEAAAAQIQhAgEHQE4BkREcAMjorGIDsIQABAAAAECEIQIBBUFLXJkkaMSw6ApCcFI88sS46QAAAAABEDAIQYBAU17YqKyVeCXFup0sJCZfLaBQnwQAAAACIIAQgwCCIpiNwu43OJAABAAAAEDkIQIBBEK0BSPGBVvn8AadLAQAAAIBjIgABBliHL6DyhjaNiMIAxBewPfNNAAAAACCcEYAAA6ysvk0BGz1H4HYb3XUULttgAAAAAEQCAhBggPUcgUsAAgAAAACOIQABBli0BiDDk+KU6onRnppmp0sBAAAAgGMiAAEG2P4DrYqLcSk7Jd7pUkLKGKNx2cnaWUkAAgAAACD8EYAAA6z4QKtGDEuQy2WcLiXkJuamaEdlk6y1TpcCAAAAAEdFAAIMsGg8ArfbxJwU1bV2qrqp3elSAAAAAOCoCECAAbb/QKsKh0VnADIhN0WStK2iyeFKAAAAAODoCECAAdTk7VSj16eCYQlOlzIgJuYEA5AdlQQgAAAAAMIbAQgwgErr2yRJhVEagGQkxyszOZ4OEAAAAABhjwAEGEAlB4IBSEF6dAYgkjQpN0XbCUAAAAAAhDkCEGAAdXeAROsWGCl4EszOqib5A5wEAwAAACB8EYAAA6i0vk1xMS5lJsU7XcqAmZiTIm9nQMUHWp0uBQAAAACOiAAEGECldW0qSE+Qy2WcLmXATOw6CWZ7RaPDlQAAAADAkRGAAAOopL4tagegdhufkyxjpO0VzU6XAgAAAABHRAACDKDSutaoHoAqSYlxMRo5PFHbK+kAAQAAABC+CECAAeLt9KumuSPqAxBJmpDDSTAAAAAAwhsBCDBAhsIJMN1OzkvV3poWVTZ6nS4FAAAAAA6LAAQYIKV1wQCkcFiiw5UMvCtmFcpljH71xi6nSwEAAACAwyIAAQZISd3Q6QAZmZGoq+aO0LIPi7Wf43ABAAAAhCECEGCAlNa3yu0yykmJd7qUQfGVxeNkjNGDy3c6XQoAAAAAfAwBCDBASuvalJvqUYx7aPw1y0tL0HXzT9Jf1pbozyuLtbOySYGAdbosAAAAAJAkxThdABCtSuvbhsT2l95uWzhW/9hcoW8//5Ek6ZyTs/XIDXMdrgoAAAAACECAAVNS16bTxmY4XcagykqJ1zt3LtKemmb99P+2671dNQoErFwu43RpAAAAAIa4odGbDwyyTn9AlY1eFaYPrQ4QSXK5jMZlp2jxpGy1dPh7hsECAAAAgJMIQIABUNHgVcAOjRNgjmRibookaVtFo8OVAAAAAAABCDAguo+CLUhPdLgS50zISZEx0raKJqdLAQAAAAACEGAgbO36oX9CTrLDlTgnKT5GI4cn0gECAAAAICwQgAADYEtZozKT45Wd6nG6FEdNyk2hAwQAAABAWCAAAQbA5rIGTclPdboMx03MTVVRTYu8nX6nSwEAAAAwxBGAACHW7vNrV1UzAYikk3NTFLDSzspmp0sBAAAAMMQRgAAhtqOiWb6A1ZT8NKdLcVz3STBbmQMCAAAAwGEEIECIbS5rkCQ6QCSdlJEkT6xL25kDAgAAAMBhMU4XAESbLeWNSu46AWWoc7uMJuSkcBIMABxBVaNX7+6q0YdFB1RU06rS+jbdctYYXXfqSU6XBgBA1CEAAUJsc1mjTs5LkctlnC4lLEzKTdHyrVVOlwEAYcPnD+gfmyv1P+/t1Zp9dZKk9MRYjc1KVl1rh97aUU0AAgDAACAAAULIH7DaWt6oq+aMcLqUsDExN1XPrC5RdVO7slLinS4HABzV3O7Tp3/9nnZVNWvk8ETdcf5EfWJClibnpcrlMvrcoytV2eh1ukwAAKJSSAIQY8z/SLpIUpW19pRQrAlEoqLaFrV2+DWZ+R89JnUNQt1e0UQAAmDIW7aqWLuqmvWzK6fr0zML5D6kWzA31cPcJAAABkiohqA+LumCEK0FRKzNZcFZFwxA/ZfxOcmSpJ1V/IMewNDW6Q/of97dq3mjh+szsws/Fn5IUl6aRzXN7fL5Aw5UCABAdAtJAGKtfVvSgVCsBUSqkrpW/WNzhWLdRuOzU5wuJ2xkJccrLSFWOyqbex6rbW7Xyj21DlYFAIPvxY1lKmvw6otnjTnia3LSPApYqbq5fRArAwBgaGAGCNBPrR0+XfPwSq3fXy9JWjQxS3ExnDDdzRijCTnJ2ln5rw6QX76xS0+u3KeP7jlfnli3g9UBwOCw1up3b+3R+OxkLZqYfcTX5aZ6JEkVDV7lpSUMVnkAAAwJgxaAGGNukXSLJI0cOXKwbgsMuMfeK9L6/fW64/yJOndyjsZnJztdUtgZn5OilzaWy1orY4zWFtep02+1t6ZFJ+exXQhA9HtjW5W2VTTpp1dMO+opYTldAUgoBqG2dfhlZZUYx++7AACQQjcD5Jistb+31s6x1s7JysoarNsCA6qhrVO/e2u3Fk/K1pcXjdOEnBQZw/G3h5qQnayGtk5VN7XL2+nX1vLgrJQdlcwFARD99h9o1R3PbtSYrCRdOiP/qK/NTQsGIOUN/Q9AvvLUWt3+1Lp+rwMAQLTgVwJAPzz67l41en36xrkTnC4lrE3ICc5E2VHZrIQ4tzr9VpK0q6r5aJcBQMRr7fDp5j+uVqc/oEeun6P4mKNv+xueGKdYt1FFCDpAtpY3qbGtU4GAPWrXCQAAQ0VIOkCMMU9J+qekicaYEmPMF0KxLhDODrR06NF39uiTU3N1SkGa0+WEtXFdJ8HsqGzqmZUyLDFWOysJQABEt/94fpN2VDbpl0tmakzWsbdIulxG2SkeVfazA8TnD6ii0aumdp+Kalv6tRYAANEiJB0g1toloVgHiCTPrtmvlg6/vn4O3R/HkpUcr/TEWO2salZLu095aR5NK0zjaFwAUW17RZOeX1eqLy8aq4VHGXx6qNw0T787QCoavfIHgt12H5U29Cl8AQAg2nFUBXCC1uyr06iMRI3P4cjbYzHGaEJ2inZ2dYDMGJGu8dkpKqptVbvP73R5ADAgfvf2biXGuXXTGUc+9vZwctM8qmzs3zG4pXVtPe9v2N/Qr7UAAIgWBCDACbDWam1xvWaOHOZ0KRFjfE6yNpU1qPhAazAAyUmWP2BVVNPqdGkAEHIlda362/oyfXbuSA1Lijuua3NTPapo8Mpae8L3L60PBiCZyXH6qLT+hNcBACCaEIAAJ6CswavqpnbNHJnudCkRY3x2srydAUnq6QCRxDYYAFHpkXf2SpJuOnP0cV+bm+pRW6dfjV7fCd+/uwPk3Mk52lTa2LMdBgCAoYwABDgB64rrJEkzR9AB0lfdJ8G4jDS1ME1jspLkMsGTYQAgmtS1dOjpD/fr0hkFyk9POO7rc7qOwq3sxxyQ0vo2ZSbHae6o4Wrr9Gt3Nf+tBQCAAAQ4AeuK6xUf49KkPOZ/9FX3rJQJOSlKjIuRJ9atkcMTtYsOEABR5s+ritXW6dctZx3f7I9uuanBAKR7G8xza0u0t+b4TnIprW9TQXqCphUGTynbWMIcEAAACECAE7CuuE7TCtMU6+avUF9lJsepID1Bp47J6HlsXHYKR+ECiCqd/oCe+GCfFozL0MTcEwvJewKQRq/+ubtW33hmg877xVv64Utb1NDW2ac1SuvaVDAsQaMzk5UU59ZHJcwBAQCAn96A49Tu82tTWSMDUI+TMUYvfHmB/t8Fk3oem5CTrL01Ler0BxysDABC59XNlSpv8Grp6cc/+6Nbdmq8JKmywaunV+9XqidGl80s0CPv7tVNf/jwmNdba3s6QNwuoykFadpYSgcIAAAEIMBx2lrepA5fQDNHMAD1eGWlxCshzt3z8ficZPkCVkXH2doNAOHq8ff3asTwBC2elH3Ca3hi3RqWGKvtlU16ZVOFPj2zQD+9YrruunCSPiyq047Ko28drGnuULsvoIKu+SPTCtK0payRY8cBAEMeAQhwnHoGoNIB0m/dJ8EwCBVApAsErDbsr9eHRXW6/tRRcrtMv9bLTUvQK5sq1OEL6Ko5IyRJn5lVqBiX0bNrSo56bfcRuAXDEiVJZ4zPVLsvoKt+94GKazl6HAAwdBGAAMdpXXG98tI8yu2a0o8TNy47WTEuo01ltGYDiEy7qpq16P4VGvPtl3Xpr99TQqy7J7Doj9zUePkDVlPyU3VKQXCQaUZyvBZPytZza0vlO8rWwe4jcLs7QBZOzNavr5mlPdXN+uSD7+i/X9953ENVAQCIBjFOFwBEmg0l9ZpeyPaXUPDEujUxN0UbGc4HIALtqmrWkoc/kLXS7WePV2KcW9MK05SWGNvvtbtD9qvnHhymXDG7UK9uqdTbO6u1eFLOYa8trQ92eRQM+9cRvJ+alqfpI9L07ec36YHlO/SL13do8aRsPXz9nH53qwAAECkIQIDj0OTt1L7aVl05u9DpUqLGtMJ0vbixTNZaGcM/wgFEhn21Lfrs7z+QJC27Zb7GZYf2WPTx2SlK8cTo0ukFBz2+aFK2MpLi9OyakiMHIHVtSomPUVrCwUFM4bBE/fHGeSpvaNMTH+zTr9/cradWFeu6U08Kae0AAIQrtsAAx2FbRXDw3OT8VIcriR7TC9PU5PWpiH3pACLIr9/cpZZ234CEH5J0w+mj9O7/W/yxbpJYt0uXzijQ61uqVN7QdthrS+vbDur+OFReWoK+ed5EnTYmQ/e/ul11LR0hrR0AgHBFAAIchy1ljZKkyXlpDlcSPaZ1bSdiGwyASNHQ2qm/bSjTp2fmD0j4IUlul/lYB0e36087STFuo9ueWHvYk11K6tp65n8ciTFG/3npFDV5fbrv1e0hqRkAgHBHAAIchy1ljRqWGKuc1HinS4ka43OSFR/j0sYSBqECiAzPrSuRtzOga+c7s3VkVGaSfn7VdK3fX6/vvrBJ1tqDnj9WB0i3CTkpWnr6KD21qlgPvbVbbR0ckwsAiG7MAAGOw5byRk3OT2VWRQjFul2akp9KBwiAiGCt1ZMrizV9RHrP6SxOuOCUPH1l8Tj98o1dqmpq18wRwzQyI0HN7X41eX3H7ADp9rVzxmtPdbN+8so2PfLOXn127gjNGTVMs04aplRP/4e5AgAQTghAgD7y+QPaXtmkG05jWFyoTStM19Mf7pfPH1CMm8Y0AOHrgz0HtKuqWfddMc3pUvT1cybI2+nX8q1VemtHtbobQYxRn8OZFE+sHvv8PH1YdEAPvL5Dv1mxSwErJca59atrZh5x0CoAAJGIAATooz01LerwBRiAOgCmFabp8feLtLu6RRNzB2Y/PQCEwhMf7FOqJ0YXT893uhS5XEb/8anJ+o9PTVZzu0+VjV4lxLqV7Ik57u6NuaOG68mbTlVzu0/ri+v1k//bqpv/uEb3XzlNl83k5DMAQHTgV61AHzEAdeB0D0LdwDYYAGFsU2mDXvqoXNeeepI8sW6nyzlIcnyMxmYlKz89oV9bV5LjY3TG+Ew9dfOpmjdquL7+9AYt31oZwkoBAHAOAQjQR1vKGxXndmlMVpLTpUSdMZlJSomPYQ4IgLBlrdW9L23R8KQ43bZwrNPlDLjg1pi5Soxz671dtU6XAwBASBCAAH20paxRE3KTFcuMipBzuYxmjEzX8q1VnEIAICwt31qlD/Yc0NfOGT9khoN6Yt3KS/OorL7N6VIAAAgJfpID+sBaq63ljZqcx/yPgfJvi8apvMGrh97a7XQpAHAQnz+gH7+yVWMyk7Rk3kinyxlU+ekJKm8gAAEARAcCEKAPqpraVdvSQQAygOaPydCnpuXpobd2q6Su1elyAKDHy5sqtLu6RXdeMGnIdQHmpyWotN7rdBkAAITE0Pq/OHCCVu49IEma2jWsEwPj2588WZL0o5e3yh+wDlcDAEF/eL9IJ2Uk6rzJQ+9I2Lx0j2qa29XuY3siACDyEYAAffDG1koNT4rTjBEEIAOpID1Bty0cq5c/qtDse1/Tl55co+0VTU6XBWAI21TaoDX76vS5U0+Sy2WcLmfQ5acnSJIqG9odrgQAgP6LcboAINz5/AG9ub1aZ5+cLfcQ/MfvYPvK4vEak5Wst3dU68WNZUqIjdHPrprudFkAhqg/vF+khFi3rpwzwulSHJGfFgxASuvbNDIj0eFqAADoHwIQ4BjW7KtTQ1unzjl56LU+O8HtMrpker4umZ6vupYOjsYF4Ji6lg79dUOZrpxdqLSEoXHyy6Hy0j2SxCBUAEBUIAABjmH5tirFuo3OHJ/pdClDzvQR6Xpje5WavJ1KGSLHTgJwnrfTr7d2VOvPK4vV4QvohtNHOV2SY7o7QMobGIQKAIh8BCDAMby+tVKnjsngB3AHTB+RLmulj0oadPo4AigAA6+2uV0X//JdlTV4lZ4Yq6+ePV4TclKcLssxCXFuDUuMVWk9HSAAgMhHAAIcxd6aFu2pbtH1p57kdClD0vTCNEnS+pJ6AhAAg+J7f9us6uZ2PXz9HC2cmDXkjr09nLy0BJUTgAAAogD/VweOYvnWSknS2cz/cER6YpxGZSRqw37mgAAYeC9tLNdLG8v1tXMm6NzJOYQfXfLTE1RWzxYYAEDkowMEOIrXt1ZqYk6KRgxn8r1Tpo9I18o9B5wuA0CUKq1v0/rietW1dujnr+3QtMI0ffGsMU6XFVby0z1aubfW6TIAAOg3AhDgCBpaO/VhUR3/EHbY9MJ0/XV9mSoavMpN8zhdDoAoYa3VkyuLde9LW+TtDEiS0hNjdf+V0xVD58dB8tMT1OT1MZAaABDxCECAI1ixo0r+gGX7i8Omj0iXJG0oqVduWq7D1QB919Lu00sflWtcdrJmjRzmdDnopdHbqW88vUGvb63UmeMzdef5k5SdGq9hiXGKiyH8OFReWvdRuF4CEABARCMAAY5g+dYqZSTFaUbXD+BwxpT8VMW4jDbsr9f5UwhAEP68nX499l6RHn5njw60dEiSFk/K1jfPm6jJ+akOV4ey+jZ9/rEPtbu6Wd+9aLI+f/oouVzG6bLCWn568Cjcsvq2IX0iDgAg8vFrDuAwfP6AVmyv0qJJ2XLzD2NHeWLdmpSXog0lDEJF+PF2+rWrqln+gO35+JY/rdF//d82TS1I01M3n6o7zp+o1UUHdOmv39Uf/1kka62zRQ9hOyubdPlv3ldpfZse//w8feGM0YQffdAdgJQ3MAgVABDZ6AABDmP1vjo1en065+Rsp0uBpBkj0vX82lJ1+AK0p2PQvb+7Rg+8vlPlDW2qbmpXUlxMzw+E2yoa1em3OjkvVXdeMFF/fL9Ib++o1k8un6rPzhspSTptbIaunT9S//7MBn3vr5u1dl+dLp1RoPz0BI3LTiZkHSQNrZ268Q8fym+t/vfW03RyHt04fZWTEi+XCXaAAAAQyQhAgMNYvrVScW6Xzhyf5XQpkLRoYrae+KBY7++u0cKJhFIYGD5/QFaSkRTjdslaq/95r0g/enmrCtITNOek4cpIilNrp19l9W3y+a1uOnOMclLi9ci7e/X5xz6UJP3osn+FH93SE+P08PVz9Ks3d+kXr+/QC+vLJEmXzsjXf3925iB/pkNPIGD1tafXqaLBq2e+SPhxvGLcLmWneDgKFwAQ8QhAgMNYvrVKp47NUFI8f0XCwYJxmUqKc+sfmysJQBBynf6AvvfXTXpq1f6exxJi3UrxxKiqqV3nTc7Rz6+eoeSj/Pfgs/NG6qlVxcpIjtcl0/MP+xqXy+j2s8frmvkjVXygVctWFet/15ToG+dO0EkZSSH/vPAvD76xU29ur9a9nz5FMxlIe0Ly0z10gAAAIh4/3QGHqGryak9Ni66ZP/LYL8ag8MS6tXBitl7bUql7P30KWwYQMk3eTn3pybV6Z2eNlswboYL0BAVs8PEDLZ2akp+qpX0YkumJdevzC0b36Z6ZyfHKTI5XQXqCnltbqj/+c5++e9HkUHw6OIxnPtyvB17fqc/MKtS1/Hf9hOWlJ2hzaYPTZQAA0C8EIMAhNpc1SpKmFqQ5XAl6O29Kjl76qFzrius0Z9Rwp8tBFNh/oFU3/3G1dlY166efmaar5o4Y1PvnpHp04dQ8PbN6v75x7gQ6zgbAyx+V61vPbdRZE7L048unyhjC0xNVkJ6g17ZUylrL1xEAELGYJggcovs3XBxXGV4WTcpWrNvoH5srnC4FUeC9XTW6+Ffvqqy+TY8tnTvo4Ue3paePUpPXp+fWlTpy/2i2fn+9vrpsnWaNHKaHrpvFAOV+ykvzqMMXUG3X0c4AAEQift0EHGJTaaNGZyYpxRPrdCnoJdUTq9PHZuofmyv17U+ezG8guwQCVpvKGpSb6lF2qsfpcsLa7upm/XV9md7bVaN1xXUam5Ws318/R6MznZu/MWtkuqYVpumhFbtVUteqGJfRlbNHaJSDNUUDa63ufXGL0hPj9OgNc5UYxz93+isvreso3HqvMpPjHa4GAIATw69DgENsKmvQFLo/wtL5U3JVfKBVW8obnS7FcQ2tnfqP5z/SvB8t1yW/ek9X//4DtXb4nC4rLHX6A3pw+U5d+MA7+tUbO+ULWP3b4vF6/ssLHA0/JMkYoy8vGqf61g49/l6Rfrtit6763T+1r7bF0boi3atbKrV6X52+ce4EpSUSZodCQdfRz2UNDEIFAEQufiUC9FLf2qGSujZdd+pJTpeCwzh/So7u+ftmPbWqWPd+eqrT5Timqsmr6x9dpd3VzTpvcq4m56fq/le36wcvbtWPLw+fr8uTK/fpobd266rZI3TV3BHaXNagFzeWa2xWsr60cOyAdfHsq23RQ2/t0ds7qhUf41Jrh18VjV5dNC1P37t4srJTwqtT5vwpudr8/QskSdsrmnT17/+pax5eqWdvO63nt+7oO58/oP/6v20am5WkK2cXOl1O1MhLD/694SQYAEAkIwABeukegHpKPgNQw1FGcrwum1GgZ9eU6N/PnahhSXFOlzQoWtp9uuC/31as26WFE7L1xrZKVTW167Gl83TG+ExJUqO3U797a48WTczSeVNyHa446P82VaiysV0/e22HfvbaDklSfIxL7b6A2jv9+sZ5E0Nyn+LaVj38zh7VNLerrrVDq/YeUIzbpbMnZcvtMvL5rS6fVRA2X5ejmZiboj/dOF/XPPyBrntkpZ699fQh8+c8VJ5evV97qlv0+8/NVoybRtdQyUiKU1yMS+UNXqdLAQDghBGAAL1s6hqAyhaY8PWFM0fr6dX79eTKffq3xeOdLmdQPLWqWPsPtGne6OF6YuU+JcS69acvzNfsk4b1vObfz52od3fW6FvPfaSzJmTJE+t2sOLgbJIN++t1xexCff70UXr5owqdUpCqM8Zn6nsvbNaDb+xSXIyrX99Da62eWrVf9760RdZKhcMSlOKJ0c1njtEXzhgdsTNRpham6dGlc3Xdoyt10x9X68mb5jvy/bTWalNpo8bnJB90/7YOv2LdJizDhbL6Nv3XK9s0b/RwnTs5x+lyoooxRvlpHpXSAQIAiGAEIEAvm8oaVZCewG9cw9iEnBSdNSFLf/jnPt181hjFxzj7g/5Aa/f59fA7e3TamAw9dcupauvwyxh97AfiuBiXvnr2eN3ypzXaXNag2Sc5e1RwUW2LGr0+TS9M0/icFH01J6XnuR9dPlWd/oDuf3WH/AHp9rPHyRijigavtpQ3KC0hTlnJ8RoxPOGI22QCAatvPrtBz60t1YJxGbrviunKT4+e7SLzRg/XA1fP0Jf/vFZfXbZOv7l2ttyuwRv8a+3/b+/O46Oq7/2Pv76zZGayTRJIQhYghFVWERRBwV1Ra61Wb3HX1qX1qr2tXWxtb2/b21ut3rbqr9S6VO2tW621WhWsWhV3BWTfSdhCQoDsyySznN8fZ8CIYUkyycwk7+fjcR4zOXPmnO85fEjmfOb7/X4s7liwjj8sKmNwuofrZo8g0+fmL4u388m2OgDcTsO4IXZS69xJBUyMc+nwcMTi239ZRjhicddFkzVRci8o8PuoVAJERESSmBIgIh2srqhnYpF6fyS662aP4IqHP+KFZTu5eHp8ypf2lb8trWBXQxt3XzwFAF/KwRM+U4ZmAbBiR/wTIMt32DfJ+9rUkdNhuOviKRhj+M1rG2hqC5LicvDQ2+W0hSL7tysZlMp5UwpxGMO7m/awp6mN780dx9kTh/CzF9fwt6UV3HLaaP7jtNE4+jA50FfOmVTAj88dz89eXMO1j33MvZdM7ZPqVOGIxY/+vpInP9rOhVOLqG5s45cL1gEwOi+db542GpfD0NQW4pNtdTy4qIyH3ynnuRtnMSGOwwcffLuMD8pq+NVFkxk+SFV0ekNhlo/3Nu+JdzNERES6TQkQkaimthDle5u5YGpRvJsih3HiqMGML8jkv15YTbrHxdmTCuLdpF4RCke4/63NTC72c+KowYfdPj/TS36mhxU76vugdYe2fHs9qSlORudldPq602G466LJ+FIcPPh2OQDnH13IZTOG09IeYnttK6+squJ3b2zCAiYX+fG6ndz4+FImFmWyqqKBr504gm+dPrpff9P/1RNH4HE7+M/nV3PR79/nm6eP/kxPkPZQhKXbanlv016G5vi4Z95U0jzd+9P+Qdle/rF8J2+u301FXSs3nTKKW88cgzGG1TvrCUcsJhX5P3e9qxsDWtNFNQAAIABJREFUnHffO9z0xCf84+YTSe/m8bsqHLF4dU0VL66oZPmOOrbXtHL2xCGa+LQXFWZ52dUQIBSOJOQQKBERkcNRAkQGvJrmdtZXNbJ6Zz2WRdy7ccvhGWN4+OrpfOPPS/nG40u54aRSbps7rt/dCL+0spKte1u4//JpR3xuk4qyWBHtfRFPy3fUMbHQf8hhGw6H4efnT2Tq0GxG56czufizvUWuOH44tc3tOIzBn+omGI7wh7c2c8/rG/nyMcXcfs5R/e7fvDOXzRjO8Jw0bnx8CTc+vvRzr3tcDqYOy+KN9bu59rHFPHLNsV2aM8SyLOa/uZm7XllPWoqTWaMGc9vZ4zhvSuH+bQ7VsyMvw8u986ZyyYMf8MO/reSeeUf3+r/LC8t38ptXN1C+p5n8TA/Th+dw5fElXDJj2ICIiXgp8PuIWLCrsW1/WVwREZFkogSIDGhvb9zNTU98Qn1rEIAUp4NJxUqAJIMCv4+nbzie/3phDX94q4z8DC9fPXFEvJsVM6FwhHte28jY/AzO7MJkjlOK/by+bheNgWCfDJfoTHsowuqdDVw18/DlpI0xfPkQ39h3nI/H7bQnTb1yVgkZHteAutE9cfRgFn3vlM9NQGkwlOam4XU7ee6THXz7L8v5xp+XMP+yaYccLgUQCIbZureFh94u45klOzj/6ELu/PLkbk24OqN0EN86fQz/++oGhvi93DZ3XK8NS1qwspJbnvyEiUWZzL/sGM6aMKRP50cZyAqjpXAr61qVABERkaQUkwSIMWYucA/gBB6yLOuOWOxXpDc9uKiMXy5Yy+i8DO69ZCqD0lLIz/QyON0T76bJEfK4nPzPBRPZ3RjglwvWcmxJTr9JYP192U7K9jRz/+XHdOlGclKxH8uCVRUNzBw5qBdbeHDrqxppD0U6nf8jFjLjlNiJt6zUFLJSDz5B8wVTi2lpD3P7c6v4wn1vc8+8qeRnenlmyXaWbasjzePCl+JkZ10rm3c3saO2Fcuy33vLaaN7PJzo308ZRXVjGw8sKqOyPsDdF0+O+STFqyrq+fZflnPMsCyeuO74uFc7Gmj2TTRcUdfK9Di3RUREpDt6nAAxxjiB3wFnADuAj40xL1iWtaan+xbpLUu21vCLl9dy9sQh3H3xlG6PmZf4M8Zw10VTOOfet7n5yaVcNK2YBauq2LKnmazUFIqzfdx10RSGDUqNd1OPWDAc4d7XNzKhMJOzJgzp0nv3DSNZsaMubgmQZfsmQC3unQSIHNxlM4YzLCeV7zyznAvmv4tlQShiMTI3jfZwhJa2MPmZXqYUZ3Hh1GJKc9MYX5DJ6PzO52rpCofD8LPzJ1CU7eOOBetobgvx0JXTY9YTpKo+wHV/Wkx2qpv7r5im5EccFPijPUDqA3FuiYiISPfE4q7vOGCTZVllAMaYp4DzASVAJGG9vLKKFKeDu5T86Bey01K4Z95U5j3wPnf/cwPHDMvi4ulDaWgNsnB1FXe+so7fXXpMvJt5xJ5dsoNtNS08fNX0Ln8jn5NmJ31WVMRvItQV2+v2t0P63uzRuSz85hx++9oGUlwO5h03jJG56X1ybGMMXz9pJKkpTv7z+dX89rUNfPvMsT3eb3VDgEsf/ICG1iBP3zCTvAxvDForXZXhdZPhdakUroiIJK1Y3PkVAds7/LwDmHHgRsaY64HrAYYNGxaDw4p0j2VZLFxVxezRg/usWoH0vuNG5PDSLbPJSnVT4P/0xrvwlfX8vzc2cePJ9XEt0Xmk2kMR7vvXJqYMzeLUcXnd2seU4ixWxqkSTHsowpKttUwp/ny1EOk72Wkp/PT8iXE7/hXHD2dVRT33/msTE4v8nNnFnkwdba9p4apHPqKqIcBjXz1OE1XHWaHfR0WdeoCIiEhy6rMaZpZlPWBZ1nTLsqbn5ub21WFFPmdVRQMVda2cNbH7H8glMR1VkPmZ5AfAdXNKyfS6+M2rG+LUqq55evF2Kupa+fYZY7qdQJhU7GdbTQu1ze0xbt1nRSIWv/7ner77zHJWVdTv/5a+bE9zvy1NLEfGGMPPzp/I5GI/33p6Gc8s3o61b8KRI1Db3M7NT37Ccb94jdm/eoPKugCPXH0sx5bk9GKr5UgUZnmprFcPEBERSU6x+Pq7Ahja4efi6DqRhLRwdSVOh+H0o468soYkL7/PzQ0njeSuV9azdFstxwzLjneTDioQDPO7f21i2vBs5owe3O39TI5OBLuyop45Y3on4RwKR/j+syt5dukOUpwOnlmyA190ToZ7L5nKFzuUUJWByet28uCV07n5iU/47l9XsGBVFT87fwLF2Yeej2dXQ4ArHv6QLXtb+MKkAiYU+Tl5bG6fDeORQyvI8rFse/xLbYuIiHRHLBIgHwOjjTEjsBMf84BLY7BfkV6xcFUVM0bkkJN28GoK0r9cPauEP75Tzq1/Wc4jVx9LyeC0eDepU09+tI2qhgC//rcpPRo+MrHIj8thWLCqslcSIKFwhJue+ISFq6v49hljuGpWCc8s3s6y7XXcfOpoxg7p+YSa0j/kZ3p56vrjeez9Ldy5cB2n3v0WV8wczpUzh+P3uUlxOWhuC9MYCFJVH2BrTQvz39xETVM7j15zLLNGdj8RKL2j0O+ltiVIa3v4sKWWRUREEk2PEyCWZYWMMTcBr2CXwf2jZVmre9wykV6wqbqRzbubuWpWSbybIn0ozePigSunce1ji7lg/rvc8eXJtLaH2VjdyMXThiZEQqS6IcD8NzdzfGkOs0b17KYv0+vmypklPPJeOZfNGB7zORMefqechaur+NG5R3Ht7FKA/Y8iB3I4DNecMIKzJgzhN69u4JF3y3n4nfKDbj84PYXHrzueo3upjLL0zL5SuJX1rZSqV46IiCSZmMwAaVnWy8DLsdiXSG9asLIKoMulRSX5TRuew3M3nsA1j37MDf+3ZP/65dvr+fO1n5u3uU+9sa6aW59ZTkt7iO/PHReTff7HGaN5YXkFP35+Fc9+fVbMSpGW7W7i169u4Izx+XztxBEx2acMDIVZPu66eAo3nDSSj7fU0Noepi0UIc3jJMPrIi/Dy7CcVAr8XlzOPpuiTLpo3zxLO+sCSoCIiEjSUQkMGVBeWlnJtOHZ5GeqhOJAVDI4jb/feALvl+1lxOA03tpQzf+8vI53Nu7hxB7MuXEokYhFWyiCy2lwOx1EIhYflO/luaUVbI1OVLqxuolxQzK475LjGZ0fm+EjmV43t519FN95ZjnPLt3BxdOHHv5NhxGJWNz27Eo8Lgf//aWJqvIi3TIqL51RebpxTlaFWfbfz52aCFVERJKQEiAyYGyqbmRdVSM/OW98vJsiceRPdTM3WgFo+KBUHntvK3cuXMcJo0444hv6irpWGlqDHFWQuX/droYAm3c3sbuxjbLdzSzZWsuKHXU0BEIAGAN5GR4MhqqGABleF+MLMhmVl84XJhdyw0mleN2xHU9/4dQinvhwK3cuXM8XJhce0Xj95rYQ22tbKM5Oxed2sraygQ/K9rK+qpH1uxpZsaOeX100WUlEkQFqiN/+v1+pUrgiIpKElACRAePFFZUYA+eoPKdEed1OvnXGGL7zzHJeXlnFuZMPHxvvb97L1/+8hPrWIMeV5HDWxCG8sa6adzfvYV+VT2Ng3JBMvjClkMHpHnxuJ63BMJV1rbS0hzlzQj5nTRgS84THgRwOww/OOYqL73+f//tgC9fPGXnI7bfubebSBz+kos7+ZjfF5aA9FAEgN8PDyNw0bj1jDBdPK+7VdotI4vK4nAxO97CzTj1AREQk+SgBIgOCZVm8uKKS40py9M21fMYFU4t4YNFmfvjcSvY0tXHpjGG4DzL/wF+X7OAHf1vB8EFpfP2kkTzx0VZ+/uIairJ8fPO00Rw3Ioe8DC8Ffi9pnsT49XpsSQ6zRw/m/rfKuHTGcNIP0q5N1Y1c9tCHtIci3HHhJGpbguxtamNSsZ8ZIwbt/9ZXRKQoy6shMCIikpQS4xO6SC9bv6uRTdVNXPWlifFuiiQYp8Pw+8un8aPnVvGTF1bz6HtbuHpWCRccU0Sm1w3YQ15++sJq/rlmF7NGDuL3l0/D73Nz/ZxSyvc0Uzo4LWaTjPaGW88cy5d+9y6PvlvO+UcX8eRH2xgxOI2LphVjjGHJ1hqu+9MSHMbw1PUzVcZWRA6pwO9jY3VjvJshIiLSZUqAyIDw4vJKHAbmqvqLdGJkbjpPXDeDN9ZX85tXN/KTF1bzywVrGZmbjjGwuboZC4vvzx3HtbNH7O8h4nSYpJjM8eihWZw2Lo/7/rWJX7+6gUh0qM5ra3cxZ0wuP31hDYVZXh655jhGJEBJYBFJbAVZXhZt3I1lWZoMWUREkooSINLv2cNfdjJz5CByMzzxbo4kKGMMp47L59Rx+azcUc/Ti7ftn+RvQoGfm08bRXF2apxb2X3fnTuWLY83c/pR+Vx9QgkvLq/kV6+s45XVuzi+NIffXzaN7LSUeDdTRJJAUZaPlvYwDa0h/KnueDdHRETkiCkBIv3ex1tq2bK3hRtPGRXvpkiSmFTsZ1LxpHg3I6bGDcnk9VtP3v/zdXNKmTlyEB+U7eXKmSWkuDqf90RE5EAFfh9gDw9UAkRERJKJEiDS7z318TYyPC6+cAQVPkQGkolFfiYW+ePdDBFJMgVZ0VK49a2ML8w8zNYiIiKJQ1/5Sb9W3xrk5ZWVfPHoQlJTlO8TERHpqaIsuwfIzvpAnFsiIiLSNUqASL/2/LIKAsEI844dFu+miIiI9AuD0z24HIaddSqFKyIiyUUJEOm3LMviyY+2M6Ewk0nF6uYvIiISC06HYYjfS6USICIikmSUAJF+a/mOetZWNjDvOPX+EBERiaVCv4+ddRoCIyIiyUUJEOmXIhGLn7+4huxUN+cfXRjv5oiIiPQrBVledtarB4iIiCQXJUCkX3pmyXaWbK3lh+ccRaZXJfpERERiqTDLx66GAOGIFe+miIiIHDElQKTfqWlu55cL1nFcSQ4XTSuOd3NERET6nUK/l2DYYk9TW7ybIiIicsRUF7SLzr33bYLhSLybIYfQ0BqiKRDivy+YiDEm3s0RERHpdwr80VK4da3kZ3rj3BoREZEjowRIF5XmphNSAiThzZ04hDH5GfFuhoiISL9UmGUnQCrrA0yNc1tERAaEUBu07AVfDri9EA5CWyN4/eBwxrt1SUMJkC667xL9mRcREZGBrTDL7vWxU6VwRUQObsFtEAnC3DvA2YN5CS0LHr8Yyt+yf3amQLjdfu71Q8lsKJ4OLh+4fTDxy+BJ73n7+yElQERERESkS/w+N6kpTpXCFRE5mGAAFj9sJyoaq+CiP4LL0719rXzGTn4cex1kDIG2BkhJt5fqNVD2Jqx78dPtGyrglB/G5DT6GyVARERERKRLjDEU+L3qASIicjAVS+zkx1Hnwdp/wFOXwlf+bPfQ6IpAPbxyOxRNg7Pv7Hy4i2XZw2HCQfjbdbDkUZjz3Z71OumnVAVGRERERLqsMMtHZb0SICKSQGrK4aMH4eXvwd9usJMH8bLtPfvxvHvhi/fBptfhyUsg2MXfm//6BbTsgXP/9+BzfRgD3kxIGwQzboCmXXbSRT5HPUBEREREpMsK/T7WVTXGuxkiIhCJwEcPwGs/gVDAHhrS3gRDJsGsm+LTpq3vQd4ESM2BY64E44Tn/x2enAcXPWKvP5yNr8LHD8L0r0HhEc5FOep0yBoGHz8MEy/s2Tn0Q+oBIiIiIiJdVpDlZXdjG22hcLybIiIDWSQMT34FFn4fRsyBWz6BH+yAocfD4j/ayZG+Fg7B9o9g+KxP1029DL40H8regl+VwgMn271VDmbXGnjmGsifAKf/15Ef2+G0EyZb34Hqtd08gf5LPUBEREREpMsK/fY49l31bQwblBrn1ojIgFVTBhv/CbNvhVN/bA8HAZj+VXjuenvy0JGn9G2bqlbYPVCGz/zs+qMvtRMa6xfAhoXw8nfsHiuzbv7sdvUV8MRXICUNLnm66xVdpl4Bb/wPvHAzDD8BfNn2EBmvH0rmQHpuz84viSkBIiIiIiJdVphlJ0B21rcqASIi8VNTZj+OPuvT5AfA+PNh4W12L5C+ToBsjc7/MWzW518rmGIvc74Lf/0q/PNH4Muxh6sE6u1eIR/Mtyc2veYl8Bd1/fhpg+CEb8LSP0Hl/E9L5oKdBDnj53aSxHHAgJBI2E4mrX4Ozp8Pzv6XLuh/ZyQiIiIiva4gywugSjAiEl815fZjTuln17u99rCT9+dDQyVkFnz6WiQCm1+3kyNDJsW+ZOzW9+z2dDzmgRxOuPABaK2F52+0l30mfhlOuR0Gjex+G0693V4sC9qb7dK59RX2PCn/uAUW3W0nQELtkDYYMovsnisNFZCebyeWcsd0//gJSgkQEREREemyfUNgKusDcW6JiAxoNWX2pKdpgz//2rRr4L374MFTwZdlT0QaCdpJh6ZdYBxQ9iac+G07YdJV7S2w9V1o3mPv150KeUfBtvdh7DmHf7/LA/MehyWP2b003Kn2vCEFk7veloMxxh5C40mHzEK46kVY/gRseMUuyetwQ3M11G2DvPF2qd0xc/ttCV0lQERERESky3wpTrJT3eoBIiLxVVsO2SM+O/xln0Ej7eEeO5dCOAhWBBwucHlhzFn2HBtPzoPyRTDmzCM7XksNrH8Z1r4IZW/Yc3h0Zngnw18648no20o1DgdMvdxeBiAlQERERESkWwr8PiVARCS+asrtXhcHc8ItB38t1Gb3Hln/8sETIOEQVC23e4psfsPu3REJgX8oHHMVjJ0L2SV2T4pAPexeZw8jmXBBT85KeokSICIiIiLSLYVZPnbUtsS7GSIyUEXCULsFxh3BcJPOuDww8lS7Iksk8umkoJZlTwS6+I9QsQSC0d9z+RNh5k32BKuFUzvpdTIUhkzs7tlIH1ACRERERES6pTDLy4fle+PdDBEZqBoq7Lk3DpwAtSvGngNrX4DKZVB0DDTthpe+BWv/AYPH2NVShs2AktmQnhe7tktcKAEiIiIiIt1SmOWjMRCiqS1EukcfK0Wkj+0rgZs9ovv7GH2mPRnqhoV2z48n59lDWU7/qd3box+Wgh3I9K8pIiIiIt1S4LerJlTWtTI6PyPOrRGRAedgJXC7Im0QDD3ersTy7j2QMQSufB7yx8emjZJQlAARERERkW4pzLJL4VYcQQKktrmdD8v3smx7PeuqGti2t4WqhgBzRudyw0mlTB2W3RdNFpH+pKYMnCl2edeeGDsXXv1PKD4WLnmq85K60i8oASIiIiIi3bIvAVJZf5AykFHrqxqZ98D71LYEcTsNo/IyGFeQwYzSHF5aUcnC1VXMGJHD108aycljczGdlbMUETlQbXm0AouzZ/s59lrwZcOki8Hti0nTJDEpASIiIiIi3ZKf4cFh7CEwB1O+p5nLH/6QFJeDv9wwk8nFfrzuT29Wbj93PE99tI2H3ynnmkc/Zmx+BtfPKeW8KYWkuBx9cRoikqxqyns2/8c+KWlwzJU9348kPP1VEREREZFucTkd5GV4qajrvAfIkq21XP7Qh4QjFo9fO4PjRuR8JvkBkO5xce3sUhZ97xR+/W9TALj1meWcdNcbPPR2GU1toV4/DxFJQpZlJ0ByYpAAkQFDPUBEREREpNsKs7xU1n/aA8SyLFZVNPD7tzbx8soq8jI8/OmrxzEq79BzhLidDi48ppgLphbx5vrd3P/WZv77pbXc+/pGrpg5nKtnjSA3w9PbpyMiyaJ5NwSbezYBqgw4SoCIiIiISLcVZPlYXVHPxl2N/PHdcl5bW83uxjZSU5x86/QxXDdnBKkpR/6R0xjDKePyOGVcHp9sq+WBRWXMf3MzD75dzkXTirludikjBqf14hmJSFKIRQlcGXCUABERERGRbivK8vHyykrO+M0ifG4npx2Vx8lj8zh1XB45aSk92vfUYdn8/vJplO1u4sG3y/nrkh08+dE25k4Ywg0njeTooVkxOgsRSSqRCOz42H6uHiDSBUqAiIiIiEi3HVuSwwvLdvJv04u5+oQRPU56dKY0N51fXjiJb50xmkff3cL/fbCVBauqOL40hxtOGsnJY1Q5RmRAqNsG78+HNX+Hxkq7ckvWsHi3SpKIsSyrzw86ffp0a/HixX1+XBERERFJfk1tof2VYyrrA4wb8mnlGLdTc/yL9CuRMGx9D5Y9ASv/Yq8bezaMPRfGnAWpOfFtnyQcY8wSy7Kmd/qaEiAiIiIikozaQxH+sXwnf1i0mQ27mij0e/na7FLmHTuUNI86OoskpUgEdq+FbR/A9g9h0+vQsgfcqXap2pk3QdbQeLdSEpgSICIiIiLSb0UiFm9uqOb+t8r4qLwGv8/NFccP5+oTShicrsoxIvEWjlgs3VbLa2t2UVHXytCcVIqyfPjcTlxOQ11LkG01LWyvaWH+BcNx/e8o+43p+VByIhz1RRh9BqRoAmQ5PCVARERERGRAWLqtlj+8tZl/rtmF2+ng4mjlmBJVjpEBJBKxKNvTzPLtdeyobcXvc5GVmkJ7KEJDIEh7OAKAwxiyfG6yUlMIRyzqW4PUtwapa22nKRDC5TB4U5wMTvNQmptGUbaP1vYwTW0hLAtcDsPupjY+LK9hxY46nA4HmV4XbaEIexrbqGlpJxiK0B6OEAxbuJ2GAr+PyvpWguHP3of63E6G5aTy+HUzGLztFRgyCbJLQPP7SBcpASIiIiIiA8rm3U089HYZzy6pIBiJcPbEIdwwZyRTelg5proxQGVdgNZgmEjEojg7laJsH07HpzdpkYhFezh60xeK4EtxdqkUsEhH1Y0B3t6wh9qWdnwpTtwOB22hME1tYTZWN7JmZwOV9QFC4QjBiEUoHCHSw1u8FKeDDK+LUMSiNRimPRQ55PbpHhdHD83CGGgMhEhxOsjN9DAoLQW304HLaZhU5GfOmFwyvW7CEYvqxgDtITsxkulzkZvu0WTGEhNKgIiIiIjIgFTdEOCR97bw5w+20hgIMbN0EDecVMpJ0coxlmVR09xOdWMbNc3tRA74bNwYCLFmZwOrd9azamcDuxvbPneMFKcDr9tBMGwRDEcIdXL3mZfhoWRQGsMHpVIyOPo4KI28TA+O6E1fx1s/c8C6jveFZt9a09lrn33/vnUOY/C6HYe8wWwPRWgMBHE5HbidBqfD4HY4cDg6f08wHKEpEKIxECIQCpPpdZOd5sbjcgJgWRZNbSHqW4MAuJ0OmtpC7KxrpbIuwM56+9HhgAyvG6/LQTBi0R6KsLepjd1NbTQFQgTDFqFIhFDYIhiJEA5bBCMWBvC6nXhcDsKWRShskZriJDfDQ16GN/ro2f+Y4XVjjH29Mrxu/D43aSnOuN90t4cibKxuZF1lI7Ut7bSFItS1tLOzLkDZnmbWVjYc9L25GR4mFGYyLCd1f6LB7bAfi7J8HD00i+GD0mgMBKlrDeJxOcjwuvG47MmC9/X6qGlux+U0ZPlS8Pvcn4uVupZ2Nu9uprK+lbQUF+leFw4D7SGLDK+LcUMycGkCYkkQSoCIiIiIyIDWGAjy1EfbefidcqoaAozNzyDV42Tjriaa2kKHfK/TYRidl874wkwmFPoZnpOKL8WJAbbVtFC+p5lAMEyKy4Hb6SDFFV2izxsDIbbubWbL3ha27m1mV8Pnkyh9wWHsb+ozvG4yvC7SPC5cDjvRsbOule21rYQ7Sd44DHZSxGFwOR04HYaW9hCBYOe9AvZtb1nW54Y5dGQM++doaQwEaQtFcDvs5EtOegp5GV7SPS7cToMrelPvdjpwOQwup8GyIBAM0xaK4HAYXA5Dc1uI3Y1t9tLUdsjjgz2EI9PnJt3jwhiIWBat7WEaAiHaQxGcDoPD2Akkh7GvlTFE19s/56SmkJvhIc3jxGBwOCAtxb6+7eEI9a1BGqJDSxoDIYyxjxsMW3ZioiX4uaSZx+WgKMtHUbaP40sHcdKYXIbmpNIWDNMejuB1O/G5nZrsV6QTSoCIiIiIiGB/2/78sgoe/3AbHpeDsUMyGDE4jbwML4PSU3Ad0NvB63YyKi8dr9sZsza0tIfYVtPClj0t7G4MALDvE3nHj+b7Pqd3/LS+73XrgG3oZBt7O/uHcMQ+bmMgREMgSFMgRHO73bsiHLEYkumlNDeNQWkphCKWvUR7s+zreREKf7rO53buT6RkeF143U4aojfzgWCYYNjCGMhOtXtaGAzt4QhpHieFfh+FWT7yM72kuHqv10Ak2ruhOpoQaWoL7r8WjYHg/vku6luDNHdIgqV67HPyOB1ELAhbFhHLwrLsHhMRyyISsYhYEIpE9vcgamkL2/u3LJrbQjQFQqS4HPh9bjJ99nXI8LqwgFA4gttp98bITnUzriCT8QWZ5GZ48LmduJ0m7j1TRJKVEiAiIiIiIiIi0u8dKgHSo5SrMeZiY8xqY0zEGNPpAURERERERERE4q2nfc5WARcCi2LQFhERERERERGRXtGjWXMsy1oLaHyaiIiIiIiIiCQ01SoSERERERERkX7vsD1AjDGvAUM6eel2y7KeP9IDGWOuB64HGDZs2BE3UERERERERESkpw6bALEs6/RYHMiyrAeAB8CuAhOLfYqIiIiIiIiIHAkNgRERERERERGRfq+nZXAvMMbsAGYCLxljXolNs0REREREREREYqenVWCeA56LUVtERERERERERHqFhsCIiIiIiIiISL+nBIiIiIiIiIiI9HtKgIiIiIiIiIhIv6cEiIiIiIiIiIj0e8ayrL4/qDG7ga0HeXkwsKcPmyP9k+JIYkFxJLGkeJJYUBxJLCiOpKsUMxILfRVHwy3Lyu3shbgkQA7FGLPYsqzp8W6HJDfFkcSC4khiSfEksaA4klhQHElXKWYkFhIhjjQERkRERERERET6PSVARERERERERKTfS8QEyAPxboD0C4ojiQXFkcSS4kliQXEksaA4kq5SzEj2Kb1jAAAGDUlEQVQsxD2OEm4OEBERERERERGRWEvEHiAiIiIiIiIiIjHV4wSIMWaoMeYNY8waY8xqY8w3o+tzjDGvGmM2Rh+zo+svM8asMMasNMa8Z4yZ0mFfc40x640xm4wxtx3imFdF97vRGHNVh/ULjTHLo+243xjj7On5Sd9IsDh6M/r+ZdElrzfPXWInUeLIGJPRIX6WGWP2GGN+29vnL7GVKPEUXf+V6L5XG2Pu7M3zltiKUxwtNMbUGWNePGD9TdH3WsaYwb11zhJ7MY6jPxpjqo0xqw5zzE7jTXGUHBIsZh429j3aCmPMX40x6b113hJbCRZHjxpjys2nn6+P7tZJWZbVowUoAI6JPs8ANgDjgV8Bt0XX3wbcGX0+C8iOPj8b+DD63AlsBkqBFGA5ML6T4+UAZdHH7OjzffvLjD4a4FlgXk/PT0vfLAkWR28C0+N9TbQkdxwdsN0SYE68r4+W5IwnYBCwDciNbvcYcFq8r4+WxIyj6LanAecBLx6wfipQAmwBBsf72mjp+ziK/jwHOAZYdYjjHTTeFEfJsSRYzGR22O7X+46vJfGXBIujR4GLenpOPe4BYllWpWVZS6PPG4G1QBFwPvaHNKKPX4pu855lWbXR9R8AxdHnxwGbLMsqsyyrHXgquo8DnQW8allWTXQ/rwJzo/tuiG7jil4wTXCSJBIpjiR5JWIcGWPGAHnA27E5S+krCRRPpcBGy7J2R7d7Dfhy7M5UelMc4gjLsl4HGjtZ/4llWVticV7St2IYR1iWtQioOcwhDxpviqPkkGAx0wBgjDGAD92jJY1EiqNYiekcIMaYEuys8IdAvmVZldGXqoD8Tt7yNWBB9HkRsL3Dazui6w50yO2MMa8A1dh/+P/a1XOQ+EuEOAIeiXat+nH0l7UkmQSJI4B5wNNWNHUtySnO8bQJGGuMKTHGuLA/ZAzt1olIXPVRHEk/18M4OlKKt34kEWLGGPNI9HjjgPu6uG9JAIkQR8AvokNsfmOM8XRx30AMEyDRsVzPAv/RoScGANEP/tYB25+CfVG+H6s2RI91FnZXHQ9waiz3Lb0vQeLoMsuyJgGzo8sVMdy39IEEiaN95gFP9sJ+pY/EO56i36R8A3gauyfRFiAci31L34l3HEn/oDiSrkqUmLEs6xqgELsHwVdiuW/pfQkSRz/ATqAdiz1cuFv7jkkCxBjjxr4gj1uW9bfo6l3GmILo6wXYvTL2bT8ZeAg437KsvdHVFXz2G61ioMIYM6PDRCdfPNh2HdtjWVYAeJ4Yd5eR3pUocWRZ1r7HRuAJ7K5YkiQSJY6i+54CuCzLWhLTk5Q+kyjxZFnWPyzLmmFZ1kxgPfYYXEkSfRxH0k/FKI4Otu+hHeLo6xzB521JfIkWM5ZlhbGHNGgYZxJJlDiKDsexLMtqAx6hu/doVs8nRjHAn4DfHrD+Lj47Mcqvos+HYXfnnXXA9i7sCd9G8OmEJxM6OV4OUI49MVx29HkOkA4UdNjX08BNPT0/LX2zJFAcuYhO6AW4sYdRfT3e10dLcsVRh9fvAH4a7+uiJfnjCciLPmYDy4Ax8b4+WhIzjjpsfzIHTILa4bUtaPLKpFpiFUcd3lfCoSciPGy8KY4Se0mUmIm2Y1SHNt0N3B3v66MlueIo+lpBhzb9FrijW+cUg4tyInaXlxXRD2XLgHOwZ61/HdiIPWHbvg9xDwG1HbZd3GFf52B/q7UZuP0Qx/xq9MJuAq6JrssHPo62YxX22DJXvINGS9LFURp2xY4VwGrgHsAZ7+ujJbniqMNrZcC4eF8XLckfT9jDqNZEF1U4S6IlTnH0NrAbaMUeP31WdP0t0Z9DwE7goXhfHy1xiaMngUogGI2Hrx3kmJ3Gm+IoOZZEiRnsEQfvAiux79Eep0NVGC2JvSRKHEXX/6tDHP0ZSO/OOZnozkRERERERERE+q2YVoEREREREREREUlESoCIiIiIiIiISL+nBIiIiIiIiIiI9HtKgIiIiIiIiIhIv6cEiIiIiIiIiIj0e0qAiIiIiIiIiEi/pwSIiIiIiIiIiPR7SoCIiIiIiIiISL/3/wHmLbajGosROAAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 1080x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V-bANnT35oe-"
      },
      "source": [
        "**2. Création des datasets**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V_EweLDJ5oe-"
      },
      "source": [
        "# Fonction permettant de créer un dataset à partir des données de la série temporelle\n",
        "\n",
        "def prepare_dataset_XY(serie, taille_fenetre, horizon, batch_size):\n",
        "  dataset = tf.data.Dataset.from_tensor_slices(serie)\n",
        "  dataset = dataset.window(taille_fenetre+horizon, shift=1, drop_remainder=True)\n",
        "  dataset = dataset.flat_map(lambda x: x.batch(taille_fenetre + horizon))\n",
        "  dataset = dataset.map(lambda x: (tf.expand_dims(x[0:taille_fenetre],axis=1),x[-1:]))\n",
        "  dataset = dataset.batch(batch_size,drop_remainder=True).prefetch(1)\n",
        "  return dataset"
      ],
      "execution_count": 369,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Jh1RZYo5oe_"
      },
      "source": [
        "# Définition des caractéristiques du dataset que l'on souhaite créer\n",
        "taille_fenetre = 200\n",
        "horizon = 1\n",
        "batch_size = 1\n",
        "\n",
        "# Création du dataset\n",
        "dataset = prepare_dataset_XY(serie_entrainement,taille_fenetre,horizon,batch_size)\n",
        "dataset_val = prepare_dataset_XY(serie_test,taille_fenetre,horizon,batch_size)"
      ],
      "execution_count": 370,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dr2pbMox5oe_",
        "outputId": "a2f6121b-a249-4b49-acb7-4bc486a3ddda",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(len(list(dataset.as_numpy_iterator())))\n",
        "for element in dataset.take(1):\n",
        "  print(element[0].shape)\n",
        "  print(element[1].shape)"
      ],
      "execution_count": 371,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "160\n",
            "(1, 200, 1)\n",
            "(1, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "itll4lU9q67C",
        "outputId": "14456979-23bd-4d99-c7fb-f369ddc135a4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(len(list(dataset_val.as_numpy_iterator())))\n",
        "for element in dataset_val.take(1):\n",
        "  print(element[0].shape)\n",
        "  print(element[1].shape)"
      ],
      "execution_count": 372,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BHCcYn6i5oe_"
      },
      "source": [
        "On extrait maintenant les deux tenseurs (X,Y) pour l'entrainement :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z3ZhLIK15ofA",
        "outputId": "e004550d-8fe9-42fe-af6b-8ced313a3243",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Extrait les X,Y du dataset\n",
        "#56x((1000,4,1),(1000,1)) => (56*1000,4,1) ; (56*1000,1)\n",
        "\n",
        "x,y = tuple(zip(*dataset))\n",
        "\n",
        "# Recombine les données\n",
        "# (56,1000,4,1) => (56*128,4,1)\n",
        "# (56,1000,1) => (56*128,1)\n",
        "x_train = np.asarray(tf.reshape(np.asarray(x,dtype=np.float32),shape=(np.asarray(x).shape[0]*np.asarray(x).shape[1],taille_fenetre,1)))\n",
        "y_train = np.asarray(tf.reshape(np.asarray(y,dtype=np.float32),shape=(np.asarray(y).shape[0]*np.asarray(y).shape[1])))\n",
        "\n",
        "# Affiche les formats\n",
        "print(x_train.shape)\n",
        "print(y_train.shape)"
      ],
      "execution_count": 373,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(160, 200, 1)\n",
            "(160,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "llnKyLvl5ofA"
      },
      "source": [
        "Puis la même chose pour les données de validation :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hadrKVrZ5ofB",
        "outputId": "59bcb707-a46a-42de-f6e6-6917725901c2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Extrait les X,Y du dataset_val\n",
        "\n",
        "x,y = tuple(zip(*dataset_val))\n",
        "\n",
        "# Recombine les données\n",
        "\n",
        "x_val = np.asarray(tf.reshape(np.asarray(x,dtype=np.float32),shape=(np.asarray(x).shape[0]*np.asarray(x).shape[1],taille_fenetre,1)))\n",
        "y_val = np.asarray(tf.reshape(np.asarray(y,dtype=np.float32),shape=(np.asarray(y).shape[0]*np.asarray(y).shape[1])))\n",
        "\n",
        "# Affiche les formats\n",
        "print(x_val.shape)\n",
        "print(y_val.shape)"
      ],
      "execution_count": 271,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(71, 10, 1)\n",
            "(71,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "083QISTMM3AM"
      },
      "source": [
        "# Optimisation des hyperparamètres"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2VzGM7ODMf8e"
      },
      "source": [
        "**1. Création de la série horaire pour l'optimisation des hyperparamètres**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zUpvJmTQiNk-"
      },
      "source": [
        "**3. Définition du modèle**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AuAyb8pciUle"
      },
      "source": [
        "Dans le modèle, les paramètres dim_LSTM, l1_reg, l2_reg seront optimisés :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WRY7JTnlrTMf"
      },
      "source": [
        "def ModelLSTM(dim_LSTM = 10, l1_reg=0, l2_reg=0):\n",
        "  # Définition de l'entrée du modèle\n",
        "  entrees = tf.keras.layers.Input(shape=(taille_fenetre,1),batch_size=batch_size)\n",
        "\n",
        "  # Encodeur\n",
        "  s_encodeur = tf.keras.layers.LSTM(dim_LSTM, kernel_regularizer=tf.keras.regularizers.l1_l2(l1=l1_reg,l2=l2_reg),stateful=True)(entrees)\n",
        "\n",
        "  # Décodeur\n",
        "  s_decodeur = tf.keras.layers.Dense(dim_LSTM,activation=\"tanh\",kernel_regularizer=tf.keras.regularizers.l1_l2(l1=l1_reg,l2=l2_reg))(s_encodeur)\n",
        "  s_decodeur = tf.keras.layers.Concatenate()([s_decodeur,s_encodeur])\n",
        "\n",
        "  # Générateur\n",
        "  sortie = tf.keras.layers.Dense(1,kernel_regularizer=tf.keras.regularizers.l1_l2(l1=l1_reg,l2=l2_reg))(s_decodeur)\n",
        "\n",
        "  # Construction du modèle\n",
        "  model = tf.keras.Model(entrees,sortie)\n",
        "  model.comile(loss=\"mse\", optimiser=\"adam\")\n",
        "  return(model)"
      ],
      "execution_count": 319,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xYTuqrcYii9w"
      },
      "source": [
        "**4. Cross-validation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_g-t1CbmsOkn",
        "outputId": "e7da2b8d-a00e-4d31-eda4-568ab047d396",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "batch_size"
      ],
      "execution_count": 274,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 274
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CVCNBdgcihuv",
        "outputId": "02104f1a-7a2b-46eb-fe16-07fa96658f5c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 919
        }
      },
      "source": [
        "from keras.callbacks import EarlyStopping\n",
        "from keras.wrappers.scikit_learn import KerasRegressor\n",
        "from sklearn.model_selection import KFold, TimeSeriesSplit, GridSearchCV\n",
        "\n",
        "# Définitions des paramètres\n",
        "dim_LSTM = [5,10,15,20,30,40]\n",
        "l1_reg = [0,0.001,0.01,0.1]\n",
        "l2_reg = [0,0.001,0.01,0.1]\n",
        "\n",
        "param_grid = {'dim_LSTM': dim_LSTM, 'l1_reg': l1_reg, 'l2_reg': l2_reg}\n",
        "\n",
        "max_periodes = 5\n",
        "\n",
        "# Surveillance de l'entrainement\n",
        "es = EarlyStopping(monitor='loss', mode='min', verbose=1, patience=50, min_delta=1e-7, restore_best_weights=True)\n",
        "\n",
        "\n",
        "tscv = TimeSeriesSplit(n_splits = 5)\n",
        "model = KerasRegressor(build_fn=ModelLSTM, epochs=max_periodes, verbose=2)\n",
        "grid = GridSearchCV(estimator=model, param_grid=param_grid, cv=tscv, n_jobs=1, verbose=3)\n",
        "\n",
        "grid_result = grid.fit(x_train, y_train,callbacks=[es])"
      ],
      "execution_count": 374,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 96 candidates, totalling 480 fits\n",
            "[CV] dim_LSTM=5, l1_reg=0, l2_reg=0 ..................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning:\n",
            "\n",
            "Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "AttributeError: 'Functional' object has no attribute 'comile'\n",
            "\n",
            "\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.2s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] ........ dim_LSTM=5, l1_reg=0, l2_reg=0, score=nan, total=   0.2s\n",
            "[CV] dim_LSTM=5, l1_reg=0, l2_reg=0 ..................................\n",
            "[CV] ........ dim_LSTM=5, l1_reg=0, l2_reg=0, score=nan, total=   0.2s\n",
            "[CV] dim_LSTM=5, l1_reg=0, l2_reg=0 ..................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.5s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] ........ dim_LSTM=5, l1_reg=0, l2_reg=0, score=nan, total=   0.2s\n",
            "[CV] dim_LSTM=5, l1_reg=0, l2_reg=0 ..................................\n",
            "[CV] ........ dim_LSTM=5, l1_reg=0, l2_reg=0, score=nan, total=   0.2s\n",
            "[CV] dim_LSTM=5, l1_reg=0, l2_reg=0 ..................................\n",
            "[CV] ........ dim_LSTM=5, l1_reg=0, l2_reg=0, score=nan, total=   0.2s\n",
            "[CV] dim_LSTM=5, l1_reg=0, l2_reg=0.001 ..............................\n",
            "[CV] .... dim_LSTM=5, l1_reg=0, l2_reg=0.001, score=nan, total=   0.2s\n",
            "[CV] dim_LSTM=5, l1_reg=0, l2_reg=0.001 ..............................\n",
            "[CV] .... dim_LSTM=5, l1_reg=0, l2_reg=0.001, score=nan, total=   0.2s\n",
            "[CV] dim_LSTM=5, l1_reg=0, l2_reg=0.001 ..............................\n",
            "[CV] .... dim_LSTM=5, l1_reg=0, l2_reg=0.001, score=nan, total=   0.2s\n",
            "[CV] dim_LSTM=5, l1_reg=0, l2_reg=0.001 ..............................\n",
            "[CV] .... dim_LSTM=5, l1_reg=0, l2_reg=0.001, score=nan, total=   0.2s\n",
            "[CV] dim_LSTM=5, l1_reg=0, l2_reg=0.001 ..............................\n",
            "[CV] .... dim_LSTM=5, l1_reg=0, l2_reg=0.001, score=nan, total=   0.2s\n",
            "[CV] dim_LSTM=5, l1_reg=0, l2_reg=0.01 ...............................\n",
            "[CV] ..... dim_LSTM=5, l1_reg=0, l2_reg=0.01, score=nan, total=   0.2s\n",
            "[CV] dim_LSTM=5, l1_reg=0, l2_reg=0.01 ...............................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-374-46a5b6b96fba>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0mgrid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_grid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtscv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0mgrid_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mes\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    708\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    709\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 710\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    711\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    712\u001b[0m         \u001b[0;31m# For multi-metric evaluation, store the best_index_, best_params_ and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1149\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1150\u001b[0m         \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1151\u001b[0;31m         \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params)\u001b[0m\n\u001b[1;32m    687\u001b[0m                                \u001b[0;32mfor\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    688\u001b[0m                                in product(candidate_params,\n\u001b[0;32m--> 689\u001b[0;31m                                           cv.split(X, y, groups)))\n\u001b[0m\u001b[1;32m    690\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    691\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1042\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1043\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1044\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1045\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1046\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    857\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 859\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    860\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    775\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    776\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 777\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    778\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    570\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 572\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 263\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 263\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, error_score)\u001b[0m\n\u001b[1;32m    513\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    514\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 515\u001b[0;31m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    516\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    517\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/wrappers/scikit_learn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, **kwargs)\u001b[0m\n\u001b[1;32m    155\u001b[0m           **self.filter_sk_params(self.build_fn.__call__))\n\u001b[1;32m    156\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 157\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilter_sk_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m     if (losses.is_categorical_crossentropy(self.model.loss) and\n",
            "\u001b[0;32m<ipython-input-319-9148db1febec>\u001b[0m in \u001b[0;36mModelLSTM\u001b[0;34m(dim_LSTM, l1_reg, l2_reg)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0;31m# Encodeur\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m   \u001b[0ms_encodeur\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLSTM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim_LSTM\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel_regularizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregularizers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ml1_l2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0ml1_reg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0ml2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0ml2_reg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstateful\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mentrees\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m   \u001b[0;31m# Décodeur\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/layers/recurrent.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, initial_state, constants, **kwargs)\u001b[0m\n\u001b[1;32m    658\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    659\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minitial_state\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mconstants\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 660\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRNN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    661\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    662\u001b[0m     \u001b[0;31m# If any of `initial_state` or `constants` are specified and are Keras\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    950\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_in_functional_construction_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    951\u001b[0m       return self._functional_construction_call(inputs, args, kwargs,\n\u001b[0;32m--> 952\u001b[0;31m                                                 input_list)\n\u001b[0m\u001b[1;32m    953\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    954\u001b[0m     \u001b[0;31m# Maintains info about the `Layer.call` stack.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_functional_construction_call\u001b[0;34m(self, inputs, args, kwargs, input_list)\u001b[0m\n\u001b[1;32m   1089\u001b[0m         \u001b[0;31m# Check input assumptions set after layer building, e.g. input shape.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1090\u001b[0m         outputs = self._keras_tensor_symbolic_call(\n\u001b[0;32m-> 1091\u001b[0;31m             inputs, input_masks, args, kwargs)\n\u001b[0m\u001b[1;32m   1092\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1093\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0moutputs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_keras_tensor_symbolic_call\u001b[0;34m(self, inputs, input_masks, args, kwargs)\u001b[0m\n\u001b[1;32m    820\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeras_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mKerasTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_signature\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 822\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_infer_output_signature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    823\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    824\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_infer_output_signature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_infer_output_signature\u001b[0;34m(self, inputs, args, kwargs, input_masks)\u001b[0m\n\u001b[1;32m    861\u001b[0m           \u001b[0;31m# TODO(kaftan): do we maybe_build here, or have we already done it?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    862\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_build\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 863\u001b[0;31m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    864\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    865\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_activity_regularization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/layers/recurrent_v2.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, mask, training, initial_state)\u001b[0m\n\u001b[1;32m   1268\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1269\u001b[0m           (last_output, outputs, new_h, new_c,\n\u001b[0;32m-> 1270\u001b[0;31m            runtime) = lstm_with_backend_selection(**normal_lstm_kwargs)\n\u001b[0m\u001b[1;32m   1271\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1272\u001b[0m       \u001b[0mstates\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mnew_h\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_c\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/layers/recurrent_v2.py\u001b[0m in \u001b[0;36mlstm_with_backend_selection\u001b[0;34m(inputs, init_h, init_c, kernel, recurrent_kernel, bias, mask, time_major, go_backwards, sequence_lengths, zero_output_for_mask)\u001b[0m\n\u001b[1;32m   1654\u001b[0m     \u001b[0;31m# grappler will kick in during session execution to optimize the graph.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1655\u001b[0m     \u001b[0mlast_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_h\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_c\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mruntime\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdefun_standard_lstm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1656\u001b[0;31m     \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdefun_gpu_lstm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1657\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1658\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mlast_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_h\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_c\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mruntime\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mregister\u001b[0;34m(func, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3388\u001b[0m   \u001b[0mconcrete_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_concrete_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3389\u001b[0m   \u001b[0mconcrete_func\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_to_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3390\u001b[0;31m   \u001b[0mconcrete_func\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_gradient_functions_to_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3391\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mconcrete_func\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3392\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36madd_gradient_functions_to_graph\u001b[0;34m(self, g)\u001b[0m\n\u001b[1;32m   2055\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_delayed_rewrite_functions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_to_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2056\u001b[0m     forward_function, backward_function = (\n\u001b[0;32m-> 2057\u001b[0;31m         self._delayed_rewrite_functions.forward_backward())\n\u001b[0m\u001b[1;32m   2058\u001b[0m     \u001b[0mforward_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_to_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2059\u001b[0m     \u001b[0mbackward_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_to_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mforward_backward\u001b[0;34m(self, num_doutputs)\u001b[0m\n\u001b[1;32m    629\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mforward_backward\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    630\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mforward_backward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 631\u001b[0;31m     \u001b[0mforward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbackward\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_construct_forward_backward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_doutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    632\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cached_function_pairs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnum_doutputs\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbackward\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbackward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_construct_forward_backward\u001b[0;34m(self, num_doutputs)\u001b[0m\n\u001b[1;32m    677\u001b[0m           \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    678\u001b[0m           \u001b[0msignature\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 679\u001b[0;31m           func_graph=backwards_graph)\n\u001b[0m\u001b[1;32m    680\u001b[0m       \u001b[0mbackwards_graph_captures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbackwards_graph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexternal_captures\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    681\u001b[0m       captures_from_forward = [\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    914\u001b[0m     \u001b[0;31m# TensorSpecs by their `arg_names` for later binding.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    915\u001b[0m     func_graph.structured_input_signature = (\n\u001b[0;32m--> 916\u001b[0;31m         \u001b[0mconvert_structure_to_signature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    917\u001b[0m         convert_structure_to_signature(func_kwargs))\n\u001b[1;32m    918\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mconvert_structure_to_signature\u001b[0;34m(structure, arg_names)\u001b[0m\n\u001b[1;32m    129\u001b[0m     ]\n\u001b[1;32m    130\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m   \u001b[0mmapped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mencode_arg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mflattened\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack_sequence_as\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstructure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmapped\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    129\u001b[0m     ]\n\u001b[1;32m    130\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m   \u001b[0mmapped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mencode_arg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mflattened\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack_sequence_as\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstructure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmapped\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mencode_arg\u001b[0;34m(arg, path)\u001b[0m\n\u001b[1;32m     97\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m         \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"/\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtensor_spec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensorSpec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    100\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcomposite_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCompositeTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m       \u001b[0;31m# TODO(b/133606651) Do we need to inject arg_name?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mshape\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    441\u001b[0m     \"\"\"\n\u001b[1;32m    442\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shape_val\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 443\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shape_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_c_api_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    444\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shape_val\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    445\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_c_api_shape\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    448\u001b[0m     \u001b[0mc_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_c_graph\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    449\u001b[0m     shape_vec, unknown_shape = pywrap_tf_session.TF_GraphGetTensorShapeHelper(\n\u001b[0;32m--> 450\u001b[0;31m         c_graph, self._as_tf_output())\n\u001b[0m\u001b[1;32m    451\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0munknown_shape\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    452\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mtensor_shape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munknown_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kWTWBh8DjJpP"
      },
      "source": [
        "# Affiche les résultats\n",
        "print(\"Meilleur résultat : %f avec %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
        "means = grid_result.cv_results_['mean_test_score']\n",
        "stds = grid_result.cv_results_['std_test_score']\n",
        "params_ = grid_result.cv_results_['params']\n",
        "for mean, stdev, param_ in zip(means, stds, params_):\n",
        "  print(\"%f (%f) with %r\" % (mean, stdev, param_))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UHfiXLFZhrPs"
      },
      "source": [
        "# Création du modèle LSTM de type encodeur-décodeur"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nd9AzWFtjnjs"
      },
      "source": [
        "**1. Création du réseau**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x9OCzL7UjAhL"
      },
      "source": [
        "Par défaut, la dimension des vecteurs cachés est de 10 et aucune régularisation n'est utilisée."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SnFw_FPPhxiE",
        "outputId": "d859db9e-c337-4c67-ef9a-86cee60ca9f4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "dim_LSTM = 100\n",
        "l1_reg = 0.0\n",
        "l2_reg = 0.0\n",
        "\n",
        "# Définition de l'entrée du modèle\n",
        "entrees = tf.keras.layers.Input(shape=(taille_fenetre,1))\n",
        "\n",
        "# Encodeur\n",
        "s_encodeur = tf.keras.layers.LSTM(dim_LSTM, kernel_regularizer=tf.keras.regularizers.l1_l2(l1=l1_reg,l2=l2_reg),)(entrees)\n",
        "\n",
        "# Décodeur\n",
        "s_decodeur = tf.keras.layers.Dense(dim_LSTM,activation=\"tanh\",kernel_regularizer=tf.keras.regularizers.l1_l2(l1=l1_reg,l2=l2_reg))(s_encodeur)\n",
        "s_decodeur = tf.keras.layers.Concatenate()([s_decodeur,s_encodeur])\n",
        "\n",
        "# Générateur\n",
        "sortie = tf.keras.layers.Dense(1,kernel_regularizer=tf.keras.regularizers.l1_l2(l1=l1_reg,l2=l2_reg))(s_decodeur)\n",
        "\n",
        "# Construction du modèle\n",
        "model = tf.keras.Model(entrees,sortie)\n",
        "model.summary()"
      ],
      "execution_count": 375,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_77\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_81 (InputLayer)           [(None, 200, 1)]     0                                            \n",
            "__________________________________________________________________________________________________\n",
            "lstm_80 (LSTM)                  (None, 100)          40800       input_81[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_156 (Dense)               (None, 100)          10100       lstm_80[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_78 (Concatenate)    (None, 200)          0           dense_156[0][0]                  \n",
            "                                                                 lstm_80[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_157 (Dense)               (None, 1)            201         concatenate_78[0][0]             \n",
            "==================================================================================================\n",
            "Total params: 51,101\n",
            "Trainable params: 51,101\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_azfJaeUo2nU"
      },
      "source": [
        "**2. Optimisation de l'apprentissage**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pf3lwaQBnjxL"
      },
      "source": [
        "Pour accélérer le traitement des données, nous n'allons pas utiliser l'intégralité des données pendant la mise à jour du gradient, comme cela a été fait jusqu'à présent (en utilisant le dataset).  \n",
        "Cette fois-ci, nous allons forcer les mises à jour du gradient à se produire de manière moins fréquente en attribuant la valeur du batch_size à prendre en compte lors de la regression du modèle.  \n",
        "Pour cela, on utilise l'argument \"batch_size\" dans la méthode fit. En précisant un batch_size=1000, cela signifie que :\n",
        " - Sur notre total de 56000 échantillons, 56 seront utilisés pour les calculs du gradient\n",
        " - Il y aura également 56 itérations à chaque période.\n",
        "  \n",
        "    \n",
        "    \n",
        "Si nous avions pris le dataset comme entrée, nous aurions eu :\n",
        "- Un total de 56000 échantillons également\n",
        "- Chaque période aurait également pris 56 itérations pour se compléter\n",
        "- Mais 1000 échantillons auraient été utilisés pour le calcul du gradient, au lieu de 56 avec la méthode utilisée."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K6Z35rNWj5SA",
        "outputId": "3c93fe87-3185-49db-8e52-d1022bc0393b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Définition de la fonction de régulation du taux d'apprentissage\n",
        "def RegulationTauxApprentissage(periode, taux):\n",
        "  return 1e-8*10**(periode/10)\n",
        "\n",
        "# Définition de l'optimiseur à utiliser\n",
        "optimiseur=tf.keras.optimizers.SGD()\n",
        "\n",
        "# Compile le modèle\n",
        "model.compile(loss=\"mse\", optimizer=optimiseur, metrics=\"mse\")\n",
        "\n",
        "# Utilisation de la méthode ModelCheckPoint\n",
        "CheckPoint = tf.keras.callbacks.ModelCheckpoint(\"poids.hdf5\", monitor='loss', verbose=1, save_best_only=True, save_weights_only = True, mode='auto', save_freq='epoch')\n",
        "\n",
        "# Entraine le modèle en utilisant notre fonction personnelle de régulation du taux d'apprentissage\n",
        "historique = model.fit(dataset,epochs=100,verbose=1, callbacks=[tf.keras.callbacks.LearningRateScheduler(RegulationTauxApprentissage), CheckPoint],batch_size=batch_size)"
      ],
      "execution_count": 347,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "4/4 [==============================] - 1s 9ms/step - loss: 0.2976 - mse: 0.2976\n",
            "\n",
            "Epoch 00001: loss improved from inf to 0.49595, saving model to poids.hdf5\n",
            "Epoch 2/100\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.2976 - mse: 0.2976\n",
            "\n",
            "Epoch 00002: loss improved from 0.49595 to 0.49595, saving model to poids.hdf5\n",
            "Epoch 3/100\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.2976 - mse: 0.2976\n",
            "\n",
            "Epoch 00003: loss improved from 0.49595 to 0.49595, saving model to poids.hdf5\n",
            "Epoch 4/100\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.2976 - mse: 0.2976\n",
            "\n",
            "Epoch 00004: loss improved from 0.49595 to 0.49595, saving model to poids.hdf5\n",
            "Epoch 5/100\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.2976 - mse: 0.2976\n",
            "\n",
            "Epoch 00005: loss improved from 0.49595 to 0.49595, saving model to poids.hdf5\n",
            "Epoch 6/100\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.2976 - mse: 0.2976\n",
            "\n",
            "Epoch 00006: loss improved from 0.49595 to 0.49595, saving model to poids.hdf5\n",
            "Epoch 7/100\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.2976 - mse: 0.2976\n",
            "\n",
            "Epoch 00007: loss improved from 0.49595 to 0.49595, saving model to poids.hdf5\n",
            "Epoch 8/100\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.2976 - mse: 0.2976\n",
            "\n",
            "Epoch 00008: loss improved from 0.49595 to 0.49595, saving model to poids.hdf5\n",
            "Epoch 9/100\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.2976 - mse: 0.2976\n",
            "\n",
            "Epoch 00009: loss improved from 0.49595 to 0.49595, saving model to poids.hdf5\n",
            "Epoch 10/100\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.2976 - mse: 0.2976\n",
            "\n",
            "Epoch 00010: loss improved from 0.49595 to 0.49595, saving model to poids.hdf5\n",
            "Epoch 11/100\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.2976 - mse: 0.2976\n",
            "\n",
            "Epoch 00011: loss improved from 0.49595 to 0.49595, saving model to poids.hdf5\n",
            "Epoch 12/100\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.2976 - mse: 0.2976\n",
            "\n",
            "Epoch 00012: loss improved from 0.49595 to 0.49595, saving model to poids.hdf5\n",
            "Epoch 13/100\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.2976 - mse: 0.2976\n",
            "\n",
            "Epoch 00013: loss improved from 0.49595 to 0.49595, saving model to poids.hdf5\n",
            "Epoch 14/100\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.2976 - mse: 0.2976\n",
            "\n",
            "Epoch 00014: loss improved from 0.49595 to 0.49594, saving model to poids.hdf5\n",
            "Epoch 15/100\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.2976 - mse: 0.2976\n",
            "\n",
            "Epoch 00015: loss improved from 0.49594 to 0.49594, saving model to poids.hdf5\n",
            "Epoch 16/100\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.2976 - mse: 0.2976\n",
            "\n",
            "Epoch 00016: loss improved from 0.49594 to 0.49594, saving model to poids.hdf5\n",
            "Epoch 17/100\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.2976 - mse: 0.2976\n",
            "\n",
            "Epoch 00017: loss improved from 0.49594 to 0.49594, saving model to poids.hdf5\n",
            "Epoch 18/100\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.2976 - mse: 0.2976\n",
            "\n",
            "Epoch 00018: loss improved from 0.49594 to 0.49593, saving model to poids.hdf5\n",
            "Epoch 19/100\n",
            "4/4 [==============================] - 0s 12ms/step - loss: 0.2976 - mse: 0.2976\n",
            "\n",
            "Epoch 00019: loss improved from 0.49593 to 0.49593, saving model to poids.hdf5\n",
            "Epoch 20/100\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.2976 - mse: 0.2976\n",
            "\n",
            "Epoch 00020: loss improved from 0.49593 to 0.49592, saving model to poids.hdf5\n",
            "Epoch 21/100\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.2976 - mse: 0.2976\n",
            "\n",
            "Epoch 00021: loss improved from 0.49592 to 0.49591, saving model to poids.hdf5\n",
            "Epoch 22/100\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.2976 - mse: 0.2976\n",
            "\n",
            "Epoch 00022: loss improved from 0.49591 to 0.49590, saving model to poids.hdf5\n",
            "Epoch 23/100\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.2975 - mse: 0.2975\n",
            "\n",
            "Epoch 00023: loss improved from 0.49590 to 0.49589, saving model to poids.hdf5\n",
            "Epoch 24/100\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.2975 - mse: 0.2975\n",
            "\n",
            "Epoch 00024: loss improved from 0.49589 to 0.49587, saving model to poids.hdf5\n",
            "Epoch 25/100\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.2975 - mse: 0.2975\n",
            "\n",
            "Epoch 00025: loss improved from 0.49587 to 0.49585, saving model to poids.hdf5\n",
            "Epoch 26/100\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.2975 - mse: 0.2975\n",
            "\n",
            "Epoch 00026: loss improved from 0.49585 to 0.49582, saving model to poids.hdf5\n",
            "Epoch 27/100\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.2975 - mse: 0.2975\n",
            "\n",
            "Epoch 00027: loss improved from 0.49582 to 0.49579, saving model to poids.hdf5\n",
            "Epoch 28/100\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.2975 - mse: 0.2975\n",
            "\n",
            "Epoch 00028: loss improved from 0.49579 to 0.49574, saving model to poids.hdf5\n",
            "Epoch 29/100\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.2975 - mse: 0.2975\n",
            "\n",
            "Epoch 00029: loss improved from 0.49574 to 0.49569, saving model to poids.hdf5\n",
            "Epoch 30/100\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.2974 - mse: 0.2974\n",
            "\n",
            "Epoch 00030: loss improved from 0.49569 to 0.49562, saving model to poids.hdf5\n",
            "Epoch 31/100\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.2974 - mse: 0.2974\n",
            "\n",
            "Epoch 00031: loss improved from 0.49562 to 0.49553, saving model to poids.hdf5\n",
            "Epoch 32/100\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.2973 - mse: 0.2973\n",
            "\n",
            "Epoch 00032: loss improved from 0.49553 to 0.49542, saving model to poids.hdf5\n",
            "Epoch 33/100\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.2973 - mse: 0.2973\n",
            "\n",
            "Epoch 00033: loss improved from 0.49542 to 0.49529, saving model to poids.hdf5\n",
            "Epoch 34/100\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.2972 - mse: 0.2972\n",
            "\n",
            "Epoch 00034: loss improved from 0.49529 to 0.49511, saving model to poids.hdf5\n",
            "Epoch 35/100\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.2971 - mse: 0.2971\n",
            "\n",
            "Epoch 00035: loss improved from 0.49511 to 0.49490, saving model to poids.hdf5\n",
            "Epoch 36/100\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.2969 - mse: 0.2969\n",
            "\n",
            "Epoch 00036: loss improved from 0.49490 to 0.49462, saving model to poids.hdf5\n",
            "Epoch 37/100\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.2968 - mse: 0.2968\n",
            "\n",
            "Epoch 00037: loss improved from 0.49462 to 0.49428, saving model to poids.hdf5\n",
            "Epoch 38/100\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.2966 - mse: 0.2966\n",
            "\n",
            "Epoch 00038: loss improved from 0.49428 to 0.49385, saving model to poids.hdf5\n",
            "Epoch 39/100\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.2963 - mse: 0.2963\n",
            "\n",
            "Epoch 00039: loss improved from 0.49385 to 0.49331, saving model to poids.hdf5\n",
            "Epoch 40/100\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.2960 - mse: 0.2960\n",
            "\n",
            "Epoch 00040: loss improved from 0.49331 to 0.49262, saving model to poids.hdf5\n",
            "Epoch 41/100\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.2956 - mse: 0.2956\n",
            "\n",
            "Epoch 00041: loss improved from 0.49262 to 0.49177, saving model to poids.hdf5\n",
            "Epoch 42/100\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.2951 - mse: 0.2951\n",
            "\n",
            "Epoch 00042: loss improved from 0.49177 to 0.49069, saving model to poids.hdf5\n",
            "Epoch 43/100\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.2944 - mse: 0.2944\n",
            "\n",
            "Epoch 00043: loss improved from 0.49069 to 0.48934, saving model to poids.hdf5\n",
            "Epoch 44/100\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.2936 - mse: 0.2936\n",
            "\n",
            "Epoch 00044: loss improved from 0.48934 to 0.48766, saving model to poids.hdf5\n",
            "Epoch 45/100\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.2926 - mse: 0.2926\n",
            "\n",
            "Epoch 00045: loss improved from 0.48766 to 0.48555, saving model to poids.hdf5\n",
            "Epoch 46/100\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.2913 - mse: 0.2913\n",
            "\n",
            "Epoch 00046: loss improved from 0.48555 to 0.48291, saving model to poids.hdf5\n",
            "Epoch 47/100\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.2898 - mse: 0.2898\n",
            "\n",
            "Epoch 00047: loss improved from 0.48291 to 0.47962, saving model to poids.hdf5\n",
            "Epoch 48/100\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.2878 - mse: 0.2878\n",
            "\n",
            "Epoch 00048: loss improved from 0.47962 to 0.47554, saving model to poids.hdf5\n",
            "Epoch 49/100\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.2854 - mse: 0.2854\n",
            "\n",
            "Epoch 00049: loss improved from 0.47554 to 0.47048, saving model to poids.hdf5\n",
            "Epoch 50/100\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.2825 - mse: 0.2825\n",
            "\n",
            "Epoch 00050: loss improved from 0.47048 to 0.46423, saving model to poids.hdf5\n",
            "Epoch 51/100\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.2789 - mse: 0.2789\n",
            "\n",
            "Epoch 00051: loss improved from 0.46423 to 0.45655, saving model to poids.hdf5\n",
            "Epoch 52/100\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.2745 - mse: 0.2745\n",
            "\n",
            "Epoch 00052: loss improved from 0.45655 to 0.44719, saving model to poids.hdf5\n",
            "Epoch 53/100\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.2691 - mse: 0.2691\n",
            "\n",
            "Epoch 00053: loss improved from 0.44719 to 0.43584, saving model to poids.hdf5\n",
            "Epoch 54/100\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.2628 - mse: 0.2628\n",
            "\n",
            "Epoch 00054: loss improved from 0.43584 to 0.42222, saving model to poids.hdf5\n",
            "Epoch 55/100\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.2553 - mse: 0.2553\n",
            "\n",
            "Epoch 00055: loss improved from 0.42222 to 0.40605, saving model to poids.hdf5\n",
            "Epoch 56/100\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.2466 - mse: 0.2466\n",
            "\n",
            "Epoch 00056: loss improved from 0.40605 to 0.38712, saving model to poids.hdf5\n",
            "Epoch 57/100\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.2367 - mse: 0.2367\n",
            "\n",
            "Epoch 00057: loss improved from 0.38712 to 0.36529, saving model to poids.hdf5\n",
            "Epoch 58/100\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.2254 - mse: 0.2254\n",
            "\n",
            "Epoch 00058: loss improved from 0.36529 to 0.34058, saving model to poids.hdf5\n",
            "Epoch 59/100\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.2130 - mse: 0.2130\n",
            "\n",
            "Epoch 00059: loss improved from 0.34058 to 0.31316, saving model to poids.hdf5\n",
            "Epoch 60/100\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.1993 - mse: 0.1993\n",
            "\n",
            "Epoch 00060: loss improved from 0.31316 to 0.28339, saving model to poids.hdf5\n",
            "Epoch 61/100\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.1844 - mse: 0.1844\n",
            "\n",
            "Epoch 00061: loss improved from 0.28339 to 0.25172, saving model to poids.hdf5\n",
            "Epoch 62/100\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.1679 - mse: 0.1679\n",
            "\n",
            "Epoch 00062: loss improved from 0.25172 to 0.21866, saving model to poids.hdf5\n",
            "Epoch 63/100\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.1496 - mse: 0.1496\n",
            "\n",
            "Epoch 00063: loss improved from 0.21866 to 0.18470, saving model to poids.hdf5\n",
            "Epoch 64/100\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.1289 - mse: 0.1289\n",
            "\n",
            "Epoch 00064: loss improved from 0.18470 to 0.15046, saving model to poids.hdf5\n",
            "Epoch 65/100\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.1062 - mse: 0.1062\n",
            "\n",
            "Epoch 00065: loss improved from 0.15046 to 0.11710, saving model to poids.hdf5\n",
            "Epoch 66/100\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.0831 - mse: 0.0831\n",
            "\n",
            "Epoch 00066: loss improved from 0.11710 to 0.08693, saving model to poids.hdf5\n",
            "Epoch 67/100\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.0629 - mse: 0.0629\n",
            "\n",
            "Epoch 00067: loss improved from 0.08693 to 0.06321, saving model to poids.hdf5\n",
            "Epoch 68/100\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.0486 - mse: 0.0486\n",
            "\n",
            "Epoch 00068: loss improved from 0.06321 to 0.04831, saving model to poids.hdf5\n",
            "Epoch 69/100\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.0408 - mse: 0.0408\n",
            "\n",
            "Epoch 00069: loss improved from 0.04831 to 0.04123, saving model to poids.hdf5\n",
            "Epoch 70/100\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.0371 - mse: 0.0371\n",
            "\n",
            "Epoch 00070: loss improved from 0.04123 to 0.03848, saving model to poids.hdf5\n",
            "Epoch 71/100\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.0355 - mse: 0.0355\n",
            "\n",
            "Epoch 00071: loss improved from 0.03848 to 0.03750, saving model to poids.hdf5\n",
            "Epoch 72/100\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.0349 - mse: 0.0349\n",
            "\n",
            "Epoch 00072: loss did not improve from 0.03750\n",
            "Epoch 73/100\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.0354 - mse: 0.0354\n",
            "\n",
            "Epoch 00073: loss did not improve from 0.03750\n",
            "Epoch 74/100\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.0378 - mse: 0.0378\n",
            "\n",
            "Epoch 00074: loss did not improve from 0.03750\n",
            "Epoch 75/100\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.0477 - mse: 0.0477\n",
            "\n",
            "Epoch 00075: loss did not improve from 0.03750\n",
            "Epoch 76/100\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.0926 - mse: 0.0926\n",
            "\n",
            "Epoch 00076: loss did not improve from 0.03750\n",
            "Epoch 77/100\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.1622 - mse: 0.1622\n",
            "\n",
            "Epoch 00077: loss did not improve from 0.03750\n",
            "Epoch 78/100\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.1632 - mse: 0.1632\n",
            "\n",
            "Epoch 00078: loss did not improve from 0.03750\n",
            "Epoch 79/100\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.2163 - mse: 0.2163\n",
            "\n",
            "Epoch 00079: loss did not improve from 0.03750\n",
            "Epoch 80/100\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 1.2950 - mse: 1.2950\n",
            "\n",
            "Epoch 00080: loss did not improve from 0.03750\n",
            "Epoch 81/100\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 1446265.5880 - mse: 1446265.5880\n",
            "\n",
            "Epoch 00081: loss did not improve from 0.03750\n",
            "Epoch 82/100\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 2199947092255846.5000 - mse: 2199947092255846.5000\n",
            "\n",
            "Epoch 00082: loss did not improve from 0.03750\n",
            "Epoch 83/100\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 240466750630331957641216.0000 - mse: 240466750630331957641216.0000\n",
            "\n",
            "Epoch 00083: loss did not improve from 0.03750\n",
            "Epoch 84/100\n",
            "4/4 [==============================] - 0s 15ms/step - loss: nan - mse: nan                                                     \n",
            "\n",
            "Epoch 00084: loss did not improve from 0.03750\n",
            "Epoch 85/100\n",
            "4/4 [==============================] - 0s 15ms/step - loss: nan - mse: nan\n",
            "\n",
            "Epoch 00085: loss did not improve from 0.03750\n",
            "Epoch 86/100\n",
            "4/4 [==============================] - 0s 15ms/step - loss: nan - mse: nan\n",
            "\n",
            "Epoch 00086: loss did not improve from 0.03750\n",
            "Epoch 87/100\n",
            "4/4 [==============================] - 0s 16ms/step - loss: nan - mse: nan\n",
            "\n",
            "Epoch 00087: loss did not improve from 0.03750\n",
            "Epoch 88/100\n",
            "4/4 [==============================] - 0s 14ms/step - loss: nan - mse: nan\n",
            "\n",
            "Epoch 00088: loss did not improve from 0.03750\n",
            "Epoch 89/100\n",
            "4/4 [==============================] - 0s 14ms/step - loss: nan - mse: nan\n",
            "\n",
            "Epoch 00089: loss did not improve from 0.03750\n",
            "Epoch 90/100\n",
            "4/4 [==============================] - 0s 15ms/step - loss: nan - mse: nan\n",
            "\n",
            "Epoch 00090: loss did not improve from 0.03750\n",
            "Epoch 91/100\n",
            "4/4 [==============================] - 0s 16ms/step - loss: nan - mse: nan\n",
            "\n",
            "Epoch 00091: loss did not improve from 0.03750\n",
            "Epoch 92/100\n",
            "4/4 [==============================] - 0s 16ms/step - loss: nan - mse: nan\n",
            "\n",
            "Epoch 00092: loss did not improve from 0.03750\n",
            "Epoch 93/100\n",
            "4/4 [==============================] - 0s 15ms/step - loss: nan - mse: nan\n",
            "\n",
            "Epoch 00093: loss did not improve from 0.03750\n",
            "Epoch 94/100\n",
            "4/4 [==============================] - 0s 16ms/step - loss: nan - mse: nan\n",
            "\n",
            "Epoch 00094: loss did not improve from 0.03750\n",
            "Epoch 95/100\n",
            "4/4 [==============================] - 0s 15ms/step - loss: nan - mse: nan\n",
            "\n",
            "Epoch 00095: loss did not improve from 0.03750\n",
            "Epoch 96/100\n",
            "4/4 [==============================] - 0s 16ms/step - loss: nan - mse: nan\n",
            "\n",
            "Epoch 00096: loss did not improve from 0.03750\n",
            "Epoch 97/100\n",
            "4/4 [==============================] - 0s 14ms/step - loss: nan - mse: nan\n",
            "\n",
            "Epoch 00097: loss did not improve from 0.03750\n",
            "Epoch 98/100\n",
            "4/4 [==============================] - 0s 14ms/step - loss: nan - mse: nan\n",
            "\n",
            "Epoch 00098: loss did not improve from 0.03750\n",
            "Epoch 99/100\n",
            "4/4 [==============================] - 0s 15ms/step - loss: nan - mse: nan\n",
            "\n",
            "Epoch 00099: loss did not improve from 0.03750\n",
            "Epoch 100/100\n",
            "4/4 [==============================] - 0s 18ms/step - loss: nan - mse: nan\n",
            "\n",
            "Epoch 00100: loss did not improve from 0.03750\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u2aP9J3TkNGG",
        "outputId": "9a76ab9d-507d-4f07-ad99-f450ce461ee1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 411
        }
      },
      "source": [
        "# Construit un vecteur avec les valeurs du taux d'apprentissage à chaque période \n",
        "taux = 1e-8*(10**(np.arange(100)/10))\n",
        "\n",
        "# Affiche l'erreur en fonction du taux d'apprentissage\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.semilogx(taux,historique.history[\"loss\"])\n",
        "plt.axis([ taux[0], taux[99], 0, 1])\n",
        "plt.title(\"Evolution de l'erreur en fonction du taux d'apprentissage\")"
      ],
      "execution_count": 348,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, \"Evolution de l'erreur en fonction du taux d'apprentissage\")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 348
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cZxCgpuYkQ2Q"
      },
      "source": [
        "# Chargement des poids sauvegardés\n",
        "model.load_weights(\"poids.hdf5\")"
      ],
      "execution_count": 349,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zmdbo23qkTKE",
        "outputId": "0973b4be-3f26-42db-f13c-5976fcd0d82c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "max_periodes = 1000\n",
        "\n",
        "# Classe permettant d'arrêter l'entrainement si la variation\n",
        "# devient plus petite qu'une valeur à choisir sur un nombre\n",
        "# de périodes à choisir\n",
        "class StopTrain(keras.callbacks.Callback):\n",
        "    def __init__(self, delta=0.01,periodes=100, term=\"loss\", logs={}):\n",
        "      self.n_periodes = 0\n",
        "      self.periodes = periodes\n",
        "      self.loss_1 = 100\n",
        "      self.delta = delta\n",
        "      self.term = term\n",
        "    def on_epoch_end(self, epoch, logs={}):\n",
        "      diff_loss = abs(self.loss_1 - logs[self.term])\n",
        "      self.loss_1 = logs[self.term]\n",
        "      if (diff_loss < self.delta):\n",
        "        self.n_periodes = self.n_periodes + 1\n",
        "      else:\n",
        "        self.n_periodes = 0\n",
        "      if (self.n_periodes == self.periodes):\n",
        "        print(\"Arrêt de l'entrainement...\")\n",
        "        self.model.stop_training = True\n",
        "\n",
        "# Définition des paramètres liés à l'évolution du taux d'apprentissage\n",
        "lr_schedule = tf.keras.optimizers.schedules.InverseTimeDecay(\n",
        "    initial_learning_rate=0.1,\n",
        "    decay_steps=10,\n",
        "    decay_rate=0.01)\n",
        "\n",
        "# Définition de l'optimiseur à utiliser\n",
        "optimiseur=tf.keras.optimizers.SGD(learning_rate=lr_schedule,momentum=0.9)\n",
        "\n",
        "# Utilisation de la méthode ModelCheckPoint\n",
        "CheckPoint = tf.keras.callbacks.ModelCheckpoint(\"poids_train.hdf5\", monitor='loss', verbose=1, save_best_only=True, save_weights_only = True, mode='auto', save_freq='epoch')\n",
        "\n",
        "# Compile le modèle\n",
        "model.compile(loss=\"mse\", optimizer=optimiseur, metrics=[\"mse\"])\n",
        "\n",
        "# Entraine le modèle, avec une réduction des calculs du gradient\n",
        "#historique = model.fit(x=x_train,y=y_train,validation_data=(x_val,y_val), epochs=max_periodes,verbose=1, callbacks=[CheckPoint,StopTrain(delta=1e-7,periodes = 10, term=\"My_MSE\")],batch_size=batch_size)\n",
        "\n",
        "# Entraine le modèle sans réduction de calculs\n",
        "historique = model.fit(dataset,validation_data=dataset_val, epochs=max_periodes,verbose=1, callbacks=[CheckPoint,StopTrain(delta=1e-8,periodes = 10, term=\"loss\")])\n",
        "#historique = model.fit(dataset, epochs=max_periodes)\n"
      ],
      "execution_count": 376,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/1000\n",
            "160/160 [==============================] - 2s 8ms/step - loss: 0.0298 - mse: 0.0298\n",
            "\n",
            "Epoch 00001: loss improved from inf to 0.02374, saving model to poids_train.hdf5\n",
            "Epoch 2/1000\n",
            "160/160 [==============================] - 1s 6ms/step - loss: 0.1093 - mse: 0.1093\n",
            "\n",
            "Epoch 00002: loss did not improve from 0.02374\n",
            "Epoch 3/1000\n",
            "160/160 [==============================] - 1s 6ms/step - loss: 0.2120 - mse: 0.2120\n",
            "\n",
            "Epoch 00003: loss did not improve from 0.02374\n",
            "Epoch 4/1000\n",
            "160/160 [==============================] - 1s 6ms/step - loss: 0.1721 - mse: 0.1721\n",
            "\n",
            "Epoch 00004: loss did not improve from 0.02374\n",
            "Epoch 5/1000\n",
            "160/160 [==============================] - 1s 6ms/step - loss: 0.3180 - mse: 0.3180\n",
            "\n",
            "Epoch 00005: loss did not improve from 0.02374\n",
            "Epoch 6/1000\n",
            "160/160 [==============================] - 1s 6ms/step - loss: 0.1737 - mse: 0.1737\n",
            "\n",
            "Epoch 00006: loss did not improve from 0.02374\n",
            "Epoch 7/1000\n",
            "160/160 [==============================] - 1s 6ms/step - loss: 0.1822 - mse: 0.1822\n",
            "\n",
            "Epoch 00007: loss did not improve from 0.02374\n",
            "Epoch 8/1000\n",
            "160/160 [==============================] - 1s 6ms/step - loss: 0.1882 - mse: 0.1882\n",
            "\n",
            "Epoch 00008: loss did not improve from 0.02374\n",
            "Epoch 9/1000\n",
            "160/160 [==============================] - 1s 6ms/step - loss: 0.1883 - mse: 0.1883\n",
            "\n",
            "Epoch 00009: loss did not improve from 0.02374\n",
            "Epoch 10/1000\n",
            "160/160 [==============================] - 1s 6ms/step - loss: 0.2677 - mse: 0.2677\n",
            "\n",
            "Epoch 00010: loss did not improve from 0.02374\n",
            "Epoch 11/1000\n",
            "160/160 [==============================] - 1s 6ms/step - loss: 0.1191 - mse: 0.1191\n",
            "\n",
            "Epoch 00011: loss did not improve from 0.02374\n",
            "Epoch 12/1000\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.2485 - mse: 0.2485\n",
            "\n",
            "Epoch 00012: loss did not improve from 0.02374\n",
            "Epoch 13/1000\n",
            "160/160 [==============================] - 1s 6ms/step - loss: 0.1377 - mse: 0.1377\n",
            "\n",
            "Epoch 00013: loss did not improve from 0.02374\n",
            "Epoch 14/1000\n",
            "160/160 [==============================] - 1s 6ms/step - loss: 0.1764 - mse: 0.1764\n",
            "\n",
            "Epoch 00014: loss did not improve from 0.02374\n",
            "Epoch 15/1000\n",
            "160/160 [==============================] - 1s 6ms/step - loss: 0.1350 - mse: 0.1350\n",
            "\n",
            "Epoch 00015: loss did not improve from 0.02374\n",
            "Epoch 16/1000\n",
            "160/160 [==============================] - 1s 6ms/step - loss: 0.1019 - mse: 0.1019\n",
            "\n",
            "Epoch 00016: loss did not improve from 0.02374\n",
            "Epoch 17/1000\n",
            "160/160 [==============================] - 1s 6ms/step - loss: 0.0641 - mse: 0.0641\n",
            "\n",
            "Epoch 00017: loss did not improve from 0.02374\n",
            "Epoch 18/1000\n",
            "160/160 [==============================] - 1s 6ms/step - loss: 0.0402 - mse: 0.0402\n",
            "\n",
            "Epoch 00018: loss improved from 0.02374 to 0.02099, saving model to poids_train.hdf5\n",
            "Epoch 19/1000\n",
            "160/160 [==============================] - 1s 6ms/step - loss: 0.0278 - mse: 0.0278\n",
            "\n",
            "Epoch 00019: loss improved from 0.02099 to 0.01625, saving model to poids_train.hdf5\n",
            "Epoch 20/1000\n",
            "160/160 [==============================] - 1s 6ms/step - loss: 0.0225 - mse: 0.0225\n",
            "\n",
            "Epoch 00020: loss improved from 0.01625 to 0.01398, saving model to poids_train.hdf5\n",
            "Epoch 21/1000\n",
            "160/160 [==============================] - 1s 6ms/step - loss: 0.0204 - mse: 0.0204\n",
            "\n",
            "Epoch 00021: loss improved from 0.01398 to 0.01293, saving model to poids_train.hdf5\n",
            "Epoch 22/1000\n",
            "160/160 [==============================] - 1s 6ms/step - loss: 0.0193 - mse: 0.0193\n",
            "\n",
            "Epoch 00022: loss improved from 0.01293 to 0.01231, saving model to poids_train.hdf5\n",
            "Epoch 23/1000\n",
            "160/160 [==============================] - 1s 6ms/step - loss: 0.0182 - mse: 0.0182\n",
            "\n",
            "Epoch 00023: loss improved from 0.01231 to 0.01175, saving model to poids_train.hdf5\n",
            "Epoch 24/1000\n",
            "160/160 [==============================] - 1s 6ms/step - loss: 0.0171 - mse: 0.0171\n",
            "\n",
            "Epoch 00024: loss improved from 0.01175 to 0.01121, saving model to poids_train.hdf5\n",
            "Epoch 25/1000\n",
            "160/160 [==============================] - 1s 6ms/step - loss: 0.0162 - mse: 0.0162\n",
            "\n",
            "Epoch 00025: loss improved from 0.01121 to 0.01073, saving model to poids_train.hdf5\n",
            "Epoch 26/1000\n",
            "160/160 [==============================] - 1s 6ms/step - loss: 0.0154 - mse: 0.0154\n",
            "\n",
            "Epoch 00026: loss improved from 0.01073 to 0.01032, saving model to poids_train.hdf5\n",
            "Epoch 27/1000\n",
            "160/160 [==============================] - 1s 6ms/step - loss: 0.0148 - mse: 0.0148\n",
            "\n",
            "Epoch 00027: loss improved from 0.01032 to 0.00997, saving model to poids_train.hdf5\n",
            "Epoch 28/1000\n",
            "160/160 [==============================] - 1s 6ms/step - loss: 0.0142 - mse: 0.0142\n",
            "\n",
            "Epoch 00028: loss improved from 0.00997 to 0.00966, saving model to poids_train.hdf5\n",
            "Epoch 29/1000\n",
            "160/160 [==============================] - 1s 6ms/step - loss: 0.0138 - mse: 0.0138\n",
            "\n",
            "Epoch 00029: loss improved from 0.00966 to 0.00939, saving model to poids_train.hdf5\n",
            "Epoch 30/1000\n",
            "160/160 [==============================] - 1s 6ms/step - loss: 0.0133 - mse: 0.0133\n",
            "\n",
            "Epoch 00030: loss improved from 0.00939 to 0.00915, saving model to poids_train.hdf5\n",
            "Epoch 31/1000\n",
            "160/160 [==============================] - 1s 6ms/step - loss: 0.0130 - mse: 0.0130\n",
            "\n",
            "Epoch 00031: loss improved from 0.00915 to 0.00893, saving model to poids_train.hdf5\n",
            "Epoch 32/1000\n",
            "160/160 [==============================] - 1s 6ms/step - loss: 0.0126 - mse: 0.0126\n",
            "\n",
            "Epoch 00032: loss improved from 0.00893 to 0.00873, saving model to poids_train.hdf5\n",
            "Epoch 33/1000\n",
            "160/160 [==============================] - 1s 6ms/step - loss: 0.0123 - mse: 0.0123\n",
            "\n",
            "Epoch 00033: loss improved from 0.00873 to 0.00855, saving model to poids_train.hdf5\n",
            "Epoch 34/1000\n",
            "160/160 [==============================] - 1s 6ms/step - loss: 0.0121 - mse: 0.0121\n",
            "\n",
            "Epoch 00034: loss improved from 0.00855 to 0.00839, saving model to poids_train.hdf5\n",
            "Epoch 35/1000\n",
            "160/160 [==============================] - 1s 6ms/step - loss: 0.0119 - mse: 0.0119\n",
            "\n",
            "Epoch 00035: loss improved from 0.00839 to 0.00824, saving model to poids_train.hdf5\n",
            "Epoch 36/1000\n",
            "160/160 [==============================] - 1s 6ms/step - loss: 0.0116 - mse: 0.0116\n",
            "\n",
            "Epoch 00036: loss improved from 0.00824 to 0.00810, saving model to poids_train.hdf5\n",
            "Epoch 37/1000\n",
            "160/160 [==============================] - 1s 6ms/step - loss: 0.0115 - mse: 0.0115\n",
            "\n",
            "Epoch 00037: loss improved from 0.00810 to 0.00798, saving model to poids_train.hdf5\n",
            "Epoch 38/1000\n",
            "160/160 [==============================] - 1s 6ms/step - loss: 0.0113 - mse: 0.0113\n",
            "\n",
            "Epoch 00038: loss improved from 0.00798 to 0.00786, saving model to poids_train.hdf5\n",
            "Epoch 39/1000\n",
            "160/160 [==============================] - 1s 6ms/step - loss: 0.0111 - mse: 0.0111\n",
            "\n",
            "Epoch 00039: loss improved from 0.00786 to 0.00775, saving model to poids_train.hdf5\n",
            "Epoch 40/1000\n",
            "160/160 [==============================] - 1s 6ms/step - loss: 0.0110 - mse: 0.0110\n",
            "\n",
            "Epoch 00040: loss improved from 0.00775 to 0.00765, saving model to poids_train.hdf5\n",
            "Epoch 41/1000\n",
            "160/160 [==============================] - 1s 6ms/step - loss: 0.0108 - mse: 0.0108\n",
            "\n",
            "Epoch 00041: loss improved from 0.00765 to 0.00756, saving model to poids_train.hdf5\n",
            "Epoch 42/1000\n",
            "160/160 [==============================] - 1s 6ms/step - loss: 0.0107 - mse: 0.0107\n",
            "\n",
            "Epoch 00042: loss improved from 0.00756 to 0.00747, saving model to poids_train.hdf5\n",
            "Epoch 43/1000\n",
            "160/160 [==============================] - 1s 6ms/step - loss: 0.0106 - mse: 0.0106\n",
            "\n",
            "Epoch 00043: loss improved from 0.00747 to 0.00739, saving model to poids_train.hdf5\n",
            "Epoch 44/1000\n",
            "160/160 [==============================] - 1s 6ms/step - loss: 0.0105 - mse: 0.0105\n",
            "\n",
            "Epoch 00044: loss improved from 0.00739 to 0.00731, saving model to poids_train.hdf5\n",
            "Epoch 45/1000\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0104 - mse: 0.0104\n",
            "\n",
            "Epoch 00045: loss improved from 0.00731 to 0.00724, saving model to poids_train.hdf5\n",
            "Epoch 46/1000\n",
            "160/160 [==============================] - 1s 6ms/step - loss: 0.0103 - mse: 0.0103\n",
            "\n",
            "Epoch 00046: loss improved from 0.00724 to 0.00718, saving model to poids_train.hdf5\n",
            "Epoch 47/1000\n",
            "160/160 [==============================] - 1s 6ms/step - loss: 0.0102 - mse: 0.0102\n",
            "\n",
            "Epoch 00047: loss improved from 0.00718 to 0.00711, saving model to poids_train.hdf5\n",
            "Epoch 48/1000\n",
            "160/160 [==============================] - 1s 6ms/step - loss: 0.0101 - mse: 0.0101\n",
            "\n",
            "Epoch 00048: loss improved from 0.00711 to 0.00705, saving model to poids_train.hdf5\n",
            "Epoch 49/1000\n",
            "160/160 [==============================] - 1s 6ms/step - loss: 0.0101 - mse: 0.0101\n",
            "\n",
            "Epoch 00049: loss improved from 0.00705 to 0.00700, saving model to poids_train.hdf5\n",
            "Epoch 50/1000\n",
            "160/160 [==============================] - 1s 6ms/step - loss: 0.0100 - mse: 0.0100\n",
            "\n",
            "Epoch 00050: loss improved from 0.00700 to 0.00694, saving model to poids_train.hdf5\n",
            "Epoch 51/1000\n",
            "160/160 [==============================] - 1s 6ms/step - loss: 0.0099 - mse: 0.0099\n",
            "\n",
            "Epoch 00051: loss improved from 0.00694 to 0.00689, saving model to poids_train.hdf5\n",
            "Epoch 52/1000\n",
            "160/160 [==============================] - 1s 6ms/step - loss: 0.0099 - mse: 0.0099\n",
            "\n",
            "Epoch 00052: loss improved from 0.00689 to 0.00684, saving model to poids_train.hdf5\n",
            "Epoch 53/1000\n",
            "160/160 [==============================] - 1s 6ms/step - loss: 0.0098 - mse: 0.0098\n",
            "\n",
            "Epoch 00053: loss improved from 0.00684 to 0.00679, saving model to poids_train.hdf5\n",
            "Epoch 54/1000\n",
            "160/160 [==============================] - 1s 6ms/step - loss: 0.0098 - mse: 0.0098\n",
            "\n",
            "Epoch 00054: loss improved from 0.00679 to 0.00675, saving model to poids_train.hdf5\n",
            "Epoch 55/1000\n",
            "160/160 [==============================] - 1s 6ms/step - loss: 0.0097 - mse: 0.0097\n",
            "\n",
            "Epoch 00055: loss improved from 0.00675 to 0.00671, saving model to poids_train.hdf5\n",
            "Epoch 56/1000\n",
            "160/160 [==============================] - 1s 6ms/step - loss: 0.0096 - mse: 0.0096\n",
            "\n",
            "Epoch 00056: loss improved from 0.00671 to 0.00667, saving model to poids_train.hdf5\n",
            "Epoch 57/1000\n",
            "160/160 [==============================] - 1s 6ms/step - loss: 0.0096 - mse: 0.0096\n",
            "\n",
            "Epoch 00057: loss improved from 0.00667 to 0.00663, saving model to poids_train.hdf5\n",
            "Epoch 58/1000\n",
            "160/160 [==============================] - 1s 6ms/step - loss: 0.0095 - mse: 0.0095\n",
            "\n",
            "Epoch 00058: loss improved from 0.00663 to 0.00659, saving model to poids_train.hdf5\n",
            "Epoch 59/1000\n",
            "160/160 [==============================] - 1s 6ms/step - loss: 0.0095 - mse: 0.0095\n",
            "\n",
            "Epoch 00059: loss improved from 0.00659 to 0.00655, saving model to poids_train.hdf5\n",
            "Epoch 60/1000\n",
            "160/160 [==============================] - 1s 6ms/step - loss: 0.0095 - mse: 0.0095\n",
            "\n",
            "Epoch 00060: loss improved from 0.00655 to 0.00652, saving model to poids_train.hdf5\n",
            "Epoch 61/1000\n",
            "160/160 [==============================] - 1s 6ms/step - loss: 0.0094 - mse: 0.0094\n",
            "\n",
            "Epoch 00061: loss improved from 0.00652 to 0.00648, saving model to poids_train.hdf5\n",
            "Epoch 62/1000\n",
            "160/160 [==============================] - 1s 6ms/step - loss: 0.0094 - mse: 0.0094\n",
            "\n",
            "Epoch 00062: loss improved from 0.00648 to 0.00645, saving model to poids_train.hdf5\n",
            "Epoch 63/1000\n",
            "160/160 [==============================] - 1s 6ms/step - loss: 0.0093 - mse: 0.0093\n",
            "\n",
            "Epoch 00063: loss improved from 0.00645 to 0.00642, saving model to poids_train.hdf5\n",
            "Epoch 64/1000\n",
            "160/160 [==============================] - 1s 6ms/step - loss: 0.0093 - mse: 0.0093\n",
            "\n",
            "Epoch 00064: loss improved from 0.00642 to 0.00639, saving model to poids_train.hdf5\n",
            "Epoch 65/1000\n",
            "160/160 [==============================] - 1s 6ms/step - loss: 0.0092 - mse: 0.0092\n",
            "\n",
            "Epoch 00065: loss improved from 0.00639 to 0.00636, saving model to poids_train.hdf5\n",
            "Epoch 66/1000\n",
            "160/160 [==============================] - 1s 6ms/step - loss: 0.0092 - mse: 0.0092\n",
            "\n",
            "Epoch 00066: loss improved from 0.00636 to 0.00633, saving model to poids_train.hdf5\n",
            "Epoch 67/1000\n",
            "160/160 [==============================] - 1s 6ms/step - loss: 0.0092 - mse: 0.0092\n",
            "\n",
            "Epoch 00067: loss improved from 0.00633 to 0.00630, saving model to poids_train.hdf5\n",
            "Epoch 68/1000\n",
            "160/160 [==============================] - 1s 6ms/step - loss: 0.0091 - mse: 0.0091\n",
            "\n",
            "Epoch 00068: loss improved from 0.00630 to 0.00627, saving model to poids_train.hdf5\n",
            "Epoch 69/1000\n",
            "160/160 [==============================] - 1s 6ms/step - loss: 0.0091 - mse: 0.0091\n",
            "\n",
            "Epoch 00069: loss improved from 0.00627 to 0.00625, saving model to poids_train.hdf5\n",
            "Epoch 70/1000\n",
            "160/160 [==============================] - 1s 6ms/step - loss: 0.0091 - mse: 0.0091\n",
            "\n",
            "Epoch 00070: loss improved from 0.00625 to 0.00622, saving model to poids_train.hdf5\n",
            "Epoch 71/1000\n",
            "160/160 [==============================] - 1s 6ms/step - loss: 0.0090 - mse: 0.0090\n",
            "\n",
            "Epoch 00071: loss improved from 0.00622 to 0.00620, saving model to poids_train.hdf5\n",
            "Epoch 72/1000\n",
            "160/160 [==============================] - 1s 6ms/step - loss: 0.0090 - mse: 0.0090\n",
            "\n",
            "Epoch 00072: loss improved from 0.00620 to 0.00617, saving model to poids_train.hdf5\n",
            "Epoch 73/1000\n",
            "160/160 [==============================] - 1s 6ms/step - loss: 0.0090 - mse: 0.0090\n",
            "\n",
            "Epoch 00073: loss improved from 0.00617 to 0.00615, saving model to poids_train.hdf5\n",
            "Epoch 74/1000\n",
            "160/160 [==============================] - 1s 6ms/step - loss: 0.0089 - mse: 0.0089\n",
            "\n",
            "Epoch 00074: loss improved from 0.00615 to 0.00612, saving model to poids_train.hdf5\n",
            "Epoch 75/1000\n",
            "160/160 [==============================] - 1s 6ms/step - loss: 0.0089 - mse: 0.0089\n",
            "\n",
            "Epoch 00075: loss improved from 0.00612 to 0.00610, saving model to poids_train.hdf5\n",
            "Epoch 76/1000\n",
            "160/160 [==============================] - 1s 6ms/step - loss: 0.0089 - mse: 0.0089\n",
            "\n",
            "Epoch 00076: loss improved from 0.00610 to 0.00608, saving model to poids_train.hdf5\n",
            "Epoch 77/1000\n",
            "160/160 [==============================] - 1s 7ms/step - loss: 0.0089 - mse: 0.0089\n",
            "\n",
            "Epoch 00077: loss improved from 0.00608 to 0.00606, saving model to poids_train.hdf5\n",
            "Epoch 78/1000\n",
            "160/160 [==============================] - 1s 6ms/step - loss: 0.0088 - mse: 0.0088\n",
            "\n",
            "Epoch 00078: loss improved from 0.00606 to 0.00604, saving model to poids_train.hdf5\n",
            "Epoch 79/1000\n",
            "160/160 [==============================] - 1s 6ms/step - loss: 0.0088 - mse: 0.0088\n",
            "\n",
            "Epoch 00079: loss improved from 0.00604 to 0.00601, saving model to poids_train.hdf5\n",
            "Epoch 80/1000\n",
            "160/160 [==============================] - 1s 6ms/step - loss: 0.0088 - mse: 0.0088\n",
            "\n",
            "Epoch 00080: loss improved from 0.00601 to 0.00599, saving model to poids_train.hdf5\n",
            "Epoch 81/1000\n",
            "160/160 [==============================] - 1s 6ms/step - loss: 0.0087 - mse: 0.0087\n",
            "\n",
            "Epoch 00081: loss improved from 0.00599 to 0.00597, saving model to poids_train.hdf5\n",
            "Epoch 82/1000\n",
            "160/160 [==============================] - 1s 6ms/step - loss: 0.0087 - mse: 0.0087\n",
            "\n",
            "Epoch 00082: loss improved from 0.00597 to 0.00596, saving model to poids_train.hdf5\n",
            "Epoch 83/1000\n",
            "160/160 [==============================] - 1s 6ms/step - loss: 0.0087 - mse: 0.0087\n",
            "\n",
            "Epoch 00083: loss improved from 0.00596 to 0.00594, saving model to poids_train.hdf5\n",
            "Epoch 84/1000\n",
            "160/160 [==============================] - 1s 6ms/step - loss: 0.0087 - mse: 0.0087\n",
            "\n",
            "Epoch 00084: loss improved from 0.00594 to 0.00592, saving model to poids_train.hdf5\n",
            "Epoch 85/1000\n",
            "160/160 [==============================] - 1s 6ms/step - loss: 0.0086 - mse: 0.0086\n",
            "\n",
            "Epoch 00085: loss improved from 0.00592 to 0.00590, saving model to poids_train.hdf5\n",
            "Epoch 86/1000\n",
            "160/160 [==============================] - 1s 6ms/step - loss: 0.0086 - mse: 0.0086\n",
            "\n",
            "Epoch 00086: loss improved from 0.00590 to 0.00588, saving model to poids_train.hdf5\n",
            "Epoch 87/1000\n",
            "160/160 [==============================] - 1s 6ms/step - loss: 0.0086 - mse: 0.0086\n",
            "\n",
            "Epoch 00087: loss improved from 0.00588 to 0.00586, saving model to poids_train.hdf5\n",
            "Epoch 88/1000\n",
            "160/160 [==============================] - 1s 6ms/step - loss: 0.0086 - mse: 0.0086\n",
            "\n",
            "Epoch 00088: loss improved from 0.00586 to 0.00585, saving model to poids_train.hdf5\n",
            "Epoch 89/1000\n",
            "160/160 [==============================] - 1s 6ms/step - loss: 0.0086 - mse: 0.0086\n",
            "\n",
            "Epoch 00089: loss improved from 0.00585 to 0.00583, saving model to poids_train.hdf5\n",
            "Epoch 90/1000\n",
            "160/160 [==============================] - 1s 6ms/step - loss: 0.0085 - mse: 0.0085\n",
            "\n",
            "Epoch 00090: loss improved from 0.00583 to 0.00581, saving model to poids_train.hdf5\n",
            "Epoch 91/1000\n",
            "160/160 [==============================] - 1s 6ms/step - loss: 0.0085 - mse: 0.0085\n",
            "\n",
            "Epoch 00091: loss improved from 0.00581 to 0.00580, saving model to poids_train.hdf5\n",
            "Epoch 92/1000\n",
            "160/160 [==============================] - 1s 6ms/step - loss: 0.0085 - mse: 0.0085\n",
            "\n",
            "Epoch 00092: loss improved from 0.00580 to 0.00578, saving model to poids_train.hdf5\n",
            "Epoch 93/1000\n",
            "160/160 [==============================] - 1s 6ms/step - loss: 0.0085 - mse: 0.0085\n",
            "\n",
            "Epoch 00093: loss improved from 0.00578 to 0.00576, saving model to poids_train.hdf5\n",
            "Epoch 94/1000\n",
            "160/160 [==============================] - 1s 6ms/step - loss: 0.0084 - mse: 0.0084\n",
            "\n",
            "Epoch 00094: loss improved from 0.00576 to 0.00575, saving model to poids_train.hdf5\n",
            "Epoch 95/1000\n",
            "160/160 [==============================] - 1s 6ms/step - loss: 0.0084 - mse: 0.0084\n",
            "\n",
            "Epoch 00095: loss improved from 0.00575 to 0.00573, saving model to poids_train.hdf5\n",
            "Epoch 96/1000\n",
            "160/160 [==============================] - 1s 6ms/step - loss: 0.0084 - mse: 0.0084\n",
            "\n",
            "Epoch 00096: loss improved from 0.00573 to 0.00572, saving model to poids_train.hdf5\n",
            "Epoch 97/1000\n",
            "160/160 [==============================] - 1s 6ms/step - loss: 0.0084 - mse: 0.0084\n",
            "\n",
            "Epoch 00097: loss improved from 0.00572 to 0.00570, saving model to poids_train.hdf5\n",
            "Epoch 98/1000\n",
            "160/160 [==============================] - 1s 6ms/step - loss: 0.0084 - mse: 0.0084\n",
            "\n",
            "Epoch 00098: loss improved from 0.00570 to 0.00569, saving model to poids_train.hdf5\n",
            "Epoch 99/1000\n",
            "160/160 [==============================] - 1s 6ms/step - loss: 0.0083 - mse: 0.0083\n",
            "\n",
            "Epoch 00099: loss improved from 0.00569 to 0.00567, saving model to poids_train.hdf5\n",
            "Epoch 100/1000\n",
            "160/160 [==============================] - 1s 6ms/step - loss: 0.0083 - mse: 0.0083\n",
            "\n",
            "Epoch 00100: loss improved from 0.00567 to 0.00566, saving model to poids_train.hdf5\n",
            "Epoch 101/1000\n",
            "160/160 [==============================] - 1s 6ms/step - loss: 0.0083 - mse: 0.0083\n",
            "\n",
            "Epoch 00101: loss improved from 0.00566 to 0.00565, saving model to poids_train.hdf5\n",
            "Epoch 102/1000\n",
            " 37/160 [=====>........................] - ETA: 0s - loss: 0.0028 - mse: 0.0028"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-376-1116ffaf082e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;31m# Entraine le modèle sans réduction de calculs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m \u001b[0mhistorique\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdataset_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_periodes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mCheckPoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mStopTrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdelta\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-8\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mperiodes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mterm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"loss\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m \u001b[0;31m#historique = model.fit(dataset, epochs=max_periodes)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 _r=1):\n\u001b[1;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    853\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 855\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    856\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    857\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2942\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2943\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2945\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1917\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1918\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1919\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1921\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    558\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    561\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CfbomV0LS9LD"
      },
      "source": [
        "model.load_weights(\"poids_train.hdf5\")"
      ],
      "execution_count": 377,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8MDY8O1-l6kN",
        "outputId": "15fbd7bf-1d0b-48a4-8cc3-858c93730ae2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        }
      },
      "source": [
        "erreur_entrainement = historique.history[\"loss\"]\n",
        "#erreur_validation = historique.history[\"val_loss\"]\n",
        "\n",
        "# Affiche l'erreur en fonction de la période\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(np.arange(0,len(erreur_entrainement)),erreur_entrainement, label=\"Erreurs sur les entrainements\")\n",
        "#plt.plot(np.arange(0,len(erreur_entrainement)),erreur_validation, label =\"Erreurs sur les validations\")\n",
        "plt.legend()\n",
        "\n",
        "plt.title(\"Evolution de l'erreur en fonction de la période\")"
      ],
      "execution_count": 335,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, \"Evolution de l'erreur en fonction de la période\")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 335
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uEuSDQ6vZnBm",
        "outputId": "d663ba72-ca26-42ee-8e1a-8a595d40d8b4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Evaluation du modèle\n",
        "\n",
        "model.evaluate(dataset)\n",
        "#model.evaluate(dataset_val)\n"
      ],
      "execution_count": 353,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4/4 [==============================] - 0s 12ms/step - loss: 0.0035 - mse: 0.0035\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.0035034799948334694, 0.0035034799948334694]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 353
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lbzro22hgt4b"
      },
      "source": [
        "**3. Prédictions**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wMmVn1e5zEAm",
        "outputId": "ee39e397-353d-470e-dc80-ecbc8bebe21e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 728
        }
      },
      "source": [
        "# Création des instants d'entrainement et de validation\n",
        "y_train_timing = serie_entrainement.index[taille_fenetre + horizon - 1:taille_fenetre + horizon - 1+len(y_train)]\n",
        "y_val_timing = serie_test.index[taille_fenetre + horizon - 1:taille_fenetre + horizon - 1+len(y_val)]\n",
        "\n",
        "# Calcul des prédictions\n",
        "pred_ent = model.predict(x_train, verbose=1)\n",
        "pred_val = model.predict(x_val, verbose=1)"
      ],
      "execution_count": 354,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "8/8 [==============================] - 0s 3ms/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-354-6e28f18428f0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Calcul des prédictions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mpred_ent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mpred_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1627\u001b[0m           \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1628\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_predict_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1629\u001b[0;31m             \u001b[0mtmp_batch_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1630\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1631\u001b[0m               \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    860\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 862\u001b[0;31m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    863\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_variables\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    864\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2939\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2940\u001b[0m       (graph_function,\n\u001b[0;32m-> 2941\u001b[0;31m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0m\u001b[1;32m   2942\u001b[0m     return graph_function._call_flat(\n\u001b[1;32m   2943\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3356\u001b[0m               call_context_key in self._function_cache.missed):\n\u001b[1;32m   3357\u001b[0m             return self._define_function_with_shape_relaxation(\n\u001b[0;32m-> 3358\u001b[0;31m                 args, kwargs, flat_args, filtered_flat_args, cache_key_context)\n\u001b[0m\u001b[1;32m   3359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3360\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_define_function_with_shape_relaxation\u001b[0;34m(self, args, kwargs, flat_args, filtered_flat_args, cache_key_context)\u001b[0m\n\u001b[1;32m   3278\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3279\u001b[0m     graph_function = self._create_graph_function(\n\u001b[0;32m-> 3280\u001b[0;31m         args, kwargs, override_flat_arg_shapes=relaxed_arg_shapes)\n\u001b[0m\u001b[1;32m   3281\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marg_relaxed\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrank_only_cache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3282\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3204\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3205\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3206\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   3207\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3208\u001b[0m         \u001b[0mfunction_spec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_spec\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    988\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    989\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 990\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    991\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    992\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    632\u001b[0m             \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 634\u001b[0;31m           \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    635\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    975\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    976\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 977\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    978\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    979\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1478 predict_function  *\n        return step_function(self, iterator)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1468 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_lib.py:1259 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_lib.py:2730 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_lib.py:3417 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1461 run_step  **\n        outputs = model.predict_step(data)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1434 predict_step\n        return self(x, training=False)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer.py:998 __call__\n        input_spec.assert_input_compatibility(self.input_spec, inputs, self.name)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/input_spec.py:274 assert_input_compatibility\n        ', found shape=' + display_shape(x.shape))\n\n    ValueError: Input 0 is incompatible with layer model_64: expected shape=(None, 100, 1), found shape=(None, 10, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NvAclrEVLW97"
      },
      "source": [
        "from statsmodels.tsa.statespace.tools import diff\n",
        "\n",
        "predictions=[]\n",
        "\n",
        "for t in range(0,serie_entrainement.size-taille_fenetre):\n",
        "  data_to_predict = serie_entrainement[t:t+taille_fenetre]\n",
        "\n",
        "  data_to_predict = tf.expand_dims(data_to_predict,axis=1)\n",
        "  data_to_predict = tf.expand_dims(data_to_predict,axis=0)\n",
        "  pred = model.predict(data_to_predict)\n",
        "  predictions.append(pred[0])"
      ],
      "execution_count": 379,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TACq-1J4MNRy",
        "outputId": "bf720fdc-299d-49c9-a004-722779a0b690",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        }
      },
      "source": [
        "import plotly.graph_objects as go\n",
        "\n",
        "fig = go.Figure()\n",
        "\n",
        "tmax = len(np.asarray(predictions)[:,0])\n",
        "\n",
        "# Courbes des prédictions d'entrainement\n",
        "#fig.add_trace(go.Scatter(x=serie_etude.index,y=data_to_predict[:,:,0][0],line=dict(color='green', width=1),name=\"data_to_predict\"))\n",
        "fig.add_trace(go.Scatter(x=df_paris.index[taille_fenetre:taille_fenetre+tmax],y=np.asarray(predictions)[:,0],line=dict(color='red', width=1),name=\"prediction\"))\n",
        "\n",
        "fig.add_trace(go.Scatter(x=df_paris.index[taille_fenetre:taille_fenetre+tmax],y=serie_entrainement[taille_fenetre:taille_fenetre+tmax],line=dict(color='black', width=1),name=\"true\"))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "fig.update_xaxes(rangeslider_visible=True)\n",
        "yaxis=dict(autorange = True,fixedrange= False)\n",
        "fig.update_yaxes(yaxis)\n",
        "fig.show()"
      ],
      "execution_count": 380,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>\n",
              "            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>\n",
              "                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-latest.min.js\"></script>    \n",
              "            <div id=\"bc0f24b5-4d4a-4287-83e2-608ccadb9de7\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>\n",
              "            <script type=\"text/javascript\">\n",
              "                \n",
              "                    window.PLOTLYENV=window.PLOTLYENV || {};\n",
              "                    \n",
              "                if (document.getElementById(\"bc0f24b5-4d4a-4287-83e2-608ccadb9de7\")) {\n",
              "                    Plotly.newPlot(\n",
              "                        'bc0f24b5-4d4a-4287-83e2-608ccadb9de7',\n",
              "                        [{\"line\": {\"color\": \"red\", \"width\": 1}, \"name\": \"prediction\", \"type\": \"scatter\", \"x\": [\"2020-10-04T00:00:00\", \"2020-10-05T00:00:00\", \"2020-10-06T00:00:00\", \"2020-10-07T00:00:00\", \"2020-10-08T00:00:00\", \"2020-10-09T00:00:00\", \"2020-10-10T00:00:00\", \"2020-10-11T00:00:00\", \"2020-10-12T00:00:00\", \"2020-10-13T00:00:00\", \"2020-10-14T00:00:00\", \"2020-10-15T00:00:00\", \"2020-10-16T00:00:00\", \"2020-10-17T00:00:00\", \"2020-10-18T00:00:00\", \"2020-10-19T00:00:00\", \"2020-10-20T00:00:00\", \"2020-10-21T00:00:00\", \"2020-10-22T00:00:00\", \"2020-10-23T00:00:00\", \"2020-10-24T00:00:00\", \"2020-10-25T00:00:00\", \"2020-10-26T00:00:00\", \"2020-10-27T00:00:00\", \"2020-10-28T00:00:00\", \"2020-10-29T00:00:00\", \"2020-10-30T00:00:00\", \"2020-10-31T00:00:00\", \"2020-11-01T00:00:00\", \"2020-11-02T00:00:00\", \"2020-11-03T00:00:00\", \"2020-11-04T00:00:00\", \"2020-11-05T00:00:00\", \"2020-11-06T00:00:00\", \"2020-11-07T00:00:00\", \"2020-11-08T00:00:00\", \"2020-11-09T00:00:00\", \"2020-11-10T00:00:00\", \"2020-11-11T00:00:00\", \"2020-11-12T00:00:00\", \"2020-11-13T00:00:00\", \"2020-11-14T00:00:00\", \"2020-11-15T00:00:00\", \"2020-11-16T00:00:00\", \"2020-11-17T00:00:00\", \"2020-11-18T00:00:00\", \"2020-11-19T00:00:00\", \"2020-11-20T00:00:00\", \"2020-11-21T00:00:00\", \"2020-11-22T00:00:00\", \"2020-11-23T00:00:00\", \"2020-11-24T00:00:00\", \"2020-11-25T00:00:00\", \"2020-11-26T00:00:00\", \"2020-11-27T00:00:00\", \"2020-11-28T00:00:00\", \"2020-11-29T00:00:00\", \"2020-11-30T00:00:00\", \"2020-12-01T00:00:00\", \"2020-12-02T00:00:00\", \"2020-12-03T00:00:00\", \"2020-12-04T00:00:00\", \"2020-12-05T00:00:00\", \"2020-12-06T00:00:00\", \"2020-12-07T00:00:00\", \"2020-12-08T00:00:00\", \"2020-12-09T00:00:00\", \"2020-12-10T00:00:00\", \"2020-12-11T00:00:00\", \"2020-12-12T00:00:00\", \"2020-12-13T00:00:00\", \"2020-12-14T00:00:00\", \"2020-12-15T00:00:00\", \"2020-12-16T00:00:00\", \"2020-12-17T00:00:00\", \"2020-12-18T00:00:00\", \"2020-12-19T00:00:00\", \"2020-12-20T00:00:00\", \"2020-12-21T00:00:00\", \"2020-12-22T00:00:00\", \"2020-12-23T00:00:00\", \"2020-12-24T00:00:00\", \"2020-12-25T00:00:00\", \"2020-12-26T00:00:00\", \"2020-12-27T00:00:00\", \"2020-12-28T00:00:00\", \"2020-12-29T00:00:00\", \"2020-12-30T00:00:00\", \"2020-12-31T00:00:00\", \"2021-01-01T00:00:00\", \"2021-01-02T00:00:00\", \"2021-01-03T00:00:00\", \"2021-01-04T00:00:00\", \"2021-01-05T00:00:00\", \"2021-01-06T00:00:00\", \"2021-01-07T00:00:00\", \"2021-01-08T00:00:00\", \"2021-01-09T00:00:00\", \"2021-01-10T00:00:00\", \"2021-01-11T00:00:00\", \"2021-01-12T00:00:00\", \"2021-01-13T00:00:00\", \"2021-01-14T00:00:00\", \"2021-01-15T00:00:00\", \"2021-01-16T00:00:00\", \"2021-01-17T00:00:00\", \"2021-01-18T00:00:00\", \"2021-01-19T00:00:00\", \"2021-01-20T00:00:00\", \"2021-01-21T00:00:00\", \"2021-01-22T00:00:00\", \"2021-01-23T00:00:00\", \"2021-01-24T00:00:00\", \"2021-01-25T00:00:00\", \"2021-01-26T00:00:00\", \"2021-01-27T00:00:00\", \"2021-01-28T00:00:00\", \"2021-01-29T00:00:00\", \"2021-01-30T00:00:00\", \"2021-01-31T00:00:00\", \"2021-02-01T00:00:00\", \"2021-02-02T00:00:00\", \"2021-02-03T00:00:00\", \"2021-02-04T00:00:00\", \"2021-02-05T00:00:00\", \"2021-02-06T00:00:00\", \"2021-02-07T00:00:00\", \"2021-02-08T00:00:00\", \"2021-02-09T00:00:00\", \"2021-02-10T00:00:00\", \"2021-02-11T00:00:00\", \"2021-02-12T00:00:00\", \"2021-02-13T00:00:00\", \"2021-02-14T00:00:00\", \"2021-02-15T00:00:00\", \"2021-02-16T00:00:00\", \"2021-02-17T00:00:00\", \"2021-02-18T00:00:00\", \"2021-02-19T00:00:00\", \"2021-02-20T00:00:00\", \"2021-02-21T00:00:00\", \"2021-02-22T00:00:00\", \"2021-02-23T00:00:00\", \"2021-02-24T00:00:00\", \"2021-02-25T00:00:00\", \"2021-02-26T00:00:00\", \"2021-02-27T00:00:00\", \"2021-02-28T00:00:00\", \"2021-03-01T00:00:00\", \"2021-03-02T00:00:00\", \"2021-03-03T00:00:00\", \"2021-03-04T00:00:00\", \"2021-03-05T00:00:00\", \"2021-03-06T00:00:00\", \"2021-03-07T00:00:00\", \"2021-03-08T00:00:00\", \"2021-03-09T00:00:00\", \"2021-03-10T00:00:00\", \"2021-03-11T00:00:00\", \"2021-03-12T00:00:00\"], \"y\": [-0.00406038761138916, 0.017331577837467194, 0.05502094328403473, 0.104703888297081, 0.13701970875263214, 0.15299926698207855, 0.19639526307582855, 0.2646244168281555, 0.3205902576446533, 0.37525123357772827, 0.41660618782043457, 0.44638997316360474, 0.45268476009368896, 0.4906826615333557, 0.5096200108528137, 0.5787343382835388, 0.652981162071228, 0.745015561580658, 0.7998856902122498, 0.8087926506996155, 0.8633089661598206, 0.932863712310791, 0.9815367460250854, 1.0459014177322388, 1.068482518196106, 1.0683029890060425, 1.0565274953842163, 0.776060938835144, 0.7205890417098999, 0.6870537996292114, 0.6042149066925049, 0.5406748056411743, 0.5179622173309326, 0.5200525522232056, 0.7669653296470642, 0.7347778677940369, 0.6922093033790588, 0.6592622399330139, 0.5953173041343689, 0.5546379685401917, 0.5354288220405579, 0.5065460205078125, 0.24577678740024567, -0.10578632354736328, -0.4689415693283081, -0.8050351738929749, -0.8893910646438599, -0.8721961975097656, -0.8165737390518188, -0.7445822358131409, -0.6961832046508789, -0.6676257252693176, -0.6665926575660706, -0.6796217560768127, -0.6988463997840881, -0.720096230506897, -0.7414162755012512, -0.7620668411254883, -0.781907320022583, -0.8010490536689758, -0.8196753263473511, -0.8379608392715454, -0.8560425639152527, -0.8740158677101135, -0.8919403553009033, -0.8953893184661865, -0.8936276435852051, -0.8920588493347168, -0.8910467624664307, -0.8857382535934448, -0.8793281316757202, -0.8756604790687561, -0.877840518951416, -0.8784503936767578, -0.878081738948822, -0.8780171871185303, -0.8815773725509644, -0.8864145278930664, -0.8917503356933594, -0.8941450715065002, -0.8954415321350098, -0.8958297967910767, -0.8954100012779236, -0.8946658372879028, -0.8938047885894775, -0.8942822217941284, -0.8949939012527466, -0.89579176902771, -0.8957525491714478, -0.8957128524780273, -0.8974344730377197, -0.8991429805755615, -0.9003870487213135, -0.8974353671073914, -0.8963294625282288, -0.8971647024154663, -0.8976458311080933, -0.897895336151123, -0.8971296548843384, -0.8950021862983704, -0.8957224488258362, -0.896592378616333, -0.8953230381011963, -0.8951089382171631, -0.8928658366203308, -0.8887185454368591, -0.8880820274353027, -0.8875245451927185, -0.8851537704467773, -0.8832026720046997, -0.8823598623275757, -0.8816323280334473, -0.8822160959243774, -0.8821300268173218, -0.8842665553092957, -0.8874876499176025, -0.8911558389663696, -0.8927910327911377, -0.895118236541748, -0.8974015712738037, -0.8983474373817444, -0.8973301649093628, -0.8967162370681763, -0.8968279957771301, -0.8964771032333374, -0.8972110748291016, -0.8997799158096313, -0.9010494947433472, -0.90288245677948, -0.9024303555488586, -0.9003725051879883, -0.899761974811554, -0.8982112407684326, -0.8931608200073242, -0.8899059295654297, -0.8858963251113892, -0.8776047229766846, -0.8746711611747742, -0.8727561831474304, -0.8677387237548828, -0.8654868602752686, -0.8637569546699524, -0.8582702875137329, -0.8574737310409546, -0.8559858798980713, -0.8553682565689087, -0.8569172620773315, -0.8559459447860718, -0.8540999293327332, -0.8540397882461548, -0.8575688600540161, -0.8579576015472412, -0.8584374189376831, -0.8528355956077576, -0.8513387441635132, -0.8485430479049683, -0.8468495607376099, -0.8390769958496094, -0.8385196328163147, -0.8390248417854309]}, {\"line\": {\"color\": \"black\", \"width\": 1}, \"name\": \"true\", \"type\": \"scatter\", \"x\": [\"2020-10-04T00:00:00\", \"2020-10-05T00:00:00\", \"2020-10-06T00:00:00\", \"2020-10-07T00:00:00\", \"2020-10-08T00:00:00\", \"2020-10-09T00:00:00\", \"2020-10-10T00:00:00\", \"2020-10-11T00:00:00\", \"2020-10-12T00:00:00\", \"2020-10-13T00:00:00\", \"2020-10-14T00:00:00\", \"2020-10-15T00:00:00\", \"2020-10-16T00:00:00\", \"2020-10-17T00:00:00\", \"2020-10-18T00:00:00\", \"2020-10-19T00:00:00\", \"2020-10-20T00:00:00\", \"2020-10-21T00:00:00\", \"2020-10-22T00:00:00\", \"2020-10-23T00:00:00\", \"2020-10-24T00:00:00\", \"2020-10-25T00:00:00\", \"2020-10-26T00:00:00\", \"2020-10-27T00:00:00\", \"2020-10-28T00:00:00\", \"2020-10-29T00:00:00\", \"2020-10-30T00:00:00\", \"2020-10-31T00:00:00\", \"2020-11-01T00:00:00\", \"2020-11-02T00:00:00\", \"2020-11-03T00:00:00\", \"2020-11-04T00:00:00\", \"2020-11-05T00:00:00\", \"2020-11-06T00:00:00\", \"2020-11-07T00:00:00\", \"2020-11-08T00:00:00\", \"2020-11-09T00:00:00\", \"2020-11-10T00:00:00\", \"2020-11-11T00:00:00\", \"2020-11-12T00:00:00\", \"2020-11-13T00:00:00\", \"2020-11-14T00:00:00\", \"2020-11-15T00:00:00\", \"2020-11-16T00:00:00\", \"2020-11-17T00:00:00\", \"2020-11-18T00:00:00\", \"2020-11-19T00:00:00\", \"2020-11-20T00:00:00\", \"2020-11-21T00:00:00\", \"2020-11-22T00:00:00\", \"2020-11-23T00:00:00\", \"2020-11-24T00:00:00\", \"2020-11-25T00:00:00\", \"2020-11-26T00:00:00\", \"2020-11-27T00:00:00\", \"2020-11-28T00:00:00\", \"2020-11-29T00:00:00\", \"2020-11-30T00:00:00\", \"2020-12-01T00:00:00\", \"2020-12-02T00:00:00\", \"2020-12-03T00:00:00\", \"2020-12-04T00:00:00\", \"2020-12-05T00:00:00\", \"2020-12-06T00:00:00\", \"2020-12-07T00:00:00\", \"2020-12-08T00:00:00\", \"2020-12-09T00:00:00\", \"2020-12-10T00:00:00\", \"2020-12-11T00:00:00\", \"2020-12-12T00:00:00\", \"2020-12-13T00:00:00\", \"2020-12-14T00:00:00\", \"2020-12-15T00:00:00\", \"2020-12-16T00:00:00\", \"2020-12-17T00:00:00\", \"2020-12-18T00:00:00\", \"2020-12-19T00:00:00\", \"2020-12-20T00:00:00\", \"2020-12-21T00:00:00\", \"2020-12-22T00:00:00\", \"2020-12-23T00:00:00\", \"2020-12-24T00:00:00\", \"2020-12-25T00:00:00\", \"2020-12-26T00:00:00\", \"2020-12-27T00:00:00\", \"2020-12-28T00:00:00\", \"2020-12-29T00:00:00\", \"2020-12-30T00:00:00\", \"2020-12-31T00:00:00\", \"2021-01-01T00:00:00\", \"2021-01-02T00:00:00\", \"2021-01-03T00:00:00\", \"2021-01-04T00:00:00\", \"2021-01-05T00:00:00\", \"2021-01-06T00:00:00\", \"2021-01-07T00:00:00\", \"2021-01-08T00:00:00\", \"2021-01-09T00:00:00\", \"2021-01-10T00:00:00\", \"2021-01-11T00:00:00\", \"2021-01-12T00:00:00\", \"2021-01-13T00:00:00\", \"2021-01-14T00:00:00\", \"2021-01-15T00:00:00\", \"2021-01-16T00:00:00\", \"2021-01-17T00:00:00\", \"2021-01-18T00:00:00\", \"2021-01-19T00:00:00\", \"2021-01-20T00:00:00\", \"2021-01-21T00:00:00\", \"2021-01-22T00:00:00\", \"2021-01-23T00:00:00\", \"2021-01-24T00:00:00\", \"2021-01-25T00:00:00\", \"2021-01-26T00:00:00\", \"2021-01-27T00:00:00\", \"2021-01-28T00:00:00\", \"2021-01-29T00:00:00\", \"2021-01-30T00:00:00\", \"2021-01-31T00:00:00\", \"2021-02-01T00:00:00\", \"2021-02-02T00:00:00\", \"2021-02-03T00:00:00\", \"2021-02-04T00:00:00\", \"2021-02-05T00:00:00\", \"2021-02-06T00:00:00\", \"2021-02-07T00:00:00\", \"2021-02-08T00:00:00\", \"2021-02-09T00:00:00\", \"2021-02-10T00:00:00\", \"2021-02-11T00:00:00\", \"2021-02-12T00:00:00\", \"2021-02-13T00:00:00\", \"2021-02-14T00:00:00\", \"2021-02-15T00:00:00\", \"2021-02-16T00:00:00\", \"2021-02-17T00:00:00\", \"2021-02-18T00:00:00\", \"2021-02-19T00:00:00\", \"2021-02-20T00:00:00\", \"2021-02-21T00:00:00\", \"2021-02-22T00:00:00\", \"2021-02-23T00:00:00\", \"2021-02-24T00:00:00\", \"2021-02-25T00:00:00\", \"2021-02-26T00:00:00\", \"2021-02-27T00:00:00\", \"2021-02-28T00:00:00\", \"2021-03-01T00:00:00\", \"2021-03-02T00:00:00\", \"2021-03-03T00:00:00\", \"2021-03-04T00:00:00\", \"2021-03-05T00:00:00\", \"2021-03-06T00:00:00\", \"2021-03-07T00:00:00\", \"2021-03-08T00:00:00\", \"2021-03-09T00:00:00\", \"2021-03-10T00:00:00\", \"2021-03-11T00:00:00\", \"2021-03-12T00:00:00\"], \"y\": [-0.0202088603086986, 0.01978447555162034, 0.06736959849212389, 0.08553034405648706, 0.0938168044642702, 0.14973800733595688, 0.22223213102320985, 0.26450796495992424, 0.31511987882782155, 0.34985354520775114, 0.37783895640529436, 0.3808161278092884, 0.4397641216083689, 0.4525659586455429, 0.5455033259735546, 0.6165088639588107, 0.7131676955418148, 0.7524167385511351, 0.7539549437765319, 0.8460983987301451, 0.9306996861269737, 0.9790291019184758, 1.0651189750173014, 1.0824858082072661, 1.0931043862148446, 1.0983640556952339, 0.7252748592513902, 0.8271933603147834, 0.8045668576444293, 0.6995719461302423, 0.6504982374877418, 0.6429064504075571, 0.6444446556329539, 0.9707426415106924, 0.776631065970286, 0.7479013619217444, 0.7343056125101719, 0.6678650706777066, 0.6474714465603479, 0.6383910737781664, 0.6021192021728399, 0.2578961634668877, -0.08632687523906452, -0.43054991394501674, -0.7747729526509689, -0.7558679142356073, -0.7445546629004304, -0.7226724530810745, -0.6810912924719589, -0.6728048320641757, -0.6674955430603864, -0.685740260125888, -0.7039849771913895, -0.7222296942568909, -0.7404744113223924, -0.7587191283878939, -0.7769638454533954, -0.7952085625188968, -0.8134532795843983, -0.8316979966498999, -0.8499427137154012, -0.8681874307809028, -0.8864321478464042, -0.9046768649119057, -0.8978789902061194, -0.8941079064277271, -0.8941079064277271, -0.8941079064277271, -0.885771826496544, -0.8789739517907578, -0.8774853660887608, -0.8835389479435486, -0.8820007427181517, -0.8805121570161546, -0.8805121570161546, -0.8865657388709424, -0.8918254083513317, -0.8971346973551211, -0.8971346973551211, -0.8978789902061194, -0.8978789902061194, -0.8971346973551211, -0.8963904045041226, -0.8955964921297241, -0.8971346973551211, -0.8978789902061194, -0.8986232830571179, -0.8978789902061194, -0.8978789902061194, -0.9009057811335134, -0.9023943668355102, -0.9031882792099087, -0.8971346973551211, -0.8978789902061194, -0.9001614882825149, -0.9001614882825149, -0.9001614882825149, -0.8986232830571179, -0.8955964921297241, -0.8986232830571179, -0.8993675759081164, -0.8963904045041226, -0.8971346973551211, -0.8933636135767286, -0.8880543245729394, -0.8903368226493348, -0.8895925297983363, -0.885771826496544, -0.8842832407945471, -0.8842832407945471, -0.8835389479435486, -0.8850275336455454, -0.8842832407945471, -0.8880543245729394, -0.8918254083513317, -0.8955964921297241, -0.8955964921297241, -0.8986232830571179, -0.9009057811335134, -0.9009057811335134, -0.8986232830571179, -0.8986232830571179, -0.8993675759081164, -0.8986232830571179, -0.9001614882825149, -0.9039325720609072, -0.9039325720609072, -0.9061654506139027, -0.9039325720609072, -0.9009057811335134, -0.9016500739845119, -0.8993675759081164, -0.8918254083513317, -0.8903368226493348, -0.885771826496544, -0.8744585751613669, -0.8759967803867638, -0.8744585751613669, -0.8669164076045823, -0.8669164076045823, -0.8653782023791854, -0.8570917419714021, -0.860118532898796, -0.8578360348224007, -0.8578360348224007, -0.8608628257497946, -0.8578360348224007, -0.8556031562694052, -0.8570917419714021, -0.8631453238261898, -0.8608628257497946, -0.861607118600793, -0.8517824529676129, -0.8540649510440083, -0.8502938672656158, -0.8495495744146174, -0.837442410705042, -0.8427516997088312, -0.8434959925598298, -0.8381867035560404]}],\n",
              "                        {\"template\": {\"data\": {\"bar\": [{\"error_x\": {\"color\": \"#2a3f5f\"}, \"error_y\": {\"color\": \"#2a3f5f\"}, \"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"bar\"}], \"barpolar\": [{\"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"barpolar\"}], \"carpet\": [{\"aaxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"baxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"type\": \"carpet\"}], \"choropleth\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"choropleth\"}], \"contour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"contour\"}], \"contourcarpet\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"contourcarpet\"}], \"heatmap\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmap\"}], \"heatmapgl\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmapgl\"}], \"histogram\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"histogram\"}], \"histogram2d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2d\"}], \"histogram2dcontour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2dcontour\"}], \"mesh3d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"mesh3d\"}], \"parcoords\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"parcoords\"}], \"pie\": [{\"automargin\": true, \"type\": \"pie\"}], \"scatter\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter\"}], \"scatter3d\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter3d\"}], \"scattercarpet\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattercarpet\"}], \"scattergeo\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergeo\"}], \"scattergl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergl\"}], \"scattermapbox\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattermapbox\"}], \"scatterpolar\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolar\"}], \"scatterpolargl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolargl\"}], \"scatterternary\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterternary\"}], \"surface\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"surface\"}], \"table\": [{\"cells\": {\"fill\": {\"color\": \"#EBF0F8\"}, \"line\": {\"color\": \"white\"}}, \"header\": {\"fill\": {\"color\": \"#C8D4E3\"}, \"line\": {\"color\": \"white\"}}, \"type\": \"table\"}]}, \"layout\": {\"annotationdefaults\": {\"arrowcolor\": \"#2a3f5f\", \"arrowhead\": 0, \"arrowwidth\": 1}, \"coloraxis\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"colorscale\": {\"diverging\": [[0, \"#8e0152\"], [0.1, \"#c51b7d\"], [0.2, \"#de77ae\"], [0.3, \"#f1b6da\"], [0.4, \"#fde0ef\"], [0.5, \"#f7f7f7\"], [0.6, \"#e6f5d0\"], [0.7, \"#b8e186\"], [0.8, \"#7fbc41\"], [0.9, \"#4d9221\"], [1, \"#276419\"]], \"sequential\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"sequentialminus\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}, \"colorway\": [\"#636efa\", \"#EF553B\", \"#00cc96\", \"#ab63fa\", \"#FFA15A\", \"#19d3f3\", \"#FF6692\", \"#B6E880\", \"#FF97FF\", \"#FECB52\"], \"font\": {\"color\": \"#2a3f5f\"}, \"geo\": {\"bgcolor\": \"white\", \"lakecolor\": \"white\", \"landcolor\": \"#E5ECF6\", \"showlakes\": true, \"showland\": true, \"subunitcolor\": \"white\"}, \"hoverlabel\": {\"align\": \"left\"}, \"hovermode\": \"closest\", \"mapbox\": {\"style\": \"light\"}, \"paper_bgcolor\": \"white\", \"plot_bgcolor\": \"#E5ECF6\", \"polar\": {\"angularaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"radialaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"scene\": {\"xaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"yaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"zaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}}, \"shapedefaults\": {\"line\": {\"color\": \"#2a3f5f\"}}, \"ternary\": {\"aaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"baxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"caxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"title\": {\"x\": 0.05}, \"xaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}, \"yaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}}}, \"xaxis\": {\"rangeslider\": {\"visible\": true}}, \"yaxis\": {\"autorange\": true, \"fixedrange\": false}},\n",
              "                        {\"responsive\": true}\n",
              "                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('bc0f24b5-4d4a-4287-83e2-608ccadb9de7');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })\n",
              "                };\n",
              "                \n",
              "            </script>\n",
              "        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fsT_RRS6iFhA"
      },
      "source": [
        "**4.Affichage sur une période de 1 heure**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hoGhoCJWHOuj"
      },
      "source": [
        "Création d'une série contenant les valeurs originales et les prédictions, synchronisées dans le temps :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mBWDeZVBfynP"
      },
      "source": [
        "serie_btc_ent_ori = serie_entrainement*std+mean\n",
        "serie_btc_val_ori = serie_test*std+mean\n",
        "\n",
        "serie_btc_ent_pred = pd.Series(data=(pred_ent[:,0]*std+mean),index=y_train_timing)\n",
        "serie_btc_val_pred = pd.Series(data=(pred_val[:,0]*std+mean),index=y_val_timing)\n",
        "\n",
        "serie_btc_ori = pd.concat([serie_btc_ent_ori,serie_btc_val_ori])\n",
        "serie_btc_pred = pd.concat([serie_btc_ent_pred,serie_btc_val_pred])\n",
        "\n",
        "serie_btc_ori = serie_btc_ori.fillna(method=\"backfill\")\n",
        "serie_btc_pred = serie_btc_pred.fillna(method=\"backfill\")\n",
        "\n",
        "serie_btc_ent_ori = serie_btc_ent_ori.fillna(method=\"backfill\")\n",
        "serie_btc_val_ori = serie_btc_val_ori.fillna(method=\"backfill\")\n",
        "serie_btc_ent_pred = serie_btc_ent_pred.fillna(method=\"backfill\")\n",
        "serie_btc_val_pred = serie_btc_val_pred.fillna(method=\"backfill\")\n",
        "\n",
        "frame = {'BTC_ALL' : serie_btc_ori, 'BTC_ENT': serie_btc_ent_ori, 'BTC_VAL' : serie_btc_val_ori, 'BTC_PRED' : serie_btc_pred, 'BTC_PRED_ENT' : serie_btc_ent_pred, 'BTC_PRED_VAL':serie_btc_val_pred}\n",
        "df_resultats = pd.DataFrame(frame)\n",
        "df_resultats"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5pFnvAVy-3lM"
      },
      "source": [
        "import plotly.graph_objects as go\n",
        "\n",
        "fig = go.Figure()\n",
        "\n",
        "# Courbe originale\n",
        "fig.add_trace(go.Scatter(x=df_resultats.index,y=df_resultats['BTC_ALL'],line=dict(color='blue', width=1),name=\"Prix BTC\"))\n",
        "\n",
        "# Courbes des prédictions d'entrainement\n",
        "fig.add_trace(go.Scatter(x=df_resultats.index,y=df_resultats['BTC_PRED_ENT'],line=dict(color='green', width=1),name=\"Entrainement\"))\n",
        "\n",
        "# Courbe de validation\n",
        "fig.add_trace(go.Scatter(x=df_resultats.index,y=df_resultats['BTC_PRED_VAL'],line=dict(color='red', width=1),name=\"Validation\"))\n",
        "\n",
        "fig.update_xaxes(rangeslider_visible=True)\n",
        "yaxis=dict(autorange = True,fixedrange= False)\n",
        "fig.update_yaxes(yaxis)\n",
        "fig.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kNUg-0NAR0gv"
      },
      "source": [
        "serie_etude"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V0SkDEbHS2my"
      },
      "source": [
        "from scipy.special import inv_boxcox"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Nv-2zsjTTJ6"
      },
      "source": [
        "from scipy.integrate import cumtrapz\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def f(x):\n",
        "    return serie_etude['Open'][0:taille_fenetre+1]\n",
        "\n",
        "f = np.vectorize(f)\n",
        "\n",
        "X = np.linspace(0,taille_fenetre+1,taille_fenetre+2)\n",
        "\n",
        "fv = f(X)\n",
        "plt.plot(fv)\n",
        "\n",
        "F = cumtrapz(fv, x=X, initial=0)\n",
        "plt.plot(F);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3_C5qDpsRkrP"
      },
      "source": [
        "from statsmodels.tsa.statespace.tools import diff\n",
        "\n",
        "predictions=[]\n",
        "\n",
        "for t in range(0,200):\n",
        "  data_to_predict = serie_etude['Open'][t:t+taille_fenetre+1]\n",
        "  data_to_predict = boxcox(data_to_predict,lam)\n",
        "  data_to_predict = data_to_predict - trend[t:t+taille_fenetre+1]\n",
        "  data_to_predict = diff(data_to_predict,1)\n",
        "  data_to_predict = np.insert(data_to_predict,0,0)\n",
        "\n",
        "  data_to_predict = tf.expand_dims(data_to_predict,axis=1)\n",
        "  data_to_predict = tf.expand_dims(data_to_predict,axis=0)\n",
        "  pred = model.predict(data_to_predict[:,1:,:])\n",
        "  predictions.append(pred[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Zp30SLWZ7cG"
      },
      "source": [
        "np.asarray(predictions)[:,0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OP2cvVBUW36R"
      },
      "source": [
        "serie_etude.index[taille_fenetre+1:taille_fenetre+2]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7n75-EQyUfk8"
      },
      "source": [
        "import plotly.graph_objects as go\n",
        "\n",
        "fig = go.Figure()\n",
        "\n",
        "tmax = len(np.asarray(predictions)[:,0])\n",
        "\n",
        "# Courbe originale\n",
        "fig.add_trace(go.Scatter(x=serie_etude.index,y=serie_etude['diff'][0:taille_fenetre+1],line=dict(color='blue', width=1),name=\"diff_reel\"))\n",
        "\n",
        "# Courbes des prédictions d'entrainement\n",
        "#fig.add_trace(go.Scatter(x=serie_etude.index,y=data_to_predict[:,:,0][0],line=dict(color='green', width=1),name=\"data_to_predict\"))\n",
        "fig.add_trace(go.Scatter(x=serie_etude.index[taille_fenetre+1:taille_fenetre+1+tmax],y=np.asarray(predictions)[:,0],line=dict(color='red', width=1),name=\"prediction\"))\n",
        "\n",
        "fig.add_trace(go.Scatter(x=serie_etude.index[taille_fenetre+1:taille_fenetre+1+tmax],y=serie_etude['diff'][taille_fenetre+1:taille_fenetre+1+tmax],line=dict(color='black', width=1),name=\"true\"))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "fig.update_xaxes(rangeslider_visible=True)\n",
        "yaxis=dict(autorange = True,fixedrange= False)\n",
        "fig.update_yaxes(yaxis)\n",
        "fig.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T72zWjfGrtQu"
      },
      "source": [
        "# Création du modèle LSTM"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jr-AD-INrtQv"
      },
      "source": [
        "**1. Création du réseau**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ipNxd-RNrtQv"
      },
      "source": [
        "Par défaut, la dimension des vecteurs cachés est de 10 et aucune régularisation n'est utilisée."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "52Iv3nK0rtQ9"
      },
      "source": [
        "dim_LSTM = 40\n",
        "l1_reg = 0.0\n",
        "l2_reg = 0.0\n",
        "\n",
        "entrees = tf.keras.layers.Input(shape=(taille_fenetre,1))\n",
        "\n",
        "# Encodeur\n",
        "s_encodeur = tf.keras.layers.LSTM(dim_LSTM, kernel_regularizer=tf.keras.regularizers.l1_l2(l1=l1_reg,l2=l2_reg))(entrees)\n",
        "  \n",
        "# Générateur\n",
        "sortie = tf.keras.layers.Dense(1,kernel_regularizer=tf.keras.regularizers.l1_l2(l1=l1_reg,l2=l2_reg))(s_encodeur)\n",
        "\n",
        "# Construction du modèle\n",
        "model = tf.keras.Model(entrees,sortie)\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3qv4ZaPfrtQ-"
      },
      "source": [
        "**2. Optimisation de l'apprentissage**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TlrGDGQ-rtQ-"
      },
      "source": [
        "Pour accélérer le traitement des données, nous n'allons pas utiliser l'intégralité des données pendant la mise à jour du gradient, comme cela a été fait jusqu'à présent (en utilisant le dataset).  \n",
        "Cette fois-ci, nous allons forcer les mises à jour du gradient à se produire de manière moins fréquente en attribuant la valeur du batch_size à prendre en compte lors de la regression du modèle.  \n",
        "Pour cela, on utilise l'argument \"batch_size\" dans la méthode fit. En précisant un batch_size=1000, cela signifie que :\n",
        " - Sur notre total de 56000 échantillons, 56 seront utilisés pour les calculs du gradient\n",
        " - Il y aura également 56 itérations à chaque période.\n",
        "  \n",
        "    \n",
        "    \n",
        "Si nous avions pris le dataset comme entrée, nous aurions eu :\n",
        "- Un total de 56000 échantillons également\n",
        "- Chaque période aurait également pris 56 itérations pour se compléter\n",
        "- Mais 1000 échantillons auraient été utilisés pour le calcul du gradient, au lieu de 56 avec la méthode utilisée."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IOnTaeMSrtQ_"
      },
      "source": [
        "batch_size = 1000"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "APgK7pSyrtQ_"
      },
      "source": [
        "# Définition de la fonction de régulation du taux d'apprentissage\n",
        "def RegulationTauxApprentissage(periode, taux):\n",
        "  return 1e-8*10**(periode/10)\n",
        "\n",
        "# Définition de l'optimiseur à utiliser\n",
        "optimiseur=tf.keras.optimizers.Adam()\n",
        "\n",
        "# Compile le modèle\n",
        "model.compile(loss=\"logcosh\", optimizer=optimiseur, metrics=\"mse\")\n",
        "\n",
        "# Utilisation de la méthode ModelCheckPoint\n",
        "CheckPoint = tf.keras.callbacks.ModelCheckpoint(\"poids.hdf5\", monitor='loss', verbose=1, save_best_only=True, save_weights_only = True, mode='auto', save_freq='epoch')\n",
        "\n",
        "# Entraine le modèle en utilisant notre fonction personnelle de régulation du taux d'apprentissage\n",
        "historique = model.fit(x=x_train,y=y_train,epochs=100,verbose=1, callbacks=[tf.keras.callbacks.LearningRateScheduler(RegulationTauxApprentissage), CheckPoint],batch_size=batch_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oFX_PudkrtRA"
      },
      "source": [
        "# Construit un vecteur avec les valeurs du taux d'apprentissage à chaque période \n",
        "taux = 1e-8*(10**(np.arange(100)/10))\n",
        "\n",
        "# Affiche l'erreur en fonction du taux d'apprentissage\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.semilogx(taux,historique.history[\"loss\"])\n",
        "plt.axis([ taux[30], taux[99], 0, 0.04])\n",
        "plt.title(\"Evolution de l'erreur en fonction du taux d'apprentissage\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W8ptlq-JrtRA"
      },
      "source": [
        "# Chargement des poids sauvegardés\n",
        "model.load_weights(\"poids.hdf5\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OQ_TJVE_rtRB"
      },
      "source": [
        "max_periodes = 1000\n",
        "\n",
        "# Classe permettant d'arrêter l'entrainement si la variation\n",
        "# devient plus petite qu'une valeur à choisir sur un nombre\n",
        "# de périodes à choisir\n",
        "class StopTrain(keras.callbacks.Callback):\n",
        "    def __init__(self, delta=0.01,periodes=100, term=\"loss\", logs={}):\n",
        "      self.n_periodes = 0\n",
        "      self.periodes = periodes\n",
        "      self.loss_1 = 100\n",
        "      self.delta = delta\n",
        "      self.term = term\n",
        "    def on_epoch_end(self, epoch, logs={}):\n",
        "      diff_loss = abs(self.loss_1 - logs[self.term])\n",
        "      self.loss_1 = logs[self.term]\n",
        "      if (diff_loss < self.delta):\n",
        "        self.n_periodes = self.n_periodes + 1\n",
        "      else:\n",
        "        self.n_periodes = 0\n",
        "      if (self.n_periodes == self.periodes):\n",
        "        print(\"Arrêt de l'entrainement...\")\n",
        "        self.model.stop_training = True\n",
        "\n",
        "def  My_MSE(y_true,y_pred):\n",
        "  return(tf.keras.metrics.mse(y_true,y_pred)*std.numpy()+mean.numpy())\n",
        "  \n",
        "# Définition des paramètres liés à l'évolution du taux d'apprentissage\n",
        "lr_schedule = tf.keras.optimizers.schedules.InverseTimeDecay(\n",
        "    initial_learning_rate=0.02,\n",
        "    decay_steps=10,\n",
        "    decay_rate=0.01)\n",
        "\n",
        "# Définition de l'optimiseur à utiliser\n",
        "optimiseur=tf.keras.optimizers.Adam(learning_rate=lr_schedule)\n",
        "\n",
        "\n",
        "# Utilisation de la méthode ModelCheckPoint\n",
        "CheckPoint = tf.keras.callbacks.ModelCheckpoint(\"poids_train.hdf5\", monitor='loss', verbose=1, save_best_only=True, save_weights_only = True, mode='auto', save_freq='epoch')\n",
        "\n",
        "# Compile le modèle\n",
        "model.compile(loss=\"logcosh\", optimizer=optimiseur, metrics=[\"mse\",My_MSE])\n",
        "\n",
        "# Entraine le modèle, avec une réduction des calculs du gradient\n",
        "historique = model.fit(x=x_train,y=y_train,validation_data=(x_val,y_val), epochs=max_periodes,verbose=1, callbacks=[CheckPoint,StopTrain(delta=0.005,periodes = 10, term=\"My_MSE\")],batch_size=batch_size)\n",
        "\n",
        "# Entraine le modèle sans réduction de calculs\n",
        "#historique = model.fit(dataset,validation_data=dataset_val, epochs=max_periodes,verbose=1, callbacks=[CheckPoint,StopTrain(delta=0.1,periodes = 10, term=\"val_My_MSE\")])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G5ec3f0brtRC"
      },
      "source": [
        "erreur_entrainement = historique.history[\"loss\"]\n",
        "erreur_validation = historique.history[\"val_loss\"]\n",
        "\n",
        "# Affiche l'erreur en fonction de la période\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(np.arange(0,len(erreur_entrainement)),erreur_entrainement, label=\"Erreurs sur les entrainements\")\n",
        "plt.plot(np.arange(0,len(erreur_entrainement)),erreur_validation, label =\"Erreurs sur les validations\")\n",
        "plt.legend()\n",
        "\n",
        "plt.title(\"Evolution de l'erreur en fonction de la période\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ZFhBaeYrtRC"
      },
      "source": [
        "# Evaluation du modèle\n",
        "# Avec le modèle type encodeur/décodeur :\n",
        "# 56/56 [==============================] - 7s 113ms/step - loss: 1.1795e-04 - mse: 2.3664e-04 - My_MSE: 2712.2415\n",
        "# 14/14 [==============================] - 2s 113ms/step - loss: 0.3602 - mse: 1.9360 - My_MSE: 9650.2637\n",
        "model.evaluate(dataset)\n",
        "model.evaluate(dataset_val)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uy8gdKf3rtRC"
      },
      "source": [
        "**3. Prédictions**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iodlvc6frtRD"
      },
      "source": [
        "# Création des instants d'entrainement et de validation\n",
        "y_train_timing = serie_entrainement.index[taille_fenetre + horizon - 1:taille_fenetre + horizon - 1+len(y_train)]\n",
        "y_val_timing = serie_test.index[taille_fenetre + horizon - 1:taille_fenetre + horizon - 1+len(y_val)]\n",
        "\n",
        "# Calcul des prédictions\n",
        "pred_ent = model.predict(x_train, verbose=1)\n",
        "pred_val = model.predict(x_val, verbose=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T7URVy7qrtRD"
      },
      "source": [
        "**4.Affichage sur une période de 1 heure**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vqONHLBbrtRD"
      },
      "source": [
        "Création d'une série contenant les valeurs originales et les prédictions, synchronisées dans le temps :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wDgJ20qOrtRE"
      },
      "source": [
        "serie_btc_ent_ori = serie_entrainement*std+mean\n",
        "serie_btc_val_ori = serie_test*std+mean\n",
        "\n",
        "serie_btc_ent_pred = pd.Series(data=(pred_ent[:,0]*std+mean),index=y_train_timing)\n",
        "serie_btc_val_pred = pd.Series(data=(pred_val[:,0]*std+mean),index=y_val_timing)\n",
        "\n",
        "serie_btc_ori = pd.concat([serie_btc_ent_ori,serie_btc_val_ori])\n",
        "serie_btc_pred = pd.concat([serie_btc_ent_pred,serie_btc_val_pred])\n",
        "\n",
        "serie_btc_ori = serie_btc_ori.fillna(method=\"backfill\")\n",
        "serie_btc_pred = serie_btc_pred.fillna(method=\"backfill\")\n",
        "\n",
        "serie_btc_ent_ori = serie_btc_ent_ori.fillna(method=\"backfill\")\n",
        "serie_btc_val_ori = serie_btc_val_ori.fillna(method=\"backfill\")\n",
        "serie_btc_ent_pred = serie_btc_ent_pred.fillna(method=\"backfill\")\n",
        "serie_btc_val_pred = serie_btc_val_pred.fillna(method=\"backfill\")\n",
        "\n",
        "frame = {'BTC_ALL' : serie_btc_ori, 'BTC_ENT': serie_btc_ent_ori, 'BTC_VAL' : serie_btc_val_ori, 'BTC_PRED' : serie_btc_pred, 'BTC_PRED_ENT' : serie_btc_ent_pred, 'BTC_PRED_VAL':serie_btc_val_pred}\n",
        "df_resultats = pd.DataFrame(frame)\n",
        "df_resultats"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7W2aoMPBrtRE"
      },
      "source": [
        "date_separation"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kfObUyVjrtRF"
      },
      "source": [
        "df_resultats.loc[date_separation-pd.Timedelta(hours=7):date_separation+pd.Timedelta(hours=7)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wv1MZoxPrtRF"
      },
      "source": [
        "import plotly.graph_objects as go\n",
        "\n",
        "fig = go.Figure()\n",
        "\n",
        "# Courbe originale\n",
        "fig.add_trace(go.Scatter(x=df_resultats.index,y=df_resultats['BTC_ALL'],line=dict(color='blue', width=1),name=\"Prix BTC\"))\n",
        "\n",
        "# Courbes des prédictions d'entrainement\n",
        "fig.add_trace(go.Scatter(x=df_resultats.index,y=df_resultats['BTC_PRED_ENT'],line=dict(color='green', width=1),name=\"Entrainement\"))\n",
        "\n",
        "# Courbe de validation\n",
        "fig.add_trace(go.Scatter(x=df_resultats.index,y=df_resultats['BTC_PRED_VAL'],line=dict(color='red', width=1),name=\"Validation\"))\n",
        "\n",
        "fig.update_xaxes(rangeslider_visible=True)\n",
        "yaxis=dict(autorange = True,fixedrange= False)\n",
        "fig.update_yaxes(yaxis)\n",
        "fig.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Aq51_Kk6rtRK"
      },
      "source": [
        "**5. Détection de l'augmentation des erreurs dans la zone de validation**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I2-WtViDrtRK"
      },
      "source": [
        "On peut imaginer devoir suivre en temps réel l'évolution des prédictions afin de détecter lorsque le modèle n'est plus valide."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h6hb5UnZrtRK"
      },
      "source": [
        "# Détection de la date où commencent les anomalies\n",
        "# sur la période de validation\n",
        "\n",
        "# Construit les dataframe pour calculer les erreurs\n",
        "df_error_btc_ent = df_resultats[['BTC_ENT','BTC_PRED_ENT']].dropna()\n",
        "df_error_btc_val = df_resultats[['BTC_VAL','BTC_PRED_VAL']].dropna()\n",
        "\n",
        "# Calcul des erreurs relatives sur les entrainements et les validations\n",
        "erreur_ent = abs(np.asarray(df_error_btc_ent['BTC_ENT']) - np.asarray(df_error_btc_ent['BTC_PRED_ENT']))/np.asarray(df_error_btc_ent['BTC_ENT'])*100.0\n",
        "erreur_val = abs(np.asarray(df_error_btc_val['BTC_VAL']) - np.asarray(df_error_btc_val['BTC_PRED_VAL']))/np.asarray(df_error_btc_val['BTC_VAL'])*100.0\n",
        "\n",
        "# Erreur relative moyenne sur les entrainements\n",
        "erreur_ent_mape = tf.keras.metrics.mape(np.asarray(df_error_btc_ent['BTC_ENT']),np.asarray(df_error_btc_ent['BTC_PRED_ENT']))\n",
        "erreur_ent_mape_max = np.amax(erreur_ent)\n",
        "\n",
        "# Calcul le nombre d'anomalies sur les entrainements avec le ratio spécifié\n",
        "nbr_anomalies_ent = np.count_nonzero(erreur_ent>erreur_ent_mape)\n",
        "\n",
        "# Calcul du ratio d'anomalies sur la période d'entrainement\n",
        "ratio_ent = np.count_nonzero(erreur_ent>erreur_ent_mape)/erreur_ent.size\n",
        "\n",
        "# Recherche de la date à partir de laquelle on dépasse l\n",
        "n_erreurs = 0\n",
        "for i in range(5,erreur_val.size):\n",
        "  erreur_val_ = abs(np.asarray(df_error_btc_val['BTC_VAL'][i]) - np.asarray(df_error_btc_val['BTC_PRED_VAL'][i]))/np.asarray(df_error_btc_val['BTC_VAL'][i])*100.0\n",
        "  seuil = erreur_ent_mape_max*1\n",
        "  if erreur_val_ > seuil:\n",
        "    n_erreurs = n_erreurs + 1\n",
        "    if n_erreurs == 5:\n",
        "      index = df_error_btc_val.index[i]\n",
        "      break\n",
        "  else:\n",
        "    n_erreurs = 0\n",
        "print(index)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fBcqczT7rtRL"
      },
      "source": [
        "import plotly.graph_objects as go\n",
        "\n",
        "fig = go.Figure()\n",
        "\n",
        "# Courbe originale\n",
        "fig.add_trace(go.Scatter(x=df_resultats.index,y=df_resultats['BTC_ALL'],line=dict(color='blue', width=1),name=\"Prix BTC\"))\n",
        "\n",
        "# Courbes des prédictions d'entrainement\n",
        "fig.add_trace(go.Scatter(x=df_resultats.index,y=df_resultats['BTC_PRED_ENT'],line=dict(color='green', width=1),name=\"Entrainement\"))\n",
        "\n",
        "# Courbe de validation\n",
        "fig.add_trace(go.Scatter(x=df_resultats.index,y=df_resultats['BTC_PRED_VAL'],line=dict(color='red', width=1),name=\"Validation\"))\n",
        "\n",
        "# Délimite la zone d'erreur\n",
        "fig.add_shape(type=\"line\",x0=index,y0=0,x1=index,y1=np.amax(df_resultats['BTC_ALL']),name=\"Zone d'erreur\")\n",
        "\n",
        "# Affiche les courbes\n",
        "fig.update_xaxes(rangeslider_visible=True)\n",
        "yaxis=dict(autorange = True,fixedrange= False)\n",
        "fig.update_yaxes(yaxis)\n",
        "fig.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QlsQSJqmrtRR"
      },
      "source": [
        "**5.Affichage sur une période de 1 jour**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P20ThOgSrtRR"
      },
      "source": [
        "# Echantillonage des données\n",
        "time = \"1D\"\n",
        "\n",
        "df_resultats = df_resultats.resample(time).asfreq()\n",
        "df_resultats"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hhUmbb8TrtRS"
      },
      "source": [
        "import plotly.graph_objects as go\n",
        "\n",
        "fig = go.Figure()\n",
        "\n",
        "# Courbe originale\n",
        "fig.add_trace(go.Scatter(x=df_resultats.index,y=df_resultats['BTC_ALL'],line=dict(color='blue', width=1),name=\"Prix BTC\"))\n",
        "\n",
        "# Courbes des prédictions d'entrainement\n",
        "fig.add_trace(go.Scatter(x=df_resultats.index,y=df_resultats['BTC_PRED_ENT'],line=dict(color='green', width=1),name=\"Entrainement\"))\n",
        "\n",
        "# Courbe de validation\n",
        "fig.add_trace(go.Scatter(x=df_resultats.index,y=df_resultats['BTC_PRED_VAL'],line=dict(color='red', width=1),name=\"Validation\"))\n",
        "\n",
        "# Délimite la zone d'erreur\n",
        "fig.add_shape(type=\"line\",x0=index,y0=0,x1=index,y1=np.amax(df_resultats['BTC_ALL']),name=\"Zone d'erreur\")\n",
        "\n",
        "# Affiche les courbes\n",
        "fig.update_xaxes(rangeslider_visible=True)\n",
        "yaxis=dict(autorange = True,fixedrange= False)\n",
        "fig.update_yaxes(yaxis)\n",
        "fig.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KFgrzd6NrtRT"
      },
      "source": [
        "**6.Synthèse des erreurs sur les différentes zones**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TIdnnWaYrtRU"
      },
      "source": [
        "# Echantillonage des données\n",
        "time = \"1H\"\n",
        "\n",
        "df_resultats = df_resultats.resample(time).asfreq()\n",
        "df_resultats"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vpdOSJcZrtRU"
      },
      "source": [
        "# Détection de la date où commencnte les anomalies\n",
        "# sur la période de validation\n",
        "\n",
        "# Construit les dataframe pour calculer les erreurs\n",
        "df_error_btc_ent = df_resultats[['BTC_ENT','BTC_PRED_ENT']].dropna()\n",
        "df_error_btc_val = df_resultats[['BTC_VAL','BTC_PRED_VAL']].dropna()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nou-vexFrtRU"
      },
      "source": [
        "# Erreurs d'entrainement\n",
        "mae_ent = tf.keras.metrics.mean_absolute_error(np.asarray(df_error_btc_ent['BTC_ENT']),np.asarray(df_error_btc_ent['BTC_PRED_ENT'])).numpy()\n",
        "mse_ent = tf.keras.metrics.mean_squared_error(np.asarray(df_error_btc_ent['BTC_ENT']),np.asarray(df_error_btc_ent['BTC_PRED_ENT'])).numpy()\n",
        "mape_ent = tf.keras.metrics.mape(np.asarray(df_error_btc_ent['BTC_ENT']),np.asarray(df_error_btc_ent['BTC_PRED_ENT'])).numpy()\n",
        "\n",
        "# Erreurs de validation\n",
        "mae_val = tf.keras.metrics.mean_absolute_error(np.asarray(df_error_btc_val['BTC_VAL']),np.asarray(df_error_btc_val['BTC_PRED_VAL'])).numpy()\n",
        "mse_val = tf.keras.metrics.mean_squared_error(np.asarray(df_error_btc_val['BTC_VAL']),np.asarray(df_error_btc_val['BTC_PRED_VAL'])).numpy()\n",
        "mape_val = tf.keras.metrics.mape(np.asarray(df_error_btc_val['BTC_VAL']),np.asarray(df_error_btc_val['BTC_PRED_VAL'])).numpy()\n",
        "\n",
        "# Erreurs sur la zone valide de validation\n",
        "mae_val_ok = tf.keras.metrics.mean_absolute_error(df_error_btc_val['BTC_VAL'][:index],np.asarray(df_error_btc_val['BTC_PRED_VAL'][:index])).numpy()\n",
        "mse_val_ok = tf.keras.metrics.mean_squared_error(df_error_btc_val['BTC_VAL'][:index],np.asarray(df_error_btc_val['BTC_PRED_VAL'][:index])).numpy()\n",
        "mape_val_ok = tf.keras.metrics.mape(df_error_btc_val['BTC_VAL'][:index],np.asarray(df_error_btc_val['BTC_PRED_VAL'][:index])).numpy()\n",
        "\n",
        "\n",
        "print(\"Erreur mae entrainement %s\" %mae_ent)\n",
        "print(\"Erreur mse entrainement : %s\" %mse_ent)\n",
        "print(\"Erreur mape entrainement : %s\\n\" %mape_ent)\n",
        "\n",
        "print(\"Erreur mae validation %s\" %mae_val)\n",
        "print(\"Erreur mse validation : %s\" %mse_val)\n",
        "print(\"Erreur mape entrainement : %s\\n\" %mape_val)\n",
        "\n",
        "print(\"Erreur mae validation zone OK %s\" %mae_val_ok)\n",
        "print(\"Erreur mse validation zone OK: %s\" %mse_val_ok)\n",
        "print(\"Erreur mape validation zone OK: %s\" %mape_val_ok)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6PSUZ4SN2WRM"
      },
      "source": [
        "# Création du modèle LSTM avec auto-attention"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NC6DrlYT2WRS"
      },
      "source": [
        "**1. Création du réseau**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wUF802Z22WRS"
      },
      "source": [
        "Par défaut, la dimension des vecteurs cachés est de 10 et aucune régularisation n'est utilisée."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sGtT8icQ7HBN"
      },
      "source": [
        "# Classe d'auto-attention\n",
        "# Applique les poids de la matrice d'attention sur les vecteurs de la couche récurrente\n",
        "\n",
        "# Importe le Backend de Keras\n",
        "from keras import backend as K\n",
        "\n",
        "# Définit une nouvelle classe Couche_Attention\n",
        "# Héritée de la classe Layer de Keras\n",
        "\n",
        "class Couche_Auto_Attention(tf.keras.layers.Layer):\n",
        "  # Fonction d'initialisation de la classe d'attention\n",
        "  def __init__(self,dim_att,nbr_hop):\n",
        "    self.dim_att = dim_att          # Dimension du vecteur d'attention\n",
        "    self.nbr_hop = nbr_hop\n",
        "    super().__init__()              # Appel du __init__() de la classe Layer\n",
        "  \n",
        "  def build(self,input_shape):\n",
        "    self.W = self.add_weight(shape=(self.dim_att,input_shape[2]),initializer='glorot_uniform',name=\"W\")\n",
        "    self.U = self.add_weight(shape=(self.nbr_hop,self.dim_att),initializer='glorot_uniform',name=\"U\")\n",
        "    super().build(input_shape)        # Appel de la méthode build()\n",
        "\n",
        "  # Définit la logique de la couche d'attention\n",
        "  # Arguments :   x : Tenseur d'entrée de dimension (None, nbr_v,dim)\n",
        "  def call(self,x):\n",
        "    # Calcul de la matrice XH contenant les\n",
        "    # représentations cachées des vecteurs\n",
        "    # issus de la couche GRU\n",
        "    xt = tf.transpose(x,perm=[0,2,1])           # (None,20,40) => (None,40,20)\n",
        "    Xh = tf.matmul(self.W,xt)                   # (#Att,40)x(None,40,20) = (None,#Att,20)\n",
        "    Xh = K.tanh(Xh)                             # Xh = (None,#Att,20)\n",
        "\n",
        "    # Calcul de la matrice des poids d'attention normalisés\n",
        "    A = tf.matmul(self.U,Xh)                    # (#hop,#Att)x(None,#Att,20) = (None,#Att,20)\n",
        "    A = tf.keras.activations.softmax(A,axis=2)  # (None,#Att,20)\n",
        "\n",
        "    # Calcul de la matrice des vecteur d'attentions\n",
        "    sortie = tf.matmul(A,x)                     # (None,#Att,20)x(None,20,40) = (None,#Att,40)\n",
        "    return tf.keras.layers.Flatten()(sortie)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4uMyWVKe2WRT"
      },
      "source": [
        "dim_LSTM = 100\n",
        "l1_reg = 0.0\n",
        "l2_reg = 0.00\n",
        "nbr_hop = 20\n",
        "\n",
        "# Définition de l'entrée du modèle\n",
        "entrees = tf.keras.layers.Input(shape=(taille_fenetre,1))\n",
        "\n",
        "# Encodeur\n",
        "s_encodeur = tf.keras.layers.LSTM(dim_LSTM,return_sequences=True,recurrent_regularizer=tf.keras.regularizers.l2(1e-5))(entrees)\n",
        "s_attention = Couche_Auto_Attention(dim_att=dim_LSTM,nbr_hop=nbr_hop)(s_encodeur)\n",
        "\n",
        "# Décodeur\n",
        "s_decodeur = tf.keras.layers.Dense(dim_LSTM*nbr_hop,activation=\"tanh\")(s_attention)\n",
        "s_decodeur = tf.keras.layers.Concatenate()([s_decodeur,s_attention])\n",
        "\n",
        "# Générateur\n",
        "sortie = tf.keras.layers.Dense(1)(s_decodeur)\n",
        "\n",
        "# Construction du modèle\n",
        "model = tf.keras.Model(entrees,sortie)\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IwZnK5dl2WRV"
      },
      "source": [
        "**2. Optimisation de l'apprentissage**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UwVSsLyv2WRV"
      },
      "source": [
        "Pour accélérer le traitement des données, nous n'allons pas utiliser l'intégralité des données pendant la mise à jour du gradient, comme cela a été fait jusqu'à présent (en utilisant le dataset).  \n",
        "Cette fois-ci, nous allons forcer les mises à jour du gradient à se produire de manière moins fréquente en attribuant la valeur du batch_size à prendre en compte lors de la regression du modèle.  \n",
        "Pour cela, on utilise l'argument \"batch_size\" dans la méthode fit. En précisant un batch_size=1000, cela signifie que :\n",
        " - Sur notre total de 56000 échantillons, 56 seront utilisés pour les calculs du gradient\n",
        " - Il y aura également 56 itérations à chaque période.\n",
        "  \n",
        "    \n",
        "    \n",
        "Si nous avions pris le dataset comme entrée, nous aurions eu :\n",
        "- Un total de 56000 échantillons également\n",
        "- Chaque période aurait également pris 56 itérations pour se compléter\n",
        "- Mais 1000 échantillons auraient été utilisés pour le calcul du gradient, au lieu de 56 avec la méthode utilisée."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CCl_AlQc2WRW"
      },
      "source": [
        "batch_size = 1000"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Ka2d6HB2WRW"
      },
      "source": [
        "# Définition de la fonction de régulation du taux d'apprentissage\n",
        "def RegulationTauxApprentissage(periode, taux):\n",
        "  return 1e-8*10**(periode/10)\n",
        "\n",
        "# Définition de l'optimiseur à utiliser\n",
        "optimiseur=tf.keras.optimizers.Adam()\n",
        "\n",
        "# Compile le modèle\n",
        "model.compile(loss=\"mse\", optimizer=optimiseur, metrics=\"mse\")\n",
        "\n",
        "# Utilisation de la méthode ModelCheckPoint\n",
        "CheckPoint = tf.keras.callbacks.ModelCheckpoint(\"poids.hdf5\", monitor='loss', verbose=1, save_best_only=True, save_weights_only = True, mode='auto', save_freq='epoch')\n",
        "\n",
        "# Entraine le modèle en utilisant notre fonction personnelle de régulation du taux d'apprentissage\n",
        "historique = model.fit(x=x_train,y=y_train,epochs=100,verbose=1, callbacks=[tf.keras.callbacks.LearningRateScheduler(RegulationTauxApprentissage), CheckPoint],batch_size=batch_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lr6bQEZq2WRX"
      },
      "source": [
        "# Construit un vecteur avec les valeurs du taux d'apprentissage à chaque période \n",
        "taux = 1e-8*(10**(np.arange(100)/10))\n",
        "\n",
        "# Affiche l'erreur en fonction du taux d'apprentissage\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.semilogx(taux,historique.history[\"loss\"])\n",
        "plt.axis([ taux[0], taux[99], 0, 2])\n",
        "plt.title(\"Evolution de l'erreur en fonction du taux d'apprentissage\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ryUpPIEF2WRX"
      },
      "source": [
        "# Chargement des poids sauvegardés\n",
        "model.load_weights(\"poids.hdf5\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HhV93IpO2WRY"
      },
      "source": [
        "max_periodes = 1000\n",
        "\n",
        "# Classe permettant d'arrêter l'entrainement si la variation\n",
        "# devient plus petite qu'une valeur à choisir sur un nombre\n",
        "# de périodes à choisir\n",
        "class StopTrain(keras.callbacks.Callback):\n",
        "    def __init__(self, delta=0.01,periodes=100, term=\"loss\", logs={}):\n",
        "      self.n_periodes = 0\n",
        "      self.periodes = periodes\n",
        "      self.loss_1 = 100\n",
        "      self.delta = delta\n",
        "      self.term = term\n",
        "    def on_epoch_end(self, epoch, logs={}):\n",
        "      diff_loss = abs(self.loss_1 - logs[self.term])\n",
        "      self.loss_1 = logs[self.term]\n",
        "      if (diff_loss < self.delta):\n",
        "        self.n_periodes = self.n_periodes + 1\n",
        "      else:\n",
        "        self.n_periodes = 0\n",
        "      if (self.n_periodes == self.periodes):\n",
        "        print(\"Arrêt de l'entrainement...\")\n",
        "        self.model.stop_training = True\n",
        "\n",
        "def  My_MSE(y_true,y_pred):\n",
        "  return(tf.keras.metrics.mse(y_true,y_pred)*std.numpy()+mean.numpy())\n",
        "  \n",
        "# Définition des paramètres liés à l'évolution du taux d'apprentissage\n",
        "lr_schedule = tf.keras.optimizers.schedules.InverseTimeDecay(\n",
        "    initial_learning_rate=0.001,\n",
        "    decay_steps=10,\n",
        "    decay_rate=0.1)\n",
        "\n",
        "# Définition de l'optimiseur à utiliser\n",
        "optimiseur=tf.keras.optimizers.Adam(learning_rate=lr_schedule)\n",
        "\n",
        "\n",
        "# Utilisation de la méthode ModelCheckPoint\n",
        "CheckPoint = tf.keras.callbacks.ModelCheckpoint(\"poids_train.hdf5\", monitor='loss', verbose=1, save_best_only=True, save_weights_only = True, mode='auto', save_freq='epoch')\n",
        "\n",
        "# Compile le modèle\n",
        "model.compile(loss=\"mse\", optimizer=optimiseur, metrics=[\"mse\",My_MSE])\n",
        "\n",
        "# Entraine le modèle, avec une réduction des calculs du gradient\n",
        "historique = model.fit(x=x_train,y=y_train,validation_data=(x_val,y_val), epochs=max_periodes,verbose=1, callbacks=[CheckPoint,StopTrain(delta=0.0005,periodes = 10, term=\"My_MSE\")],batch_size=batch_size)\n",
        "\n",
        "# Entraine le modèle sans réduction de calculs\n",
        "#historique = model.fit(dataset,validation_data=dataset_val, epochs=max_periodes,verbose=1, callbacks=[CheckPoint,StopTrain(delta=0.1,periodes = 10, term=\"val_My_MSE\")])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dgf1eJPPay1b"
      },
      "source": [
        "model.load_weights('poids_train.hdf5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-JM-dtd32WRZ"
      },
      "source": [
        "erreur_entrainement = historique.history[\"loss\"]\n",
        "erreur_validation = historique.history[\"val_loss\"]\n",
        "\n",
        "# Affiche l'erreur en fonction de la période\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(np.arange(0,len(erreur_entrainement)),erreur_entrainement, label=\"Erreurs sur les entrainements\")\n",
        "plt.plot(np.arange(0,len(erreur_entrainement)),erreur_validation, label =\"Erreurs sur les validations\")\n",
        "plt.legend()\n",
        "\n",
        "plt.title(\"Evolution de l'erreur en fonction de la période\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KQj5FkF72WRa"
      },
      "source": [
        "# Evaluation du modèle\n",
        "\n",
        "model.evaluate(dataset)\n",
        "model.evaluate(dataset_val)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rExhkpy-2WRa"
      },
      "source": [
        "**3. Prédictions**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ii9KzNlZ2WRb"
      },
      "source": [
        "# Création des instants d'entrainement et de validation\n",
        "y_train_timing = serie_entrainement_x.index[taille_fenetre + horizon - 1:taille_fenetre + horizon - 1+len(y_train)]\n",
        "y_val_timing = serie_test_x.index[taille_fenetre + horizon - 1:taille_fenetre + horizon - 1+len(y_val)]\n",
        "\n",
        "# Calcul des prédictions\n",
        "pred_ent = model.predict(x_train, verbose=1)\n",
        "pred_val = model.predict(x_val, verbose=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KEBjS2gG2WRb"
      },
      "source": [
        "**4.Affichage sur une période de 1 heure**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ee3YihHo2WRb"
      },
      "source": [
        "Création d'une série contenant les valeurs originales et les prédictions, synchronisées dans le temps :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tbyOs-He2WRc"
      },
      "source": [
        "serie_btc_ent_ori = serie_entrainement_y*std+mean\n",
        "serie_btc_val_ori = serie_test_y*std+mean\n",
        "\n",
        "serie_btc_ent_pred = pd.Series(data=(pred_ent[:,0]*std+mean),index=y_train_timing)\n",
        "serie_btc_val_pred = pd.Series(data=(pred_val[:,0]*std+mean),index=y_val_timing)\n",
        "\n",
        "serie_btc_ori = pd.concat([serie_btc_ent_ori,serie_btc_val_ori])\n",
        "serie_btc_pred = pd.concat([serie_btc_ent_pred,serie_btc_val_pred])\n",
        "\n",
        "serie_btc_ori = serie_btc_ori.fillna(method=\"backfill\")\n",
        "serie_btc_pred = serie_btc_pred.fillna(method=\"backfill\")\n",
        "\n",
        "serie_btc_ent_ori = serie_btc_ent_ori.fillna(method=\"backfill\")\n",
        "serie_btc_val_ori = serie_btc_val_ori.fillna(method=\"backfill\")\n",
        "serie_btc_ent_pred = serie_btc_ent_pred.fillna(method=\"backfill\")\n",
        "serie_btc_val_pred = serie_btc_val_pred.fillna(method=\"backfill\")\n",
        "\n",
        "frame = {'BTC_ALL' : serie_btc_ori, 'BTC_ENT': serie_btc_ent_ori, 'BTC_VAL' : serie_btc_val_ori, 'BTC_PRED' : serie_btc_pred, 'BTC_PRED_ENT' : serie_btc_ent_pred, 'BTC_PRED_VAL':serie_btc_val_pred}\n",
        "df_resultats = pd.DataFrame(frame)\n",
        "df_resultats"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RMvz38v02WRc"
      },
      "source": [
        "date_separation"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t3tE5FK-2WRd"
      },
      "source": [
        "df_resultats.loc[date_separation-pd.Timedelta(hours=7):date_separation+pd.Timedelta(hours=7)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lvF19ok42WRd"
      },
      "source": [
        "import plotly.graph_objects as go\n",
        "\n",
        "fig = go.Figure()\n",
        "\n",
        "# Courbe originale\n",
        "fig.add_trace(go.Scatter(x=df_resultats.index,y=df_resultats['BTC_ALL'],line=dict(color='blue', width=1),name=\"Prix BTC\"))\n",
        "\n",
        "# Courbes des prédictions d'entrainement\n",
        "fig.add_trace(go.Scatter(x=df_resultats.index,y=df_resultats['BTC_PRED_ENT'],line=dict(color='green', width=1),name=\"Entrainement\"))\n",
        "\n",
        "# Courbe de validation\n",
        "fig.add_trace(go.Scatter(x=df_resultats.index,y=df_resultats['BTC_PRED_VAL'],line=dict(color='red', width=1),name=\"Validation\"))\n",
        "\n",
        "fig.update_xaxes(rangeslider_visible=True)\n",
        "yaxis=dict(autorange = True,fixedrange= False)\n",
        "fig.update_yaxes(yaxis)\n",
        "fig.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mmyOVcdD2WRh"
      },
      "source": [
        "**5. Détection de l'augmentation des erreurs dans la zone de validation**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IvS4fipz2WRi"
      },
      "source": [
        "On peut imaginer devoir suivre en temps réel l'évolution des prédictions afin de détecter lorsque le modèle n'est plus valide."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z_aSn4Gg2WRi"
      },
      "source": [
        "# Détection de la date où commencent les anomalies\n",
        "# sur la période de validation\n",
        "\n",
        "# Construit les dataframe pour calculer les erreurs\n",
        "df_error_btc_ent = df_resultats[['BTC_ENT','BTC_PRED_ENT']].dropna()\n",
        "df_error_btc_val = df_resultats[['BTC_VAL','BTC_PRED_VAL']].dropna()\n",
        "\n",
        "# Calcul des erreurs relatives sur les entrainements et les validations\n",
        "erreur_ent = abs(np.asarray(df_error_btc_ent['BTC_ENT']) - np.asarray(df_error_btc_ent['BTC_PRED_ENT']))/np.asarray(df_error_btc_ent['BTC_ENT'])*100.0\n",
        "erreur_val = abs(np.asarray(df_error_btc_val['BTC_VAL']) - np.asarray(df_error_btc_val['BTC_PRED_VAL']))/np.asarray(df_error_btc_val['BTC_VAL'])*100.0\n",
        "\n",
        "# Erreur relative moyenne sur les entrainements\n",
        "erreur_ent_mape = tf.keras.metrics.mape(np.asarray(df_error_btc_ent['BTC_ENT']),np.asarray(df_error_btc_ent['BTC_PRED_ENT']))\n",
        "erreur_ent_mape_max = np.amax(erreur_ent)\n",
        "\n",
        "# Calcul le nombre d'anomalies sur les entrainements avec le ratio spécifié\n",
        "nbr_anomalies_ent = np.count_nonzero(erreur_ent>erreur_ent_mape)\n",
        "\n",
        "# Calcul du ratio d'anomalies sur la période d'entrainement\n",
        "ratio_ent = np.count_nonzero(erreur_ent>erreur_ent_mape)/erreur_ent.size\n",
        "\n",
        "# Recherche de la date à partir de laquelle on dépasse l\n",
        "n_erreurs = 0\n",
        "for i in range(5,erreur_val.size):\n",
        "  erreur_val_ = abs(np.asarray(df_error_btc_val['BTC_VAL'][i]) - np.asarray(df_error_btc_val['BTC_PRED_VAL'][i]))/np.asarray(df_error_btc_val['BTC_VAL'][i])*100.0\n",
        "  seuil = erreur_ent_mape_max*1\n",
        "  if erreur_val_ > seuil:\n",
        "    n_erreurs = n_erreurs + 1\n",
        "    if n_erreurs == 1:\n",
        "      index = df_error_btc_val.index[i]\n",
        "      break\n",
        "  else:\n",
        "    n_erreurs = 0\n",
        "print(index)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rXx0vqSX2WRj"
      },
      "source": [
        "import plotly.graph_objects as go\n",
        "\n",
        "fig = go.Figure()\n",
        "\n",
        "# Courbe originale\n",
        "fig.add_trace(go.Scatter(x=df_resultats.index,y=df_resultats['BTC_ALL'],line=dict(color='blue', width=1),name=\"Prix BTC\"))\n",
        "\n",
        "# Courbes des prédictions d'entrainement\n",
        "fig.add_trace(go.Scatter(x=df_resultats.index,y=df_resultats['BTC_PRED_ENT'],line=dict(color='green', width=1),name=\"Entrainement\"))\n",
        "\n",
        "# Courbe de validation\n",
        "fig.add_trace(go.Scatter(x=df_resultats.index,y=df_resultats['BTC_PRED_VAL'],line=dict(color='red', width=1),name=\"Validation\"))\n",
        "\n",
        "# Délimite la zone d'erreur\n",
        "fig.add_shape(type=\"line\",x0=index,y0=0,x1=index,y1=np.amax(df_resultats['BTC_ALL']),name=\"Zone d'erreur\")\n",
        "\n",
        "# Affiche les courbes\n",
        "fig.update_xaxes(rangeslider_visible=True)\n",
        "yaxis=dict(autorange = True,fixedrange= False)\n",
        "fig.update_yaxes(yaxis)\n",
        "fig.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "st8Ynp3T2WRo"
      },
      "source": [
        "**5.Affichage sur une période de 1 jour**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LZe5LHTL2WRo"
      },
      "source": [
        "# Echantillonage des données\n",
        "time = \"1D\"\n",
        "\n",
        "df_resultats = df_resultats.resample(time).asfreq()\n",
        "df_resultats"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IG6DOtBk2WRo"
      },
      "source": [
        "import plotly.graph_objects as go\n",
        "\n",
        "fig = go.Figure()\n",
        "\n",
        "# Courbe originale\n",
        "fig.add_trace(go.Scatter(x=df_resultats.index,y=df_resultats['BTC_ALL'],line=dict(color='blue', width=1),name=\"Prix BTC\"))\n",
        "\n",
        "# Courbes des prédictions d'entrainement\n",
        "fig.add_trace(go.Scatter(x=df_resultats.index,y=df_resultats['BTC_PRED_ENT'],line=dict(color='green', width=1),name=\"Entrainement\"))\n",
        "\n",
        "# Courbe de validation\n",
        "fig.add_trace(go.Scatter(x=df_resultats.index,y=df_resultats['BTC_PRED_VAL'],line=dict(color='red', width=1),name=\"Validation\"))\n",
        "\n",
        "# Délimite la zone d'erreur\n",
        "fig.add_shape(type=\"line\",x0=index,y0=0,x1=index,y1=np.amax(df_resultats['BTC_ALL']),name=\"Zone d'erreur\")\n",
        "\n",
        "# Affiche les courbes\n",
        "fig.update_xaxes(rangeslider_visible=True)\n",
        "yaxis=dict(autorange = True,fixedrange= False)\n",
        "fig.update_yaxes(yaxis)\n",
        "fig.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SRKI61PK2WRp"
      },
      "source": [
        "**6.Synthèse des erreurs sur les différentes zones**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Hxnr0oT2WRq"
      },
      "source": [
        "# Echantillonage des données\n",
        "time = \"1H\"\n",
        "\n",
        "df_resultats = df_resultats.resample(time).asfreq()\n",
        "df_resultats"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hMW1t-kp2WRq"
      },
      "source": [
        "# Détection de la date où commencnte les anomalies\n",
        "# sur la période de validation\n",
        "\n",
        "# Construit les dataframe pour calculer les erreurs\n",
        "df_error_btc_ent = df_resultats[['BTC_ENT','BTC_PRED_ENT']].dropna()\n",
        "df_error_btc_val = df_resultats[['BTC_VAL','BTC_PRED_VAL']].dropna()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9bxhjwQK2WRq"
      },
      "source": [
        "# Erreurs d'entrainement\n",
        "mae_ent = tf.keras.metrics.mean_absolute_error(np.asarray(df_error_btc_ent['BTC_ENT']),np.asarray(df_error_btc_ent['BTC_PRED_ENT'])).numpy()\n",
        "mse_ent = tf.keras.metrics.mean_squared_error(np.asarray(df_error_btc_ent['BTC_ENT']),np.asarray(df_error_btc_ent['BTC_PRED_ENT'])).numpy()\n",
        "mape_ent = tf.keras.metrics.mape(np.asarray(df_error_btc_ent['BTC_ENT']),np.asarray(df_error_btc_ent['BTC_PRED_ENT'])).numpy()\n",
        "\n",
        "# Erreurs de validation\n",
        "mae_val = tf.keras.metrics.mean_absolute_error(np.asarray(df_error_btc_val['BTC_VAL']),np.asarray(df_error_btc_val['BTC_PRED_VAL'])).numpy()\n",
        "mse_val = tf.keras.metrics.mean_squared_error(np.asarray(df_error_btc_val['BTC_VAL']),np.asarray(df_error_btc_val['BTC_PRED_VAL'])).numpy()\n",
        "mape_val = tf.keras.metrics.mape(np.asarray(df_error_btc_val['BTC_VAL']),np.asarray(df_error_btc_val['BTC_PRED_VAL'])).numpy()\n",
        "\n",
        "# Erreurs sur la zone valide de validation\n",
        "mae_val_ok = tf.keras.metrics.mean_absolute_error(df_error_btc_val['BTC_VAL'][:index],np.asarray(df_error_btc_val['BTC_PRED_VAL'][:index])).numpy()\n",
        "mse_val_ok = tf.keras.metrics.mean_squared_error(df_error_btc_val['BTC_VAL'][:index],np.asarray(df_error_btc_val['BTC_PRED_VAL'][:index])).numpy()\n",
        "mape_val_ok = tf.keras.metrics.mape(df_error_btc_val['BTC_VAL'][:index],np.asarray(df_error_btc_val['BTC_PRED_VAL'][:index])).numpy()\n",
        "\n",
        "\n",
        "print(\"Erreur mae entrainement %s\" %mae_ent)\n",
        "print(\"Erreur mse entrainement : %s\" %mse_ent)\n",
        "print(\"Erreur mape entrainement : %s\\n\" %mape_ent)\n",
        "\n",
        "print(\"Erreur mae validation %s\" %mae_val)\n",
        "print(\"Erreur mse validation : %s\" %mse_val)\n",
        "print(\"Erreur mape entrainement : %s\\n\" %mape_val)\n",
        "\n",
        "print(\"Erreur mae validation zone OK %s\" %mae_val_ok)\n",
        "print(\"Erreur mse validation zone OK: %s\" %mse_val_ok)\n",
        "print(\"Erreur mape validation zone OK: %s\" %mape_val_ok)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ntshp_muADWt"
      },
      "source": [
        "# Création du modèle End-To-End Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vddiuNuhAliy"
      },
      "source": [
        "def prepare_dataset_XY(serie, taille_fenetre, batch_size, nbr_sequences):\n",
        "  dataset = tf.data.Dataset.from_tensor_slices(serie)\n",
        "  dataset = dataset.window(taille_fenetre+1, shift=1, drop_remainder=True)\n",
        "  dataset = dataset.flat_map(lambda x: x.batch(taille_fenetre + 1))\n",
        "  dataset = dataset.window(nbr_sequences+1, shift=1, drop_remainder=True)\n",
        "  dataset = dataset.flat_map(lambda x: x.batch(nbr_sequences+1,drop_remainder=True))\n",
        "  dataset = dataset.map(lambda x: [(tf.slice(x,[0,0],[nbr_sequences,taille_fenetre]),                           # (30;20)       [((30,20),(20)),(1)]\n",
        "                                   tf.squeeze(tf.slice(x,[nbr_sequences,0],[1,taille_fenetre]),axis=0)),        # (20)\n",
        "                                   tf.squeeze(tf.slice(x,[nbr_sequences,taille_fenetre],[1,1]),axis=0)])        # (1)\n",
        "  dataset = dataset.batch(batch_size,drop_remainder=True)\n",
        "  return dataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_WG2KIkJApxh"
      },
      "source": [
        "# Définition des caractéristiques du dataset que l'on souhaite créer\n",
        "taille_fenetre = 15\n",
        "batch_size = 1000\n",
        "Nbr_Sequences = 10\n",
        "\n",
        "dataset = prepare_dataset_XY(serie_entrainement,taille_fenetre,batch_size,Nbr_Sequences)              # 56x((1000,10,15),(1000,15)),(1000,1)\n",
        "dataset_val = prepare_dataset_XY(serie_test,taille_fenetre,batch_size,Nbr_Sequences)              # 56x((1000,10,15),(1000,15)),(1000,1)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iQEziTjSCFDg"
      },
      "source": [
        "len(list(dataset.as_numpy_iterator()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n4z2Y65dCJg4"
      },
      "source": [
        "for element in dataset.take(1):\n",
        "  print(element)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J9JXgCGOCiiP"
      },
      "source": [
        "# Extrait les X,Y du dataset\n",
        "#56x((1000,4,1),(1000,1)) => (56*1000,4,1) ; (56*1000,1)\n",
        "\n",
        "x,y = tuple(zip(*dataset))\n",
        "\n",
        "# Recombine les données\n",
        "# (56,1000,4,1) => (56*128,4,1)\n",
        "# (56,1000,1) => (56*128,1)\n",
        "x_train = np.asarray(tf.reshape(np.asarray(x,dtype=np.float32),shape=(np.asarray(x).shape[0]*np.asarray(x).shape[1],taille_fenetre,1)))\n",
        "y_train = np.asarray(tf.reshape(np.asarray(y,dtype=np.float32),shape=(np.asarray(y).shape[0]*np.asarray(y).shape[1])))\n",
        "\n",
        "# Affiche les formats\n",
        "print(x_train.shape)\n",
        "print(y_train.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OW2AKgnLADW9"
      },
      "source": [
        "**1. Création du réseau**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NNx-iQ3bADW9"
      },
      "source": [
        "Par défaut, la dimension des vecteurs cachés est de 10 et aucune régularisation n'est utilisée."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s1P16yDVAM0B"
      },
      "source": [
        "# Définition du de la couche du modèle\n",
        "# End-to-End Memory Network\n",
        "# Epaquetage des données avec le dernier état caché d'une couche GRU\n",
        "\n",
        "from keras import backend as K\n",
        "\n",
        "class Couche_End_to_End_MN(tf.keras.layers.Layer):\n",
        "  # Fonction d'initialisation de la classe d'attention\n",
        "  # dim_GRU : Dimension des vecteurs GRU\n",
        "  # x : Séquences à mémoriser (batch_size, Nbr_Sequence, taille_fenetre)\n",
        "  # Fonction de la couche lambda d'entrée\n",
        "  def __init__(self,dim_GRU,regul=0.0):\n",
        "    self.dim_GRU = dim_GRU\n",
        "    self.regul = regul\n",
        "    super().__init__()          # Appel du __init__() de la classe Layer\n",
        "  \n",
        "  def build(self,input_shape):\n",
        "    # Définition des couches GRU pour traiter les séquences d'entrée\n",
        "    self.couche_GRU_A = tf.keras.layers.GRU(self.dim_GRU,kernel_regularizer=tf.keras.regularizers.l2(self.regul))\n",
        "    self.couche_GRU_B = tf.keras.layers.GRU(self.dim_GRU,kernel_regularizer=tf.keras.regularizers.l2(self.regul))\n",
        "    self.couche_GRU_C = tf.keras.layers.GRU(self.dim_GRU,kernel_regularizer=tf.keras.regularizers.l2(self.regul))\n",
        "\n",
        "    super().build(input_shape)        # Appel de la méthode build()\n",
        "\n",
        "  # Définit la logique de la couche d'attention\n",
        "  # Arguments :     x : (batch_size, Nbr_Sequence, taille_fenetre)\n",
        "  #                 y : (batch_size, taille_fenetre)\n",
        "  # Exemple :   batch_size = 32\n",
        "  #             Nbr_Sequence =30\n",
        "  #             taille_fenetre = 20\n",
        "  #             dim_GRU = 40 \n",
        "  def call(self,x,y):\n",
        "    # Création des vecteurs mi dans le tenseur M\n",
        "    M = tf.expand_dims(x,axis=-1)                                   # (32,30,20) => (32,30,20,1)\n",
        "    M = tf.keras.layers.TimeDistributed(self.couche_GRU_A)(M)       # (32,30,20,1) => (32,30,40) : TimeStep = 30 : (32,20,1) envoyé\n",
        "    M = K.tanh(M)\n",
        "\n",
        "    # Création du vecteur d'état u\n",
        "    u = tf.expand_dims(y,axis=-1)                                   # (32,20) => (32,20,1)\n",
        "    u = self.couche_GRU_B(u)                                        # (32,20,1) => (32,40)\n",
        "    u = tf.expand_dims(u,axis=-1)                                   # (32,40) => (32,40,1)\n",
        "    u = K.tanh(u)                                                   # (32,40,1)\n",
        "\n",
        "    # Calcul des poids d'attention\n",
        "    p = tf.matmul(M,u)                                              # (32,30,40)x(32,40,1)=(32,30,1)\n",
        "    p = tf.keras.activations.softmax(p,axis=1)                      # (32,30,1)\n",
        "\n",
        "    # Création des vecteurs ci dans le tenseur C\n",
        "    C = tf.expand_dims(x,axis=-1)                                   # (32,30,20) => (32,30,20,1)\n",
        "    C = tf.keras.layers.TimeDistributed(self.couche_GRU_C)(C)       # (32,30,20,1) => (32,30,40) : TimeStep = 30 : (32,20,1) envoyé\n",
        "    C = K.tanh(C)\n",
        "\n",
        "    # Calcul du vecteur réponse issu de la mémoire\n",
        "    o = tf.multiply(C,p)                                            # (32,30,40)_x_(32,30,1) = (32,30,40)\n",
        "    o = K.sum(o, axis=1)                                            # (32,40)\n",
        "    o = K.tanh(o)                                                   # (32,40)\n",
        "    \n",
        "    # Retourne le vecteur d'attention\n",
        "    return (o+tf.squeeze(u,axis=2))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ygj7fwujADW-"
      },
      "source": [
        "dim_LSTM = 40\n",
        "l1_reg = 0.0\n",
        "l2_reg = 0.0\n",
        "\n",
        "# Définition des entrées du modèle\n",
        "entrees_sequences = tf.keras.layers.Input(shape=(Nbr_Sequences,taille_fenetre))\n",
        "entrees_entrainement = tf.keras.layers.Input(shape=(taille_fenetre))\n",
        "\n",
        "# Encodeur\n",
        "s_encodeur = Couche_End_to_End_MN(dim_GRU=dim_LSTM,regul=0.0)(entrees_sequences,entrees_entrainement)\n",
        "\n",
        "# Décodeur\n",
        "s_decodeur = tf.keras.layers.Dense(dim_LSTM,activation=\"tanh\")(s_encodeur)\n",
        "s_decodeur = tf.keras.layers.Concatenate()([s_decodeur,s_encodeur])\n",
        "\n",
        "# Générateur\n",
        "sortie = tf.keras.layers.Dense(1)(s_decodeur)\n",
        "\n",
        "# Construction du modèle\n",
        "model = tf.keras.Model([entrees_sequences,entrees_entrainement],sortie)\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oFNCcD1BADW_"
      },
      "source": [
        "**2. Optimisation de l'apprentissage**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YTQVpBLpADW_"
      },
      "source": [
        "Pour accélérer le traitement des données, nous n'allons pas utiliser l'intégralité des données pendant la mise à jour du gradient, comme cela a été fait jusqu'à présent (en utilisant le dataset).  \n",
        "Cette fois-ci, nous allons forcer les mises à jour du gradient à se produire de manière moins fréquente en attribuant la valeur du batch_size à prendre en compte lors de la regression du modèle.  \n",
        "Pour cela, on utilise l'argument \"batch_size\" dans la méthode fit. En précisant un batch_size=1000, cela signifie que :\n",
        " - Sur notre total de 56000 échantillons, 56 seront utilisés pour les calculs du gradient\n",
        " - Il y aura également 56 itérations à chaque période.\n",
        "  \n",
        "    \n",
        "    \n",
        "Si nous avions pris le dataset comme entrée, nous aurions eu :\n",
        "- Un total de 56000 échantillons également\n",
        "- Chaque période aurait également pris 56 itérations pour se compléter\n",
        "- Mais 1000 échantillons auraient été utilisés pour le calcul du gradient, au lieu de 56 avec la méthode utilisée."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "atvCPpf-ADXA"
      },
      "source": [
        "batch_size = 1000"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mZm9WrqVADXA"
      },
      "source": [
        "# Définition de la fonction de régulation du taux d'apprentissage\n",
        "def RegulationTauxApprentissage(periode, taux):\n",
        "  return 1e-8*10**(periode/10)\n",
        "\n",
        "# Définition de l'optimiseur à utiliser\n",
        "optimiseur=tf.keras.optimizers.Adam()\n",
        "\n",
        "# Compile le modèle\n",
        "model.compile(loss=\"logcosh\", optimizer=optimiseur, metrics=\"mse\")\n",
        "\n",
        "# Utilisation de la méthode ModelCheckPoint\n",
        "CheckPoint = tf.keras.callbacks.ModelCheckpoint(\"poids.hdf5\", monitor='loss', verbose=1, save_best_only=True, save_weights_only = True, mode='auto', save_freq='epoch')\n",
        "\n",
        "# Entraine le modèle en utilisant notre fonction personnelle de régulation du taux d'apprentissage\n",
        "historique = model.fit(dataset,epochs=100,verbose=1, callbacks=[tf.keras.callbacks.LearningRateScheduler(RegulationTauxApprentissage), CheckPoint],batch_size=batch_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b2zHrpiAADXB"
      },
      "source": [
        "# Construit un vecteur avec les valeurs du taux d'apprentissage à chaque période \n",
        "taux = 1e-8*(10**(np.arange(100)/10))\n",
        "\n",
        "# Affiche l'erreur en fonction du taux d'apprentissage\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.semilogx(taux,historique.history[\"loss\"])\n",
        "plt.axis([ taux[30], taux[99], 0, 0.04])\n",
        "plt.title(\"Evolution de l'erreur en fonction du taux d'apprentissage\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ha5ZDQyOADXC"
      },
      "source": [
        "# Chargement des poids sauvegardés\n",
        "model.load_weights(\"poids.hdf5\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0SzpxsrQADXC"
      },
      "source": [
        "max_periodes = 1000\n",
        "\n",
        "# Classe permettant d'arrêter l'entrainement si la variation\n",
        "# devient plus petite qu'une valeur à choisir sur un nombre\n",
        "# de périodes à choisir\n",
        "class StopTrain(keras.callbacks.Callback):\n",
        "    def __init__(self, delta=0.01,periodes=100, term=\"loss\", logs={}):\n",
        "      self.n_periodes = 0\n",
        "      self.periodes = periodes\n",
        "      self.loss_1 = 100\n",
        "      self.delta = delta\n",
        "      self.term = term\n",
        "    def on_epoch_end(self, epoch, logs={}):\n",
        "      diff_loss = abs(self.loss_1 - logs[self.term])\n",
        "      self.loss_1 = logs[self.term]\n",
        "      if (diff_loss < self.delta):\n",
        "        self.n_periodes = self.n_periodes + 1\n",
        "      else:\n",
        "        self.n_periodes = 0\n",
        "      if (self.n_periodes == self.periodes):\n",
        "        print(\"Arrêt de l'entrainement...\")\n",
        "        self.model.stop_training = True\n",
        "\n",
        "def  My_MSE(y_true,y_pred):\n",
        "  return(tf.keras.metrics.mse(y_true,y_pred)*std.numpy()+mean.numpy())\n",
        "  \n",
        "# Définition des paramètres liés à l'évolution du taux d'apprentissage\n",
        "lr_schedule = tf.keras.optimizers.schedules.InverseTimeDecay(\n",
        "    initial_learning_rate=0.001,\n",
        "    decay_steps=10,\n",
        "    decay_rate=0.01)\n",
        "\n",
        "# Définition de l'optimiseur à utiliser\n",
        "optimiseur=tf.keras.optimizers.Adam(learning_rate=lr_schedule)\n",
        "\n",
        "\n",
        "# Utilisation de la méthode ModelCheckPoint\n",
        "CheckPoint = tf.keras.callbacks.ModelCheckpoint(\"poids_train.hdf5\", monitor='loss', verbose=1, save_best_only=True, save_weights_only = True, mode='auto', save_freq='epoch')\n",
        "\n",
        "# Compile le modèle\n",
        "model.compile(loss=\"logcosh\", optimizer=optimiseur, metrics=[\"mse\",My_MSE])\n",
        "\n",
        "# Entraine le modèle, avec une réduction des calculs du gradient\n",
        "#historique = model.fit(x=x_train,y=y_train,validation_data=(x_val,y_val), epochs=max_periodes,verbose=1, callbacks=[CheckPoint,StopTrain(delta=0.005,periodes = 10, term=\"My_MSE\")],batch_size=batch_size)\n",
        "\n",
        "# Entraine le modèle sans réduction de calculs\n",
        "historique = model.fit(dataset,validation_data=dataset_val, epochs=max_periodes,verbose=1, callbacks=[CheckPoint,StopTrain(delta=0.1,periodes = 10, term=\"val_My_MSE\")])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xiy0xyuYJpC8"
      },
      "source": [
        "from google.colab import files\n",
        "files.download('poids_train.hdf5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1nehoz4YADXD"
      },
      "source": [
        "erreur_entrainement = historique.history[\"loss\"]\n",
        "erreur_validation = historique.history[\"val_loss\"]\n",
        "\n",
        "# Affiche l'erreur en fonction de la période\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(np.arange(0,len(erreur_entrainement)),erreur_entrainement, label=\"Erreurs sur les entrainements\")\n",
        "plt.plot(np.arange(0,len(erreur_entrainement)),erreur_validation, label =\"Erreurs sur les validations\")\n",
        "plt.legend()\n",
        "\n",
        "plt.title(\"Evolution de l'erreur en fonction de la période\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f7fBX8FzADXE"
      },
      "source": [
        "# Evaluation du modèle\n",
        "# Avec le modèle type encodeur/décodeur :\n",
        "# 56/56 [==============================] - 7s 113ms/step - loss: 1.1795e-04 - mse: 2.3664e-04 - My_MSE: 2712.2415\n",
        "# 14/14 [==============================] - 2s 113ms/step - loss: 0.3602 - mse: 1.9360 - My_MSE: 9650.2637\n",
        "model.evaluate(dataset)\n",
        "model.evaluate(dataset_val)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ibjW2608ADXE"
      },
      "source": [
        "**3. Prédictions**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b4XVlUVqADXF"
      },
      "source": [
        "horizon = 1\n",
        "# Création des instants d'entrainement et de validation\n",
        "y_train_timing = serie_entrainement.index[taille_fenetre + horizon - 1:taille_fenetre + horizon - 1+len(y_train)]\n",
        "y_val_timing = serie_test.index[taille_fenetre + horizon - 1:taille_fenetre + horizon - 1+len(y_val)]\n",
        "\n",
        "# Calcul des prédictions\n",
        "pred_ent = model.predict(x_train, verbose=1)\n",
        "pred_val = model.predict(x_val, verbose=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qssOW-x2ADXF"
      },
      "source": [
        "**4.Affichage sur une période de 1 heure**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GLGHAwjIADXF"
      },
      "source": [
        "Création d'une série contenant les valeurs originales et les prédictions, synchronisées dans le temps :"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AoyojCloADXG"
      },
      "source": [
        "serie_btc_ent_ori = serie_entrainement*std+mean\n",
        "serie_btc_val_ori = serie_test*std+mean\n",
        "\n",
        "serie_btc_ent_pred = pd.Series(data=(pred_ent[:,0]*std+mean),index=y_train_timing)\n",
        "serie_btc_val_pred = pd.Series(data=(pred_val[:,0]*std+mean),index=y_val_timing)\n",
        "\n",
        "serie_btc_ori = pd.concat([serie_btc_ent_ori,serie_btc_val_ori])\n",
        "serie_btc_pred = pd.concat([serie_btc_ent_pred,serie_btc_val_pred])\n",
        "\n",
        "serie_btc_ori = serie_btc_ori.fillna(method=\"backfill\")\n",
        "serie_btc_pred = serie_btc_pred.fillna(method=\"backfill\")\n",
        "\n",
        "serie_btc_ent_ori = serie_btc_ent_ori.fillna(method=\"backfill\")\n",
        "serie_btc_val_ori = serie_btc_val_ori.fillna(method=\"backfill\")\n",
        "serie_btc_ent_pred = serie_btc_ent_pred.fillna(method=\"backfill\")\n",
        "serie_btc_val_pred = serie_btc_val_pred.fillna(method=\"backfill\")\n",
        "\n",
        "frame = {'BTC_ALL' : serie_btc_ori, 'BTC_ENT': serie_btc_ent_ori, 'BTC_VAL' : serie_btc_val_ori, 'BTC_PRED' : serie_btc_pred, 'BTC_PRED_ENT' : serie_btc_ent_pred, 'BTC_PRED_VAL':serie_btc_val_pred}\n",
        "df_resultats = pd.DataFrame(frame)\n",
        "df_resultats"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0SwwQkjiADXG"
      },
      "source": [
        "date_separation"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MqvOoeoYADXG"
      },
      "source": [
        "df_resultats.loc[date_separation-pd.Timedelta(hours=7):date_separation+pd.Timedelta(hours=7)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zNqabyNzADXH"
      },
      "source": [
        "import plotly.graph_objects as go\n",
        "\n",
        "fig = go.Figure()\n",
        "\n",
        "# Courbe originale\n",
        "fig.add_trace(go.Scatter(x=df_resultats.index,y=df_resultats['BTC_ALL'],line=dict(color='blue', width=1),name=\"Prix BTC\"))\n",
        "\n",
        "# Courbes des prédictions d'entrainement\n",
        "fig.add_trace(go.Scatter(x=df_resultats.index,y=df_resultats['BTC_PRED_ENT'],line=dict(color='green', width=1),name=\"Entrainement\"))\n",
        "\n",
        "# Courbe de validation\n",
        "fig.add_trace(go.Scatter(x=df_resultats.index,y=df_resultats['BTC_PRED_VAL'],line=dict(color='red', width=1),name=\"Validation\"))\n",
        "\n",
        "fig.update_xaxes(rangeslider_visible=True)\n",
        "yaxis=dict(autorange = True,fixedrange= False)\n",
        "fig.update_yaxes(yaxis)\n",
        "fig.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WCTa2-ZEADXM"
      },
      "source": [
        "**5. Détection de l'augmentation des erreurs dans la zone de validation**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z3cjdfFLADXN"
      },
      "source": [
        "On peut imaginer devoir suivre en temps réel l'évolution des prédictions afin de détecter lorsque le modèle n'est plus valide."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "snd-tMArADXN"
      },
      "source": [
        "# Détection de la date où commencent les anomalies\n",
        "# sur la période de validation\n",
        "\n",
        "# Construit les dataframe pour calculer les erreurs\n",
        "df_error_btc_ent = df_resultats[['BTC_ENT','BTC_PRED_ENT']].dropna()\n",
        "df_error_btc_val = df_resultats[['BTC_VAL','BTC_PRED_VAL']].dropna()\n",
        "\n",
        "# Calcul des erreurs relatives sur les entrainements et les validations\n",
        "erreur_ent = abs(np.asarray(df_error_btc_ent['BTC_ENT']) - np.asarray(df_error_btc_ent['BTC_PRED_ENT']))/np.asarray(df_error_btc_ent['BTC_ENT'])*100.0\n",
        "erreur_val = abs(np.asarray(df_error_btc_val['BTC_VAL']) - np.asarray(df_error_btc_val['BTC_PRED_VAL']))/np.asarray(df_error_btc_val['BTC_VAL'])*100.0\n",
        "\n",
        "# Erreur relative moyenne sur les entrainements\n",
        "erreur_ent_mape = tf.keras.metrics.mape(np.asarray(df_error_btc_ent['BTC_ENT']),np.asarray(df_error_btc_ent['BTC_PRED_ENT']))\n",
        "erreur_ent_mape_max = np.amax(erreur_ent)\n",
        "\n",
        "# Calcul le nombre d'anomalies sur les entrainements avec le ratio spécifié\n",
        "nbr_anomalies_ent = np.count_nonzero(erreur_ent>erreur_ent_mape)\n",
        "\n",
        "# Calcul du ratio d'anomalies sur la période d'entrainement\n",
        "ratio_ent = np.count_nonzero(erreur_ent>erreur_ent_mape)/erreur_ent.size\n",
        "\n",
        "# Recherche de la date à partir de laquelle on dépasse l\n",
        "n_erreurs = 0\n",
        "for i in range(5,erreur_val.size):\n",
        "  erreur_val_ = abs(np.asarray(df_error_btc_val['BTC_VAL'][i]) - np.asarray(df_error_btc_val['BTC_PRED_VAL'][i]))/np.asarray(df_error_btc_val['BTC_VAL'][i])*100.0\n",
        "  seuil = erreur_ent_mape_max*1\n",
        "  if erreur_val_ > seuil:\n",
        "    n_erreurs = n_erreurs + 1\n",
        "    if n_erreurs == 5:\n",
        "      index = df_error_btc_val.index[i]\n",
        "      break\n",
        "  else:\n",
        "    n_erreurs = 0\n",
        "print(index)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ubGN_i0fADXO"
      },
      "source": [
        "import plotly.graph_objects as go\n",
        "\n",
        "fig = go.Figure()\n",
        "\n",
        "# Courbe originale\n",
        "fig.add_trace(go.Scatter(x=df_resultats.index,y=df_resultats['BTC_ALL'],line=dict(color='blue', width=1),name=\"Prix BTC\"))\n",
        "\n",
        "# Courbes des prédictions d'entrainement\n",
        "fig.add_trace(go.Scatter(x=df_resultats.index,y=df_resultats['BTC_PRED_ENT'],line=dict(color='green', width=1),name=\"Entrainement\"))\n",
        "\n",
        "# Courbe de validation\n",
        "fig.add_trace(go.Scatter(x=df_resultats.index,y=df_resultats['BTC_PRED_VAL'],line=dict(color='red', width=1),name=\"Validation\"))\n",
        "\n",
        "# Délimite la zone d'erreur\n",
        "fig.add_shape(type=\"line\",x0=index,y0=0,x1=index,y1=np.amax(df_resultats['BTC_ALL']),name=\"Zone d'erreur\")\n",
        "\n",
        "# Affiche les courbes\n",
        "fig.update_xaxes(rangeslider_visible=True)\n",
        "yaxis=dict(autorange = True,fixedrange= False)\n",
        "fig.update_yaxes(yaxis)\n",
        "fig.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "emkQ01bfADXT"
      },
      "source": [
        "**5.Affichage sur une période de 1 jour**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ShhfXg8yADXU"
      },
      "source": [
        "# Echantillonage des données\n",
        "time = \"1D\"\n",
        "\n",
        "df_resultats = df_resultats.resample(time).asfreq()\n",
        "df_resultats"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "btEN2yyyADXU"
      },
      "source": [
        "import plotly.graph_objects as go\n",
        "\n",
        "fig = go.Figure()\n",
        "\n",
        "# Courbe originale\n",
        "fig.add_trace(go.Scatter(x=df_resultats.index,y=df_resultats['BTC_ALL'],line=dict(color='blue', width=1),name=\"Prix BTC\"))\n",
        "\n",
        "# Courbes des prédictions d'entrainement\n",
        "fig.add_trace(go.Scatter(x=df_resultats.index,y=df_resultats['BTC_PRED_ENT'],line=dict(color='green', width=1),name=\"Entrainement\"))\n",
        "\n",
        "# Courbe de validation\n",
        "fig.add_trace(go.Scatter(x=df_resultats.index,y=df_resultats['BTC_PRED_VAL'],line=dict(color='red', width=1),name=\"Validation\"))\n",
        "\n",
        "# Délimite la zone d'erreur\n",
        "fig.add_shape(type=\"line\",x0=index,y0=0,x1=index,y1=np.amax(df_resultats['BTC_ALL']),name=\"Zone d'erreur\")\n",
        "\n",
        "# Affiche les courbes\n",
        "fig.update_xaxes(rangeslider_visible=True)\n",
        "yaxis=dict(autorange = True,fixedrange= False)\n",
        "fig.update_yaxes(yaxis)\n",
        "fig.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V0eIXJrhADXV"
      },
      "source": [
        "**6.Synthèse des erreurs sur les différentes zones**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nP8wjWErADXV"
      },
      "source": [
        "# Echantillonage des données\n",
        "time = \"1H\"\n",
        "\n",
        "df_resultats = df_resultats.resample(time).asfreq()\n",
        "df_resultats"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fuofOZLJADXW"
      },
      "source": [
        "# Détection de la date où commencnte les anomalies\n",
        "# sur la période de validation\n",
        "\n",
        "# Construit les dataframe pour calculer les erreurs\n",
        "df_error_btc_ent = df_resultats[['BTC_ENT','BTC_PRED_ENT']].dropna()\n",
        "df_error_btc_val = df_resultats[['BTC_VAL','BTC_PRED_VAL']].dropna()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IAyfDmMLADXW"
      },
      "source": [
        "# Erreurs d'entrainement\n",
        "mae_ent = tf.keras.metrics.mean_absolute_error(np.asarray(df_error_btc_ent['BTC_ENT']),np.asarray(df_error_btc_ent['BTC_PRED_ENT'])).numpy()\n",
        "mse_ent = tf.keras.metrics.mean_squared_error(np.asarray(df_error_btc_ent['BTC_ENT']),np.asarray(df_error_btc_ent['BTC_PRED_ENT'])).numpy()\n",
        "mape_ent = tf.keras.metrics.mape(np.asarray(df_error_btc_ent['BTC_ENT']),np.asarray(df_error_btc_ent['BTC_PRED_ENT'])).numpy()\n",
        "\n",
        "# Erreurs de validation\n",
        "mae_val = tf.keras.metrics.mean_absolute_error(np.asarray(df_error_btc_val['BTC_VAL']),np.asarray(df_error_btc_val['BTC_PRED_VAL'])).numpy()\n",
        "mse_val = tf.keras.metrics.mean_squared_error(np.asarray(df_error_btc_val['BTC_VAL']),np.asarray(df_error_btc_val['BTC_PRED_VAL'])).numpy()\n",
        "mape_val = tf.keras.metrics.mape(np.asarray(df_error_btc_val['BTC_VAL']),np.asarray(df_error_btc_val['BTC_PRED_VAL'])).numpy()\n",
        "\n",
        "# Erreurs sur la zone valide de validation\n",
        "mae_val_ok = tf.keras.metrics.mean_absolute_error(df_error_btc_val['BTC_VAL'][:index],np.asarray(df_error_btc_val['BTC_PRED_VAL'][:index])).numpy()\n",
        "mse_val_ok = tf.keras.metrics.mean_squared_error(df_error_btc_val['BTC_VAL'][:index],np.asarray(df_error_btc_val['BTC_PRED_VAL'][:index])).numpy()\n",
        "mape_val_ok = tf.keras.metrics.mape(df_error_btc_val['BTC_VAL'][:index],np.asarray(df_error_btc_val['BTC_PRED_VAL'][:index])).numpy()\n",
        "\n",
        "\n",
        "print(\"Erreur mae entrainement %s\" %mae_ent)\n",
        "print(\"Erreur mse entrainement : %s\" %mse_ent)\n",
        "print(\"Erreur mape entrainement : %s\\n\" %mape_ent)\n",
        "\n",
        "print(\"Erreur mae validation %s\" %mae_val)\n",
        "print(\"Erreur mse validation : %s\" %mse_val)\n",
        "print(\"Erreur mape entrainement : %s\\n\" %mape_val)\n",
        "\n",
        "print(\"Erreur mae validation zone OK %s\" %mae_val_ok)\n",
        "print(\"Erreur mse validation zone OK: %s\" %mse_val_ok)\n",
        "print(\"Erreur mape validation zone OK: %s\" %mape_val_ok)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}