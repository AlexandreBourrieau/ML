{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "VariableSelection.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyM+6gIoznX4Qky1o+TmICIT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AlexandreBourrieau/ML/blob/main/Carnets%20Jupyter/RandomForest/VariableSelection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "je1rf58Xthhv"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import re\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_selection import RFECV\n",
        "from sklearn.preprocessing import MinMaxScaler, RobustScaler\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.pipeline import Pipeline\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "import tensorflow as tf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PDUENtEI_1pe"
      },
      "source": [
        "# Chargement des données"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4caNgF6R-MnT"
      },
      "source": [
        "!wget --no-check-certificate --content-disposition \"https://raw.githubusercontent.com/AlexandreBourrieau/ML/main/Carnets%20Jupyter/RandomForest/prostate.csv\"\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UAP4qAjOB2lo"
      },
      "source": [
        "Les données contiennent 102 observations de 6033 gènes. Dans cet ensemble, il y a 52 cancers sur les 102 patients :\n",
        " - 2 variables sont très importantes\n",
        " - Environ 20 variables sont de moyenne importance\n",
        " - Le reste des variables est de faible importance "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sI1KcYjB_gzg"
      },
      "source": [
        "df_data=pd.read_csv('prostate.csv')\n",
        "df_data = df_data.set_index(df_data['Unnamed: 0'])\n",
        "df_data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3MSE5gQoECgQ"
      },
      "source": [
        "# Random Forest - Choix des paramètres"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LPr5APL_ERLg"
      },
      "source": [
        "La caractérisation de l'importance des variables est cruciale. Cette caractéristique va dépendre :\n",
        " - Du ratio entre le nombre de variables p et le nombre d'observations n\n",
        " - Des paramètres définissant le modèle :\n",
        "    - Nombre d'arbres construits par l'algorithme (ntree)\n",
        "    - Nombre de variables testées à chaque division (mtry) \n",
        " - De la présence de variables fortements corrélées"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TuFF-dDpGBZn"
      },
      "source": [
        "**1. Choix du nombre d'arbres**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wg9FshnxGE5W"
      },
      "source": [
        "On choisit le nombre d'arbres en prenant comme valeur de mtry la racine carrée du nombre de variables, puis on teste plusieurs valeurs en évaluant comment réduit l'OOB en fonction du nombre d'arbres générés.  \n",
        "On choisit la valeur qui stabilise le minimum de l'erreur."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7lC9CWoHIuku"
      },
      "source": [
        "X = df_data.drop(columns='y')\n",
        "X = X.drop(columns='Unnamed: 0')\n",
        "X"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vHMwwooC-tiK"
      },
      "source": [
        "Y = df_data['y'].apply(lambda x: 1 if (x=='cancer') else 0)\n",
        "Y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6hzgaWaQPDgL"
      },
      "source": [
        "RandomForestClassifier :\n",
        "  - n_estimators : Nombre d'arbre dans la forêt (ntree)\n",
        "  - oob_score : Sauvegarde du score OOB\n",
        "  - max_samples : Nombre maximal d'observations à utiliser\n",
        "  - max_features : Nombre maximum de divisions (mtry)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yxDWIrdZGVUg"
      },
      "source": [
        "# Informations sur les données\n",
        "n = 102               # Nombre d'observations\n",
        "p = 6033              # Nombre de variables\n",
        "\n",
        "n_arbres_max = 5000\n",
        "\n",
        "n_arbres = np.linspace(1,n_arbres_max,10).astype(np.int32)\n",
        "mtry = np.sqrt(p).astype(np.int32)\n",
        "OOB_err = []\n",
        "\n",
        "for i in n_arbres:\n",
        "  print(\"#Arbres : %d\" %i)\n",
        "  clf = RandomForestClassifier(n_estimators=i, bootstrap=True, oob_score=True, max_samples = n, max_features = mtry, n_jobs=-1)\n",
        "  clf.fit(X,np.asarray(Y))\n",
        "  OOB_err.append(1 - clf.oob_score_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wFDj7jp9LP6l"
      },
      "source": [
        "plt.plot(n_arbres,OOB_err)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BFMk4we0O8DL"
      },
      "source": [
        "**2. Choix de mtry**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iX_nyT9KPXLS"
      },
      "source": [
        "Pour choisir la valeur de mtry, on fait tourner Random Forest 10 fois avec dix valeurs de mtry différentes, puis on choisit celle pour laquelle le mtry est minimal et se stabilise."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fgSPi5-SDHlI"
      },
      "source": [
        "# Informations sur les données\n",
        "n = 102               # Nombre d'observations\n",
        "p = 6033              # Nombre de variables\n",
        "\n",
        "n_arbres = 2000\n",
        "mtry_0 = (np.sqrt(p)/2).astype(np.int32)\n",
        "\n",
        "m_try = np.linspace(mtry_0,2000,10).astype(np.int32)\n",
        "\n",
        "OOB_err = []\n",
        "\n",
        "for i in m_try:\n",
        "   print(\"mtry = %s\" %i)\n",
        "   clf = RandomForestClassifier(n_estimators=n_arbres, bootstrap=True, oob_score=True, max_features=i, n_jobs=-1)\n",
        "   clf.fit(X,np.asarray(Y))\n",
        "   OOB_err.append(1 - clf.oob_score_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q4zbPtNvUZxp"
      },
      "source": [
        "plt.plot(m_try,OOB_err)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ISV9bD0NkwHz"
      },
      "source": [
        "On choisit m_try = 1000"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "18Yewap0k-xy"
      },
      "source": [
        "# Random Forest - Importance des variables"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kbTM8MyNRBkW"
      },
      "source": [
        "Permutation importance is a technique where we shuffle the values of a single column and run the model to see how the scores get affected. If the scores are affected greatly, then the feature is highly important to the model and if not, it does not add significant value to the model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TWWgAJVrSw2n"
      },
      "source": [
        "**1. Calcul de l'importance des variables avec la méthode Gini**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zhen475ZS-j5"
      },
      "source": [
        "from sklearn.inspection import permutation_importance\n",
        "\n",
        "# Informations sur les données\n",
        "n = 102               # Nombre d'observations\n",
        "p = 6033              # Nombre de variables\n",
        "n_arbres = 2000\n",
        "m_try = 2011\n",
        "\n",
        "clf = RandomForestClassifier(n_estimators=n_arbres, bootstrap=True, oob_score=True, max_features=m_try, n_jobs=-1)\n",
        "clf.fit(X,np.asarray(Y))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VSt6wd-pTCo-"
      },
      "source": [
        "col_sorted_by_importance=clf.feature_importances_.argsort()\n",
        "feat_imp = pd.DataFrame({'cols':X.columns[col_sorted_by_importance],'imps':clf.feature_importances_[col_sorted_by_importance]})\n",
        "feat_imp"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j15gF18lThYi"
      },
      "source": [
        "!pip install plotly_express --upgrade -q"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SxQ3rBWOTd5v"
      },
      "source": [
        "import plotly_express as px\n",
        "import plotly.offline as po\n",
        "\n",
        "px.bar(feat_imp.sort_values(['imps'], ascending=False)[:25], x='cols', y='imps', labels={'cols':'column', 'imps':'feature importance'})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QE6iO2y9QMkG"
      },
      "source": [
        "**2. Calcul de l'importance des variables avec la méthode des permutations**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FC8DxDbMRUJH"
      },
      "source": [
        "import random\n",
        "\n",
        "def PermImportance(X, y, clf, metric, num_iterations=100):\n",
        "    '''\n",
        "    Calculates the permutation importance of features in a dataset.\n",
        "    Inputs:\n",
        "    X: dataframe with all the features\n",
        "    y: array-like sequence of labels\n",
        "    clf: sklearn classifier, already trained on training data\n",
        "    metric: sklearn metric, such as accuracy_score, precision_score or recall_score\n",
        "    num_iterations: no. of repetitive runs of the permutation\n",
        "    Outputs:\n",
        "    baseline: the baseline metric without any of the columns permutated\n",
        "    scores: differences in baseline metric caused by permutation of each feature, dict in the format {feature:[diffs]}\n",
        "    '''\n",
        "    bar=progressbar.ProgressBar(max_value=len(X.columns))\n",
        "    baseline_metric=metric(y, clf.predict(X))\n",
        "    scores={c:[] for c in X.columns}\n",
        "    for c in X.columns:\n",
        "        X1=X.copy(deep=True)\n",
        "        for _ in range(num_iterations):\n",
        "            temp=X1[c].tolist()\n",
        "            random.shuffle(temp)\n",
        "            X1[c]=temp\n",
        "            score=metric(y, clf.predict(X1))\n",
        "            scores[c].append(baseline_metric-score)\n",
        "        bar.update(X.columns.tolist().index(c))\n",
        "    return baseline_metric, scores"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kPFn7WL-no-i"
      },
      "source": [
        "from sklearn.inspection import permutation_importance\n",
        "\n",
        "# Informations sur les données\n",
        "n = 102               # Nombre d'observations\n",
        "p = 6033              # Nombre de variables\n",
        "n_arbres = 2000\n",
        "m_try = 2011\n",
        "\n",
        "clf = RandomForestClassifier(n_estimators=n_arbres, bootstrap=True, oob_score=True, max_features=m_try, n_jobs=-1)\n",
        "clf.fit(X,np.asarray(Y))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EpBP4wn_RVZ3"
      },
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "import progressbar\n",
        "\n",
        "baseline, scores=PermImportance(X, np.asarray(Y), clf, recall_score, num_iterations=10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UFPyeWeI4vb6"
      },
      "source": [
        "X.transpose().index"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6pyeJeqWqz4w"
      },
      "source": [
        "fig, ax = plt.subplots()\n",
        "foret_importances[3:20].plot.bar(ax=ax)\n",
        "ax.set_title(\"Importances\")\n",
        "ax.set_ylabel(\"Mean decrease in impurity\")\n",
        "fig.tight_layout()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}