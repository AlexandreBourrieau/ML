{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled16.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOhEJFs8QUQk6/Kpeh6LRuP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AlexandreBourrieau/ML/blob/main/Wavenet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Calc_UEmd7t_"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.python.keras import initializers, activations, constraints, regularizers"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BwArqRyHeSl8"
      },
      "source": [
        "# Classes Dense3D, TemporalConv"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ExjytBM-eLBU"
      },
      "source": [
        "class Dense3D(tf.keras.layers.Layer):\n",
        "    def __init__(self, units,\n",
        "                 activation=None,\n",
        "                 kernel_initializer='glorot_uniform',\n",
        "                 kernel_regularizer=None,\n",
        "                 kernel_constraint=None,\n",
        "                 use_bias=True,\n",
        "                 bias_initializer=\"zeros\",\n",
        "                 trainable=True,\n",
        "                 name=None):\n",
        "        super(Dense3D, self).__init__(trainable=trainable, name=name)\n",
        "        self.units = units\n",
        "        self.activation = activations.get(activation)\n",
        "        self.kernel_initializer = initializers.get(kernel_initializer)\n",
        "        self.kernel_regularizer = regularizers.get(kernel_regularizer)\n",
        "        self.kernel_constraint = constraints.get(kernel_constraint)\n",
        "        self.use_bias = use_bias\n",
        "        self.bias_initializer = bias_initializer\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        inputs_units = int(input_shape[-1])  # input.get_shape().as_list()[-1]\n",
        "        self.kernel = self.add_weight('kernel',\n",
        "                                      shape=[inputs_units, self.units],\n",
        "                                      initializer=self.kernel_initializer,\n",
        "                                      regularizer=self.kernel_regularizer,\n",
        "                                      constraint=self.kernel_constraint,\n",
        "                                      dtype=tf.float32,\n",
        "                                      trainable=True)\n",
        "        if self.use_bias:\n",
        "            self.bias = self.add_weight(\"bias\",\n",
        "                                        shape=[self.units],\n",
        "                                        initializer=self.bias_initializer,\n",
        "                                        dtype=self.dtype,\n",
        "                                        trainable=True)\n",
        "        super(Dense3D, self).build(input_shape)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        output = tf.einsum('ijk,kl->ijl', inputs, self.kernel)\n",
        "\n",
        "        if self.use_bias:\n",
        "            output += self.bias\n",
        "\n",
        "        if self.activation is not None:\n",
        "            output = self.activation(output)\n",
        "        return output"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xrePLtAieRNm"
      },
      "source": [
        "class TemporalConv(tf.keras.layers.Layer):\n",
        "    \"\"\" Temporal convolutional layer\n",
        "\n",
        "    \"\"\"\n",
        "    def __init__(self, filters,\n",
        "                 kernel_size,\n",
        "                 strides=1,\n",
        "                 dilation_rate=1,\n",
        "                 activation=None,\n",
        "                 causal=True,\n",
        "                 kernel_initializer='glorot_uniform',\n",
        "                 name=None):\n",
        "        super(TemporalConv, self).__init__(name=name)\n",
        "        self.filters = filters\n",
        "        self.kernel_size = kernel_size\n",
        "        self.strides = strides\n",
        "        self.dilation_rate = dilation_rate\n",
        "        self.activation = activations.get(activation)\n",
        "        self.causal = causal\n",
        "        self.kernel_initializer = initializers.get(kernel_initializer)\n",
        "\n",
        "    def build(self, input_shape):  # Create the weights\n",
        "        self.conv = tf.keras.layers.Conv1D(kernel_size=self.kernel_size,\n",
        "                                           kernel_initializer=self.kernel_initializer,\n",
        "                                           filters=self.filters,\n",
        "                                           padding='valid',\n",
        "                                           dilation_rate=self.dilation_rate,\n",
        "                                           activation=self.activation)\n",
        "        super(TemporalConv, self).build(input_shape)\n",
        "\n",
        "    def call(self, input):\n",
        "        if self.causal:\n",
        "            padding_size = (self.kernel_size - 1) * self.dilation_rate\n",
        "            # padding: 1st dim is batch, so [0,0]; 2nd dim is time, so [padding_size, 0]; 3rd dim is feature [0,0]\n",
        "            input = tf.pad(input, [[0, 0], [padding_size, 0], [0, 0]])\n",
        "\n",
        "        output = self.conv(input)\n",
        "        return output"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "64fRlw7ZebQB"
      },
      "source": [
        "# Classe Wavenet"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VOmtNataep2r"
      },
      "source": [
        "**Encodeur**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TNDXfGRWeo3k"
      },
      "source": [
        "class Encoder(object):\n",
        "    def __init__(self, params):\n",
        "        self.params = params\n",
        "        self.conv_times = []\n",
        "        for i, (kernel_size, dilation) in enumerate(zip(self.params['kernel_sizes'], self.params['dilation_rates'])):\n",
        "            self.conv_times.append(TemporalConv(filters=2 * self.params['filters'],\n",
        "                                                kernel_size=kernel_size,\n",
        "                                                causal=True,\n",
        "                                                dilation_rate=dilation))\n",
        "        self.dense_time1 = Dense3D(units=self.params['filters'], activation='tanh', name='encoder_dense_time1')\n",
        "        self.dense_time2 = Dense3D(units=self.params['filters'] + self.params['filters'], name='encoder_dense_time2')\n",
        "        self.dense_time3 = Dense3D(units=self.params['dense_hidden_size'], activation='relu', name='encoder_dense_time3')\n",
        "        self.dense_time4 = Dense3D(units=1, name='encoder_dense_time_4')\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        :param x:\n",
        "        :return: conv_inputs [batch_size, time_sequence_length, filters] * time_sequence_length\n",
        "        \"\"\"\n",
        "        inputs = self.dense_time1(inputs=x)  # batch_size * time_sequence_length * filters\n",
        "\n",
        "        skip_outputs = []\n",
        "        conv_inputs = [inputs]\n",
        "        for conv_time in self.conv_times:\n",
        "            dilated_conv = conv_time(inputs)\n",
        "            conv_filter, conv_gate = tf.split(dilated_conv, 2, axis=2)\n",
        "            dilated_conv = tf.nn.tanh(conv_filter) * tf.nn.sigmoid(conv_gate)\n",
        "            outputs = self.dense_time2(inputs=dilated_conv)\n",
        "            skips, residuals = tf.split(outputs, [self.params['filters'], self.params['filters']], axis=2)\n",
        "            inputs += residuals\n",
        "            conv_inputs.append(inputs)  # batch_size * time_sequence_length * filters\n",
        "            skip_outputs.append(skips)\n",
        "\n",
        "        skip_outputs = tf.nn.relu(tf.concat(skip_outputs, axis=2))\n",
        "        h = self.dense_time3(skip_outputs)\n",
        "        y_hat = self.dense_time4(h)\n",
        "        return y_hat, conv_inputs[:-1]\n",
        "\n",
        "    def __call__(self, x):\n",
        "        return self.forward(x)"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2rP2WQa_esxb"
      },
      "source": [
        "**DÃ©codeur**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RDw9gPhQeupr"
      },
      "source": [
        "class Decoder(object):\n",
        "    \"\"\" Decoder need avoid future data leaks\n",
        "\n",
        "    \"\"\"\n",
        "    def __init__(self, params):\n",
        "        self.params = params\n",
        "        self.dense_1 = Dense(self.params['filters'], activation='tanh', name='decoder_dense_1')\n",
        "        self.dense_2 = Dense(2 * self.params['filters'], name='decoder_dense_2')\n",
        "        self.dense_3 = Dense(2 * self.params['filters'], use_bias=False, name='decoder_dense_3')\n",
        "        self.dense_4 = Dense(2 * self.params['filters'], name='decoder_dense_4')\n",
        "        self.dense_5 = Dense(self.params['dense_hidden_size'], activation='relu', name='decoder_dense_5')\n",
        "        self.dense_6 = Dense(1, name='decoder_dense_6')\n",
        "\n",
        "    def foward(self, x, decoder_feature, encoder_states, predict_seq_length, teacher):\n",
        "        decoder_init_value = x[:, -1, :]\n",
        "\n",
        "        def cond_fn(time, prev_output, decoder_output_ta):\n",
        "            return time < predict_seq_length\n",
        "\n",
        "        def body(time, prev_output, decoder_output_ta):\n",
        "            if time == 0 or teacher is None:\n",
        "                current_input = prev_output\n",
        "            else:\n",
        "                current_input = teacher[:, time - 1, :]\n",
        "\n",
        "            if decoder_feature is not None:\n",
        "                current_feature = decoder_feature[:, time, :]\n",
        "                current_input = tf.concat([current_input, current_feature], axis=1)\n",
        "\n",
        "            inputs = self.dense_1(current_input)\n",
        "\n",
        "            skip_outputs = []\n",
        "            for i, dilation in enumerate(self.params['dilation_rates']):\n",
        "                state = encoder_states[i][:, -dilation, :]\n",
        "\n",
        "                dilated_conv = self.dense_2(state) + self.dense_3(inputs)\n",
        "                conv_filter, conv_gate = tf.split(dilated_conv, 2, axis=1)\n",
        "                dilated_conv = tf.nn.tanh(conv_filter) * tf.nn.sigmoid(conv_gate)\n",
        "                outputs = self.dense_4(dilated_conv)\n",
        "                skips, residuals = tf.split(outputs, [self.params['filters'], self.params['filters']], axis=1)\n",
        "                inputs += residuals\n",
        "                encoder_states[i] = tf.concat([encoder_states[i], tf.expand_dims(inputs, 1)], axis=1)\n",
        "                skip_outputs.append(skips)\n",
        "\n",
        "            skip_outputs = tf.nn.relu(tf.concat(skip_outputs, axis=1))\n",
        "            h = self.dense_5(skip_outputs)\n",
        "            y_hat = self.dense_6(h)\n",
        "            decoder_output_ta = decoder_output_ta.write(time, y_hat)\n",
        "            return time + 1, y_hat, decoder_output_ta\n",
        "\n",
        "#        loop_init = [tf.constant(0, dtype=tf.int32),decoder_init_value,tf.TensorArray(dtype=tf.float32, size=predict_seq_length)]\n",
        "\n",
        "        for time in range(0,predict_seq_length):\n",
        "          _, _, decoder_outputs_ta = body(time,decoder_init_value,tf.TensorArray(dtype=tf.float32, size=predict_seq_length))\n",
        "\n",
        "#        _, _, decoder_outputs_ta = tf.while_loop(cond=cond_fn, body=body, loop_vars=loop_init)\n",
        "        decoder_outputs = decoder_outputs_ta.stack()\n",
        "        decoder_outputs = tf.transpose(decoder_outputs, [1, 0, 2])\n",
        "        return decoder_outputs\n",
        "\n",
        "    def __call__(self, x, decoder_feature, encoder_states, predict_seq_length, teacher=None):\n",
        "        return self.foward(x,decoder_feature,encoder_states,predict_seq_length=predict_seq_length,teacher=teacher)"
      ],
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3FY3KQTQeztj"
      },
      "source": [
        "**Wavenet**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pLzZnfbueeDD"
      },
      "source": [
        "params = {\n",
        "    'dilation_rates': [2 ** i for i in range(4)],\n",
        "    'kernel_sizes': [2 for i in range(4)],\n",
        "    'filters': 128,\n",
        "    'dense_hidden_size': 64\n",
        "}\n",
        "\n",
        "class WaveNet(object):\n",
        "    \"\"\"WaveNet network\n",
        "\n",
        "    \"\"\"\n",
        "    def __init__(self, custom_model_params={}, dynamic_decoding=True):\n",
        "        params.update(custom_model_params)\n",
        "        self.encoder = Encoder(params)\n",
        "        self.decoder = Decoder(params)\n",
        "\n",
        "    def __call__(self, inputs, training, predict_seq_length, teacher=None):\n",
        "        if isinstance(inputs, tuple):\n",
        "            x, encoder_feature, decoder_feature = inputs\n",
        "            encoder_feature = tf.concat([x, encoder_feature], axis=-1)\n",
        "        else:  # for single variable prediction\n",
        "            encoder_feature = x = inputs\n",
        "            decoder_feature = None\n",
        "\n",
        "        encoder_output, encoder_states = self.encoder(encoder_feature)\n",
        "        decoder_output = self.decoder(x,decoder_feature,encoder_states=encoder_states,predict_seq_length=predict_seq_length,teacher=teacher)\n",
        "        return decoder_output"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F9lUIAxIe5C8"
      },
      "source": [
        "# Utilisation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TgopO-Cllckf",
        "outputId": "a4e2b96b-910e-4d3d-9246-d38ca635180e"
      },
      "source": [
        "%tensorflow_version 1.x"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow is already loaded. Please restart the runtime to change versions.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vt426ngllrCa",
        "outputId": "b5228c82-58a8-4919-af40-9b7f482db6fb"
      },
      "source": [
        "!pip install --upgrade keras"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already up-to-date: keras in /usr/local/lib/python3.7/dist-packages (2.4.3)\n",
            "Requirement already satisfied, skipping upgrade: numpy>=1.9.1 in /usr/local/lib/python3.7/dist-packages (from keras) (1.19.5)\n",
            "Requirement already satisfied, skipping upgrade: scipy>=0.14 in /usr/local/lib/python3.7/dist-packages (from keras) (1.4.1)\n",
            "Requirement already satisfied, skipping upgrade: pyyaml in /usr/local/lib/python3.7/dist-packages (from keras) (3.13)\n",
            "Requirement already satisfied, skipping upgrade: h5py in /usr/local/lib/python3.7/dist-packages (from keras) (2.10.0)\n",
            "Requirement already satisfied, skipping upgrade: six in /usr/local/lib/python3.7/dist-packages (from h5py->keras) (1.15.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "8yf6R2q5fDO5",
        "outputId": "86e99d7d-664d-47b8-f1c7-9f3c59334b9c"
      },
      "source": [
        "input_seq_length = 100\n",
        "output_seq_length = 1\n",
        "\n",
        "Model = WaveNet()\n",
        "inputs = tf.keras.layers.Input([input_seq_length, 1])\n",
        "outputs = Model(inputs, training=True, predict_seq_length=output_seq_length)"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-59-7dad22dc2693>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mModel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mWaveNet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minput_seq_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredict_seq_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_seq_length\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-41-80dc1c7b22e4>\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, training, predict_seq_length, teacher)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0mencoder_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder_feature\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m         \u001b[0mdecoder_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdecoder_feature\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mencoder_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoder_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpredict_seq_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpredict_seq_length\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mteacher\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mteacher\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdecoder_output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-58-bcb3a36908e3>\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, x, decoder_feature, encoder_states, predict_seq_length, teacher)\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_feature\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredict_seq_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mteacher\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfoward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdecoder_feature\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mencoder_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpredict_seq_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpredict_seq_length\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mteacher\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mteacher\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-58-bcb3a36908e3>\u001b[0m in \u001b[0;36mfoward\u001b[0;34m(self, x, decoder_feature, encoder_states, predict_seq_length, teacher)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtime\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpredict_seq_length\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m           \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_outputs_ta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdecoder_init_value\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensorArray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpredict_seq_length\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;31m#        _, _, decoder_outputs_ta = tf.while_loop(cond=cond_fn, body=body, loop_vars=loop_init)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-58-bcb3a36908e3>\u001b[0m in \u001b[0;36mbody\u001b[0;34m(time, prev_output, decoder_output_ta)\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdense_5\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mskip_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m             \u001b[0my_hat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdense_6\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m             \u001b[0mdecoder_output_ta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecoder_output_ta\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_hat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mtime\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_hat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_output_ta\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/tf_should_use.py\u001b[0m in \u001b[0;36mwrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    245\u001b[0m     \u001b[0;34m\"\"\"Decorates the input function.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 247\u001b[0;31m       return _add_should_use_warning(fn(*args, **kwargs),\n\u001b[0m\u001b[1;32m    248\u001b[0m                                      \u001b[0mwarn_in_eager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwarn_in_eager\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m                                      error_in_function=error_in_function)\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/tensor_array_ops.py\u001b[0m in \u001b[0;36mwrite\u001b[0;34m(self, index, value, name)\u001b[0m\n\u001b[1;32m   1157\u001b[0m       \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mthere\u001b[0m \u001b[0mare\u001b[0m \u001b[0mmore\u001b[0m \u001b[0mwriters\u001b[0m \u001b[0mthan\u001b[0m \u001b[0mspecified\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1158\u001b[0m     \"\"\"\n\u001b[0;32m-> 1159\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_implementation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1160\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1161\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/tensor_array_ops.py\u001b[0m in \u001b[0;36mwrite\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    832\u001b[0m     \u001b[0;34m\"\"\"See TensorArray.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    833\u001b[0m     \u001b[0;32mdel\u001b[0m \u001b[0mname\u001b[0m  \u001b[0;31m# not meaningful when executing eagerly.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 834\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_write\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    835\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    836\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/tensor_array_ops.py\u001b[0m in \u001b[0;36m_write\u001b[0;34m(self, index, value)\u001b[0m\n\u001b[1;32m    812\u001b[0m       \u001b[0;31m# TODO(b/129870929): Fix after all callers provide proper init dtype.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    813\u001b[0m       value = ops.convert_to_tensor(\n\u001b[0;32m--> 814\u001b[0;31m           value, preferred_dtype=self._dtype, name=\"value\")\n\u001b[0m\u001b[1;32m    815\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    816\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dtype\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/profiler/trace.py\u001b[0m in \u001b[0;36mwrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    161\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrace_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mtrace_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m           \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)\u001b[0m\n\u001b[1;32m   1538\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1539\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1540\u001b[0;31m       \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconversion_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mas_ref\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1541\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1542\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNotImplemented\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36m_constant_tensor_conversion_function\u001b[0;34m(v, dtype, name, as_ref)\u001b[0m\n\u001b[1;32m    337\u001b[0m                                          as_ref=False):\n\u001b[1;32m    338\u001b[0m   \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 339\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    340\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconstant\u001b[0;34m(value, dtype, shape, name)\u001b[0m\n\u001b[1;32m    263\u001b[0m   \"\"\"\n\u001b[1;32m    264\u001b[0m   return _constant_impl(value, dtype, shape, name, verify_shape=False,\n\u001b[0;32m--> 265\u001b[0;31m                         allow_broadcast=True)\n\u001b[0m\u001b[1;32m    266\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36m_constant_impl\u001b[0;34m(value, dtype, shape, name, verify_shape, allow_broadcast)\u001b[0m\n\u001b[1;32m    274\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"tf.constant\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_constant_eager_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverify_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 276\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_constant_eager_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverify_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    277\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m   \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_default_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36m_constant_eager_impl\u001b[0;34m(ctx, value, dtype, shape, verify_shape)\u001b[0m\n\u001b[1;32m    299\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_constant_eager_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverify_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    300\u001b[0m   \u001b[0;34m\"\"\"Implementation of eager constant.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 301\u001b[0;31m   \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_to_eager_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    302\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mshape\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    303\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconvert_to_eager_tensor\u001b[0;34m(value, ctx, dtype)\u001b[0m\n\u001b[1;32m     96\u001b[0m       \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_datatype_enum\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m   \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEagerTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/keras_tensor.py\u001b[0m in \u001b[0;36m__array__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    272\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__array__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m     raise TypeError(\n\u001b[0;32m--> 274\u001b[0;31m         \u001b[0;34m'Cannot convert a symbolic Keras input/output to a numpy array. '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    275\u001b[0m         \u001b[0;34m'This error may indicate that you\\'re trying to pass a symbolic value '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m         \u001b[0;34m'to a NumPy call, which is not supported. Or, '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: Cannot convert a symbolic Keras input/output to a numpy array. This error may indicate that you're trying to pass a symbolic value to a NumPy call, which is not supported. Or, you may be trying to pass Keras symbolic inputs/outputs to a TF API that does not register dispatching, preventing Keras from automatically converting the API call to a lambda layer in the Functional Model."
          ]
        }
      ]
    }
  ]
}